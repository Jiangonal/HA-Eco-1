{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075547f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/conda-envs/bertopic_py3.10/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0463c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/bertopic_py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\") # set your huggingface token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588c6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d069a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Llama2-7b'\n",
    "MODEL_FullName = 'meta-llama/Llama-2-7b-chat-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ce9ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/bertopic_py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import bfloat16\n",
    "import transformers\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit quantization\n",
    "    bnb_4bit_quant_type='nf4',  # Normalized float 4\n",
    "    bnb_4bit_use_double_quant=True,  # Second quantization after the first\n",
    "    bnb_4bit_compute_dtype=bfloat16  # Computation type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07c7ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import bfloat16\n",
    "import transformers\n",
    "# Llama 3 Tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Llama 3 Model\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",  # This will ensure the model is loaded to GPU\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857f5ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Our text generator\n",
    "generator = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=500,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9524cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "df= pd.read_csv('pull_requests_filtered_raw.csv')\n",
    "df['comments'] = df['comments'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "df['review_comments'] = df['comments'].apply(lambda comments: [item for item in comments if item['type'] != 'issue'] if type(comments) is not float else comments)\n",
    "df = df[df['review_comments'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "df['issue_comments'] = df['comments'].apply(lambda comments: [item for item in comments if item['type'] != 'review'] if type(comments) is not float else comments)\n",
    "df = df[df['issue_comments'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84c9ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'review',\n",
       "  'diff_hunk': '@@ -276,6 +276,18 @@\\n         \"hostname\": \"polisy*\",\\n         \"macaddress\": \"000DB9*\",\\n     },\\n+    {\\n+        \"domain\": \"lamarzocco\",\\n+        \"hostname\": \"gs[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]\",',\n",
       "  'comment': {'id': 1826864432,\n",
       "   'timestamp': '2024-11-02T22:28:28Z',\n",
       "   'body': '```suggestion\\r\\n        \"hostname\": \"gs[0-9]{6}\",\\r\\n```',\n",
       "   'is_from_author': False},\n",
       "  'replies': [{'id': 1826909573,\n",
       "    'timestamp': '2024-11-03T05:51:17Z',\n",
       "    'body': \"This are glob pattern not regexes, so the {6} doesn't work afaik. The [0-9] appears to be fine though. \",\n",
       "    'is_from_author': True}]},\n",
       " {'type': 'review',\n",
       "  'diff_hunk': '@@ -276,6 +276,18 @@\\n         \"hostname\": \"polisy*\",\\n         \"macaddress\": \"000DB9*\",\\n     },\\n+    {\\n+        \"domain\": \"lamarzocco\",\\n+        \"hostname\": \"gs[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]\",\\n+    },\\n+    {\\n+        \"domain\": \"lamarzocco\",\\n+        \"hostname\": \"lm[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]\",',\n",
       "  'comment': {'id': 1826864496,\n",
       "   'timestamp': '2024-11-02T22:28:58Z',\n",
       "   'body': '```suggestion\\r\\n        \"hostname\": \"lm[0-9]{6}\",\\r\\n```',\n",
       "   'is_from_author': False},\n",
       "  'replies': []},\n",
       " {'type': 'review',\n",
       "  'diff_hunk': '@@ -276,6 +276,18 @@\\n         \"hostname\": \"polisy*\",\\n         \"macaddress\": \"000DB9*\",\\n     },\\n+    {\\n+        \"domain\": \"lamarzocco\",\\n+        \"hostname\": \"gs[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]\",\\n+    },\\n+    {\\n+        \"domain\": \"lamarzocco\",\\n+        \"hostname\": \"lm[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]\",\\n+    },\\n+    {\\n+        \"domain\": \"lamarzocco\",\\n+        \"hostname\": \"mr[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]\",',\n",
       "  'comment': {'id': 1826864514,\n",
       "   'timestamp': '2024-11-02T22:29:22Z',\n",
       "   'body': '```suggestion\\r\\n        \"hostname\": \"mr[0-9]{6}\",\\r\\n```',\n",
       "   'is_from_author': False},\n",
       "  'replies': []},\n",
       " {'type': 'review',\n",
       "  'diff_hunk': '@@ -435,6 +441,46 @@ async def test_bluetooth_discovery_errors(\\n     }\\n \\n \\n+async def test_dhcp_discovery(\\n+    hass: HomeAssistant,\\n+    mock_lamarzocco: MagicMock,\\n+    mock_cloud_client: MagicMock,\\n+    mock_device_info: LaMarzoccoDeviceInfo,\\n+) -> None:\\n+    \"\"\"Test dhcp discovery.\"\"\"\\n+\\n+    result = await hass.config_entries.flow.async_init(\\n+        DOMAIN,\\n+        context={\"source\": SOURCE_DHCP},\\n+        data=DhcpServiceInfo(\\n+            ip=\"192.168.1.42\",\\n+            hostname=mock_lamarzocco.serial_number,',\n",
       "  'comment': {'id': 1826864824,\n",
       "   'timestamp': '2024-11-02T22:31:31Z',\n",
       "   'body': 'May be parametrize some hostnames to make sure all regex expressions are tested.',\n",
       "   'is_from_author': False},\n",
       "  'replies': [{'id': 1826909997,\n",
       "    'timestamp': '2024-11-03T05:55:26Z',\n",
       "    'body': \"I don't understand? I mean we are not evaluating the glob patterns here anyways, so we are just passing through the strings here. \",\n",
       "    'is_from_author': True},\n",
       "   {'id': 1826923728,\n",
       "    'timestamp': '2024-11-03T07:51:35Z',\n",
       "    'body': \"It's not a bad idea though (added it)\",\n",
       "    'is_from_author': True}]},\n",
       " {'type': 'issue',\n",
       "  'comment': {'id': 2453342814,\n",
       "   'type': 'issue',\n",
       "   'timestamp': '2024-11-03T09:30:30Z',\n",
       "   'body': 'Do we need a docs PR here?',\n",
       "   'is_from_author': False}},\n",
       " {'type': 'issue',\n",
       "  'comment': {'id': 2453345628,\n",
       "   'type': 'issue',\n",
       "   'timestamp': '2024-11-03T09:42:22Z',\n",
       "   'body': '> Do we need a docs PR here?\\r\\n\\r\\nI added a note to docs.',\n",
       "   'is_from_author': True}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(df['comments'].tolist()[1]))\n",
    "# df['comments'].tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8c7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This are glob pattern not regexes, so the {6} doesn't work afaik. The [0-9] appears to be fine though. \", 'May be parametrize some hostnames to make sure all regex expressions are tested.', \"I don't understand? I mean we are not evaluating the glob patterns here anyways, so we are just passing through the strings here. \", \"It's not a bad idea though (added it)\"]\n",
      "['Do we need a docs PR here?', '> Do we need a docs PR here?\\r\\n\\r\\nI added a note to docs.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "\n",
    "    pattern = r\"```.*?```|http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    return re.sub(pattern, lambda m: \"\" if m.group(0).startswith(\"```\") else \"\", text, flags=re.DOTALL)\n",
    "\n",
    "def extract_text(comment_thread):\n",
    "    \n",
    "    conversation = []\n",
    "    for comment in comment_thread:\n",
    "        main_comment = clean_text(comment.get('comment', {}).get('body', ''))\n",
    "        \n",
    "        # Extract replies' bodies\n",
    "        replies = comment.get('replies', [])\n",
    "        reply_bodies = [reply.get('body', '') for reply in replies]\n",
    "\n",
    "        if main_comment:\n",
    "            conversation.append(main_comment)\n",
    "\n",
    "        for r in reply_bodies:\n",
    "            cleaned_reply = clean_text(r)  # Apply regex cleaning\n",
    "            if cleaned_reply.strip():  # Ensure we don't add empty strings\n",
    "                conversation.append(cleaned_reply)\n",
    "            \n",
    "    return conversation\n",
    "# Apply the function to extract text from the comments column\n",
    "df['processed_comments_review'] = df['review_comments'].apply(extract_text)\n",
    "print(df['processed_comments_review'].iloc[1])\n",
    "df['processed_comments_issue'] = df['issue_comments'].apply(extract_text)\n",
    "print(df['processed_comments_issue'].iloc[1])\n",
    "\n",
    "# extract_text(df['review_comments'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f0a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR Number</th>\n",
       "      <th>processed_comments_review</th>\n",
       "      <th>processed_comments_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129755</td>\n",
       "      <td>[Tests are missing., Waiting on an intents bum...</td>\n",
       "      <td>[Why is this added to the November release mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129675</td>\n",
       "      <td>[This are glob pattern not regexes, so the {6}...</td>\n",
       "      <td>[Do we need a docs PR here?, &gt; Do we need a do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129299</td>\n",
       "      <td>[Please reduce to one platform #home-assistant...</td>\n",
       "      <td>[I made the single PR for the whole lg_thinq i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129232</td>\n",
       "      <td>[I think a few of these are bugfixes that shou...</td>\n",
       "      <td>[There are quite a few tests which does a reau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129088</td>\n",
       "      <td>[This can now be moved to a constant at the to...</td>\n",
       "      <td>[@epenet What's the advantage of `suggested_va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PR Number                          processed_comments_review  \\\n",
       "0     129755  [Tests are missing., Waiting on an intents bum...   \n",
       "1     129675  [This are glob pattern not regexes, so the {6}...   \n",
       "2     129299  [Please reduce to one platform #home-assistant...   \n",
       "3     129232  [I think a few of these are bugfixes that shou...   \n",
       "4     129088  [This can now be moved to a constant at the to...   \n",
       "\n",
       "                            processed_comments_issue  \n",
       "0  [Why is this added to the November release mil...  \n",
       "1  [Do we need a docs PR here?, > Do we need a do...  \n",
       "2  [I made the single PR for the whole lg_thinq i...  \n",
       "3  [There are quite a few tests which does a reau...  \n",
       "4  [@epenet What's the advantage of `suggested_va...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['PR Number', 'processed_comments_review', 'processed_comments_issue']].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43d77e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the list of strings to a single string, and truncate it\n",
    "df['processed_comments_review'] = df['processed_comments_review'].apply(lambda x: ' '.join(x)[:2000])\n",
    "df['processed_comments_issue'] = df['processed_comments_issue'].apply(lambda x: ' '.join(x)[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c0df89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This are glob pattern not regexes, so the {6} doesn't work afaik. The [0-9] appears to be fine though.  May be parametrize some hostnames to make sure all regex expressions are tested. I don't understand? I mean we are not evaluating the glob patterns here anyways, so we are just passing through the strings here.  It's not a bad idea though (added it)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['processed_comments_review'].tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1bb933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, TextGeneration\n",
    "# KeyBERT\n",
    "keybert_model = KeyBERTInspired()\n",
    "\n",
    "\n",
    "# MMR\n",
    "mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "\n",
    "# System prompt describes information given to all conversations\n",
    "system_prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics.\n",
    "<</SYS>>\n",
    "\"\"\"\n",
    "main_prompt = \"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = \"\"\"\n",
    "I have a topic that contains the following documents:\n",
    "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
    "- Meat, but especially beef, is the word food in terms of emissions.\n",
    "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
    "\n",
    "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "\n",
    "[/INST] Environmental impacts of eating meat\n",
    "\"\"\"\n",
    "\n",
    "prompt = system_prompt+ example_prompt + main_prompt\n",
    "\n",
    "\n",
    "llama2 = TextGeneration(generator, prompt=prompt)\n",
    "representation_model = {\n",
    "    \"Llama2\": llama2,\n",
    "    \"MMR\": mmr_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0dd7ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 106/106 [00:06<00:00, 17.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "df['processed_comments_review'] = df['processed_comments_review'].apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "# df['processed_comments_issue'] = df['processed_comments_issue'].apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "embeddings_30k = embedding_model.encode(df['processed_comments_review'].tolist(), show_progress_bar=True)\n",
    "# embeddings_issue = embedding_model.encode(df['processed_comments_issue'].tolist(), show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "425b4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "umap_model_30k = UMAP(n_neighbors=5, n_components=4, min_dist=0., metric='cosine', random_state=42)\n",
    "hdbscan_model_30k = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e44e80ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 21:48:19,817 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-02-02 21:48:32,079 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-02-02 21:48:32,082 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-02-02 21:48:32,211 - BERTopic - Cluster - Completed ✓\n",
      "2025-02-02 21:48:32,214 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "100%|██████████| 150/150 [02:20<00:00,  1.06it/s]\n",
      "2025-02-02 21:50:57,468 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 6, 5, -1, 52, 22, 15, 36, -1, 140]\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import nltk\n",
    "from bertopic.vectorizers import ClassTfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "topic_model_30k = BERTopic(\n",
    "\n",
    "  # Sub-models\n",
    "  embedding_model=embedding_model,\n",
    "  umap_model=umap_model_30k,\n",
    "  hdbscan_model=hdbscan_model_30k,\n",
    "  vectorizer_model=vectorizer_model,\n",
    "  ctfidf_model=ctfidf_model,\n",
    "  representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "topics_30k, probs_30k = topic_model_30k.fit_transform(df['processed_comments_review'].tolist(), embeddings_30k)\n",
    "# topics_issue, probs_issue = topic_model_30k.fit_transform(df['processed_comments_review'].tolist(), embeddings_issue)\n",
    "\n",
    "print(topics_30k[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f76f502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Llama2</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1_use_don_need_sensor</td>\n",
       "      <td>[use, don, need, sensor, add, state, think, ju...</td>\n",
       "      <td>[Environmental Impacts of Eating Meat, , , , ,...</td>\n",
       "      <td>[use, sensor, state, device, pr, code, config,...</td>\n",
       "      <td>[There is no need to store the entry data, as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0_climate_mode_hvac_temperature</td>\n",
       "      <td>[climate, mode, hvac, temperature, modes, fan,...</td>\n",
       "      <td>[Climate Control Entity Integration, , , , , ,...</td>\n",
       "      <td>[climate, hvac, modes, heating, entity, thermo...</td>\n",
       "      <td>[You shouldn't name your entities, but follow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1____</td>\n",
       "      <td>[, , , , , , , , , ]</td>\n",
       "      <td>[Sustainable Food Systems, , , , , , , , , ]</td>\n",
       "      <td>[, , , , , , , , , , , , , , , , , , , , , , ,...</td>\n",
       "      <td>[, , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2_translation_translations_json_language</td>\n",
       "      <td>[translation, translations, json, language, ke...</td>\n",
       "      <td>[Home Assistant Language Configuration, , , , ...</td>\n",
       "      <td>[translation, keys, holidays, markdown, get_op...</td>\n",
       "      <td>[Can the default language use the home assista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>3_datetime_time_timestamp_date</td>\n",
       "      <td>[datetime, time, timestamp, date, profile, upt...</td>\n",
       "      <td>[Uptime and Timestamp, , , , , , , , , ]</td>\n",
       "      <td>[datetime, timestamp, uptime, img, src, timer,...</td>\n",
       "      <td>[With the new naming system we don't need a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>144</td>\n",
       "      <td>5</td>\n",
       "      <td>144_binary_smarttubsensor_wall_e2</td>\n",
       "      <td>[binary, smarttubsensor, wall, e2, warming, ou...</td>\n",
       "      <td>[Environmental Impacts of Eating Meat, , , , ,...</td>\n",
       "      <td>[smarttubsensor, e2, sensors, enocean, binary_...</td>\n",
       "      <td>[\\r\\nEnglish is weird #:~:text=pronunciation%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>145_color_colormode_white_hue</td>\n",
       "      <td>[color, colormode, white, hue, mode, saturatio...</td>\n",
       "      <td>[Color Mode Management for Smart Lighting, , ,...</td>\n",
       "      <td>[color, colormode, hue, saturation, ios, modes...</td>\n",
       "      <td>[This is copying the condition from the `hs_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>146</td>\n",
       "      <td>5</td>\n",
       "      <td>146_attrgetter_differential_significant_change...</td>\n",
       "      <td>[attrgetter, differential, significant_change,...</td>\n",
       "      <td>[Energy Metrics and Significant Changes, , , ,...</td>\n",
       "      <td>[attrgetter, significant_change, delta, operat...</td>\n",
       "      <td>[Taking the difference between two constants g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>147</td>\n",
       "      <td>5</td>\n",
       "      <td>147_id_unique_id_unique_hostname</td>\n",
       "      <td>[id, unique_id, unique, hostname, host, zones,...</td>\n",
       "      <td>[Label: RemoteIO Integration Issues, , , , , ,...</td>\n",
       "      <td>[unique_id, hostname, zones, config, key_, asy...</td>\n",
       "      <td>[You can remove these lines (they are empty) i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "      <td>148_distance_constant_docker_supervisor</td>\n",
       "      <td>[distance, constant, docker, supervisor, state...</td>\n",
       "      <td>[HA Measurement Standards and Best Practices, ...</td>\n",
       "      <td>[distance, docker, supervisor, state_class_mea...</td>\n",
       "      <td>[If we only use the constant in one place the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name  \\\n",
       "0       -1   1000                             -1_use_don_need_sensor   \n",
       "1        0    121                    0_climate_mode_hvac_temperature   \n",
       "2        1     64                                              1____   \n",
       "3        2     48           2_translation_translations_json_language   \n",
       "4        3     47                     3_datetime_time_timestamp_date   \n",
       "..     ...    ...                                                ...   \n",
       "145    144      5                  144_binary_smarttubsensor_wall_e2   \n",
       "146    145      5                      145_color_colormode_white_hue   \n",
       "147    146      5  146_attrgetter_differential_significant_change...   \n",
       "148    147      5                   147_id_unique_id_unique_hostname   \n",
       "149    148      5            148_distance_constant_docker_supervisor   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [use, don, need, sensor, add, state, think, ju...   \n",
       "1    [climate, mode, hvac, temperature, modes, fan,...   \n",
       "2                                 [, , , , , , , , , ]   \n",
       "3    [translation, translations, json, language, ke...   \n",
       "4    [datetime, time, timestamp, date, profile, upt...   \n",
       "..                                                 ...   \n",
       "145  [binary, smarttubsensor, wall, e2, warming, ou...   \n",
       "146  [color, colormode, white, hue, mode, saturatio...   \n",
       "147  [attrgetter, differential, significant_change,...   \n",
       "148  [id, unique_id, unique, hostname, host, zones,...   \n",
       "149  [distance, constant, docker, supervisor, state...   \n",
       "\n",
       "                                                Llama2  \\\n",
       "0    [Environmental Impacts of Eating Meat, , , , ,...   \n",
       "1    [Climate Control Entity Integration, , , , , ,...   \n",
       "2         [Sustainable Food Systems, , , , , , , , , ]   \n",
       "3    [Home Assistant Language Configuration, , , , ...   \n",
       "4             [Uptime and Timestamp, , , , , , , , , ]   \n",
       "..                                                 ...   \n",
       "145  [Environmental Impacts of Eating Meat, , , , ,...   \n",
       "146  [Color Mode Management for Smart Lighting, , ,...   \n",
       "147  [Energy Metrics and Significant Changes, , , ,...   \n",
       "148  [Label: RemoteIO Integration Issues, , , , , ,...   \n",
       "149  [HA Measurement Standards and Best Practices, ...   \n",
       "\n",
       "                                                   MMR  \\\n",
       "0    [use, sensor, state, device, pr, code, config,...   \n",
       "1    [climate, hvac, modes, heating, entity, thermo...   \n",
       "2    [, , , , , , , , , , , , , , , , , , , , , , ,...   \n",
       "3    [translation, keys, holidays, markdown, get_op...   \n",
       "4    [datetime, timestamp, uptime, img, src, timer,...   \n",
       "..                                                 ...   \n",
       "145  [smarttubsensor, e2, sensors, enocean, binary_...   \n",
       "146  [color, colormode, hue, saturation, ios, modes...   \n",
       "147  [attrgetter, significant_change, delta, operat...   \n",
       "148  [unique_id, hostname, zones, config, key_, asy...   \n",
       "149  [distance, docker, supervisor, state_class_mea...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [There is no need to store the entry data, as ...  \n",
       "1    [You shouldn't name your entities, but follow ...  \n",
       "2                                               [, , ]  \n",
       "3    [Can the default language use the home assista...  \n",
       "4    [With the new naming system we don't need a de...  \n",
       "..                                                 ...  \n",
       "145  [\\r\\nEnglish is weird #:~:text=pronunciation%2...  \n",
       "146  [This is copying the condition from the `hs_co...  \n",
       "147  [Taking the difference between two constants g...  \n",
       "148  [You can remove these lines (they are empty) i...  \n",
       "149  [If we only use the constant in one place the ...  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "if False:\n",
    "    df = pd.DataFrame(topic_model_30k.get_topic_info())\n",
    "    df.to_csv('bertopic_output_30k.csv', index=False)\n",
    "    \n",
    "# Show topics\n",
    "topic_model_30k.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9840ce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR Number</th>\n",
       "      <th>processed_comments_review</th>\n",
       "      <th>processed_comments_issue</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129755</td>\n",
       "      <td>Tests are missing. Waiting on an intents bump ...</td>\n",
       "      <td>Why is this added to the November release mile...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129675</td>\n",
       "      <td>This are glob pattern not regexes, so the {6} ...</td>\n",
       "      <td>Do we need a docs PR here? &gt; Do we need a docs...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129299</td>\n",
       "      <td>Please reduce to one platform #home-assistant-...</td>\n",
       "      <td>I made the single PR for the whole lg_thinq in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129232</td>\n",
       "      <td>I think a few of these are bugfixes that shoul...</td>\n",
       "      <td>There are quite a few tests which does a reaut...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129088</td>\n",
       "      <td>This can now be moved to a constant at the top...</td>\n",
       "      <td>@epenet What's the advantage of `suggested_val...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128984</td>\n",
       "      <td>Can we let this function return a list instead...</td>\n",
       "      <td>I'll add more tests once I get some feedback o...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128947</td>\n",
       "      <td></td>\n",
       "      <td>drafting for one more lib bump since the CO2 m...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128942</td>\n",
       "      <td>We normally only want to import from the integ...</td>\n",
       "      <td>Your force push overwrote my commit. &gt; Your fo...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128919</td>\n",
       "      <td>let's make the domain `music_assistant` Hah, I...</td>\n",
       "      <td>Small note: the coverage for config_flow.py do...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128909</td>\n",
       "      <td>Are both of these exceptions realistic? When s...</td>\n",
       "      <td>&gt; Also, I am now wondering, does `nest` suppor...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128870</td>\n",
       "      <td>Is this a real value? You probably use Twitch ...</td>\n",
       "      <td>Added tier to tests.  Tests do not currently p...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128856</td>\n",
       "      <td>Please use the migrate function for this `asyn...</td>\n",
       "      <td>Nice work @bouwew</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128794</td>\n",
       "      <td>Please use `SnapshotAssertion` in diagnostic t...</td>\n",
       "      <td>You can exclude those keys in the snapshot</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128789</td>\n",
       "      <td>Hi there @vingerha 👋 \\r\\n\\r\\nWe do not allow i...</td>\n",
       "      <td>@exxamalte quite a while ago I asked if reduci...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128547</td>\n",
       "      <td>Why didn't we implement the water_heater platf...</td>\n",
       "      <td>This PR needs to be rebased properly.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128455</td>\n",
       "      <td>No other data that we send to the frontend is ...</td>\n",
       "      <td>A camera test is failing. Frontend is approved...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>128452</td>\n",
       "      <td>Does this only support 1 room? Yes, it is the ...</td>\n",
       "      <td>Not sure why the tests are failing.\\r\\n\\r\\nI a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>128432</td>\n",
       "      <td>Maybe add an enum for these strings and use th...</td>\n",
       "      <td>Ready to merge. Frontend is approved</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128430</td>\n",
       "      <td>Single-use variable\\r\\n</td>\n",
       "      <td>Can be merged when frontend is happy. Looks go...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>128365</td>\n",
       "      <td>\".HA_RESTORE\" is only here while testing, this...</td>\n",
       "      <td>Thanks @MartinHjelmare; I _think_ I covered al...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PR Number                          processed_comments_review  \\\n",
       "0      129755  Tests are missing. Waiting on an intents bump ...   \n",
       "1      129675  This are glob pattern not regexes, so the {6} ...   \n",
       "2      129299  Please reduce to one platform #home-assistant-...   \n",
       "3      129232  I think a few of these are bugfixes that shoul...   \n",
       "4      129088  This can now be moved to a constant at the top...   \n",
       "5      128984  Can we let this function return a list instead...   \n",
       "6      128947                                                      \n",
       "7      128942  We normally only want to import from the integ...   \n",
       "8      128919  let's make the domain `music_assistant` Hah, I...   \n",
       "9      128909  Are both of these exceptions realistic? When s...   \n",
       "10     128870  Is this a real value? You probably use Twitch ...   \n",
       "11     128856  Please use the migrate function for this `asyn...   \n",
       "12     128794  Please use `SnapshotAssertion` in diagnostic t...   \n",
       "13     128789  Hi there @vingerha 👋 \\r\\n\\r\\nWe do not allow i...   \n",
       "14     128547  Why didn't we implement the water_heater platf...   \n",
       "15     128455  No other data that we send to the frontend is ...   \n",
       "16     128452  Does this only support 1 room? Yes, it is the ...   \n",
       "17     128432  Maybe add an enum for these strings and use th...   \n",
       "18     128430                            Single-use variable\\r\\n   \n",
       "19     128365  \".HA_RESTORE\" is only here while testing, this...   \n",
       "\n",
       "                             processed_comments_issue  topic  \n",
       "0   Why is this added to the November release mile...     98  \n",
       "1   Do we need a docs PR here? > Do we need a docs...      6  \n",
       "2   I made the single PR for the whole lg_thinq in...      5  \n",
       "3   There are quite a few tests which does a reaut...     -1  \n",
       "4   @epenet What's the advantage of `suggested_val...     52  \n",
       "5   I'll add more tests once I get some feedback o...     22  \n",
       "6   drafting for one more lib bump since the CO2 m...     15  \n",
       "7   Your force push overwrote my commit. > Your fo...     36  \n",
       "8   Small note: the coverage for config_flow.py do...     -1  \n",
       "9   > Also, I am now wondering, does `nest` suppor...    140  \n",
       "10  Added tier to tests.  Tests do not currently p...     99  \n",
       "11                                 Nice work @bouwew      -1  \n",
       "12         You can exclude those keys in the snapshot     25  \n",
       "13  @exxamalte quite a while ago I asked if reduci...     35  \n",
       "14              This PR needs to be rebased properly.      0  \n",
       "15  A camera test is failing. Frontend is approved...    108  \n",
       "16  Not sure why the tests are failing.\\r\\n\\r\\nI a...      0  \n",
       "17               Ready to merge. Frontend is approved     22  \n",
       "18  Can be merged when frontend is happy. Looks go...     65  \n",
       "19  Thanks @MartinHjelmare; I _think_ I covered al...     38  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"topic\"] = topics_30k\n",
    "df.iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f307fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddb5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24d694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
