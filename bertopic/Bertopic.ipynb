{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c968326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\david\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a79353",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"\") # set your huggingface token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffa31ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c768626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Llama2-7b'\n",
    "MODEL_FullName = 'meta-llama/Llama-2-7b-chat-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879540bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import bfloat16\n",
    "import transformers\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit quantization\n",
    "    bnb_4bit_quant_type='nf4',  # Normalized float 4\n",
    "    bnb_4bit_use_double_quant=True,  # Second quantization after the first\n",
    "    bnb_4bit_compute_dtype=bfloat16  # Computation type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab318404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13b198ef8564021b4c9e3e7f3b5b09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import bfloat16\n",
    "import transformers\n",
    "# Llama 3 Tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Llama 3 Model\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",  # This will ensure the model is loaded to GPU\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f49e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Our text generator\n",
    "generator = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=500,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617469e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "df= pd.read_csv('pull_requests_filtered_raw.csv')\n",
    "df['comments'] = df['comments'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "df['review_comments'] = df['comments'].apply(lambda comments: [item for item in comments if item['type'] != 'issue'] if type(comments) is not float else comments)\n",
    "df = df[df['review_comments'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "df['issue_comments'] = df['comments'].apply(lambda comments: [item for item in comments if item['type'] != 'review'] if type(comments) is not float else comments)\n",
    "df = df[df['issue_comments'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b14f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This are glob pattern not regexes, so the {6} doesn't work afaik. The [0-9] appears to be fine though. \", 'May be parametrize some hostnames to make sure all regex expressions are tested.', \"I don't understand? I mean we are not evaluating the glob patterns here anyways, so we are just passing through the strings here. \", \"It's not a bad idea though (added it)\"]\n",
      "['Do we need a docs PR here?', '> Do we need a docs PR here?\\r\\n\\r\\nI added a note to docs.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "\n",
    "    pattern = r\"```.*?```|http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    return re.sub(pattern, lambda m: \"\" if m.group(0).startswith(\"```\") else \"\", text, flags=re.DOTALL)\n",
    "\n",
    "def extract_text(comment_thread):\n",
    "    \n",
    "    conversation = []\n",
    "    for comment in comment_thread:\n",
    "        main_comment = clean_text(comment.get('comment', {}).get('body', ''))\n",
    "        \n",
    "        # Extract replies' bodies\n",
    "        replies = comment.get('replies', [])\n",
    "        reply_bodies = [reply.get('body', '') for reply in replies]\n",
    "\n",
    "        if main_comment:\n",
    "            conversation.append(main_comment)\n",
    "\n",
    "        for r in reply_bodies:\n",
    "            cleaned_reply = clean_text(r)  # Apply regex cleaning\n",
    "            if cleaned_reply.strip():  # Ensure we don't add empty strings\n",
    "                conversation.append(cleaned_reply)\n",
    "            \n",
    "    return conversation\n",
    "# Apply the function to extract text from the comments column\n",
    "df['processed_comments_review'] = df['review_comments'].apply(extract_text)\n",
    "print(df['processed_comments_review'].iloc[1])\n",
    "df['processed_comments_issue'] = df['issue_comments'].apply(extract_text)\n",
    "print(df['processed_comments_issue'].iloc[1])\n",
    "\n",
    "# extract_text(df['review_comments'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72606df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR Number</th>\n",
       "      <th>processed_comments_review</th>\n",
       "      <th>processed_comments_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129755</td>\n",
       "      <td>[Tests are missing., Waiting on an intents bum...</td>\n",
       "      <td>[Why is this added to the November release mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129675</td>\n",
       "      <td>[This are glob pattern not regexes, so the {6}...</td>\n",
       "      <td>[Do we need a docs PR here?, &gt; Do we need a do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129299</td>\n",
       "      <td>[Please reduce to one platform #home-assistant...</td>\n",
       "      <td>[I made the single PR for the whole lg_thinq i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129232</td>\n",
       "      <td>[I think a few of these are bugfixes that shou...</td>\n",
       "      <td>[There are quite a few tests which does a reau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129088</td>\n",
       "      <td>[This can now be moved to a constant at the to...</td>\n",
       "      <td>[@epenet What's the advantage of `suggested_va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PR Number                          processed_comments_review  \\\n",
       "0     129755  [Tests are missing., Waiting on an intents bum...   \n",
       "1     129675  [This are glob pattern not regexes, so the {6}...   \n",
       "2     129299  [Please reduce to one platform #home-assistant...   \n",
       "3     129232  [I think a few of these are bugfixes that shou...   \n",
       "4     129088  [This can now be moved to a constant at the to...   \n",
       "\n",
       "                            processed_comments_issue  \n",
       "0  [Why is this added to the November release mil...  \n",
       "1  [Do we need a docs PR here?, > Do we need a do...  \n",
       "2  [I made the single PR for the whole lg_thinq i...  \n",
       "3  [There are quite a few tests which does a reau...  \n",
       "4  [@epenet What's the advantage of `suggested_va...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['PR Number', 'processed_comments_review', 'processed_comments_issue']].reset_index(drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e1b2b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tests are missing. Waiting on an intents bump before the test can be added. Tests added in ',\n",
       " \"This are glob pattern not regexes, so the {6} doesn't work afaik. The [0-9] appears to be fine though.  May be parametrize some hostnames to make sure all regex expressions are tested. I don't understand? I mean we are not evaluating the glob patterns here anyways, so we are just passing through the strings here.  It's not a bad idea though (added it)\",\n",
       " \"Please reduce to one platform #home-assistant-core Everything has been merged to an intermediary branch and already has been reviewed thoroughly :)\\r\\n\\r\\n Oh! Forget I said anything then :) Thanks for staying sharp â¤ï¸  Joost! Is this going in for this beta? I've a washer to test, in case! :) That is the plan yes :) > Joost! Is this going in for this beta? I've a washer to test, in case! :)\\r\\n\\r\\nThank u for the washer.\\r\\nI hope it works :)\",\n",
       " 'I think a few of these are bugfixes that should probably be moved to separate prs I have made prel PR\\'s for the two cases.\\r\\nI think the test fixes can be left in this PR. This block should be replaced by `result = await config_entry.start_reauth_flow(hass)`\\r\\n(preferably in a preliminary PR) As we have seen in weird implementations, I think this might be a breaking change for reauth flows triggered without a config entry.\\r\\n\\r\\nWe may need to ensure that `entry_id` is available.\\r\\n Fair point even though I think it should be mandatory to provide an `entry_id` for both `reauth` and `reconfigure` flows.\\r\\nAnyhow maybe that check should go elsewhere and do some logging (deprecation) first. I agree - a deprecation is needed in the \"init\".\\r\\n\\r\\nBut I think the check is still needed here - at least until the deprecation ends. Unfortunately yes, anyway will add it once I rebase over  that\\'s pending',\n",
       " \"This can now be moved to a constant at the top of the file. This is used only in this one place. What is the reason to move it all the way up, where it's far away from where it is actually being used? It's a general recommendation - we try to keep schemas as constants Same here, this can be converted to a constant now. Since you are now implementing reconfigure, does it make sense to still allow updating the previous entry outside of reconfigure? Single-use variable\\r\\n Why do we have an option for input sources (besides there was this option in YAML)? That was already here before this PR. It was added with the config flow. \\n\\nThe reason we have it is so that users can select which input sources are present on their receiver. Doesn't the device tell us what are present? No, it does not.\\r\\n\\r\\nThere is a discovery mechanism for that, but it is not implemented by older receivers, and even for newer ones it is still not supported by the library we are using. Ok.\",\n",
       " \"Can we let this function return a list instead of a single item? Yes, we can. You can change it in this PR Done in PR  It seems a bit unwanted to add the WebRTC specific validation here and a WebRTC specific object to hass.config.\\r\\nMaybe a webrtc integration, which just holds the configuration, would be more appropriate? Discussed offline, with the conclusion it's OK to add this to the core config This class is the same as `RTCConfiguration`. We could use that one instead\",\n",
       " '',\n",
       " \"We normally only want to import from the integration package module and not from submodules. Should I change the export of the camera package? Should it be done within this PR? This import will be removed once #129032 is merged This fixture is legacy. The new way is to use the `cloud` fixture and `set_cloud_prefs` fixture. Did I do it in a way you meant now? Update the `cloud` fixture instead. We shouldn't create the cloud client in the test. That will happen when we set up the cloud integration. Set up the integration either in the test or in a fixture. The mock cloud will be set on the client by the integration when it's setup. Add the `ice_servers` mock to the cloud fixture mock in `conftest.py`. \\r\\n\\r\\nIf we need to set preferences we can use the `set_cloud_prefs` fixture. See other tests that use these fixtures for examples. I couldn't use `set_cloud_prefs` as I wanted because it did not get executed in the proper order, so I modified the test flow a bit and also defined Alexa and Google configs as they were needed because I could not set prefs before initialization. This should be a separate PR. Yep, it's for testing now. I was hoping someone will do it before me; if not, I will do it myself. I will also create a separate PR for `hass-nabucasa`.\",\n",
       " 'let\\'s make the domain `music_assistant` Hah, I already discussed this with both Marcel and Jozef :P Working on it as we speak\\r\\n Not needed, it\\'s just the name in the manifest.\\r\\n removed in latest commit We only allow catching bare exceptions in the config flow, we should be more specific here Please use entry.runtime_data to store runtimedata Why don\\'t we do this before forwarding the setups? ~~You mean move the entry.runtime_data call from above to after this block?~~\\r\\nScratch that, I see what you mean\\r\\n Let\\'s not do this yet Let\\'s move reconfigure for a followup Not sure why we have this extra step, can be combined \\r\\nThis should not be the case I personally like to inverse the if statement, to make it `if user_input is not None` and then just have one call to `async_show_form` Only have stuff in the try block that can raise unused Looks like this is also doing reconfigure? Let\\'s split this logic back into the user and zeroconf step Can be set outside of the constructor I personally always prefer to have this logic in the platforms instead you can use the `self.player` property here We can use the new notation for this Instead of showing the user an error a dev can understand, I would rather see user facing errors like \"Could not add to queue\" or something along those lines (they can even be translated)',\n",
       " \"Are both of these exceptions realistic? When should they occur in real life? (Maybe I will be seeing why when I am scrolling down here) The first one is for typing:\\r\\n\\r\\nso we could cast instead, but that's why its here.\\r\\n\\r\\nThe second one also shouldn't happen. I think a couple years ago there were a large number of possible states for nest configurations to be in (yaml, multiple auth types, imported subscriptions, manually created subscriptions, etc) that I was probably being paranoid and wanting a clear error message. I've updated this to assume the key exists. Ah by changing this i introduced a `KeyError` since the code will run anyway to check the old format. Sending a PR to fix. Sent  and added a test case that was missing from this PR to exercise the bug. \\r\\nI don't believe there is a difference Only have stuff in the try block that can raise Removing this instead, didn't meant to include this in the PR. I am not 100% sure on this, but you can pass a translation key to a selectselector. maybe we can use that to translate the create_new. But I am not sure if all keys that are in the options need to be in string.json, because ideally it shows the raw strings if its not found.\\r\\n\\r\\nNot a blocker, just curious Yeah, I was thinking the same thing that it would be ideal to translate create new, but then still have it work for th other options.\\r\\n\\r\\n\\r\\n\\r\\nMy assumption was that given some of the work to enforce translation keys existing, that we wouldn't want to do this. I will follow up and get a definitive answer though. is `Topic` a brand name or is it just a normal word, otherwise we should lowercase that word Lowercasing. idem for subscription name Lowercasing.\",\n",
       " 'Is this a real value? You probably use Twitch more than me, but I know that they have tier 1, 2 and 3 right? Yes, the tier values are 1000, 2000, and 3000.  I have no idea why.  See #check-user-subscription oh lol This was unused (and doesn\\'t exist in the API) so I removed it in passing. But, shouldn\\'t we show 1/2/3 here? I don\\'t think we should change the value at all.  The end user would want to get it as the API provides it, I would think.  We only show the 1000, 2000, and 3000 as-is. Yes, but users don\\'t talk to an API, users go on Twitch and have a Tier 1 sub, so they expect their tier to be `1`. If I don\\'t have knowledge of the API, seeing myself being a `tier 1000` sub just feels off Fair enough.  I\\'ll look at it. The test is incorrect, that should just stay the same This value should be what the sensor attribute ends up as though, shouldn\\'t it?  Or does it go through that part of `TwitchCoordinator`? the subscription tier is now what we put into the fixtures right? The fixture data (corrected a few minutes ago) is what gets returned from the API, so it\\'s a string there.  The attribute `subscription_tier`, which is what gets displayed to the user, would be an integer. yes, then the test should be just `sensor_state.attributes[\"subscription_tier\"] == 1`?',\n",
       " \"Please use the migrate function for this `async_migrate_entry` Tried that, can't make it work. I need to access the coordinator to be able to pick up the firmware version. Ooh right. Hmm. Would it be possible to create a new connection during migration? Unless... I store it as part of the `config-entry`, would that work? I mean, you need a few parameters to create a connection to the plugwise device right? Can't you create a new client during migration, get the info you need and close it.\\r\\n\\r\\nI think we consider things like config flow and migration to be independent from the normal workflow, as in, when you set up the config flow, we also don't store the client used to verify to use later I will try to get the required version from the `device_registry.sw_version`, that should be the simplest method. But wait (this is the moment I actually realize what we are doing here). Why don't we fetch this on runtime? Because you can change the update interval of a coordinator on runtime, why do we need to store the version in the entry? Ok, the PR has been reworked. I do like snapshots, but in this case I would rather see a test that tests if the entry is changed to what we expect. Snapshot tests are nice to fixate data objects, but they don't tell us the meaning behind the change nor what we expect it to test OK, I took inspiration from a wrong integration then ðŸ¥²  Changed as requested. This change is not related to the goal of this PR and should not be in this PR for that reason. As a side-note, essentially, the title can be fully removed. We fall back to the integration title, which a user explicitly starts the addition process for. I really think this is not integration logic.\\r\\n\\r\\nThe fact we pass down a timeout (which is also device depended) from Home Assistant down to the library is odd. Why not handle all of that in the library?\\r\\n\\r\\nHome Assistant connects with a device... without passing a timeout, and it gets a timeout raised when... well whenever ðŸ¤·  Yes, that's how we did it before but then we're stuck with an initial timeout of 30 secs for all devices.\\r\\nSo if a user makes a typo she/he has to wait for 90 sec before she/he can correct and try again.\\r\\n\\r\\nThe nice thing of the HA discovery is that we can use the discovered information to set the timeout as early as possible, from within HA, to 10 sec for most of the user having non-legacy devices.\\r\\nThat was my thinking behind this PR. There should be no reason for this to be part of the configuration data.\",\n",
       " 'Please use `SnapshotAssertion` in diagnostic tests Done! Why do we have this? We want to test the code redacting itself right? Yup right, took from below link at my first attempt to write the test.\\r\\n\\r\\n#L27L29',\n",
       " 'Hi there @vingerha ðŸ‘‹ \\r\\n\\r\\nWe do not allow integrations to configure a update interval.\\r\\n\\r\\nInstead, we provide a sane default out of the box. If a user wants a custom schedule or interval, one can use the `home_assistant.update_entity` action.\\r\\n\\r\\n../Frenck Clear but this integration does not allow that as it always defaults to 300s, so its present status it is already not adhering. I will have a look if this can be made more in-line Correction, it works now... had not looked at it for almost 2y so either it changed or I missed things back then. If I would have known this to work then I would not have spent time on a PR :(',\n",
       " \"Why didn't we implement the water_heater platform for this? HA water_heater platform support only 0.5 step.\\r\\nBut our devices only support step 1.\\r\\nThat's why we didn't implement the water_header platform. You can overwrite the precision right?\\n\\n#L194-L201 Let us discuss about that. As we tested in HomeAssistant, frontend only supporty 0.5 step with +,- buttons.\\r\\nThat is because water_heater entity does not have 'attr_target_temp_step'.\\r\\nWe need 0.5 step in frontend.\\r\\nIf I am wrong please let me know. Frontend has support but backend not (`target_temp_step` is not implemented in `WaterHeaterEntity`).\\r\\nOtherwise for Fahrenheit it will be step 1, for celsius 0.5. 'core' only supports 1step, but 'frontend' supports 0.5.\\r\\nUser could get it wrong.\\r\\nIn conclusion, \\r\\nWaterHeaterEntity does not work as we want.\\r\\nSo we need this. I think we can agree with that so I close this conversation as resolved.\",\n",
       " \"No other data that we send to the frontend is using the consumers casing format. We just output our data in the Python's used snake casing format and the frontend (or any other consumer) can translate it to their casing. Should we add the `@cache` decorator since we only need to calculate this once?  We need to recalculate it if the WebRTC provider changes, but we will look into it tomorrow. Nick told me we should use `@cache` only on a class or static functions. Otherwise, `self` will be added to the cache and, therefore, never garbage collected. Also, we can only invalidate the whole cache, not only for one instance.\\r\\n\\r\\nI converted the function to a property so I can use `@under_cached_property` `as_dict` is the function name that we use.  Why is this needed? In the WebRTC commands we didn't catch the `HomeAssistantError` coming from `get_camera_from_entity_id` since it will be handled by the common exception handler. I think we should be consistent. Can this raise HomeAssistantError? Nope good finding\",\n",
       " 'Does this only support 1 room? Yes, it is the room where the thermostat is placed. Dutch screenshot from the portal:\\r\\n![image](\\r\\n\\r\\n \\n',\n",
       " \"Maybe add an enum for these strings and use that in the parameter schema with `vol.Coerce`? good idea Should we make this websocket command a bit more generally useful ? Maybe we can just return all URLs for all situations as a dict?\\r\\n\\r\\n I wonder if we shouldn't just include this data in the existing `network` command? We can return adapters, configured adapters and the resolved URLs?  I considered this but urls are handled in a different component in the frontend and it would make loading the data even more complicated no need to move this into the network helper. Let's keep it around the WS command. Is there a reason to have this as a constant list instead of a string enum?\",\n",
       " 'Single-use variable\\r\\n',\n",
       " '\".HA_RESTORE\" is only here while testing, this will be removed. The idea is to expand this to also support passwords in a follow-up PR, so while this is not needed as a dict now, it makes future enhancement simpler. I\\'d make this a dataclass instead. Workaround to deal with the fact that the target directory will not be empty. Was included in  Try to use `pathlib.Path` as much as possible instead of `os.path` and other related os module APIs. The former is higher level and often easier/nicer to use.\\r\\n\\r\\n#corresponding-tools Does this work?\\r\\n\\r\\n#pathlib.Path.iterdir It did ðŸ‘  Generally, it\\'s safer to try and open or read from the file and catch `FileNotFoundError` than checking first. The file can be removed after the check so checking doesn\\'t completely safeguard the case that is checked. Patch a `Path.read_text` operation instead and set a side effect `FileNotFoundError`. So while the `.HA_RESTORE` file _can_ be manually added, I dont think that is something we should document.\\r\\nSo the documentation requirement of this feature, IMO should not be triggered until this is implemented in the UI, or a service call is added. I\\'d change the test parameters instead to be the return value and side effect or just the side effect, to avoid encoding logic to the parameter.',\n",
       " \"Please don't use the update entity service for this, rather let the entity naturally update, for example with either freezing and skipping time or by calling a callback function fetched from a mock Time skipping it is, thanks for the hint! \\r\\nPlease apply this to the whole file :)\",\n",
       " \"\\r\\nuse `entry.runtime_data` instead Thanks, addressed in the new revision. \\r\\nnot needed if switching to runtime_data Thanks, addressed in the new revision. better to do that in `init` instead Not sure I get that. Can I await an async call in `init`? I'll look into it. Sorry, meant `__init__.py` in setup_entry Got it. Addressed in the new revision. can we maybe instead `try:` here? This should throw some errors probably Thanks, addressed in the new revision. remove empty keys Thanks, addressed in the new revision. belongs in the lib Thanks, addressed in the new revision. \\r\\nis default Thanks, addressed in the new revision. can't this throw? I'd suggest to use the `CONF_` prefixed versions from central `const` instead Thanks, addressed in the new revision. \\r\\navoid `get` here Thanks, addressed in the new revision. same \\r\\nmake sure it's removed I removed the listener in the new revision. Using properties directly instead. can we move that code to the `available` property Addressed in the new revision. I think I'd prefer the properties here as well for readability Addressed in the new revision. Why would it be an invalid host?\",\n",
       " 'The end date should be exclusive (#calendarevent) and must be after start, so +1 day here, and below too. CalendarEvent already handles this and adds 1 day so i thought it might be unnecessary It\\'s there just to fix input bugs, and is shared with the input handling code for creating events from the service.  You can just use `dt_util.now()` here and it will give you a local datetime in the current timezone as described here #get-events  But that\\'s exactly what i need, a tz-aware datetime representation of today (starttime 0:00) for rrule to return also events for today. Is that `dt_util.start_of_local_day()`? lol, that method does the exact same thing ðŸ˜‚\\r\\n(now that I know this exists, I\\'d preferably use that instead) This doesn\\'t seem quite right to me since it is potentially hiding additional upcoming events? Current the rules are this returns either the current or next upcoming CalendarEvent.\\r\\n\\r\\nI believe a simple way to implement \"active after\" is to iterate over the sorted event list and find the first event where the start time or end time are greater than the \"now\" time like here #L371 (used by local_calendar) I would recommend implementing this logic for the upcoming event and the event date range search once, and just make each type of event supply a sorted list of `CalendarEvent` and hand the rest with shared code.  Having the variance between them may introduce some bugs if we don\\'t find all the subtle differences here so its easier to just get them right once and do them the same way.  (The logic can be the same whether or not its an all day event just by converting the dates to a timezone aware date when doing the range comparison) I think i still need some tweeking for the reminders calendar, I\\'m considering adding them in a follow-up PR It\\'s not implementing the spec correctly. I see, you removed from the pr. There are two changes needed here i think to meet the spec described here  #get-events\\r\\n\\r\\n(1) the end date is exclusive.\\r\\n(2) This need to check if the event end date is between requested start and end dates.\\r\\n The events don\\'t have enddates, so it is not necessary to check if the enddate is in between.  All calendar events have an end date. I understand the habitica tasks/events don\\'t, but i\\'m talking about how its represented as a home assistant event.  They set an end date  (\"start + timedelta(hours=1)\".) This is not implementing the get events spec correctly \"The start_date is the lower bound and applied to the event\\'s end (exclusive).\" I removed the reminders for now as there are still some other things i have to figure out about how they work in Habitica, the to-dos and dailies are all-day events so i think this doesn\\'t apply to them.  Will this prevent future occurrences from showing up here? As I was saying before for the other event type, a single  timeline view will ensure we don\\'t have inconsistent behavior. the future occurrences should still show up, just for the current day they should not show up after beeing completed I must admit, that was a very good catch. Now it does what it is expected to do ðŸ˜\\r\\n\\r\\nI think i can\\'t use a single timeline as you suggest, the future recurrences are generated events. In `async_get_events` i can use end_date to limit how many recurrence events are generated, but in the `events` property I only ask `rrule` for the next recurrence of each task. I would have to provide an arbitrary date in the future. How far into the future would i have to go if want to get sure to get the next recurrence of a task? If it is too close in the future i could miss recurrences. If it is too far in the future i would get a very long list of events for daily recurring tasks. What\\'s the intent behind `[30:]`? Skipping the first line of a multi-line rrule or something? This is pretty subtle, can this be done another way (or omitted)? This is stripping  the dtstart part of the rrule. Otherwise the calendar is unable to parse the rule. I was looking for a method to get a rule from rrule without the dtstart part but couldn\\'t find one  Two suggestions:\\r\\n- I would suggest extracting a descriptive function name that describes what this is doing. (I happy to know the format this library produces includes dtstart because i\\'ve read that library code before, but not sure that is obvious to other readers)\\r\\n- I think there may be a newline in there as a delimiter. Explicitly checking the rrule prefix would help too.  Adding tests would also be useful. Can you help me understand what the intent is here behind this check? Is `everyX` sometimes `0`? (Seems like the rrule would want to handle this, so not sure i follow this) yes, there are dailies without a recurrence, they are called grey dailies and they can be completed whenever but become never due.\\r\\nrrule seems to not be able to parse that. Does that mean they show up every day? or more? If so then maybe that can be set in the rrule on the dailies list in habitica all tasks show up, by default, although one can filter for dailies that are due or grey(completed or not due today). It is still possible to complete dailies that are not due to get the reward but they won\\'t cause damage if they are not completed, so technically grey tasks are optional. An task without a recurrence is always optional, so I think they shouldn\\'t show up in the calendar at all. I must correct myself, `rrule` is not to blame, it can parse a 0 interval correctly, it\\'s Home Assistant that freaks out, i think it\\'s getting into an infinite loop somewhere This also is not meeting the get_event spec. get_events should work for any  start/end date range. A calendar can render events from the past as well, and triggers work based on past events. In Habitica the start of the day can be set to a different time (in my account it is 4:00 am for example. If at that time all dailies that were due have been completed the cron runs at 4 and resets all dailies, marking the start of the day. If there are incompleted dailies from the past day (called yesterdailies), the user gets a last chance to mark tasks as completed (in case the task was done but forgotten to mark as completed) and then the user presses the button \\'start my day\\', which then marks the start of the day. That\\'s what I want to reflect here. \\r\\nThat\\'s also why it doesn\\'t make sense to render events from the past, dailies are reset every day. ',\n",
       " \"Device class restart, then you can also omit the translation key :) Great catch, I should've remembered that! Fixed now. This [is the test](#L170-L176) I was referring to in the comment on the same point in #discussion_r1791827763. We could potentially drop this check but it's quite handy to have a test to ensure we haven't forgotten any translations. Perhaps it could be extended to see if a unique device class is present if the translation key is not there.\",\n",
       " 'I don\\'t really like this c&p from `entity_component::motion` as I\\'d like to trust `binary_sensor` maintainers\\' to avoid out-of-sync here, but hassfest doesn\\'t seem to like indirection so.. You don\\'t need this. If has_entity_name = true and there is no related translation string found, it will fallback to the device class translations. So you can remove this and it will use the default translations We took a decision to enforce translation strings for all of our entities to avoid missing translation keys that sometimes were able to use a device class or perhaps not.  There is a test for this in the test framework to ensure that they exist. But can\\'t you also assert that a device class is set or the name is equal to None? This is now fixed with #128022. Maybe the rest of the steps could also be done in a playbook style, but I just wanted to add these necessary steps to simplify the process for whomever wants to add the next new entity :-) I think this should be `event` platform.  Potentially, yeah. But the event platform has its issues also, so I\\'d rather expose this as-is (if it works) and we can discuss about deprecating it later on.\\r\\n\\r\\nI was just reading the community forums and noticed that many people were asking why there\\'s no sensor for the motion detected, and there was a screenshot not showing the detected state. IIRC, one of the problems with events is that you won\\'t get this either, but you must know that you are looking for a specific event.\\r\\n\\r\\nEvent triggers should probably solve that issue, but it\\'s much more work than simply exposing this `binary_sensor` for anyone who\\'s looking for an easy solution. I think I\\'ll get a test device \"soonish\" to experiment a bit how it behaves to see what would be the best approach. If the motion sensor has a duration, binary sensor is OK.\\r\\n\\r\\nIf the motion sensor is an momentary sensor than the event platform should be used.\\r\\n\\r\\nSince we are polling for this, I think binary sensor is probably what we want Honestly, this doesn\\'t belong here at all.\\r\\n\\r\\nThese are mostly generic instruction on how to use the HA devs environment, besides a fixture adjustment. Agreed, I simplified it a bit to include only the fixture edit + snapshot update, I hope that\\'s fine? The idea is to make the update process as straightforward as possible for future developers. I removed all README.md updates from this PR, so this is resolved now.',\n",
       " \"You never actually initialized hass.data[DOMAIN] afaiw, so doesn't this raise a Key error?\\n\\nAlso, could we use HassKey for typing hass.data? I haven't seen the key error during testing, but the default should be set.  Are we sure media player doesn't already guard for this? This code was taken from a different integration, the media_player integration doesn't guard against this.  \\n\",\n",
       " 'this is incorrect Fixed, it\\'s just a mistake on my side this is incorrect Fixed Can you tell me a bit what this does ? Is this a new feature ? It\\'s a fallback translation key. It will be only used when we have primary attribute on multiple endpoints (when we suffix the name by the endpoint id).\\r\\nIt\\'s used here #diff-b6c426ab993a9279a458078576e5fa2a2a8746b1f97ee3ae583877b2fae9cb57R87-R88 the name got me a bit confused at first. I\\'m fine with keeping it this way but another suggestion wold be to rename this to  \"_platform_translation_key\" or \"_base_platform_translation_key\"  ? I agree the current wording it not good. I renamed to `_platform_translation_key`.',\n",
       " 'Please make sure the code is not longer than 88 characters. I think this message can be a bit to the point. I would maybe suggest keeping this list in a more central place rather than the light setup, since in the future you might have more devices that have their own speciality like idk, a physical switch or a binary sensor for detection.\\r\\n\\r\\nI would add the link to the place where they should report this.\\r\\n\\r\\n\"We found device \"x\" which is not supported by the integration. Please create an issue at x\" I have the same setup in `switch.py` as well. Should I move the supported devices list into const like so?\\r\\n\\r\\n\\r\\n\\r\\nThe reason I have it like this is because some devices may support light but not switch, and vice versa, so I have it inside the platform and not in `const`. I think it would make sense to centralize this list yes. And I think it depends on how much devices you expect to support. If you expect 100 devices, I would go for a dict with platform as key.\\r\\n\\r\\n\\r\\nand then you can also create a `set` with all the device types that you know, since all devices that you support at least 1 platform. \\r\\n\\r\\n\\r\\nIf you only expect to support a few devices or device lines, I would suggest doing it by model -> platform There\\'s only about 6 device types according to the app:\\n\\n![image](\\n![image](\\n\\nShould I implement what I suggested then? Or am I misinterpreting what you\\'re saying? That\\'s fine, I don\\'t have a strong preference, but I just wanted to say that I would have it depend on the amount of devices',\n",
       " 'Should viewers be plural to stay consistent with \"followers\"? ',\n",
       " 'We should rather check if they are used in automations and scripts and raise if they are Could you please give me a hint how to do that?\\r\\n\\r\\nWould you also briefly explain to me, what\\'s wrong about raising the issue at the moment when the entities are set up? Raising the issue should not only occur if the entities are used in automations and scripts but generally if they are used (even from the frontend)? We usually get more false positives for users and we want issues to be actionable, not a \"hey, did you know that ...\". \\n\\nIn the past we deprecated the harmony switch entities, I think that\\'s quite a clean example. (It\\'s already removed from the codebase, but the PRs are still there)\\n\\nI can link when I finally booted my pc Thanks! I guess I found it here: \\r\\nI\\'ll implement it in the same way. Let\\'s not create an issue per item',\n",
       " \"Please deduplicate this, there are 16 almost identical copies of this list comprehension I want to definitely get the code complexity down of this function, but I didn't think this PR was the place to do that. Also because all the data we get is now typed, we can't just make it more generic without a lot of hassle Why is this assert here? Hide it behind `TYPE_CHECKING` if it's a hint for mypy Don't we have better control over exceptions with the new library? We have, but I wanted to add the extra exceptions in a follow up, since they also add extra tests Please hide behind `if TYPE_CHECKING` if this is a hint for mypy Does the new library change the times? Why does it do that? The signature of media_duration is `int | None`, and we now round to adhere to the typing Apparently it was only my IDE complaining, not mypy This is kind of stupid, why don't we make `async_ensure_token_valid` return the token, then this would just be simplified to:\\r\\n`return session.async_ensure_token_valid()`\\r\\n\\r\\n(For a different PR though)\\r\\n `async_ensure_token_valid` already has a lock, you added it yourself @joostlek in  Why do we need another lock? I actually don't know lol, when I made this I did add it with a reason, but I can't remember which one it was now make a decorator which returns `None` if item is None and passes item to the function if it isn't, something like\\r\\n\",\n",
       " \"Just a hint - on reconfigure, the `reason` must be explicitely stated.\\r\\n\\r\\nNot sure, but if this will be done over all integrations, maybe it makes sense to use `self.init_step` or `self.source` as default for `async_update_reload_and_abort`? Is this what you had in mind? #127756  has been merged, so the reason can be dropped (but still needs to be added to `strings.json`) Yes, thank you! Will adjust this evening. Please update `strings.json` accordingly The data is already available in reauth flows (but not in reconfigure flows)\\r\\n What happens if the user changes the region or the username inside the reauth/reconfigure flow?\\r\\n\\r\\nIt seems to me that the entry data would no longer match the unique_id...\\r\\n\\r\\nthis is an example where I think the unique_id helper suggested in #127565 would be useful\\r\\n\\r\\n Yes, this makes absolute sense. As the helper is not available right now, I got inspired by this PR and implemented it directly in the config flow. If this changes at some point, I'm happy to adjust. I missed this earlier: could you please in a follow-up PR avoid using raise, and drop the redundant check?\\r\\n Will do in the next days! \",\n",
       " \"@peteS-UK pan we but these default values as a const named value. entry.runtime_data.options.volume_step = entry.options.get(CONF_VOLUME_STEP, 1000) -> entry.runtime_data.options.volume_step = entry.options.get(CONF_VOLUME_STEP, 5)? Yes, can do.  These are really just if something's gone awry, since the values are defaulted and required in the configflow, but as you say, t makes sense. \\r\\n1 should be an acceptable value, right?\",\n",
       " 'is this an expensive operation? Can we postpone the generation? It shouldn\\'t be too expensive, so you\\'re right we could postpone it until an error occurs. Delayed the creation of this list until needed, and also skipping config/hidden entities. We call `_normalize_name` a lot. I don\\'t know if it\\'s worth doing some caching ?  I wonder is using this normalization function would work: #L27\\r\\n\\r\\nIt ignores all whitespace, though. There are two aspects here.\\r\\n\\r\\nFirst is the question why it ignores whitespace in the first place. I was actually going to create a PR changing it, because it does not make much sense to me.\\r\\n\\r\\nSecond is that entity registry is not a `normalized_name_registry` anyway, so we don\\'t have `normalized_name` available there, so it does not really help us with the caching issue. I can see ignoring whitespace in some very specific scenarios, such as \"overhead light\" vs. \"over head light\". But it should probably not be the default. Why are we comparing it to the `entity_id` in the first place? Users should call their entities by their name, not id. This allows intent recognizers to target specific entities when there would otherwise be ambiguity. For example, I map \"TV\" to a specific entity id in a pipeline. Does that actually happen anywhere though? It would have to happen already at the sentences level and I don\\'t think we have any sentences with a name slot hard-coded with an `entity_id`.\\r\\n\\r\\nUnless I\\'m misunderstanding what you mean by:\\r\\n>For example, I map \"TV\" to a specific entity id in a pipeline. The default intents no longer to this, you\\'re correct (they did originally). I want to leave it in for now, though, as other intent recognizers may use it. I\\'m not concerned about overlap, as entity ids are very distinct from human names.\\r\\nA potential problem is with area/floor ids, though. If you have an area named \"kitchen\" but it\\'s area id is \"bedroom\" (for some reason), you could match the wrong one. I don\\'t like this logic, and all the ones following it.\\r\\n\\r\\nIf some unexposed entity happens to match required features, it does not mean that the problem is that it is unexposed. You would first need to establish that it has a matching name in the first place.\\r\\n\\r\\nSo what you want to do instead is to have a second set of candidates, consisting only of unexposed entities and do the same operations on them as on normal candidates. If at some point normal candidates don\\'t match and unexposed do match, then that is where you return `MatchFailedReason.ASSISTANT`.  Thanks for the suggestion! I\\'ve reworked the logic so that unexposed candidates are kept until the very end. I\\'m curious what you think. I\\'m not sure I understand how this works.\\r\\n\\r\\nJust because you have `constraint.name` does not mean that this is where the matching failed. It could have failed later. Or earlier.\\r\\n\\r\\nWhat is the selection logic behind this code? If we\\'re here, the match succeeded all of the other checks and failed the final exposure check (with the reworked logic). The goal is to give as much information to the user as we can so that they can expose the correct entity or entities.\\r\\n\\r\\nIf they provided a name (`constraint.name`), for example, the exposure check would only fail if there was an entity of that name but it wasn\\'t exposed. Likewise with the `constraints.area_name` underneath: if an entity by that name wasn\\'t in the area, we would have never reached the exposure check (failing instead with `MatchFailedReason.NAME`).\\r\\n\\r\\nWe have to be careful to put device class and domain last (in that order), because some intent sentences provide the domain when matched (e.g., #L6). This will add to `constraints.domains`, but we only want to say there aren\\'t any locks exposed if we don\\'t have a `name` slot like here: #L14 With the reworked logic in `intent.py` this makes sense. That should be above duplicate name check. That is then not needed. Thanks for the help! Much appreciated :slightly_smiling_face:  have we seen cases which had empty aliases ? ',\n",
       " \"I think we should also apply this to the off state.\\n\\nAlso, can you checkout `cv.ensure_list`? I think this will make sure it's always a list and thus you don't have to do instance checks on the config but you can just assume it's always a list Done For a followup PR, it would be nice if we could replace the `switch`, `turn_off` and `entity_id` with `SWITCH_DOMAIN`, (I forgot the turn off one) and `ATTR_ENTITY_ID` we'll do..\",\n",
       " 'This change does not seem to be related to the re-discovery functionality introduced by the PR?\\r\\nCan it please be moved to a separate PR? It is related, it was a sub class before, now it is a fixture. Moved removing the entry into the test As this is extended the `TestFlow` class is now a fixture',\n",
       " \"It would be better to have a base class with the common functionality and two subclasses, similar to:\\r\\n#L80\\r\\n\\r\\nSo you would end up with\\r\\n- `SwitcherBaseCoverEntity`\\r\\n- `SwitcherSingleCoverEntity`\\r\\n- `SwitcherDualCoverEntity`\\r\\n\\r\\nThe subclass will only implement changed parts It is done.. I tried to separate __init__ as well but it did make issues.. Please submit the separate init and we will fix the issues in the PR review.\\r\\n It is done. You can see current issue. Update method should be moved from the base class to here as it is not common for both classes:\\r\\n#L104-L110\\r\\n It is done. \\r\\nIf you add it to the base class it will resolve the warning It is done. Add empty method:\\r\\n It is done. Please move this to `SwitcherSingleLightEntity` class It is done. It is done. This was just an example not something you should commit (should be something like `return super().is_on() or ...`, however looking at the final result I think it would be better to remove this from the base class and add it in the subclasses. It is done. It is done. Please look at the logic used in the cover, you don't need to translate the light for a single entity. It is done, but now the light will get the device name which is not what is shown in the Switcher App. (Just like the cover in the S11 device)\\r\\n\\r\\nNow it will be like this:\\r\\nRunner S11:\\r\\ncover.switcher_runner_6cf5 (Actual name: Switcher Runner 6CF5)\\r\\nlight.switcher_runner_6cf5_light_1 (Actual name: Light 1)\\r\\nlight.switcher_runner_6cf5_light_2 (Actual name: Light 2)\\r\\n\\r\\nRunner S12:\\r\\ncover.switcher_run_plus_a9be_cover_1 (Actual name: Cover 1)\\r\\ncover.switcher_run_plus_a9be_cover_2 (Actual name: Cover 2)\\r\\nlight.switcher_run_plus_a9be  (Actual name: Switcher Runner 6CF5) It is done. It is done. It is done. It is done. It is done.\",\n",
       " 'How did device class work here again? I think they were derived with  unitGetter #L64-L70',\n",
       " \"Hmm, This is a strange name but I can't come up with something better here Yea, was also not overly joyed about it, but could not think of a better name. Please use the fixture to enable entities by default instead I did not know there was a fixture for this.\\r\\nVery nice, thanks!\",\n",
       " '\\n',\n",
       " \"If its possible to have multiple entities added here we should call `async_add_entities` only once since it creates a task under the hood and we only want one task.\\r\\n\\r\\nAlternatively if its not possible we could change this to an `if/elif/elif/elif` block to show its only one But maybe we keep it `Cct` because `RGB` is `Rgb` The class name is `RpcShellyCctLight`, I think you're looking at an older commit. I was thinking CCT should be caps but Rgb isnâ€™t so at least itâ€™s consistent  I used `Rgb` for since to make it more readable (`RgbLight`), I don't mind we align all if you think `CCT` & `RGB` is better The re could be pre-compiled as a constant instead of compiling every loop since it never changes \\r\\n\\r\\nI think this only needs to be an `Iterable`, than you can avoid making copies You could likely avoid the keys call as well\",\n",
       " \"We're not allowed to access another integration's `hass.data` items directly. We can use this helper to get all platforms of the template integration:\\r\\n\\r\\n#L1063-L1066\\r\\n\\r\\nThe `EntityPlatform` has a dict with all its entities in the `entities` attribute. Combine these two conditions with `and`. I can't use `and` since apparently the walrus does not make the assigned variable available right away in the same expression, but I have combined them in a single `if` It works by using a parenthesis. But the current way works too. I know this is crap, but I need to figure out how to avoid vol messing up a custom class dict Actually, I've refactored so that these are no longer needed, but forgot to remove them. I'll do so in a following commit. This line is not covered with tests as the RELOAD handler is [locally defined](#L84) in `async_setup`\\r\\n\\r\\nShould I take it out as a separate method and patch it to test this as well? Since the reload helper should be tested separately, I think it's enough to test that this callback calls the service. We can do that by mocking the service with that test helper, using the same service domain and name.\\r\\n\\r\\n#L346-L355 Thank you! As it stands, you can't use Jinja templates in triggers. It would be great to be able to do so, but i think that would mean moving the logic for registering triggers much later. Is that OK?\\r\\n\\r\\nHere's an example:\\r\\n\\r\\n\\r\\n`trigger_variables` might be needed, but the question is when should they be evaluated? Is it safe to do so at config validation? Or should the trigger registration be postponed to much later, when it's safe to evaluate `trigger_variables` as regular tempaltes? This isn't specific to blueprints, right? If it's not specific to blueprints I suggest discussing it separately in a new architecture discussion. I'd say that template blueprints expose the missing feature. In automations, you can use `trigger_variables` specifically for allowing the templating of `entity_id` in blueprints, which had not existed for templates until now.\\r\\n\\r\\n> The second variant is setting variables that are available when attaching a trigger when the trigger can contain templated values. These are defined using the trigger_variables key at an automation level. These variables can only contain [limited templates](#limited-templates). The triggers will not re-apply if the value of the template changes. Trigger variables are a feature meant to support using blueprint inputs in triggers.\\r\\n\\r\\n([source](#trigger-variables))\\r\\n\\r\\nI'm a but stumped about what to do here. If you think this discussion is outside the scope of this feature, I'll start a new architecture discussion, but again... template blueprints _uncovered_ this issue, so i'd say it's related. I don't think it's related since it's about triggers and not blueprints. We don't need to solve all problems at once. Roger that. I'll leave the PR as it is. Maybe call it `reference_entity` since that's what we call it in the description? Or update the description to say original entity? Maybe define the function in this module instead and import it to the package? Note that nothing is using it yet outside this integration so we could wait with exporting it.\\r\\n\\r\\nIt's the search integration that uses the corresponding function for automations to find automations with blueprints. The search integration is used by the frontend. Don't forget to document this since it will be available for all template entities and not only blueprint templates. Don't forget to document this since it will be available for all template entities and not only blueprint templates.\",\n",
       " \"Shouldn't this be UnitOfConcentration? Yes - but I forgot to push my commit !!! Good morning! > Yes - but I forgot to push my commit !!!\\r\\n\\r\\nIt's there now: ff2ccd90fcd75c04ddc80589c5650d73110347bf\\r\\n\\r\\nNote: I've used `UnitOfVolumeConcentration` The consensus from the core team meeting was not to make it concentration by as suggested in the architecture issue: glucose. But they are units of concentration. Which means we can't create a concentration device class because molecular weight, but we can have a glucose device class using units of concentration > But they are units of concentration. Which means we can't create a concentration device class because molecular weight, but we can have a glucose device class using units of concentration\\r\\n\\r\\nMy thinking too...\\r\\n- Have all concentration units as `UnitOfConcentration`\\r\\n- Have a device class for `BLOOD_SUGAR_LEVEL` which only allows two units from the enum\\r\\n- Have a unit converter for `BloodSugarLevelConverter` which only allows those two units > But they are units of concentration. Which means we can't create a concentration device class because molecular weight, but we can have a glucose device class using units of concentration\\n\\nYou where in that meeting and was in that process. This exact idea/suggestion was raised and decided against. I am ok with you raising this again, however, in that case I will revert the decision so we can re-evaluate that it the next core architecture meeting.\\n\\nA PR is not the place to have this discussion.\\n\\n../Frenck > > But they are units of concentration. Which means we can't create a concentration device class because molecular weight, but we can have a glucose device class using units of concentration\\r\\n> \\r\\n> \\r\\n> \\r\\n> My thinking too...\\r\\n> \\r\\n> - Have all concentration units as `UnitOfConcentration`\\r\\n> \\r\\n> - Have a device class for `BLOOD_SUGAR_LEVEL` which only allows two units from the enum\\r\\n> \\r\\n> - Have a unit converter for `BloodSugarLevelConverter` which only allows those two units\\r\\n\\r\\nThat is not what your architecture proposal described. Do you want to revisit the proposal?\\r\\n\\r\\n> Have a device class for `BLOOD_SUGAR_LEVEL` which only allows two units from the enum\\r\\n\\r\\nThis very specific case has been discussed a few times. Most recently with the addition of the `calories` unit added to energy. We think such limitations are unneeded. If we can provide conversation between certain units, we are fine with giving the user the ability to select it.\\r\\n\\r\\nFor example, a user can (as of 2024.10.0) set energy sensor that measures their home energy meter, to calories. I won't recommend it... but ðŸ¤· \\r\\n\\r\\n../Frenck Added a comment on #discussioncomment-10771739\",\n",
       " \"This seems an unrelated change to what is being described in this PR? @frenck  \\r\\nUser feedback:   hope this time interval is shorter ï¼š \\r\\nI will make a note in the description Let's do this in a separate PR. I have a hard time believing that this is not possible without service call. My suspicion would be that the machine they are running this on is doing too much at the same time and can't keep up with the 5 seconds. Because 5 seconds is very very low for HA standards > Let's do this in a separate PR. I have a hard time believing that this is not possible without service call. My suspicion would be that the machine they are running this on is doing too much at the same time and can't keep up with the 5 seconds. Because 5 seconds is very very low for HA standards\\r\\n\\r\\nOk, I'll delete it.\\r\\nOur device supports 5-second requests (the app also requests devices at 5-second intervals)\\r\\nUsers have previously reported this situation.\\r\\nIn the case of 5 seconds, I verified with my own computer that HA can work normally.\\r\\nThanks!\\r\\n > Let's do this in a separate PR. I have a hard time believing that this is not possible without service call. My suspicion would be that the machine they are running this on is doing too much at the same time and can't keep up with the 5 seconds. Because 5 seconds is very very low for HA standards\\r\\n\\r\\nCan I submit a separate PR for this modification pointï¼Ÿ You're always free to open a PR, but I think that 5 seconds is very very low and not useful for the majority of users I am now looking at this, and this list is exactly the same as the `em06` one. I'd rather see that deduplicated\",\n",
       " \"I'd suggest to, in an initial PR, add [event entities]( where each button is one event entity which can fire different events.\\r\\nI'm not sure if device triggers are needed as well, maybe not?\\r\\n\\r\\nAlso, should the beo remotes be their own devices? I guess I could add the Beoremote One as a device, I'll take a look at that. I didn't even know event Entities were a thing, so I'll take a look at that as well. I'll convert this PR to a draft for now. OK, I've pushed an initial commit containing event entities for the physical buttons as well as Beoremote One keys and a device for the Beoremote One. There are 10 Event entities for the physical buttons and 58 for Beoremote One keys. This seems to be a bit excessive, but still seems to be a better way to handle events. What are your thoughts? I agree it's not great. Maybe to add tens of entities which are not very likely to be used. Maybe make the event entities disabled, then users who want to use them can enable them? Yeah that sounds reasonable. It seems there is no reason to support device triggers at this point, so I'll just close this PR and open some new ones. If you decide to still support device triggers, I'd suggest to have one type for each kind of keypress, and a subtype for each button. That should avoid overwhelming the user with a huge list of triggers.\\r\\n\\r\\nExample: #L43-L75\",\n",
       " 'I think it would be nice if we wrap the lambdas in parenthesis because now the second part is on the same level as the rest of the properties Can we use icon translations? sure - feel free to propose some nice icons Does this mean that the battery is low? In that case you can omit the translation key and it will fallback to using the device class name and translation Well, yes, but this is separate from the battery sensor - so I think they mean the (9v) backup battery here that is often found in a smoke sensor.  With other words: We need the it to be named \"Battery Alert\" or \"Batter Low Alert\".\\r\\nThe device also has a battery sensor attached on the powersource cluster (in case of a battery powered device):\\r\\n\\r\\n![Scherm\\xadafbeelding 2024-09-24 om 14 47 40](\\r\\n The power source cluster is not mandatory for smoke sensor, that is why we put battery alert attribute in smoke cluster as well. \\r\\n\\r\\nUser must replace a new batter once the battery alert is set.\\r\\n\\r\\nBoth of Heiman smoke sensor and CO sensor are supported power source cluster and the batter alert attribute in Smoke cluster. Let\\'s translate these values any reason we explicitly set it to None? no, leftover I guess Whats the granularity of the data? Because we also have timestamp. (not that it makes that big of a difference, but maybe if we also take the time into account, we better line up with a manufacturer for example sending a push notification that it expired) its seconds since epoch so this may also be a datetime from my perspective Is this smoke or CO? because I think we have a device class for CO typo',\n",
       " \"What's the reason we don't add `host/logs/follow` here? thanks, I think I missed it when copied from admin paths And here? Please use snake_case variable names.\",\n",
       " 'Was the changed text from PR #120858 lost in rebase? Probably, I\\'ll fix this. The full error message from the automation is something like:\\r\\n> Got error \\'Expected HH:MM, HH:MM:SS or Entity ID with domain \\'input_datetime\\' or \\'sensor\\'\\' when setting up triggers for automation\\r\\n\\r\\nI think the exception text needs to mention it\\'s a time trigger\\'s \"at\" template that rendered to a value we could not understand?',\n",
       " 'Can be a normal `@callback`',\n",
       " 'I would like to be able to pass arguments for a command, but AFAICT `send_command` doesn\\'t support this. Any ideas? For example, when sending `DisplayMessage` which accepts the `Header` and `Text` arguments.\\r\\n\\r\\nThe only thing that comes to mind is encoding the data in the command string, but that\\'s not ideal. You can use action calls for these kind of calls Yeah, I wanted to use the provided remote command actions if at all possible but if not, likely need to create a \"send_general_command\" action. We don\\'t like these as these don\\'t provide context. (That\\'s also why remote is a bit meh, but it works). So we would rather see a `display_message` action than a general catch all. With the specific services you can ask more contextual questions and parameters, increasing the user experience Sure, I was mostly just going with what I know (I use the Apple TV remote entity frequently). But if there\\'s no way to send context to remote commands, then I agree that actions would be better. I\\'ll add actions for the commands that take arguments. I\\'m not super familiar with how HA handles actions, is this the right approach (f3b325238ff731ec10ee915034b6f76a26d43be8)? If so, I\\'ll add the rest of the commands with arguments as actions.\\r\\n\\r\\n![image](\\r\\n Where is the unique_id set? In the `JellyfinEntity` base class, to `${server_id}-${session_id}`: #L27 Can you elaborate what this entity does? As in, afaik a remote is usually a physical device, and Jellyfin is software, so is the remote virtual or did they introduce a new feature? Correct, this is a virtual remote for sending commands to clients. Does the linked doc PR clarify this? If not, let me know if there\\'s anything there that can be improved. I\\'m implementing this as someone that\\'s fairly familiar with Jellyfin so I might leave out information that I assume everyone knows (but doesn\\'t).\\r\\n\\r\\n How many remotes can a server have? Or does this create a remote for every client? Correct, one per client. Do we already have a device per client? Yes, this uses the same logic as the media player entity for that. Would it make sense to maybe do a step backwards first and create a new base enttiy for the JellyfinClient? because now the base entity is for the server and we overwrite practically everything to make it a client entity. WDYT? I was considering that, I just went with minimal changes to other areas for the initial implementation. But I agree, I\\'ll add that. We can introduce it in a preliminary PR I think it\\'s simple enough to include here, see 5018ebef3ce5b6820e9fe1191c03e1cfa6af0184. I did only just now learn that remote.send_command has more properties, but does every integration have to implement it themselves? You\\'re referring to the `ATTR_NUM_REPEATS` and `ATTR_DELAY_SECS`, right? My understanding is yes. I skimmed the code seeing how other remote integrations (Apple TV, Android TV, etc.) implement it and it all seems to be via this approach. So when can this be `None`? We always get session data from the constructor right? Good question, in `JellyfinMediaPlayer` it can be set to `None` inside `_handle_coordinator_update`.\\r\\n\\r\\nWhich begs the question: should `JellyfinRemote` also have a `_handle_coordinator_update` that updates `self.session_data`? :thinking:  Handled in 9eb04ad. Would it make sense to split even further and split the `JellyfinEntity` into a `JellyfinEntity` and a `JellyfinServerEntity`? Because now the `JellyfinEntity` requires an entity description, which results in that we only create a small `RemoteEntityDescription` for the key, and even though it works, we don\\'t really have a good reason to create one.\\r\\n\\r\\n(If we do this, I would recommend doing this in a preliminary PR so we can keep the scope on this one nice and tight :) ) It would also help with always putting in the session id in the unique_id, so adding more entities for the client in the future would be easier > Would it make sense to split even further and split the JellyfinEntity into a JellyfinEntity and a JellyfinServerEntity?\\r\\n\\r\\nNot sure, I\\'m not an expert in this area. I\\'m assuming there was a reason `JellyfinMediaPlayer` was based off of the server-based `JellyfinEntity` so my default stance was not to change that.\\r\\n\\r\\nIMO it makes sense having the server be the base: all entities ultimately are linked (at least conceptually) to the Jellyfin server, with some also being linked to individual clients.\\r\\n\\r\\n> Because now the JellyfinEntity requires an entity description, which results in that we only create a small RemoteEntityDescription for the key, and even though it works, we don\\'t really have a good reason to create one.\\r\\n\\r\\nMy understanding is we want to pass the descriptor to help determine the entity type (e.g. `MediaPlayerEntityDescription` for `JellyfinMediaPlayer` vs. `RemoteEntityDescription` for `JellyfinRemote`). So that information needs to be passed in or set somewhere. Oh but that doesn\\'t matter here, because your `JellyfinRemote` inherits `RemoteEntity` and the mediaplayer `MediaPlayer` entity. We usually use entity descriptions to create 1 generic entity class and change the data and appearance of that entity with injecting an entity description, but that is not the case with the remote When doesn\\'t it support this identifier? Capabilities are reported by clients, some clients can be ephemeral without a persistent identifier (they don\\'t send a device-id back when talking with the Jellyfin server). I don\\'t know if there\\'s a list anywhere of which clients do or don\\'t support a persistent identifier.',\n",
       " \"Can you also add off_grid_unintentional, as I've had a user report it's also a valid state. Fixed in [a682d25]( True is the default value so you can just remove this line. Fixed in [a682d25]( Just a question, but shouldnâ€™t that be for island_status? Yep, in my rush I did it on the wrong line. Good catch. Fixed in [8ef08a5]( From the name it sounds like it should be a `binary_sensor` e.g. status is `True` or `False`? Yeah, it does certainly looks binary\\r\\n#L16 @JEMcats how about you remove it from this PR, as I am going to drop it in Teslemetry and Tessie at the same time in  I have removed the Storm Watch active sensor. [6eb19f6]( Missing translations are probably causing this to result in an update of the snapshot files Same here Should this really be translated same as the one above? I don't think it should be, I'd suggest adding the intentional / unintentional aspect to the translation. are you talking about off_grid and off_grid_unintentional? If the key name contains `unintentional` I guess it would be logic to add that as a word to the translation.  Resolved [d492c28]( I storm mode active still in this PR? It was going to be a binary right? If its not in this PR you need to remove it from strings.json\",\n",
       " 'duplicate statement Not sure if I like github links as manufacturer Tricky bit is that Squeezelite is a software only player and that\\'s the only home page there is for it.  It\\'s also the most common software player by far nowadays in the squeezelite ecosystem, so listing something makes sense.  It\\'s the link which is referenced on the Lyrion home pages.  Or, we could use the Lyrion page which links to it -  if that\\'s preferable? I think we should set it to the manufacturer, as in, whenever I see a manufacturer of a device, I see the manufacturer or the developer, not an URL OK - so you\\'re suggesting we should just have Ralph Irving as the manufacturer then?  If so, that\\'s fine to change as well.  I think that\\'s fine and have made that change. Set to `None` if not set OK - was just trying to avoid \"undefined\" in the device list which is a bit messy.  Is your preference \"Undefined\" then rather than just a blank? I think `None` is the default? returning None leaves the manufacturer as <unknown>.  I\\'ve changed it to None - number of unknown devices is going to be very small anyway. Be beware that device infoes don\\'t overwrite. So try to readd the integration and check again Yes, deleted and re-added.  None returns <unknown>, but that\\'s OK - that\\'ll only be a very small number of devices (Squeezebox, Squeezelite, Squeezeplay will cover the vast majority). This one can be merged with the other one Merged FYI, this says `Squeezelite` while we check for `SqueezeLite`, what should it be? Yes - SqueezeLite is correct.  Test didn\\'t seem to change, but have updated.',\n",
       " \"What entity did we got you to revert in teslemetry or tessie that wasn't a lock? Speed Limit. I made sure not to sneak it in here.\",\n",
       " \"You could also consider adding a listener to the coordinator and check for this at runtime instead of at reload. I have something similar in `airgradient` where I check if the communication method is updated and if it's `cloud`, it deletes all control entities I could do it at runtime, however I don't think its a setting that is going to change that frequently.  At least it seems unlikely that a user would be switching back and forth between coordinator and router modes often. on second thoughts, having the entity created dynamically at runtime will make more sense, once we add the ability to switch Zigbee radio modes from within HA. I have implemented this now. We should not have if statements in test code ok, I guess for now will run all button tests as router, since it has all buttons available. Might change in the future though if other conditional buttons get added.\",\n",
       " \"It is done. Move this to shorthand attribute.\\r\\n`self._attr_name = ...` It is done. Let's add a translation key and use translation placeholders to add the light id. We should however add a space in between the light and the id I guess this can be resolved now :) This test can be removed by parametrizing the `test_light` test:\\r\\n\\r\\n It is done.\",\n",
       " '',\n",
       " '\\r\\nswitched order makes this slightly more readable \\r\\nThose can be combined to a single `if`.\\r\\nDo we need explicit check for `self._attr_fan_modes`? I think if it was `None`, `self._device.current_fan_speed` would also be `None` so this check would never be reached. yes, but mypy doesn\\'t know it and complains about it. Is it fine to leave mypy warnings? Then just leave it in for type safety, that\\'s fine. \\r\\nWe can\\'t ignore mypy warnings as it would not pass CI, but we can either add a check or add `# type: ignore[...]` Have not seen this in UI yet, but should there be a space between the value and the %-sign? <img width=\"182\" alt=\"Screenshot 2024-09-22 at 8 54 04\" src=\"\">\\r\\n\\r\\nLooks good to me without the space.  If you want to go the `CONF_FAN_PERCENTAGES_MODES` route, I think it should be `vol.exclusive` with `CONF_FAN_MAX_STEP`. \\r\\nprevent empty lists \\r\\nthis could be unindented.\\r\\n\\r\\nIf you want to add the space before % `int(fan_mode.split()[0])` could be used (imho slightly better readable). It would be possible to receive a value from bus, that isn\\'t configured as fan_mode. So eg. fan modes are `[33, 66, 100]` and some other device sets the fan to `50`% we would have a mode that isn\\'t available in `fan_modes`. Is this valid?\\r\\nIf not, we could coerce it to the next mode by doing something like\\r\\n I think you want the last value here, no? anyway, I fixed the code to find the closest and added a test for that. Nice idea ðŸ‘\\r\\nOne suggestion though: I\\'d remove `0` from `self._fan_modes_percentages` in the `fan_modes` property. That way if modes are `[0, 33, 66, 100]` and the controller returns `15%` (or lower >0), it would show `FAN_LOW` instead of `FAN_OFF` and the user would have the ability to turn the fan off completely as the OFF item wouln\\'t already be preselected.\\r\\n-> #discussion_r1770825256 Another way would be to not have the `0` item in `self._fan_modes_percentages` and handle `FAN_OFF` explicitly in `async_set_fan_mode(self, fan_mode: str)`.\\r\\nHowever you prefer. removing zero makes sense, because the other use of _fan_modes_percentages, also omit the first element. Would have to add 1 when apply to the mode index. actually, missing around with the index is confusing, I would go what you suggested above. Fixed, I also added a test for the case. Looking at other integrations, it seems common to use a dict for that lookup and an inverted dict for the reverse-lookup instead of using lists with index. \\nBut for plain percent (no low-quiet-mode etc.) I guess index is fine.  \\r\\nImport FAN_OFF and FAN_AUTO from the climate component (alternatively move this enum to knx.climate). \\r\\nWe can then replace `climate.py`\\r\\n\\r\\nwith\\r\\n\\r\\n\\r\\nIn the schema this could even be used like\\r\\n\\r\\n\\r\\nStrEnum should be preferred over plain Enum in HA integrations. Those plain Enums we have are more or less pre-py-3.11 leftovers (although HA had a StrEnum backport before).\\r\\n fixed',\n",
       " \"Please wrap the multiline lambdas to make them stand out from the rest of the parameters we should collect all entities and add them once. \\r\\n\\r\\nAlso, would it be logical to create logic to compare the state of the user on runtime? We could register a listener at the coordinator and check the class of the user and compare that with the class we added entities for, and if they differ delete the entities for that other class. This would also enable us to auto add on reaching level 10.\\r\\n\\r\\nNot a blocker, but maybe a nice way to give the intergation that extra âœ¨  Would love to do that but don't know how, you surely know an integration to get some inspiration from ðŸ˜¬ `airgradient` You can only have 1 setup at a time right?  ? You only have one class right? yes, checking for the players class and selection which skills get loaded happens in the callback\\r\\n\\r\\n But why do we create the full list then? Can't we compare against the chosen class and store for what entities the class has been added? Isn't this the default implementation?\\n\\nAlso, everything starts with ASSETSURL, might as well move that here so you can remove that prefix Is that better now? ðŸ˜\",\n",
       " \"Extra logging Removed Stale docstring? My commit was lost in a rebase again. Personally not a fan of dispatchers anymore, as it's unclear who will be using the signal. Not sure what the official stance from core is on this. An alternative is to share a dict with events between the HTTP view and the WebSocket command. I don't agree. Searching for the signal name will immediately reveal who is involved in the signal. Why reinvent the wheel? The problem is the lack of typing on the dispatcher. The things are too loosely coupled.  Ah, that's indeed a good point ðŸ‘  Can't we add the same type mechanism for that as for `hass.data`? I wonder if this should be a subscription or that actually a normal call could be enough? \",\n",
       " \"So what do we put in here? What's possible? It is the absolute time (ex. 00:00 ~ 23:59)\\r\\nThe reason we didn't use 'time' entity is that we can't cancel with 'None'\\r\\n\\r\\n I am also wondering if `time` entities have you to deal with timezones. I think I'll discuss this with others since I don't think a text entity is a right way to display this (its too free form), you'll hear from me I am waiting for updates from you about this. :) Okay so I discussed this and we think that a text entity is a bad idea since its too free form and a time entity works better for this. But we have a question to make sure that that is the right choice:\\r\\n\\r\\nIs it able to set only one of the two entities? Or do they both need to be set? It is able to set only one.\\r\\nI have a question. \\r\\nDo we have a way to set None to time entity?\\r\\nOr if there is a any new recommendation to cancel the timer, please let me know. @LG-ThinQ-Integration I think you can also use a `sensor` with `device_class: duration`, which supports units like `d`, `h`, `min`, and `s`, or alternatively, use `device_class: timestamp` (like [Home Connect](#L57-L68) do). > @LG-ThinQ-Integration I think you can also use a `sensor` with `device_class: duration`, which supports units like `d`, `h`, `min`, and `s`, or alternatively, use `device_class: timestamp` (like [Home Connect](#L57-L68) do).\\r\\n\\r\\nWe use this to set the timer.\\r\\nBut we can't set with sensor which is read-only.\\r\\n > But we can't set with sensor which is read-only.\\r\\n\\r\\nMy bad. Then the `time` platform is probably the best option. I think that resetting the timer in this case can only be done with a separate `button`. @joostlek \\r\\nDo you agree with this idea?\\r\\nThen we are going to add button entity and time entity.\\r\\nIn my guess, this would take some time and would not be included in the first release.\\r\\nPlease let me know your suggestion.\\r\\n > > But we can't set with sensor which is read-only.\\r\\n> \\r\\n> My bad. Then the `time` platform is probably the best option. I think that resetting the timer in this case can only be done with a separate `button`.\\r\\n\\r\\nbtw, Thank you for the suggestion.\",\n",
       " 'We should not add `unknown`, we should return `None` if that\\'s the case. That will render the entity as `unknown`, otherwise there are 2 `unknown` states to pick from and that\\'s bad This \"unknown\" is for the case:\\r\\n- the device receives a new software version and transmits new values that are not this option list\\r\\n- all new values are displayed by this sensor as \"unknown\", showing that the Lektrico integration needs to be updated too.\\r\\n\\r\\nHow should we handle this case? Thank you. it should return `None` instead of the string `unknown` I removed `unknown`  and used  `None`, thank you.',\n",
       " \"Since it was only 2 states I ended up [switching these](#discussion_r1754085889) to the `binary_sensor` platform in PR #125490 . It makes sense.\\r\\nGiven that the API docs specifies that door states use an enum data type, I believe enum sensors are a better choice.\\r\\nHereâ€™s why: if any of these entities, which we currently assume that they have only 2 states, suddenly support an additional state (like a locked state for doors, or any new possible state), we need to ensure compatibility. This would mean deprecating the binary door sensor and introducing a new enum sensor, along with handling any collateral effects. To me the main reason to use `EntityDescription` data classes was to have a [unified class](#L373-L406) for the Platform to make it easier for entities to be added in the future since a developer or user would only need to add an item to the appropriate tuple instead of duplicating a class and changing its logic.\\r\\n\\r\\nSeparate classes also make it similar to the current method of adding entities which, as you've probably seen in the switch entity, can make adding additional entities complicated and add more duplicate code than necessary. I understand your idea, however, I think that simplifying so much the sensor entity class results in more complicated entity descriptions that contains duplicated code.\\r\\nAlso, this PR was about door enum entities, code quailty improvements and simplifications comes in another PR I'm preparing these days. Is this one still needed here\",\n",
       " \"Not needed afaia rather make this a normal if statement. I would suggest moving that time creation to a separate function to give it extra context about what this function is doing \\r\\nNot needed as `blocking=True` Can we also try covering these lines while we are at it? What do you mean? Add tests for this line. It seems to be the last line that needs coverage, so it would be nice if we could cover everything so we don't regress on it in the future as I assume that the integration will have quite some changes in the future I would move this to a function as well for the context Let's move this out of the class Do you mean to a helper file in Home Connect module? Or maybe to a more general module such `homeassistant.helpers`? you can just create the function on the root level of this file\",\n",
       " 'Got a blocking call error here:\\r\\n\\r\\n `None` is the default so you can probably remove that. Also missing `unit_of_measurement`.\\r\\n\\r\\nFor `native_step`, this is what I get back from the API for my fridge:\\r\\n\\r\\n Awesome!\\r\\nstepsize wasn\\'t documented on the API docs, this is a great addition! Yeah, and the simulator doesn\\'t return `stepsize` either so I don\\'t think there would be any way to know. Aren\\'t these in `homeassistant.const`? Nope, but they are in `homeassistant.components.number`, maybe we can use those If we use those values, would it be okay if I use `\"max\"` and `\"min\"` in the test to ensure that if the constants\\' values change in the future, we\\'ll know that we need other constants? stale docstring Why do we run this here? Do we expect it to change on runtime or is this just for the first time running? Otherwise I would suggest adding the function to `async_added_to_hass` Is just for the first time running (or the following times if home assistant is not able to fetch it) What the hell has 3 wine compartments This is present in all the tests for Home Connect, among other integrations such as Azure Data Explorer, Bang & Olufsen, and Tibber. uuuuugh, we can use `is` here since its an enum Sure! What I meant in the previous message is that we should also consider changing those in the future. (and even maybe leave the ones from this PR for that change also)',\n",
       " 'Why is every scene its own device? It doesn\\'t need to be. Scenes are not a device in the real world, so we could skip this part. But I am interested in how they work since they are linked to a room On the automatically created dashboard it puts them into the corresponding room:\\r\\n<img width=\"595\" alt=\"image\" src=\"\">\\r\\n It works the same as with other entities which have device information:\\r\\n<img width=\"1088\" alt=\"image\" src=\"\">\\r\\n yeye, I get that, but how does Scenes work in the world of WMS It is basically just a one-off trigger of saved target states. You configure them like this:\\r\\n![image](\\r\\nYou can add any WMS device/destination there and set a desired target state. Scenes in WMS are basically the same thing as in [HA]( \"A scene entity is an entity that can reproduce a wanted state for a group of entities. A scene entity can activate the scene towards a group of devices but remains stateless ...\" Check. Yea I remember that Hue also has scenes, but they are coupled to the group they affect Okay, so should I remove or keep the device info? I just checked: The following integrations also provide DeviceInfo for Scene implementations:\\r\\n- fibaro\\r\\n- hue\\r\\n- litejet\\r\\n- lutron_caseta\\r\\n- tuya I did some more research and found out the following:\\r\\n\\r\\n**Fibaro** links the scenes to the **hub** device:\\r\\n#L51-L54\\r\\n\\r\\nHue actually links the scenes to the **room/zone** device:\\r\\n#L103-L107\\r\\n\\r\\n**Litejet** links the scenes to the **hub** (mcp?) device:\\r\\n#L51-L56\\r\\n\\r\\n**Lutron Caseta** links the scenes to the **hub** (bridge) device:\\r\\n#L41-L43\\r\\n\\r\\nOnly **Tuya** links the scene to its own (scene_id) device:\\r\\n#L37\\r\\n#L44-L50\\r\\n\\r\\nSo, we have **Hue** linking to rooms, 3 others linking to their hub and just **Tuya** creating per scene devices.\\r\\n\\r\\nBased on these findings, any suggestion on how to move forward?\\r\\n \\r\\nRather call it something else than Pascal_Case That is too similar to the new class `WebControlProScene` implemented here. Also, the `WMS_*` prefix with CamelCase is used for other imported constants from `pywmspro`.  Personal preference, have the bigger objects first We had this exchange before regarding the base entity class and destinations. Since I cannot base the Scenes on the base entity class (but other device types will follow doing that, don\\'t worry), I would like to keep the parameter order at least aligned with that:\\r\\n#L20 We should rather have a device per area Implemented, thanks for the feedback. ðŸ‘  Model name based on Hue integration.',\n",
       " \"Please bump in a separate PR Can we refactor this to return a EntityDescription?  for sure, will do I think this part should be like\\r\\n\\r\\n\\r\\nand the thing down below can use `.replace` to add the UoM and device class\\r\\n\\r\\nWDYT? will do with `.replace` you meant like that? \\r\\n`entity_description.native_unit_of_measurement = UnitOfEnergy.WATT_HOUR` `dataclasses.replace` you only have to parenthesize lambdas if they span more than one line will remove What will the unique_id be? unique_id is assembled in entity.py using device serial and entity description key. entity description key is ATTR_RESETTABLE_COUNTER or ATTR_NON_RESETTABLE_COUNTER with added counter index\\r\\n\\r\\nIn line 177 in sensor.py (get_counter_entity_description) i use .format to add index\\r\\n\\r\\n i hope this is OK.  Can the counter change? We want to avoid setting up and having the data point that previously represented counter `1` to be counter `2` and vice versa they cannot those counters are directly from the energy meter's registers, always in same order\",\n",
       " \"Should we just fallback to the device class provided translations? That would mean the name would become `battery`.\\r\\nWe already have a sensor called `battery` showing the state of charge in %.\\r\\nI found that too confusing, that's why I named this type of binary_sensor as `battery_state`. I don't mind changing to the device class provided translations, but maybe it's an idea to improve the naming for these particular battery `binary_sensor` and `sensor`? But that would break stuff ðŸ˜®\\u200dðŸ’¨  In that case I would like to keep the name as is ðŸ˜ƒ \",\n",
       " 'So why do we observe states? We can inline this Still relevant the host is a bad unique_id since it could change. If there is nothing unique to be used, use `async_abort_entries_match` They are required and have defaults, why do you still use `.get()` in `__init__.py`? unused why do we store this twice? (Or three times if you could the state of the library?) I would suggest to remove the `self.devices` and co.\\r\\n\\r\\nEither make this return `None` and just update the client and read the state in the entities via `self.coordinator.client`. OR make a dataclass with the data you want to store in the state and replace this dict with creating that dataclass and access it typesafe via `self.coordinator.data` Raise `UpdateFailed` Still relevant Overwrite the config_entry typing in the coordinator This doesn\\'t sound like a sensor. States have a max length and this sounds like it could reach it.\\r\\n\\r\\nEither create entities for those devices and make them proper devices (via `via_device` you can link devices to other devices so you can see it as \"connected via\") or make this an action call (separate PR) Not a good unique_id. Rather use `entry_id`. Please use the common translation keys here and use `data_description` to add context Use common keys The host is a bad unique_id as it can change You need to pass in data IIRC Please add a return type Please add the type of the async_update_data as generic type \\r\\n Not needed Do we have something more unique for the device other than the device name? Please wrap the lambda in parenthesis What are the possible states? Are they custom? Please run async_add_entities once, so extend the for loop in the `async_add_entities` to include the `for device ...` Please don\\'t log in a constructor',\n",
       " '',\n",
       " '\\n Have you considered just creating the object in init.py and passing it to the coordinators separately  hmm, no I didnt, that would be simpler for sure! Why does it extend? I think was due to type errors, but not quite right, will fix Why do you change this type? If you share a lot of logic I think creating a base coordinator is better. Withings has some of these ok I see, yes base coordinator here is cleaner. you should overwrite the coordinator which is used, just like how the entity_description type is overwritten oh yes, of course..',\n",
       " '',\n",
       " 'If you have this everywhere, consider moving it to `AirzoneEntity`',\n",
       " 'Please use the DeviceClass.RESTART I added DeviceClass.RESTART, thank you. Please don\\'t raise integraton here I removed it, thank you. Stale docstring I updated it, thank you. I removed translation_key=\"reboot\", thank you. I am missing the `strings.json` changes (and maybe `icons.json` if you want custom icons for htese entities) I added buttons in strings.json, thank you. I removed the reboot button from strings.json, thank you.',\n",
       " \"Is this true? Do we know what the current option is? Shouldn't it be set to `None`, causing the entity to show unknown? yes, good call. fixed.\",\n",
       " \"Let's add the name and description to `strings.json`. That way they can be translated into other languages.  Same These are already defined in `strings.json`\",\n",
       " 'joostlek reviewed>\\r\\nThe class is always created right? Should we make it not nullable?\\r\\n\\r\\nMy comment>\\r\\nWhat if mqtt is not working, but the other cloud functions are working well temporarily?\\r\\nDo we have to stop other functions?\\r\\nIf we want to keep the functions to work, we should allow None for \\'mqtt_client\\'. can a message not have a deviceId? Updated as below\\r\\n\\r\\ndevice_id = message[\"deviceId\"]',\n",
       " 'If the source entity gets the wind speed device class this can be omitted Since same key _for_location exist, I want to maintain the \"wind_volume\". Why exactly? You can just remove this one and save translations for our contributors  Please revert this one Please revert the change of the references Reverted. This can be removed if the entity gets device class battery',\n",
       " \"\\r\\n\\r\\nThis should not be needed if you move the entity description class and definitions above the `RingNumber` class which is where they should be anyway (n.b. some other ring entities still need to have this cleaned up) Oh yeah, I didn't realize that. The whole structure was copy & paste from `switch.py` I think :thinking:  Fixed in 4da13d3e28 This can be done in one step:\\r\\n ad988f8218 \\r\\n**If**  gets merged before this PR you should drop the `no_updates_until` logic in favour of replacing `exception_wrap` with `refresh_after`. This is an old pattern that is not covered by tests and the `refresh_after` is more deterministic.\\r\\n\\r\\nEDIT: Actually having now tested this with my ring devices I think you should probably wait until  is merged and then pick up the `refresh_after` because when I set the volume, the volume sensor remains on the old value until the next refresh which can be up to a minute.\\r\\n\\r\\nEDIT:  has now been merged so you can pull in the changes and use `refresh_after`. You will need to configure the mock [like in this example](#diff-b487e8bddceac9e066a21d6090120f137d32187383b9a18ae4f2a0abe0f531f1R157-R163) so that the new state will be returned after the refresh. Awesome, that's good timing that #125775 just got merged. Here are my changes: cf98410b18. I hope I didn't miss anything. FWIW, tests are passing and setting volume still seems to work. \\r\\nThis comment is not relevant to this platform as it doesn't use the history. 096dccd9b1 \\r\\nWe shouldn't need the null check `value_fn` may return `None`, at least according to the type definitions:\\r\\n\\r\\n\\r\\n\\r\\nSince `float(None)` raises an exception, I think the check should stay. As above cf98410b18 As above cf98410b18 \\r\\nThe setters take a float and do the conversion\\r\\n\\r\\nEDIT: Actually I've just realised this looks like a mistake. This should be doing\\r\\n`await self.entity_description.async_setter(self._device, value)` instead of `getattr` on the device. Yup, good catch! I noticed the same when I saw your review yesterday :) Forgot to adapt this part after refactoring. Fixed in 23deff562e This can be combined with the `RingChime` `volume` entity description above as per the `sensor` implementation. I have separated them because they don't have the same max. volume, at least according to the `python-ring-doorbell`:\\r\\n\\r\\n\\r\\n\\r\\nThat being said, I *think* that `CHIME_VOL_MAX` is wrong. It should be `11` as well. Since happen to be the maintainer of that library, you may consider this an informal bug report :smile:  It would be great if you'd submit a PR to the library as I don't have a chime myself to test with (and it'll be tiny). It might also encourage you to add more amazing features to the lib ðŸ˜„  Can you also add the same icons for the other volume entities under `sensor` 5f6260f8ba 1df09e7b65 \\r\\n\\r\\nAnd please do this tweak for the other tests below. 3af64af837 1df09e7b65 A better way to do this would be to use the snapshots. See #L32 for an example. To generate the snapshot run `pytest tests/components/ring/test_number.py::test_states --snapshot-update` \\r\\n\\r\\nPrefer the constants which are here:\\r\\n\\r\\nexcept for `ATTR_ENTITY_ID` which is in `homeassistant.const`. See e2d2a9dfdd\",\n",
       " 'Should we just create a new MockConfigEntry just so the test will keep working in the future, independent of what happens with the `entry` fixture? Done Should we use `data_description` to give more context to the user about what this means for them? I added the `data_description` to those two options. We only use v1_1 here right? Should we just create it here instead of using a fixture? I find it kinda strange to use a fixture for a test and directly run async update entry to modify it I removed the fixture and added a parameter to `create_config_entry` to set the version.',\n",
       " \"When a flow is aborted, we update discovery data if there's an existing ignored entry with matching `unique_id`.\\r\\n\\r\\nWe keep more than one item of discovery data to handle cases such as:\\r\\n- `cast` where a single config entry manages all Google Cast devices\\r\\n- integrations which support more than one kind of discovery If `zeroconf` is an instance attribute we don't need to pass it around to instance methods. You're right, but the zeroconf instance is passed to us by the zeroconf callback, I didn't want to change the existing pattern. I can clean it up though? Follow up is ok too. What other result types do we expect here? `async_finish_flow` is called on `FlowResultType.ABOIRT` and `FlowResultType.CREATE_ENTRY`.\\r\\nI agree it's not clear, a separate PR could add that to the docstring of `async_finish_flow`, in `FlowManager` and in derived classes? Done in PR  I don't completely follow how storing a single key here plays with updating many known keys with a discovery key above when finishing the flow. There will only be a single active discovery flow per device, also when the integration has multiple discovery sources for the same device. `async_step_ignore` is called when the user ignores a discovered device or service, we then store the key for the flow being ignored.\\r\\n\\r\\nOnce the ignore config entry is created, the code above will make sure the discovery key is kept up to date since it may not be stable unlike the unique id.\\r\\n\\r\\nIf this explanation makes sense, should I add it to the docstring? That makes sense. Please add it to the docstring. :+1:  Should we trigger rediscovery also when non-ignored config entries are removed for a more consistent experience, i.e. removing any discoverable config entry will make it show up again as discovered? Sounds good. Should we use the fixture that does this instead? yeah, definitely. Tests added in the PR should use the fixture, and existing tests improved in a separate PR. Separate PR for existing tests:  The reason for the `MappingProxyType(dict(key))` is to avoid multiple layers of `mappingproxy` when updating the config entry. Maybe it would be better to use a helper function which inspects each item and only wraps mappingproxy when needed? Looks like this line is not covered\",\n",
       " \"Modified The class is always created right? Should we make it not nullable? What if mqtt is not working, but the other cloud functions are working well temporarily?\\r\\nDo we have to stop other functions?\\r\\nIf we want to keep the functions to work, we should allow None for 'mqtt_client'.\\r\\n Why do we set it to this high value? I don't expect a majority running their HA for 180 days straight Changed to 1. Can we catch more specific exceptions? We only allow the config flow to catch bare Exceptions Modified idem idem idem idem \\r\\nThis will log the stacktrace as well Can this raise? We should only have stuff in the try block that can raise Modified\",\n",
       " \"Should we add a device class? This same as temperature in sensor.\\r\\nWe don't use device class to support Fahrenheit dynamically.\\r\\nex> When a user change UoM in the mobile app, the cloud send the temperature to the integration with UoM.\\r\\nKeep it as is.\\r\\n But we also want to allow the users to set the UoM via HA. The device class helps with categorizing entities to what their data point means The device_class converts the Celsius's min/max when config's unit is Fahrenheit. But native_step is not converted by config's different unit so the same issue as async_set_native_value occurs.\\r\\n- climate: #discussion_r1765990233\\r\\n\\r\\nWe don't want to use devices_class(NumberDeviceClass.TEMPERATURE) except for climate. unit of measurement? It is level value.\\r\\nFan speed : 0 ~ 2\\r\\nBrightness : 0 ~ 4 I might think that having this as a select entity would be more useful, but I don't think it's a blocker Because their type is range(has min/max/step) we want to use number entity.\",\n",
       " \"Who do we have 2 Turbo? Because we have device variations, some devices use 'power' for 'Turbo' and other devices use 'turbo' for 'Turbo'. These all sound like they should be switches instead If we move them to the siwtch, \\r\\n'header toggle' switch to control all together is enabled automatically.\\r\\nCan we disable it? Or we want to keep these here. What's header toggle? If there are more than one switch, a switch that control everything is enabled.\\r\\nIt is a header toggle. So how is that enabled then? We choose what entities we want for what device right? Of course, we can control each.\\r\\nBut those switches are not irrelevant.\\r\\nSo it is quite awkward to control them with a 'header toggle' at once.\\r\\nWe don't want that UX.\\r\\n I think I'm not completely understanding. These selects are now used for toggling features of a device.\\n\\nYou're talking about a switch that can turn off everything?\\n\\nWhere does that header toggle come from? (Where does the name come from? I'm assuming it's a toggle in a header, but nothing comes to mind when thinking of that, so if you have a screenshot of the problem, yes please) Problem>\\r\\n![Screenshot_20240927_155615_Home Assistant](\\r\\n\\r\\nOur intention>\\r\\n![Screenshot_20240927_155559_Home Assistant](\\r\\n The related front -end code is as below.\\r\\n#L120\\r\\n I also discussed this one and we came to the following conclusions:\\r\\n1. A humidifier is better represented by a [humidifier entity](\\r\\n2. You can set the `entity_category` of those entities to `EntityCategory.CONFIG` and it will not show up on the default dashboard\\r\\n3. This is mostly a frontend thing. We should not change choices in the backend because the frontend handles it differently.\\r\\n\\r\\nDoes this help? > I also discussed this one and we came to the following conclusions:\\r\\n> \\r\\n> 1. A humidifier is better represented by a [humidifier entity](\\r\\n> 2. You can set the `entity_category` of those entities to `EntityCategory.CONFIG` and it will not show up on the default dashboard\\r\\n> 3. This is mostly a frontend thing. We should not change choices in the backend because the frontend handles it differently.\\r\\n> \\r\\n> Does this help?\\r\\n\\r\\n1. \\r\\nAs we tested, humidifier entity doesn't support steps,\\r\\nand our devices only support 5 steps.\\r\\nIt causes errors whenever a user set humidifier target value.\\r\\nThat's why we didn't use humidifier entity.\\r\\nIf I am not right, please let me know.\\r\\n\\r\\n2.\\r\\nIf we set the 'entity_category' of those entities to 'CONFIG', \\r\\nthose entities are not added automatically when a user finishes config steps.\\r\\nThen I guess it could be some kind of burden to a user a little bit.\\r\\nBtw, I agree that this might be one of the best solutions to remove 'header toggle'\\r\\n\\r\\nIn conclusion,\\r\\nif you don't want us to use 'select' instead of 'switch',\\r\\nwe need to discuss your suggestion(no. 2) internally.\\r\\n Yep, please discuss this internally. I think it's good to know not a lot of users are using the default dashboard, so it probably won't affect that much users. Also, a new updated default dashboard is on the roadmap, so eventually it will be better (I don't think that they are planning to use that frontend card, so that means no header toggle) > Yep, please discuss this internally. I think it's good to know not a lot of users are using the default dashboard, so it probably won't affect that much users. Also, a new updated default dashboard is on the roadmap, so eventually it will be better (I don't think that they are planning to use that frontend card, so that means no header toggle)\\r\\n\\r\\nI just want to make sure what you want.\\r\\n1) Not using humidifier entity is acceptable\\r\\n2) Changing entities to CONFIG is strongly recommended.\\r\\n\\r\\nAm I right? > Not using humidifier entity is acceptable\\r\\n\\r\\nI still need to look into what ours support and what you will support, I'll let you know\\r\\n\\r\\n> Changing entities to CONFIG is strongly recommended\\r\\n\\r\\nWhen they are used for configuration yes, if they are used for control not. So the power on switch would not have the CONFIG, but one setting a certain mode does have it > As we tested, humidifier entity doesn't support steps,\\r\\nand our devices only support 5 steps.\\r\\nIt causes errors whenever a user set humidifier target value.\\r\\n\\r\\nSo you mean you have like 0%, 20%, 40%, 60%, 80% or something along those lines as modes to set the target humidity to? > > As we tested, humidifier entity doesn't support steps,\\r\\n> > and our devices only support 5 steps.\\r\\n> > It causes errors whenever a user set humidifier target value.\\r\\n> \\r\\n> So you mean you have like 0%, 20%, 40%, 60%, 80% or something along those lines as modes to set the target humidity to?\\r\\n\\r\\nYes, that's correct. All switch-like entities are removed from 'select' platform.\\r\\nLet me add those entities into 'switch' platform with a new PR later. idem idem I learned 'idem' from you. :) I think this is added accidentaly Oh, you are right.\\r\\nRemoved.\",\n",
       " 'This PR is changing our entity model. Before we can review this PR there needs to be approval in a discussion in our architecture repository.\\r\\n\\r\\n\\r\\n\\r\\n#changing-the-entity-model Oops, I missed those docs! Done:  â¤ï¸ ',\n",
       " \"Please leave the dependency bump out of this PR.\\r\\nThere is a PR that bumps the library: \\r\\n\\r\\nOnce that is merged, I'll rebase this PR and fix that last error. no device class? added Please don't duplicate the same fixture in different modules. Put it in the `conftest.py` module instead. Those fixtures can be accessed by the whole test package.\",\n",
       " '\\r\\n`from homeassistant.components.button import DOMAIN as BUTTON_DOMAIN` done in  and  idem done in ',\n",
       " \"\\n I think we have a device class for this If we use the device class, we can't use the name and icons that we want.\\r\\nWe want power on/off icons, but device class provides plug on/off icons.\\r\\n\\r\\nPlease let me know if not. You can overwrite the icons in the icons.json. but adding a device class helps with contextualising datapoints Translation key is not used  Removed\",\n",
       " 'You overwrite later on line 142, so no need to set it like this Removed I think this does the same It generates ruff syntax error.\\r\\n\\'Assignment expression target must be an identifier\\'\\r\\n\\'cannot use assignment expressions with attribute  [syntax]\\'\\r\\n\\r\\nKeep it as is\\r\\n The values we initialize with `None` can be moved outside of the constructor. The `_attr_temperature_unit` can also be moved outside of the constructor _attr_temperature_unit has to be initialized in constructor() because runtime error can be caused in super().__init__().\\r\\nKeep it as is. `super.__init__()` doesn\\'t contain any references to this right? Since we haven\\'t defined for temperature_unit\\'s property , we need this statement for initialization.\\r\\nOtherwise, the following error occurs.\\r\\n2024-09-19 10:17:21.937 ERROR (MainThread) [homeassistant.components.climate] Error adding entity None for domain climate with platform lg_thinq\\r\\nTraceback (most recent call last):\\r\\n  File \"/usr/src/homeassistant/homeassistant/helpers/entity_platform.py\", line 598, in _async_add_entities\\r\\n    await coro\\r\\n  File \"/usr/src/homeassistant/homeassistant/helpers/entity_platform.py\", line 816, in _async_add_entity\\r\\n    capabilities=entity.capability_attributes,\\r\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/src/homeassistant/homeassistant/components/climate/__init__.py\", line 323, in __getattribute__\\r\\n    return super().__getattribute__(__name)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/src/homeassistant/homeassistant/components/climate/__init__.py\", line 489, in capability_attributes\\r\\n    temperature_unit = self.temperature_unit\\r\\n                       ^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/src/homeassistant/homeassistant/components/climate/__init__.py\", line 323, in __getattribute__\\r\\n    return super().__getattribute__(__name)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/local/lib/python3.12/functools.py\", line 995, in __get__\\r\\n    val = self.func(instance)\\r\\n          ^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/src/homeassistant/homeassistant/components/climate/__init__.py\", line 579, in temperature_unit\\r\\n    return self._attr_temperature_unit\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/src/homeassistant/homeassistant/components/climate/__init__.py\", line 323, in __getattribute__\\r\\n    return super().__getattribute__(__name)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/src/homeassistant/homeassistant/components/climate/__init__.py\", line 323, in __getattribute__\\r\\n    return super().__getattribute__(__name)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\nAttributeError: \\'ThinQClimateEntity\\' object has no attribute \\'__attr_temperature_unit\\'. Did you mean: \\'_attr_temperature_unit\\'?\\r\\n Why is the step affected by the temperature unit? For example,\\r\\nwhen step is 0.5 and unit is F, \\r\\nit causes the calculation error.\\r\\nKeep it as is. Causes calculation error where? When device\\'s step is 0.5 and HA\\'s config\\'s unit is Fahrenheit, then async_set_temperature has same output value\\r\\nby +, - climate\\'s button.\\r\\n\\r\\nFor example 65.0 and 65.5 has same output converting to Celsius by _round_by_step.\\r\\n1. 65.0F -> 18.333333333333332 -> 18.5\\r\\n2. 65.5F -> 18.61111111111111 -> 18.5\\r\\n\\r\\nSo, if it is less than 1, it needs to be corrected to 1. I think if the temperature is in the kwargs its always a float\\r\\n Modified. unused Removed',\n",
       " \"What other platforms will you add? You might want to move the `_attr_name = None` to the media player, since the other platforms you will add probably won't have the device name as the entity name Yep, good catch. I'll be adding an update entity and a few switch/button entities. the client is only used in local contexts and not transferred to another step You never abort like this I am missing the zeroconf test where we try to discover an already added device, and the zeroconf test where the device doesn't respond\",\n",
       " \"\\r\\nWe want lowercase UoMs, but I do see that the rest doesn't have this, so that would be a nice followup\",\n",
       " 'Why not use a future ? It allows error and result.  I assumed you wanted me to use a listener instead :smile:  Kept the future Where do we test unsubscribing? Added a test',\n",
       " '',\n",
       " 'Therese changes should not be in the same PR as the esphome changes. Tests are also missing. Created a new PR for this: ',\n",
       " \"No need to overwrite as it's already set in `self._attr_supported_features` Can be set outside of the constructor why would it be none? Why don't we use `close_valve`? I think you can also remove those Don't do this, rather just import what you need I don't think you need to add the job thing for it to work. i have to, otherwise i get this error: \\r\\n`RuntimeError: Detected that integration 'ads' calls async_write_ha_state from a thread other than the event loop, which may cause Home Assistant to crash or data to corrupt. For more information, see #async_write_ha_state at homeassistant/components/ads/valve.py, line 83: self.async_write_ha_state().` No I mean, when you close a valve, it will automatically request a state update afterwards, and that will run in `update` in the entity.py true. tested it, thank you!\",\n",
       " 'Duck type safety\\r\\n > Duck type safety\\r\\n\\r\\nexcept here we know the exact type of the event, so should already be type safe? I have applied your other suggestions, Thanks!\\r\\n\\r\\n Entirely fair! Was mainly thinking along the lines of how we may know the type of event, but not the type of `event.settings` itself (hence the need for the `None` check at all) Instead, just fetch the function the library received via the mock call arguments. This is implemented in `knocki` ok I see. have implemented something similar.',\n",
       " 'We should remove the if statement, so rather just put the serial numbers as parameter.I think > We should remove the if statement, so rather just put the serial numbers as parameter.I think\\r\\n\\r\\nThese are now removed.',\n",
       " \"you can overwrite the `config_entry: ConfigEntry` type outside the constructor here and then you can remove this assert ðŸ‘ðŸ» done. \\r\\nDoing this removes the need for this local type overwrite ðŸ‘ðŸ» Done. You can use snapshots here ðŸ‘ðŸ» Done I personally don't like the name `test_coordinator` as it assumes an internal feature to be used. I think these are runtime tests and fit in `test_init` ðŸ‘ðŸ» Done.\",\n",
       " \"It should at least be unique in the platform.\\r\\n That's what I was thinking of doing too, but I wasn't sure about the naming convention.\",\n",
       " 'I don\\'t quite follow why we need to look at samples here, rather than simply pass `(state_change, entity_available, last_updated_time_seconds)` to `_remove_labelsets`? Thank you for pointing out my confusion. The other comment helped a lot too. Could we skip based on the key in `self._metrics`? It\\'s supposed to be the metric name anyway. Yes, this makes things much better. Thanks! The comment says \"all metrics\" which is no longer accurate, could you please adjust it? I don\\'t quite understand the reasons for resetting the registry and re-initializing the component here. I tried to [remove it]( and the tests were still passing. Perhaps this was necessary when new behavior was behind a configuration flag, but it\\'s not anymore? Yes, it was some kind of leftover code. I\\'ve removed it. Thanks!',\n",
       " 'Please wrap multiline lambdas in parenthesis If we only have 2 options, shouldn\\'t this be a binary sensor? I had as an `ENUM` state since the API returns an `ENUM` type, though since only two values are ever returned and there\\'s a `DOOR` `device_class`, making it a binary_sensor makes more sense. Please use lowercase names, you can use translations to uppercase them I am missing all entity translations in strings.json Mistake on my part not checking in `strings.json` and `icons.json` So according to icons.json, these have 2 states. Let\\'s make this an ENUM device class sensor and add the possible states in snake_case in a list in `options`. This allows HA to know the possible values and help out with automating the state [3 states](#L47) actually, the default state is `off`. Also, `SensorDeviceClass.ENUM` is the [default](#L45) device class for this child class. What\\'s confirmed? From the [API](#event-present-state-enumeration):\\r\\n> Description: The event has been confirmed by the user.\\r\\n\\r\\nBasically an acknowledgement of the alert by the user. It can be done at the appliance or in the Home Connect app. I plan on making a button entity for thin in HA. For documentation purposes -\\r\\n\\r\\nAlarm off (Default):\\r\\n<img width=\"323\" alt=\"Screenshot 2024-09-11 at 9 12 57\\u202fAM\" src=\"\">\\r\\n\\r\\n\\r\\nAlarm State:\\r\\n<img width=\"322\" alt=\"Screenshot 2024-09-11 at 9 22 45\\u202fAM\" src=\"\">\\r\\n\\r\\n\\r\\nAlarm Acknowledged:\\r\\n<img width=\"319\" alt=\"Screenshot 2024-09-11 at 9 23 03\\u202fAM\" src=\"\">\\r\\n We should add translations for the states  > We should add translations for the states\\r\\n\\r\\nI think I understand now. So missing translations is why they `present` and `confirmed` state are lower case? I\\'ll add the string translations, thanks! Yes, and we should move the placeholders to be translations themselves @joostlek, I\\'m seeing the translations for both the icons and states in the UI, though I\\'m wondering if this was not according to your recommendation. I can refactor it if you see an improvement that can be made. Thank You. We should not put the full name as placeholder, rather just make this a normal translation stale docstring I would imagine that this is only for the alarm entities, and the class name now implies its for every sensor Yeah, my goal was to get a single [description](#diff-04bb25b821c929e1f88647c802d692fdb154cc832f5570590c7c2f48feecf442R83-R96) and [entity parent class](#diff-04bb25b821c929e1f88647c802d692fdb154cc832f5570590c7c2f48feecf442R360-R364) for each sensor. Though because of the current implementation that does not utilize `entity_descriptions`, I didn\\'t want to make any breaking changes before migrating entities over.\\r\\n FYI, there\\'s another PR for that rework in the works by someone else, it\\'s linked to this PR It would be nice if we can refactor the integration to at some point use translations like normal so we can make the intergation more accessible for non native english people But in a followup I\\'ll have to research this, would you know of a similar integration that does translations well?',\n",
       " \"Please extend config entry typing and store the coordinator in entry.runtime_data Please use cannot_connect Can't we do this after we got the credentials? You are allowed to login via either `username` or `email`. I did this with the intent of blocking setup if either was the same, but didn't also grab the username from the auth response. That has been corrected. Now if you try to setup an entry using `username`, then another using `email` it should abort. I added a test for this use case as well. There's always a config entry, please overwrite the typing for this coÃ¶rdinator Please remove empty fields I think we can remove this and the forward part `internal_user_id` sounds quite unique to me tbh This is how the data comes back in their auth API response. I've got no control over naming here ðŸ¤·\\u200dâ™‚ï¸  No I mean, this sounds like a plausible unique_id to use Oh, so instead of the data check, you are suggesting to use:\\r\\n\\r\\n\\r\\n\\r\\ncorrect? I think so, yes consider doing it like `airgradient` where you can autospec the mock why don't we continue the flow we already started Do you really need the `RequestInfo`? Can't instantiate a `ClientResponseError` without it. In `august` tests I see `ClientResponseError(None, None, status=401)` Ideally parametrize this test\",\n",
       " 'Have you considered just using translations as they are meant to be? They\\'re called \"translations\" for a reason :P. Please add the names to `strings.json` Only have stuff in the try block that can raise the problem is that it will be more code and more tests if I separate the stuff that can raise and return\\r\\n\\r\\n\\r\\n    def native_value(self) -> float | None:\\r\\n        \"\"\"Return the state of the sensor.\"\"\"\\r\\n        try:\\r\\n            value = self.entity_description.value_fn(self.coordinator.data)\\r\\n        except AttributeError:\\r\\n            return None\\r\\n\\r\\n        if value is None:\\r\\n            return None\\r\\n\\r\\n        try:\\r\\n            return float(value)\\r\\n        except ValueError:\\r\\n            return None\\r\\n We would need tests for all cases anyway. I am mostly wondering why we `float()` @joostlek changed the code to this. But can\\'t make the attributeError test work.\\r\\nwould assume this would work:\\r\\n\\r\\n```\\r\\nasync def test_current_temperature_attribute_error(\\r\\n    hass: HomeAssistant,\\r\\n    mock_bsblan: AsyncMock,\\r\\n    mock_config_entry: MockConfigEntry,\\r\\n    freezer: FrozenDateTimeFactory,\\r\\n):\\r\\n    \"\"\"Test current temperature when an AttributeError is raised.\"\"\"\\r\\n    await setup_with_selected_platforms(hass, mock_config_entry, [Platform.SENSOR])\\r\\n\\r\\n    # Set up the mock to raise an AttributeError\\r\\n    mock_bsblan.sensor.return_value.current_temperature = AsyncMock(side_effect=AttributeError)\\r\\n\\r\\n    # Trigger an update\\r\\n    freezer.tick(timedelta(minutes=1))\\r\\n    async_fire_time_changed(hass)\\r\\n    await hass.async_block_till_done()\\r\\n\\r\\n    # Check the state\\r\\n    state = hass.states.get(ENTITY_CURRENT_TEMP)\\r\\n    assert state.state == STATE_UNKNOWN\\r\\n It should be a float value? (if sensor is not working on heater the return would be \\'---\\' and this is not a float. so we should check for float value? or should I change the python lib to return none when it receives \\'---\\'? Never mind. I figured it out. This is already captured in the test_sensor.ambr snapshot Let\\'s not do this :)',\n",
       " 'Looking at the Rest API for available commands, I wonder if adding the S1, S1 Plus, K10+ and K10+ Pro can be done using the same code. Yes, I think so but I have only the K10+.  \\r\\nWe add them without testing? I made the change If the API says it us compatible, let us try! Can we make these snake_cased names? Like `quiet`? This way we can translate them properly and the values still make sense when templating Yes, it\\'s possible. I\\'ll make the change Ok, I made the change What can the state be? Shouldn\\'t it be mapped to the HA vacuum states? I don\\'t know.  \\r\\nThe state sendes by switchbot :\\r\\n- StandBy\\r\\n- Clearing\\r\\n- Paused\\r\\n- GotoChargeBase\\r\\n- Charging\\r\\n- ChargeDone\\r\\n- Dormant\\r\\n- InTrouble\\r\\n- InRemoteControl\\r\\n- InDustCollecting #states So, ok, thinks for the link :-)  \\r\\n\\r\\nBut, can we discuss for mapping switchbot state and HA state ?  \\r\\n- StandBy -> STATE_IDLE ?\\r\\n- Clearing -> STATE_CLEANING\\r\\n- Paused -> STATE_PAUSED\\r\\n- GotoChargeBase -> STATE_RETURNING\\r\\n- Charging -> STATE_DOCKED but this state indicate also the charging\\r\\n- ChargeDone -> STATE_DOCKED \\r\\n- Dormant -> STATE_IDLE ? \\r\\n- InTrouble -> STATE_ERROR\\r\\n- InRemoteControl -> STATE_CLEANING but with manual control ?\\r\\n- InDustCollecting -> STATE_DOCKED ? I don\\'t have such device, but from what it looks like it sounds good Ok, I made the change Let\\'s put the list outside of the class We can add these fan speeds to the translations Hum, ok, but how to do it?  \\r\\nMaybe in const.py? Or in other file?\\r\\nAnd I suppose, same things for mapping state switchbot to HA? What\\'s the best?  \\r\\n- `_attr_fan_speed_list: list[str] = [VACUUM_FAN_SPEED_QUIET, VACUUM_FAN_SPEED_STANDARD, etc.]`\\r\\n- or `_attr_fan_speed_list: list[str] = VACUUM_FAN_SPEED_LIST` And last question, I\\'m not sure how put translation.  \\r\\nCould you give me a example or an other file with an usage, please?\\r\\nThanks in advance So, I use constant for each terme \"quiet\", \"standard\", \"strong\" and \"max\" and put it in const.py file  \\r\\nI use a dict for mapping speed to speed waiting by switchbot  \\r\\n  \\r\\nFor translation, I don\\'t know how do it so, I wait for your response Let\\'s remove the comment ok, I\\'ll do it done! Idem done! \\nThis way if there\\'s a state not in the list, it will show up as unknown ',\n",
       " 'Please bump in a separate PR Hi, the new library is necessary for Covers to work, and just making a separate PR that only bumps the lib version seems unnecessary and extra work also for the reviewers No, that\\'s what we want to happen because then we extract what is needed for that library bump to work I\\'m sorry, I\\'m not following you on this one. What would change if I made a separate PR before that? Whatever you could do \"then\" to \"extract what is needed for that library bump to work\" wouldn\\'t also work in this PR? I\\'m confused by what you are saying.\\r\\n\\r\\nAnyway, if you really want me to make a separate PR, fine by me since this is what you want to happen. Just asking to be sure, so it should go like that:\\r\\n\\r\\n1. I create a new PR that ONLY changes the requirements (so the one line here, and the files in the requirements)\\r\\n2. Draft this PR\\r\\n3. Wait for the lib bump PR to be merged\\r\\n4. Sync with dev\\r\\n5. Open this PR\\r\\n\\r\\nIs that correct? Or do you need to do anything else before that? Yep that sounds perfect Here\\'s the new PR:  Switch the CoverEntity and the CoordinatorEntity Could you please elaborate? Why would that be the case? In our previous PR in which we had a switch we followed this order and there were no issues about that Consider a preliminary PR where you create a shared base entity Hi, what do you mean exactly? You\\'d like an extra abstraction that both the IottySwitch and the IottyShutter inherit from?\\r\\nI think that\\'s an interesting approach, but since the guidelines on the docs are not really clear about what should and what should not be done I preferred going for the simple approach It\\'s not something in the docs but in the code, check AirGradient for an example Looks clear enough to me based on the example you are proposing. Is it mandatory to do it before this PR? I\\'d rather do it afterwards, especially because with two entities it would be easier to refactor later and find the correct common denominator for the base class, otherwise if I did it starting from the current dev version I would just add a layer of abstraction that references itself only. You can do it in this PR or a separate one upfront  I did it here! This looks really inefficient. can\\'t you keep a list in the cover platform with all the known shutters and just watch out for them? Hi, it\\'s not clear to me what you mean with \\r\\n\\r\\n> keep a list in the cover platform with all the known shutters and just watch out for them\\r\\n\\r\\nMoreover, this approach is already used in the Switch entity as well, and we didn\\'t have any problems with it. I understand there might be a bit of extra calculations going on here, but there doesn\\'t seem to be any concern in efficiency for the size of the lists involved here Would it make sense to already transform the coordinator data to a key-value dict of all devices? It will remove the need for all these lookups The API returns a list of devices, so every time it gets called we\\'d need to map it into a key-value dict, which would move a bit of the computation there, but definitely improve the performance.\\r\\nSince this is a change that would impact also other parts of the code, I think it would be best suited for a later optimization PR after this one, to stay aligned with the \"1 change per PR\" rule Why are there 2 different devices? Could you please elaborate?\\r\\n\\r\\nIf you mean two as in one is `self._iotty_device` and two is `device`, well the first one is the entity state, the other is the newly fetched coordinator data Are they the same object? No, they\\'re not Why don\\'t we set `self._iotty_device` to `device`? Just wanted to emphasize the fields that are actually changing (i.e. `status` and `percentage) vs the ones that are not changing (e.g. `serial_number`, `device_id`). No problem in assigning directly to the new data from the coordinator if you think that\\'s better I think it would be nice if the coordinator would become a map of coordinators instead, and the base entity gets a property for `device` which returns the device from the coordinator. This way you always have the most up to date device Can be moved to the shared base entity This one as well Can be set to `_attr_supported_features` outside of the constructor Not sure why this is here',\n",
       " '',\n",
       " \"Isn't `self.hass` already set after adding? This server code should definitely be moved to a library. Socket details should be abstracted in a library. The UDP audio will be deprecated eventually, so this code will go away. Ok.\",\n",
       " 'Why don\\'t we make this an update entity? So the information provide by LMS is very simple and unstructured making it an update entity didn\\'t really add any value so I kept it simple stupid. Can you elaborate? Sure all you get is a simple unstructured string with some embedder html that changes dependant on install type. if its not present no upgrade. Sample text:-\\r\\n`A new version of Logitech Media Server is available (8.5.2 - 0). <a href=\"updateinfo.html?installerFile=/var/lib/squeezeboxserver/cache/updates/logitechmediaserver_8.5.2_amd64.deb\" target=\"update\">Click here for further information</a>.` Yes but that doesn\\'t answer the question why an update entity doesn\\'t fit? @pssc, you likely know this already but, you can get the latest server version from  h and   This of course just gives you the current version for each track and you\\'d have to check the currently selected track (actually not sure how to do that) and the current platform and version to know if an upgrade is required.  I guess that\\'s what the server does itself to throw up the text that you\\'re checking (and to already have downloaded the new version in the background) and so it\\'s likely checking the presence of the text as a flag for \"upgrade required\" may well be the simplest. Yes and requires a separate poll, parse and all that jazz so I have taken what we have in server status and can make an update entity work I would suggest overwriting the native_value property instead Oh yeah much better Please use Sentence case Are current entities affected by this? No only some of the new entities Better idea? In that case this works Please use icon translations Should we add a suggested unit of measurement It seems to be scaling nicely Test Server has a smallish collections and Prod one is large. I get that, but knowing the duration in seconds is a bit, strange, hours seems a more logical unit Unit of measurement? What does this return? string I think I could put this int an update entity.\\r\\n What does this return 0+ total count of players But don\\'t we see all the players as devices? Total Players yes, Other Players no (other servers), You thinking Diagnostic? we get them for free as part of the status poll. Why do we recast? source dict is Any. Does mypy complain? yup',\n",
       " 'please  use the constant fixed. Can we add more types in a follow up PR? what do you mean? if ADS_TYPES, all are here except string. That doesn\\'t makes sense (to me). :)  No I mean, python typing, so adding `name: str` to make the code and linters know that `name` is of type `str` added them as you requested. Does it make sense to add the conversion in the place where we fetch the data instead of here? Because we know if the datatype is a date right? i moved the conversion to the `async_update`, which is a better place for it indeed. Oh that isn\\'t the best place as its now a polling sensor. I mean, the previous PR you used logic to make string a string, bool a bool, etc, can\\'t we move this to there? tried it, but can\\'t really get my head around it.... removing it for now (not the most useful types anyways. will add if i have more time.) I think there are two ways to look at this...\\r\\n\\r\\nOption 1 (as previously implemented):\\r\\n- in `def _device_notification_callback`, keep the raw integer value\\r\\n- in `def native_value`, use the `SensorDeviceClass` to convert the value to correct datetime\\r\\n- ignore the `ADSTYPE`\\r\\n\\r\\nOption 2 (I think this is what @joostlek has in mind)\\r\\n- in `def _device_notification_callback`, use `ADSTYPE` to convert to date/time/datetime/timestamp\\r\\n- in `def native_value`, return the existing datetime value from the state_dict\\r\\n- probably need to add some checks in `setup_platform` to confirm that `DeviceClass` is compatible with `ADSTYPE`\\r\\n Will try to achieve option 2 in a future PR. Now, i have a few more ADS devices to add, and would like to focus on those. Side note: I\\'m not sure that `unit_of_measurement` should have a default value... it\\'s been known to cause issues in some integrations.\\r\\nI\\'m also very surprised to see a default device class being set to ENUM. Again should it not default to None?\\r\\nFinally, should state class be added?\\r\\n\\r\\n#L362-L363 removed unit of measurement for now, to simplify things for now. \\r\\nEnum was there because i was testing and it just left there as is.\\r\\nAdded State class and refactored the device class. The unit of measurement needs to be kept. It\\'s just the default \"\" that needs to be removed I think. Like this:\\r\\n\\r\\n> `vol.Optional(CONF_UNIT_OF_MEASUREMENT): cv.string,`\\r\\n\\r\\n added back in. resolved.\\r\\n resolved. I wonder => can this really be missing from `hass.data`?\\r\\nI would expect that if it is not present, then `setup_platform` is never reached.\\r\\n\\r\\nYou could maybe simply replace with `ads_hub: ads.AdsHub = hass.data[ads.DATA_ADS]`\\r\\n\\r\\n#L136-L147 It would be good for maintenance if this change could be applied to all other platforms in a follow-up PR. Similarly it would be good for maintenance if type hints for `__init__` could be applied to all platforms in a follow-up PR.',\n",
       " \"I think we should use the library built api for command classes, ie `endpoint.command_classes` and `CommandClassInfo` and build a dict from scratch, or alternatively add a `to_dict` method to `CommandClassInfo` in the library. We've moved away from using `.data` elsewhere in the integration. Requires  I think we said that the frontend wanted snake_case keys, at least for `is_secure` cause the frontend was already handling that. We need to adjust that here.\",\n",
       " \"I think we should discuss the consequences of removing the default disabled here. It means that all these kinds of sensors, ie notification command class and number type, will be enabled by default. So there may now show up weird sensors that we don't label as diagnostic.\\r\\n\\r\\n@AlCalzone Is there a list of all possible number type notifications to get an idea of the impact? I'd rename this function since it returns an entity description and not a boolean. I actually changed it back as it was causing a side effect. The check is now separated from the entity description This isn't great since we don't want platforms to depend on each other. The approach in Matter would solve this but that's a large refactor not for now.\\r\\n\\r\\nI don't have a better suggestion at the moment so let's keep it for now. Yeah, I was a bit in doubt about this one - we could move it into a util module\\r\\nIn the end the check is super simple but still risky to duplicate  We need to add the value id to the set of discovered value ids when the for loop is finished regardless of what happend earlier. Otherwise we'll potentially discover the value again.\",\n",
       " \"Instead of adding this method to the base class, maybe there should be separate base classed for live and non-live data migrators. In isolation, its probably ok to add here but I think you do need to separate anyways to handle the retry case #discussion_r1783092827 `migrate_data` is wrapped in `retryable_database_job` which never gives up. I'm not sure if this is OK here, or we should instead fail after a number of attempts? I think we should be using something like `database_job_retry_wrapper` which fails after 5 attempts\",\n",
       " 'Using the default translations should be sufficient as this is the only entity of the device beside humidity. \\n\\n\\n![image]( Should this be a reference instead? \\r\\n \\r\\nCan be omitted as it will then take the device class translations idem',\n",
       " \"This one can be of device class ENUM, it can then also have `options` provided, with the possible options. But I think it would better to transalte them to `weak` instead of `1` All these entities with a device class which is not enum (where the name is the same as the device class), can be removed from strings.json and icons.json, as they get their name from the device class What does this do? What does this do? What does this do? What does this do? What does this do? device class? What does this do? What does this do? What does this do? device class? What does this do? What does this do? What does this do? What does this do? what's this used for What does this do? What does this do? What does this do? What does this do? What does this do? What does this do? What does this do? What does this do? What does this do? What does this do? What does this do? What does this do? What does this do?\",\n",
       " \"Can we sort this alphabetically? Can be set to `_attr_device_class` instead We only use this once though  This can be combined by the way Can be set outside of the constructor as it's static\",\n",
       " \"Let's use snake_case Is it possible to add mock data to have the diagnostics have a complete picture?\",\n",
       " '',\n",
       " \"Please use Sentence case for casing {location} Removed. \\r\\nAs you mentioned at #discussion_r1740516115, placeholder is not passed. Modified. We don't pass any placeholders right? No, we don't. \\r\\nRemoved.\",\n",
       " 'Mac here also needs to be redacted.\\nMaybe it can be a dict? now i learned about the [`asdict`](#dataclasses.asdict) from `dataclasses` :nerd_face: :bulb:  Add to redacted info Also redact I think',\n",
       " \"I think this is wrong (it might be wrong above too) as it's not really testing the values passed.\\r\\nIt's just testing that `A == A`, when it should be testing that `A == expected`\\r\\n\\r\\nCould we use a snapshot assertion here instead?\\r\\n Note: I have opened #125064 for the bad existing tests.\\r\\nYou will probable need to rebase once that is merged. This could have been a separate bugfix PR ðŸ˜‰ but I think it's ok to leave it in here. We should not create services that require the user to put in JSON objects. This is too error prone imo I changed both examples in the file. Also updated the documentation.\",\n",
       " \"You don't need to delete it in the end consider using the `snapshot_platform` helper, it will fixate the data objects in .ambr files. You can then run `pytest ./tests/components/met --snapshot-update` I looked into it, but felt like it was on the edge where it was better to go the individual attributes route, since the `forecast` isn't being tested. Maybe improving the test coverage should be part of a separate PR? But the UV index isn't part of the forecast object right, so testing that would be outside of the scope anyway Hmmmm... Actually, `uv_index` gets included in the forecast object if it's available, so it's fair to say it's in scope.\\r\\n\\r\\nThere's no tests for `hourly` or `daily` forecasts right now though, and that might be a sizable chunk that'll exercise a bunch of bits I haven't touched here. Would you rather I follow-up with another PR adding tests for the forecasts and updating to the `snapshot_platform` or bundle those changes here as well? Sounds good\",\n",
       " '',\n",
       " \"This is only added as `_mocked_device` constructs `modules` internally from the mapping, and the siren platform will only be initialized if the `Module.Alarm` is in the modules. I'm not 100% sure but this might interfere with  which we'll want to cherry pick into the beta so I think we should hold off merging this until 124930 is in. If there will never be more than one we don't need `_siren` Ah, I just copied this over from the climate platform with the assumption that we should add a suffix, but yeah, there can be only a single alarm per device, so I'll remove this. That is, if the unique ids are platform-scoped, as otherwise we might clash with some legacy ids here(?) Removed `_get_unique_id`. \\r\\nIs already set on `CoordinatedTPLinkEntity` Good catch, removed! This is kinda already tested by the `test_states` test Yeah, I think it makes no sense to do explicit testing in this case, so I'll just remove this test. Thanks for the review!\",\n",
       " \"Add require admin decorator This one can be a service because itâ€™s something we want to allow users to do in their automations  This should be left up to the platforms. We don't know if wake word is being listened to.\\r\\n\\r\\n I believe that we should move to make `pipeline_entity_id` and the other one properties on the entity instead of passing them around.  If `announce_media_id` is provided and it is a media source URL, it should also be resolved and processed. I believe that this if-statement should be rewritten to something like:\\r\\n\\r\\n\",\n",
       " \"If physical devices are involved at all, we don't label it as a service. `hub` seems appropriate.\\r\\n\\r\\n#integration-type\",\n",
       " '',\n",
       " 'Usually we would bump the library in a different PR, but in this case its likely that its going to raise KeyError as soon as you set up the sensor since the mappings are otherwise missing and its small enough to do it in the same PR.',\n",
       " 'The async_setup_component is not needed This tests has a few things wrong.\\r\\n1. I\\'d rather set up a real life integration setup. So it would add sensors/players and you could interact with them. \\r\\n2. We should avoid using `if` statements in the tests as it makes it unclear what its actually testing Can you share an example of an integration that does tests they way you prefer? I\\'m not sure I understand \"real life integration setup.\" Sorry, one more question - I can remove the \"if\" that appears in the test further below, but the \"ifs\" in the function mocking the pysqueezebox `async_browse` function are necessary to make the mock function respond like the real library\\'s `async_browse`. Those are ok, right? I think an integration like `reolink`, but adding tests can be a bit more work. The idea is that you patch the library to return values what we expect. Then we let HA setup the integration using those patches and then we assume that the devices that are created are created correctly. then you can call services with those devices and check the right function are called. I am not sure what is needed for media_source to work, don\\'t have that much experience with that one, but there aren\\'t a lot of examles of good media_source tests, so that\\'s sad. But feel free to contact me on discord :) Idealy we mock the library in a separate fixture, this way you can reuse the fixture in more tests Got it, very helpful. I\\'ll take a look at `reolink`. Ok, I *think* this is a better implementation of the tests (we set up a `SqueezeBoxEntity` player instance and run everything from that, just mocking the communication with `pysqueezebox` as needed). Long term I plan to add tests for the other parts of the integration, but that\\'s a separate PR. What should happen when we call this? Does this raise something? Yes, it should raise BrowseError if an item isn\\'t found. Updated test and code.',\n",
       " \"Nautical miles is two words. Please separate them with underscore in the attribute name. you're right -> #126905\",\n",
       " '',\n",
       " \"\\n - [x] yale 9843e549a505513ef1029506c2e45f93bdba8060\\r\\n- [x] august e05213a03ad768ad6703eecba76bb4a6070f3b88 Not sure if this already was there or that this could be auto detected in the future Outer for loop can be added to the comprehension  - [x] yale 9c6fa1649633a3a416cd93c06ecff37bbae49c40\\r\\n- [x] august 60d62a64c78 \\nI think epenet just changed all of these to entry_data - [x] yale b640a31fab6\\r\\n- [x] august - does not apply No abort? - [x] yale 06195fcb7077c97a0ac12fa864280be58fd5ba7a\\r\\n- [x] august does not apply Isn't this always the same now? Yes\\r\\n\\r\\n- [x] yale e1062a0e70b\\r\\n- [x] august does not apply Isn't this a base entity rather than a mixin? \\n Outer if can be moved to comprehension  Mixin already has this Didn't you remove pubnub? I can remember a PR where you migrated to websockets We have new way of notating this right? How much do users notice about this migration? Is it worth trying to split these attributes off directly so we don't have to deprecate them at some point? Looks like something for const Autouse? \\nNot needed because blocking=True Snapshots? Would the freezer work here? Snapshots? \\nPersonal ick Why dont we assert the created entry? I'm missing a test where we try to add the same account twice  - [x] yale 06195fcb7077c97a0ac12fa864280be58fd5ba7a\\r\\n- [x] august does not apply Should we use pytest.raises? Should we assert it's not loaded anymore?\",\n",
       " \"Duplicate code in the function above....not sure its enough to consolidate though Yeah I wasnt sure if I could make it less even, unless the above one just calls this new function?\\r\\n The naming isn't great, but I guess calling the other function would work.\\r\\n\\r\\nProbably not worth worrying about it since its a single line anyways\",\n",
       " 'A switch named On doesn\\'t sound logical to me imo. I\\'d rather opt for using `name=None` (causing the switch to be seen as the main feature of the device, so in this case it would be names `switch.{device_name}` and it would be like \"turn {zone} on or off\" (which sounds logical, but I think you already have a climate entity per zone))\\n\\nAnother option would be calling the switch something like Running, but it sounds meh.\\n\\nAlso, climate entities support TURN_OFF and TURN_ON actions now. The default behaviour is that it will use HVAC mode to turn on. But maybe it\\'s nice to overwrite the turn on and off actions to make this what you need > A switch named On doesn\\'t sound logical to me imo. I\\'d rather opt for using `name=None` (causing the switch to be seen as the main feature of the device, so in this case it would be names `switch.{device_name}` and it would be like \"turn {zone} on or off\" (which sounds logical, but I think you already have a climate entity per zone))\\r\\n\\r\\nDone in bb564fb4c4\\r\\n\\r\\n> Also, climate entities support TURN_OFF and TURN_ON actions now. The default behaviour is that it will use HVAC mode to turn on. But maybe it\\'s nice to overwrite the turn on and off actions to make this what you need\\r\\n\\r\\nThis is my attempt to add independent switches and [master zone mode selects](#diff-2695ddf2943968129bc3f9c43d26ea0f96bdcce8fb4657fba43b74312c16f883R194-R202) for changing the status on master and slave zones:\\r\\n\\r\\n\\r\\nBecause the following discussion has stalled:  That has not stalled, in fact, that has been implemented as far as I\\'m aware > That has not stalled, in fact, that has been implemented as far as I\\'m aware\\r\\n\\r\\nNope, the only thing that has been implemented is the on/off feature flags:\\r\\n\\r\\n\\r\\nHowever, as long as there\\'s an OFF HVAC mode, I won\\'t consider that discussion as implemented:\\r\\n#L17-L18',\n",
       " \"Not needed. Everywhere where you have entry id, you also have access to the entry data Fixed, thanks Why don't we add every module out of the box? Different modules are generally in different buildings - to me it felt presumtious to assume users would want that in a single Home Assistant instance, so it seemed sensible to allow them to be added one by one as required. Ideally for connection striaght to a device we do 1 config entry -> 1 device. But for cloud accounts we rather do 1 config entry -> 1 cloud account and import everything and let the user disable the things they don't need Okay, that's fine. I'll sort that out tomorrow. It simplifies the config flow a lot. Done, thank you! Please set the entry.runtime data to a variable first Done Typing Done Why don't you make zone a parameter Done - nice idea This can all be removed if you use `_attr_preset_modes` instead of `_preset_modes` Nice, thanks! This is small, can be inlined I left this as is - mostly because it makes the code easier to test (well, to mock) when testing the config flow. We should not mock a function in the config flow, we should mock the library Done! Thanks for the tip! Comment first off, how does roth sell their product? Touchline SL? should we rename this with an underscore in between? Let's create the coordinators here and set them to entry.runtime_data. we should also do the async_config_entry_first_refresh here \\r\\nWe can omit the True with the coordinator since the entity is already able to get a state \\r\\nLet's add the coordinator name in there so the `self.coordinator.data` is typesafe unique_id is unqiue per intergation per platform, so no need to prepend it with `touchlinesl-zone-` I would recommend checking out `fujitsu_fglair` they have a nice way of doing this. Also make sure to check the `available` property they have, you need that as well why?\",\n",
       " 'I would vote to move to warning and point the user to the documentation for manual setup I started with debug here to keep it simple, but I think it would be good to make a repair issue in a future PR This one will be difficult to cover without patching `get_url` I think it would be good to also check `ws_config[\"enable\"]` in case the outbound websocket is disabled and enable it Are you thinking something like?\\r\\n\\r\\n\\r\\nI\\'m a bit conflicted on that as I think its ok to set it up if its un-configured, but if they explicitly go in an turn if off it seems like we might not want to override their preferences.  \\r\\n While I agree there is something in your claim, I think we reach here only if it is a sleepy device, added to HA and has no entities, in this case we probably need to do our best to help the user, so I would prefer we also enable the WebSocket if it is disabled (as your diff above). \\r\\n\\r\\nThe case that makes most sense not to reconfigure is if it is enabled and set to another value, since there might be a case that the user set another address due to a proxy or different networking, but I don\\'t see a case for having a sleepy device in HA without WebSocket as it makes it non-functioning.\\r\\n I agree with Shay, when `ws_config` is disabled the device simply doesn\\'t work with Home Assistant, integration in such a case should try to fix the problem. Adjusted in a4d5f727ff97f4ead4e0388c66fd2548de1214a5',\n",
       " \"Why are we storing this in a store instead of the config entry data? Hum, I don't known.  \\r\\nI'm new in ha development (but I'm a experienced developer in other side).  \\r\\nSo, I'm inspired in other integration like samsung smartthing but if there is a best way, lest's go Withings is a good one to check ok, I'll check it that  \\r\\nmany thanks\",\n",
       " \"These are unused? Thanks! Copy paste and being tired :) I'm missing translation strings for the options. Oh good point, I didn't look at it because it didn't have entity name = true but that's unrelated, so my fault I will try to get it done before beta\",\n",
       " 'I don\\'t think you need to extend the button. `self.drink` doesn\\'t add any value since in the for loop at line 57, you can just put in the `drink` from the for loop scope instead of from the lambda This could become a list comprehension Please collect all entities you want to add in a list and add it all in once This change produces an error `B023 Function definition does not bind loop variable drink` because this can cause late binding In that case you need to disregard my previous comments and we do need a second extension, sorry for that, didn\\'t know this wasn\\'t possible I see that `type: ignored` is used a lot in the codebase. I\\'m thinking leaving it as is But that doesn\\'t mean we should introduce more of them, the most of them got added due to new python features and typing things What does this button do? Should we use a translation key and placeholders to add more context to the name? This button prepare a drink to be poured out using the device.\\r\\nThe problem is that the drinks are created using the device app and the user can choose a name there\\r\\n\\r\\nI can add the word \"prepare\" so for example for the drink called \"cup of tea\" the button name would be \"prepare cup of tea\" That sounds awesome! we still want to collect the entities in a list and call `async_add_entities` once',\n",
       " \"I believe you should be using `async_migrate_entry`.\\n\\nSee docs [here](#config-entry-migration) Maybe I'm wrong but I don't think this is required just to replace an entry option. Migration is to be used when all config entry structure is changed.  See PS4's migrate entry. Only used for country code change\\n\\n#L91 Yes, but country code is in `data`, not in `options`, and probably are some mandatory data for integration. I have no problem in implementing this, but I managed other `options` migration where this was not required, so I just wait for a confirmation if this is required or not.\",\n",
       " \"This should not be a service. It should be a websocket API to be used by the wizard.  It should also be its very own PR. Each service should be its own PR.  We should call this announce. Do not include `text` in the name as we will also allow media in the future.  Please open a standalone PR to add the `WyomingSatellite` implementation.  The trigger PR has to be layered on top.  We shouldn't include this in a user facing service. I feel like this option shuold only be available via a websocket service. \",\n",
       " \"name is not used yes, true. removed actually this is needed\\r\\n we have a new helper for this. `mock_config_entry.somethingsomethingreauth` (forgot the name) yes, very new.\\r\\n`mock_config_entry.start_reauth_flow`\\r\\nhave updated to this now this should return a form It didnt make sense to return the user to authentication form, in the case of connection error. So I opted to abort the flow on connection error.\\r\\n\\r\\nShould I handle this differently somehow? I could redirect to a new step to update device host?  Can we move this to a parametrize? Sure. Just raise `ConfigEntryAuthFailed` ok What's this for? this was to test that reauth was triggered, but maybe simpler/clearer to do it inline in the test. Can we rename the fixtures to be more meaningful? I have renamed this one `mock_config_entry_host`. I will make a followup PR to rename the existing fixture, and also use this new fixture in some of the config_entry tests. We should instead check if there is a flow in progress after this Ok, have changed it to check flow progress instead.\",\n",
       " \"In Home Assistant normally utils are tools that are not aware of Home Assistant and helpers are tools that are aware of Home Assistant. I think the client, model and utils belong in a 3rd party library in home-assistant-libs org. That is the plan when everything is ready.\\r\\nI just opened the PR to test the code on multiple machines. Shouldn't we talk about `ice servers` instead of `stun servers`? Needed to add mashumaro here otherwise we will have the same issue as with the supervisor lib This needs to be updated to take the `websession` as well as the url value or it will error. As a thought maybe the client should have the `websession` as the second parameter and allow it be passed as `None` (and create an `aiothttp.ClientSession` if it's None). I know the primary reason for the library is for HA support but it's probably good practice for it to be usable outside of HA and most consumers wouldn't expect to have to pass in a web session. If someone uses the library outside of HA, they can create easily the websession with:\\r\\n\\r\\n\\r\\nWill add this to the Readme of the lib URLs can be either a list or a string.\\r\\n This should return a list of ice servers. Shouldn't it be `register_ice_servers` and use a list of RTCIceServer? Currently, there is no use case to return multiple servers. One server can have multiple URLs  You can get the list of ice servers from ``. As discussed internally, we will merge it without it. Add the servers in a follow up I'd cache the providers in a local variable too since we need to access it twice. Can we use the `DATA_COMPONENT` key to get a typed optional result. We can mark this in the manifest instead. I think we should explain in a comment why we have this RTSP to WebRTC coupling. Why do we set up the camera integration directly? This would be a tiny bit faster with a frozenset instead oh, nevermind its being used in a genexp with startswith #diff-43b3bf64f3dd0aebbb9a33d25de61875864bf29c6fc359058a75d9bb5feca656R71\\r\\n\\r\\n\",\n",
       " \"Wouldn't this always add a conversation entity, even if the config entry doesn't support it?  Right, I forgot to add the check! Nevermind, it's checked in `wyoming/data.py` Adding an entity cannot just raise. It should not add the entity unless there is something that can handle it . It should never reach here anyways, as the services are checked earlier. So I'll just remove this. Only do this if the conversation agent was previously available for backwards compatibility. I don't think this is necessary because this is the first time Wyoming exposes a conversation agent? This appears to be quite necessary, actually :smile: \\r\\nI had just removed the migration part. Can you explain why you think it is necessary? Creating a conversation entity is the modern way. Setting agents was the old way that we shuoldn't add to new platforms.  When I removed it, the agent no longer worked. Should we be calling `async_set_agent` automatically in the entity base class? No, that should never be called anymore. It is no longer used. Users should only target the entity ID. This is not a satellite platform. Instead, it should only be handled by `data.py`.\\r\\n This is wrong. You need to do lookups based on entity IDs. Entry ID should not be used.  Same.  We shuldn't talk directly to the agent. Instead call `conversation.async_converse` Otherwise you are not testing that the method is actually called correctly from the conversation agent.  this is built-into the base entity.  Not used\\r\\n\",\n",
       " \"`[_base_trigger_validator, _backward_compat_trigger_schema]` means a list which passes at least one of `_base_trigger_validator, _backward_compat_trigger_schema`, that's not what we want.\\r\\n ohhh, that makes sense Wondering if this is still relevant since the `TRIGGER_BASE_SCHEMA` already makes them exclusive I am wondering why this adds a `trigger` key, since we now pop it There needs to be an explanation to what is going on here. Let's cover this.\\r\\nWe should add tests in tests/helpers/test_config_validation.py which call `TRIGGER_SCHEMA` and/or `_backward_compat_trigger_schema` with all the cases covered. I'm not sure restricting to `dict` is correct, I think we should allow any `Mapping` Isn't Mapping a subtype of dict? No.. This explanation is not clear, we should explain the `trigger` key is currently only for yaml, while the Python implementation still uses `platform` This copy should only happen if we mutate Please add tests for the changes to this WS command I don't think this parametrization should happen here. This should instead happen in `tests/components/automation/test_init.py` to make sure both the old and new keys work Since `trigger` is now yaml only, can we run the `_backward_compat_trigger_schema` before we run `_base_trigger_validator`? Revert these changes, these checks should be in the `_backward_compat_trigger_schema` if that runs first. I'm not sold on naming this `response`, how about this:\\r\\n Let's explain why we do this instead of fail\\r\\n\\r\\n\",\n",
       " 'Since CPU is an acronym for central processing unit we should upper case it. Changed as requested The should be \"CPU core 1 usage\", etc. Changed as requested We can use translation_placeholders here. Done Please use the freezer for changing time Could you provide an example?  Ok. I replaced everywhere idem',\n",
       " 'Please make a separate PR for this change. When making that PR, please also add an icon for the number integration for this device class. We missed this when adding this device class a couple of months ago. Please remove this change.',\n",
       " \"I don't think we should change this. It would mean that the entity would never be docked if the entity only changes state due to service calls and doesn't have a state value template. Ok, I'll change that back. Should add `lawn_mower.mower_can_return`. Not replace `lawn_mower.mower_can_dock` as it's still there\",\n",
       " 'This can be moved outside of the if statement',\n",
       " \"Done Unused Removed done Please double check if the state write is needed, it might be so that this is built in. Otherwise we're doing 2 state writes You were right, the async_write_ha_state is not necessary. I removed it.\",\n",
       " \"why the noqa Was included in the scaffold. Please keep config flow specifics out of the normal setup This is a shared function, not config flow specific. But we should not share a function with the config flow, they should live independently Okay, since you recommended to inline it anyway below, I can do this in both places.\\r\\n\\r\\nI thought it would be better to make sure both config and setup follow the same procedure to avoid unaligned behavior (also in the case of future changes / enhancements of this function). Why do we add `webcontrol` as suggested host? Let's remove that This is the default hostname given by Warema.  but `webcontrol` isn't a hostname? Yes, it is. It is not a FQDN, but a hostname that can be resolved locally. Can we use the helper for this instead of having it like this? You use the helper later on, so you know which one I mean :) The function is tiny, let's inline it Only have stuff in the try block that can raise It can raise. This structure comes from the integration scaffold. `host = user_input[CONF_HOST]` can't :) Why don't we have a dhcp entry point? Because it is not needed. The DHCP discovered entries need to be user-confirmed anyway according to the developer documentation. And this way the same form can be re-used. Do we get anything unique from the dhcp message? Do we have something unique we can set as unique identifier? Unfortunately not, the hub API doesn't return anything, no serial or mac of the hub itself. Can you elaborate on what a Destination is? Will you add more future platforms? What happens during a refresh? Please use the extended config entry Why do we refresh here? Without a refresh here the destinations actions aka device type and capabilities would be unknown/unset. Please move this to a follow up as well I need this to let users ask for more platforms or device types. I am not saying we don't want this, I am saying we don't want this in _this_ PR :) Let's not include a class name in the unique_id Let's move this to `self._attr_device_info` in the constructor\",\n",
       " \"This is not needed for this to work Just the field in the entity_description is enough Oh interesting. How does the entity description work then? Is it just a container for all of these values that is used to populate the attributes like `self.entity_registry_enabled_default`? The above suggestion causes ruff to fail, no idea why that wasn't a problem previously\\r\\n\",\n",
       " \"The code in this method is almost same as the code in `async_step_start_addon`, could you try to deduplicate them to call a common helper? It is only one return statement, but we need the separate methods as there are different steps. Why does the start task raise `AbortFlow` which does not abort the flow? Corrected. Now `AddonError` is raised instead. Take a look at  this class: <#L76>\\r\\n\\r\\nIt moved the waiting to the add-on manager which simplifies the caller's logic.\\r\\n\\r\\nCan that class be used here too? `matter` and `zwave_js` should probably also use that class. I have looked at this class. And it can help a little to install the addon. But not for the progress code.\\r\\nTo start the add on the class does not check if the discovery info is available and if the broker can be connected with the discovery data. It will take some more time after starting the addon befoe the discovery info comes available. So I'd rather not the `WaitingAddonManager` class at this state, as it does not really help, and seems to make things more complicated. It can happen that the user already have the add-on installed. We should either check that before showing the menu, or make this text more vague. Checking before showing the menu is probably better, the option would then either be to connect to the broker provided by the add-on, or to install and configure (what you already implemented) Made the text some what more vague about set up of the addon. This data was not used OK, then we clean that up in a separate PR. This should be in `addon.py` Separate PR please Let's not create a 7th copy of these fixtures.\\r\\nInstead:\\r\\n- The existing fixture implementations should be refactored to helper functions which are moved from to `tests/components/hassio/conftest.py` to `tests/components/hassio/common.py`\\r\\n- Fixtures added to `tests/components/conftest.py`\\r\\n\\r\\nIn this PR, hassio and mqtt should make use of the shared fixtures provided by `hassio`\\r\\nIn follow-up PRs, `homeassistant_hardware`, `homeassistant_sky_connect`, `homeassistant_yellow`, `matter` and `otbr` should be updated to use the shared fixtures. Right so for this PR, is it okay to add the new hassio fixtures to `tests/components/conftest.py`? I moved the shared fixtures to `tests/components/conftest.py`. In a follow up PR the redundant fixtures can be cleanup, and refactored if needed. In most cases they are copied now. The functions in this file are not pytest fixtures, they are helpers which mock hassio functionality.\\r\\nRename them accordingly, for example with this pattern: `discovery_info_fixture` -> `mock_discovery_info` Renamed them all\",\n",
       " '',\n",
       " '\\r\\n\\r\\nrather than limit to 100? Hi @pssc We don\\'t know the count at that point - until after we run the command to get the favorites.  I just picked an arbitrary number larger than I thought people would have.  To get the count first, I could do a \"favorites items\" which just returns the count, but that\\'s just an extra call I think.  I could change the number to 1000 (i.e. basically just all of them).  Thoughts@ BROWSE_LIMIT ? Yes if we\\'re going to set it to 1000, we might as well use browse_limit, but that\\'s more to limit the number of tracks etc. where the number could be very large.  Certainly no harm in using it here as well though.  Think it\\'s likely a sensible change - or at least there\\'s no harm doing it IMHO. Rather than crafting our own command and calling the API directly with async_query, I will add favorites support to [pysqueezebox]( Another place where the functionality should be in `pysqueezebox`. Does this search work for you? I\\'ve implemented this a different way in pysqueezebox because when I run a search like this, I get only count of matching albums, not the matches themselves. Yes, works fine for me - works fine when I test it in HA as well\\r\\n\\r\\n![image](\\r\\n\\r\\nreturns\\r\\n\\r\\n![image](\\r\\n Interesting, what version of LMS are you using? Ah, I figured it out. Was missing the upper limit on results, which apparently makes LMS just return count. Yes, the upper limit is officially \"itemsPerResponse\", so I guess it interprets nothing as 0, and just gives you the top level stuff back,',\n",
       " 'The docstring is misleading, the test has nothing to do with templates IMHO, it\\'s about special treatment of a payload which is `b\"...\"`. Should we also check the string starts with `b\\'` or `b\"`, since that\\'s all we care about to not waste time trying to evaluate the data?\\r\\n Can we assert in a test we don\\'t call `literal_eval` when the string does not start with `b\\'` or `b\"`? Test was expanded',\n",
       " \"If there is only 1 item in the data object, there is no reason to wrap it in a data class to begin with. Just store the `device_map` directly into the runtime data in that case.\\r\\n\\r\\nThis, right now, is adding an unneeded layer. No need to warn for that, as a matter of fact, no need to log it at all. It is already logged.\\r\\n\\r\\n And how can a user resolve this in that case? As per previous PR / review comments. Please remove all services from the initial PR.\\r\\n\\r\\n Shouldn't this be part of the library? This doesn't look Home Assistant integration specific at all. Why is the type cast here? Isn't the upstream library typed? Same comment as before: #r1711423028\\r\\n\\r\\nI could not find the public / open-source repository providing this package. pypi doesn't have any public repository linked, and couldn't find it with a search on GitHub either. String type is already inferred\\r\\n\\r\\n Shouldn't the library raise an error/exception in these cases? Seems a bit odd. As I cannot find the sources of the library, I'm not sure why this is the way it is here. This makes our translation keys coupled with an upstream library. We should be doing that. Please decouple it. Please do not ask for an config entry name in the configuration flow.\\r\\n\\r\\n There is no need to assign this to a variable first.\\r\\n\\r\\n CONF_ACCESS_TOKEN is always in the user input... the schema required it.\\r\\n\\r\\n Are there any possible side-effect from this? Not fully understanding why the device registry is retrieved in this location. Probably better to move this into the places it is actually used (since you pass along `hass` anyways, you can do it locally). body? What is that? Why is an `ininstance` check needed here? This check shouldn't be needed, according to the method signature above, this is always a list.\\r\\n\\r\\n This is already typed upstream?\\r\\n\\r\\n - These could be moved to be class variables?\\r\\n- Not sure why access token has a default?\\r\\n- Entry name can potentially be removed considering the other comment of not asking for a name in the configuration flow. We always have an access token, it is part of the schema as required?\",\n",
       " \"Don't log on info Not needed\",\n",
       " \"Bound might not be necessary here, could just put in RussoundBaseEntity as a type in function directly. Don't know the python semantics regarding this. There are new typevars for this, I'm not sure about the usage of them. I think `technove` has one Yep, they are just using the shorthand. I'm swapping over to that. The `self._device_identifier` instance attribute only seems to be used in this method. Then it doesn't need to be an instance attribute but can just be a local variable. Alternatively since it's only used once, just inline the expression where it's needed. Same comment for `self._controller` as for `self._device_identifier`.\",\n",
       " \"Better not put default init on a class. You can set this attribute also at top level since it's static ?  Wouldn't that cause the `SatelliteConfig` object to be shared among all instances then? I thought it's a frozen object that each implementation would override as necessary  This whole function needs to be defined inside the assist satellite base class and called by the VoIP satellite entity.  Moved into the base class Only import things for typing. All function calls on the assist pipeline integration need to be done inside the assist satellite base entity class.  I think everything except the pipeline event callback can be moved into the base class. The VoIP code needs to know the pipeline stage in order to play the tones, send the TTS audio, etc. I think that the device registry entry was already on the entity class. This otherwise is fine.  Is this necessary if we have a property already? Let's require classes to override on_pipeline_event ? (And call super) or maybe make it an abstract method platform entities need to implement. They all have it. And then call that method from on_pipeline_event.  This is reverse logic. The state is determined by the base class by asking if this property is true. It should be abstract and implemented by platform entities  Should muting be a supported feature since VoIP doesn't use it at all ?  This should not have an implementation. It should be abstract. The platform entity will need to ensure the microphone is muted when the method returns. Then when we update state, it checks is_microphone_muted property to determine state.  No need to have an intermediary property. Just always write to _attr_state No need to translate this. Should be handled in UI natively.  Instead of implementing it like this and computing it on the fly, set _attr_supported_features above init instead.  For a future PR, the assist satellite base class needs to handle this feels a bit like a generic util function ? queue to generator with optional timeout ? Somewhat, though it is specific to `bytes` as queue items. I guess that could be made generic. Moved to `util.async_` This is only used in tests, move this out of prod code.  I'm using this in the `make_protocol` function in `voip.py` Can we have entity register its start stream function with VoipDevice inside async added to hass ? We don't want to expose raw entity objects to other code.  If start stage is wake word, it would be something else. Should we enforce only a couple of start stages to keep code simple today?  I don't think we should because of the way I plan to implement remote pipeline triggering: the satellite will call back through this function. I just need to set the state more carefully with the pipeline events. This is the default and can be removed It's not registered as a service , described in services.yaml or used in VoIP. Let's leave it out for now  Also shouldn't be abstract as it's guarded behind a supported feature.  Let's drop it for this PR Are any of these used ? I don't think so. Maybe we can just drop it for this PR\",\n",
       " \"\\r\\n\\r\\nCan be removed as there is no difference between them, so we can use directly the base class Wasn't sure if that would be a breaking change  \\r\\n\\r\\nCan you please move it back, where it was before I will revert this whole file. That block moved so I could reference the classes in the list of description objections   The string mapping should be in strings.json so it's translatable. motionblinds_ble has a good example: #L61-L70  Thanks! Do we need a custom description class? It's not adding anything is it? I can remove it. The other components in Schlage used this pattern Make sure this supports auto-removal of the entry. See #L49-L61 for how this is done with other entities.  Sure The state test can use snapshots (#snapshot-testing). But you should also add a test for changing the state, ensuring it calls the Schlage API properly. I will look into this. For some reason when I run `pytest tests/components/schlage/test_init.py --snapshot-update` the snapshot doesn't update even though I've added a new key/value pair for `auto_lock_time` In the meantime I've updated the test to set the option based on `demo/test_select.py` Please keep lines under 88 characters The link is over 88 characters. What do you recommend? You can always remove it, when people try to remove it and test it out they will find out it doesn't work I guess Sure. Updated the comment  Would it be more natural to use minutes for some or all of these? I can update it to match the first-party Schlage app UI Why do we unload the config entry at the end of the test? Let's see if the tests pass without it. Other Schlage tests ([example](#L62)) do it Seems to work without it so I removed it Should we validate and log if we get an unexpected value, or is that not needed? I have not seen that pattern before  It was meant as a question: Do we trust that the Schlage library will never return a value which is not one of the select entity's options? If we do, no need to validate. If we don't we should check.\",\n",
       " 'Instead of hardcoding this list here, could we use `VALID_STATES` from `alarm_control_panel`?\\r\\n\\r\\n#L33-L41 I\\'m using `VALID_STATES` now. I had to add three states that were missing from this. The `alarm_control_panel` refers to these as \"states\" rather than \"modes\", so I\\'d suggest to use the work \"mode\" here and below. Changed. Please don\\'t change the entity integration in the same PR as another integration is changed.\\r\\n\\r\\nChanging an entity model needs prior approval in a discussion in our architecture repository.\\r\\n\\r\\n\\r\\n\\r\\n#changing-the-entity-model Removed the change, and submitted  Sorry, I\\'ve realized that my previous comment about this was confusing. What we are reporting here seem to be referred to as \"state\" rather than \"mode\" by the `alarm_control_panel` component, so I would suggest to avoid using the term \"mode\". Here\\'s a suggestion (you\\'d need to adjust tests accordingly):\\r\\n\\r\\n VALID_STATES shouldn\\'t be used outside of the alarm control panel reproduce state module. It\\'s just a set of states that can be reproduced and not meant for outside use. Oops, it seems like [I provided](#discussion_r1714829427) @DeathCamel58 a misguided recommendation earlier about this. Sorry!\\r\\n\\r\\n@MartinHjelmare, is there a generic way for the Prometheus component to consume a list of all valid states from another component in cases like this? I see us use a few different approaches now:\\r\\n* for `cover`, we hard-code a list of possible states: #L442\\r\\n* for `climate`, we read a `StrEnum` exported by that component: #L539\\r\\n* for `humidifer`, we read a list of modes from a separate attribute: #L608\\r\\n\\r\\nWhat would be a good approach here? Until there\\'s an enum for all alarm control panel states I suggest we hardcode the states here in Prometheus. States are now hardcoded.',\n",
       " 'Why is the command optional and then asserted to be not None below? It should not be optional, I think. Use `kw_only=True` also. ah, yes, that will also fix the above question (I made it optional due to the missing kw_only)',\n",
       " \"We don't need a translation key since we set a device class that provides a default translation. We can remove this. Please update the docstring.\",\n",
       " 'Is this name as well as `entity_id` and `original_name` related to the device class? I would have expect this to be `DHW temperature`? Looks like this is not generated correctly for me locally, but it is in [workflow]( I could fix this manually but would like to know why this is happening. @joostlek any idea why this produced wrong results locally? Missing translation? Did you generate translations? No, just the `string.json`, the `entity_id` contains the translated name?  `python3 -m script.translations develop --all`\\r\\n\\r\\nHA takes the strings from `translations/en.json`',\n",
       " \"Why do you need to change this test? I added it when I fixed controlling entities with ' in their name, e.g. Alice's room. The `param2` is defined in its schema as `vol.Any(int, float)` so a string value doesn't pass validation. We already have an `'` in `param1`, but if it is not enough, I can add another string parameter \",\n",
       " 'Please don\\'t use previous config flow implementation in Switcher as an example for config flow. It is not allowed (and not needed) to store data in `hass.data` during config flow. So can you show me a good example? Any platinum integration can be used as an example, why do you need to store the devices in `self.hass.data`? they are not used outside of this class I revert that part back.. I dont know how to progress from here.. The `async_discover_devices()` was the right direction, just don\\'t store the discovered devices inside `self.hass.data`, you can store them in a temp variable (`discovered_devices`) if they are only used inside this method, if you need them in another method you can store them as a class variable (`self._discovered devices`) This is already async, why does it run in a task? I just copied it over from the previous iteration of this file.. You copied parts which are not related and mixed them, can  you remove the `async_create_task`? I revert that part back.. I dont know how to progress from here.. Please first check if one of the discovered devices needs a token before asking the user to add a token I do that here:\\r\\n#diff-3e4eacfcf78f613ccf0f87e8409a1e040758f7e7ec9bcb802becd3de9458b96cR57-R61\\r\\nI am calling reauth to get username and token only if device that needs a token found This needs to happen in 2 places:\\r\\n1. Same place you already added, this will handle devices that are detected during runtime that needs a token.\\r\\n2. When user add the integration, if a device that needs a token is detect you need to switch to asking for credentials before continuing to create an entry.\\r\\n\\r\\nExampe:\\r\\n#L171-L172 > This needs to happen in 2 places:\\r\\n> \\r\\n> 1. Same place you already added, this will handle devices that are detected during runtime that needs a token.\\r\\n> 2. When user add the integration, if a device that needs a token is detect you need to switch to asking for credentials before continuing to create an entry.\\r\\n> \\r\\n> Exampe:\\r\\n> \\r\\n> #L171-L172\\r\\n\\r\\nMaybe I am missing something but when I tested this part I got the \"reauth\" when I initially set the integration for the first time and when I had this already set up and I pressed reload on the integration (And when I didn\\'t have the device there and restart HA)..\\r\\n\\r\\nPlus this is the only part where the bridge is detecting the devices so I can determine if this is a token-based device no? I put the missing step and did a little refactoring. Please revisit. Is it going to be used anywhere in this PR? if it is for future device add it when you add the support for that device I need the COVER1_ID but removed the COVER2_ID The implementation of the `get_circuit_number` here does not make sense, however since it is not used in this PR (it will simply return `0`) please remove it and remove the `index` parameter, you can add it in a future PR when you add support for dual cover. Removed `get_circuit_number ` and `index` Please refer to a new section in the docs instead of the URL and example @thecode \\r\\nI don\\'t understand what doc is you talking about? @thecode \\r\\nYou mean I need to make a PR [here ](\\r\\nHow is it working there? Should It be merged there and here at the same time? Yes, don\\'t worry, they will be merged together  Fix the strings.. please see now \\r\\nPlease remove this Removed. Why do we need a new method here which just return the same data from `validate_token`? please use it directly where needed. Also avoid using logger in `info` level. \\r\\nHere there is no need for logging the result as it will be visible to the user when he enter the token.\\r\\n Add the `username` and `token` to the data only if they are not `none`. This is not a valid mocking as existing entries will not have these fields at all and new entries will have them with a value.\\r\\nExample:\\r\\n#L50-L51 \\r\\nInstead of using a string, pass here the cover index which is more reflecting the physical device, than you can later use this directly in the API calls. Future devices will pass the correct index also (1, 2)',\n",
       " \"This needs to interateable.\\r\\n\\r\\n It seems there are unnecessary spaces here:\\r\\n\\r\\n can we mention the dep bump in the PR description please ? I've just added it to the list. We will release 6.5.0 of the library soon. Then we can do a PR to bump the lib version and after that rebase this PR OK\",\n",
       " \"I don't think that's needed here, you can just do `str` I think it's more user friendly to have a dropdown/selector here.\\r\\nAlso having a free text/string is more human error\\r\\nWDYT? oh, the UI is done with services.yaml, this is only for validation, but then its already validated Ok. Done idem Done please use string references I'm not sure what you mean [%key:components::seventeentrak::.....`\\r\\n Done use constnats Done I mean for Config entry id and package tracking number btw\",\n",
       " \"My understanding of this method is that it's what the assist satellite implements itself for persisting the config. \\r\\n\\r\\nSomething like this:\\r\\n\\r\\n In other cases we always hardcode them to the desired value.  we never return `unavailable`, instead, we return `False` from the available property.  For a future PR: When it's being processed, especially by LLMs, we should be able to pass some extra context for the conversation agent to understand the response of the user that comes in (ie, extra context would be the entity ID of the garage door that was left open) When these services are added back in a future PR, \\r\\nthese shouldn't be top-level functions but instead be functions on the Assist Satellite base class and then pass the string of that function to the `register_enttiy_service` function\",\n",
       " 'typing done typing done \\r\\nNot sure what you use at the other platforms, if it\\'s a `-`, just keep it like that, otherwise I\\'d recommend this as it\\'s a good practice because if you ever have to migrate in the future you can just do `.split(\"_\")` and have both sides intact In the other platforms I also already use `self._attr_unique_id = f\"{blind.mac}-battery\"` in multiple places in a simular way.\\r\\n\\r\\nAlthough a nice suggestion, i don\\'t think it is wise to deviate from the pattern for the motion_blinds integrations.\\r\\nWill keep this in mind for future integrations. typing done typing done',\n",
       " 'Use the config entry Theoretically you can move this to init and then have a\\n\\nBut it\\'s opinionated, we don\\'t have strict rules where this should live but I personally prefer the init Can we finalize the dict type? Finalize -> add the type hints of the keys and values That looks like a `g` too much\\n\\n\\n That\\'s what it has at the bottom of the about page here \\r\\nThe extra g signifies a non-profit company under German law according to a quick Google. Ooh, never heard of that, but that makes sense \\nNit This already happens in the super class I\\'d almost wager to just duplicate the keys in the entity description, you could then just remove the whole constructor of this class. But this is again opinionated :) Need the init for setting the entity_description to type the value_fn so leaving this as is, copies Mealie. You have to overwrite the type of the entity_description\\r\\n Let me look again at this then. Ah, it was the different parameter name in entity that threw me, resolved this now. Is this what mastodon calls it? Changing to posts for both the key and translation name.\\r\\nThe API calls them statuses, but the JoinMastodon home page says \"Mastodon supports audio, video and picture posts...\"\\r\\nThey moved away from Toots in 2022. Please delete the file and regenerate them, you have some leftovers from when you didn\\'t generate translations yet You don\\'t need this one as it\\'s defined here Oh whoops forgot that I made this comment when I approved it, could you please fix this one in a followup? Will do Fixed in ',\n",
       " 'Is this how the device is reported? If not let\\'s use the model number without the variant attached to follow how the other models are done.   @cdnninja, sorry, missed this earlier this week!  \\r\\n\\r\\nMy two EverestAirs report as LAP-EL551S-AUS.  I based the addition to const.py on the EverestAir models listed in [pyvesync\\'s vesyncfan.py](  For the const.py file, I tried to match the existing style of the Core/Vital models (such as line 58), by listing \"EverestAir\": \"EverestAir\" first.  Happy to revise you\\'d prefer that not be there. Oops I missed this.  You are correct. ',\n",
       " \"Why is this something stored here and not fetched during runtime? If we would fetch it at runtime when the integration gets loaded and the inverter is offline, it would lead to the integration not starting, right? And since the value won't ever change, I thought it'd be smart to obtain it at setup. I mean if the device is offiline we should not start the integration anyway. Storing it makes it look like its user configurable which its not No, that's wrong. The integration should start as the inverter is offline during the night If a device is offline we should not start as we can't get data etc. That's how it should work Okay, then I'll change it to checking it on startup. Why do we store this in self.api? Shouldn't we store this at the coordinator Because the api needs this as well, as it checks against that as well and why storing it in the api and the coordinator when the api needs it regardless of the coordinator? It sounds strange that the API requires it tbh, why do we receive the value to set it afterwards, why don't we call a function for the api to just set it themselves.\\n\\nAlso, can this raise? We should raise UpdateFailed in that case The reason is that the API shouldn't run any IO in the init function so that it can be initialized when the inverter is offline\",\n",
       " \"You shouldn't be deleting this file? Home Assistant is licensed under the Apache2 license.\\r\\nWe cannot accept proprietary licensing within our codebase.\\r\\n\\r\\nAbove all, it is very clear that parts of the code produced in this PR are copied and used from other parts of our codebase that are already published under our license. It would not be possible to claim that proprietary.\\r\\n\\r\\nPlease note that you all have signed our Contributor License Agreement at this point as well (see the above interaction you all had with our bot), which conflicts with this.\\r\\n\\r\\n\\r\\n Remove all custom services from the initial PR.\\r\\nThey can be added in separate PRs later; we want to keep PRs to the bare minimum. Please remove diagnostics platform from the initial PR, it can be added in a follow up PR later. Please remove all device triggers from the initial PR, it can be added in follow up PRs at a later stage. Please remove the notify platform; initial PRs should have a single platform. This can be added at a later stage in a follow up PR. Missing codeowner I could not find the public / open-source repository providing this package. Pypi doesn't have any linked, and couldn't find it with a search on GitHub either. nmap? Is this a weird assumption? What if one is using a different subnet or address range? This is a client implementation, which should be extracted into a package, open-sourced and published on PyPi. This is effectively putting 3 different integrations into a single integration; riddling the integration codebase with checks for each one of them.\\r\\n\\r\\nThis is not correct. Home Assistant supports multiple integrations being exposed under a single brand. Meaning we can make the LG brand and expose multiple integrations under it. This is what should be done here as well.\\r\\n\\r\\nThe pattern you are using here, is something we used in the very past and are no longer using or allowing.\\r\\n This file is a nice example; it is fully copied from an integration that Home Assistant already has in its codebase. You cannot claim copyright on this code. I'm not sure why this file is here, it is part of the webostv integration and should be part of this integration at all?\\r\\n\\r\\n Please don't use hass.data for this anymore. Instead, store the runtime data in the config entry. For more information see:\\r\\n\\r\\n\",\n",
       " 'Only add attributes here that are mandatory in the spec why is this ? I mixed it with the file used as an example: cover.py this needs to be in the calculate features no need to set this in each atrribute callback, move it to the ValveEntityDescription If this is dynamic, move it to the \"calculate_features\" logic. We can also extend the discovery schema logic to move it there We\\'re missing tests for a device that supports set position. We\\'re missing tests for state updates. tests added',\n",
       " \"How accurate is the run time? Is it changing a lot? If so, consider using [`ignore_variance`](#L169-L172) Good question. Im not sure. Will look at your suggestion  I've pinged users with the device for this information. Maybe its ok to merge this as is and I will put up a future PR to tweak this based on feedback? Looking at logs provided in  it does not update very often. The logs span 15 minutes and the value has not changed during that period Done Should we add suggested_unit_of_measurement? A sensor in seconds doesn't sound pleasant Done\",\n",
       " \"I would suggest that we generate a new unique URL instead of passing the URL around. (ie based on `ulid()`).  Where are these changes coming from ?  Must be new type checking rules. I couldn't finish the commit without the changes (even though I didn't touch those lines). After rebasing, the complaints went away! Should we return the proxy URL from `async_allow_proxy_url` ? that's also the place that defines it.  If we are returning the URL, rename it:\\r\\n\\r\\n\",\n",
       " \"~~Please rename this to `CONF_ENUM_SENSOR_OPTIONS` so it's clear what it is~~ Please add a comment explaining this is options for enum sensors done\",\n",
       " \"Using a CameraEntityFeature doesn't sound like the thing we want to use here. I have too little experience to know what to do use though I think you can scope the target device with `model`. I think I once reviewed this for `yolink` I know, I would have like to just use a number flag like `1024` but then I cant get the services.yaml target->entity->supported_features to work.\\r\\n\\r\\nHow can I define a specific feature flag so I can filter out a specific entity for the action target? I have removed the filtering of the entity ids (using a entity_id which does not belong to a chime will result in a understandable error).\\r\\nAlthough I would have liked to have filtering on the enity target as well. Why is the target domain a select entity? Wouldn't it be more logical to have a device target? Because I absolutely hate using a device as a target because that will use some random device_id in the call.\\r\\nWhen I then want to swap the device later on (because it is broke and I have a replacement, I bricked the firmware, I upgraded to a simular model with more features etc.) I just remove the old device and set the entity_ids of the new device to the same as the old device.\\r\\n\\r\\nI get back all the history of the old device in the new device enitities, but most importantly all my automations will continue to work as usual since the entity_id is used as target.\\r\\n\\r\\nOtherwise I would have to go trough my 195 automations and 102 scripts to check all the places where I used that device and re-target them to the new device. (ending up with searching trough YAML files for the old device_id, which is not user friendly). Right, but that is a concern that is not specific to reolink. So I don't think that replacing a device should be a reason not to pick this tbh I kind of dislike custom actions/services altogether, hence why I implemented the select entity in the previous PR.\\r\\nbecause:\\r\\n- they are harder to find in my opinion (don't show in the device page)\\r\\n- targeting is not nice (as explained above)\\r\\n- they require a lot more code to implement than just another entity_description in the list of entities. It has been reworked and now works both with device and with entities as targets (and a mix of multiple together).\\r\\n\\r\\nIt is become a hell of a lot of code for something which could have been just a simple select entity..... Why do we still allow entities to be selected? Is the device alone not enough? You can always select entities when using the target, I am merely filtering.\\r\\nAnd I did make it work through entities or devices, both work.\\r\\nThat keeps me happy since I can use the entity id :)\\r\\n\\r\\nAnd you can also use device_id is you prefer. It's not up to each integration to add other ids than the required id, just for the sake of ease. That should be handled centrally by Home Assistant if we want to do that.\\r\\n\\r\\nPlease remove the entity_id selector. Sure I will remove it, ~but it does not make any sense to me.\\r\\nThen you get a target select in the UI in which the user can select devices or entities (or area's or even labels) and when the user selects a entity it will just not do anything.~\\r\\n\\r\\n~Nothing in the UI tell the user to use the device as target and not a entity as target.\\r\\nSeems very confusing to me.~\\r\\n\\r\\nEdit: See post below, now makes sense entity selection has been removed Should we rename it to `play_chime`? It sounds a bit more logical imo done Can we use translatable exceptions? Thanks for the suggestion, did not know that was possible.\\r\\nHave implemented it now. This shouldn't be target. Just add a selector for `device_id`. Sure, that makes more sense. Then the user also can't select entities.\\r\\n\\r\\nAlthough I like the UI style of the target more than the select drop-down.\\r\\n\\r\\nWould be cool if you could just use the target and then somehow specify that only targetting entities is possible. Would make the UI of actions/services more uniform in my opinion.\\r\\n\\r\\nBut anyway that is not something for a integration but for a arch discussion. Done This doesn't have to be a coroutine function since we don't await inside. Make it an async callback. Done, converted to a callback We never return False so we don't need to return True either. Switched to None return type Maybe sort these ðŸ”¡? I kept the same order as in the Reolink app.\\r\\nTranslations will screw up the alphabetic order anyway (I think). I'm missing a test with unloaded config entry. I added a extra test: test_play_chime_service_unloaded.\\r\\nI hope that is what you had in mind.\",\n",
       " 'Why don\\'t we add all inverters by default? Depending on the setup there may be quite some devices with no or little added value for the user. Me for example, I do have four devices: one inverter (with values of solar yield, that I already get from base setup), one gauge for energy consumption (also already integrated in base setup), one gauge for my heat pump (this one I need) and one relais (can be triggered by solar energy surplus). Based on the SolarLog manual there could be loads more devices be connected. Hence I do not think all devices should be added by default.\\r\\nI thought about adding it in the configuration, but in my view the OptionFlow was a better fit (despite being more complicated to implement). We usually want to go with an approach where we add everything, and people can disable devices if they want I definitely would not like this from a user perspective, but if this is the rule...\\r\\nWould it be an option to copy the step to the initial ConfigFlow, so that the user can decide in the initial setup? \\r\\n\\r\\nIt\\'s an old one but it explains the decision well Thnx. In the reference it is said this applies for data retrieved in one API call. In the case at hand, for every device at least 3 calls are needed (name, consumption, power). The library does only make the calls for enabled devices. Does this still apply? In practice this rule is also applied to integrations getting data from more endpoints. Enphase for example just creates a device for every physical device and that\\'s seen as normal. I can bring this to the core meeting for you and check what they think of this if you want Perhaps this would make sense. I think the alternative to give the user the possibility to choose during the initial setup would also be user-friendly. But I would rather not like to spam the user with loads of unnecessary devices. What does device name return? A user-defined name of the device (can be set in SolarLog configuration) Then we should not have that in the unique id I double-checked in the manual ( and on my SolarLog device and have to correct my above statement.\\r\\nThe device name is automatically detected and according to my understanding cannot be changed by the user. It\\'s possible that it could be changed during the initial detection, but I also have not found a reference for this possibility in the manual either. The device name therefore is immutable. Should we split this class in a SolarLogcontrollerentity and a base entity? This way you don\\'t have to duplicate the _attr_has_entity_name thing (and it looks a bit nicer) Does every inverter have the same data as the controller? No, inverter provide less data points (at the moment solarlog-cli has only implemented yearly consumption(i.e. energy) and power). Some additional data points may follow. Should we duplicate the list to make that difference? Because currently both could contain any key and it would create an entity  According to my understanding L238 makes sure, that only those sensors are created for the specific device, that are also available for this device. Therefore a combined list is leaner and a duplication - well, a duplication... But happy to double the code if you prefer. It\\'s more that the current method comes with an unknown factor. When refactoring integrations, it\\'s always nice to have a view like, okay for this device it will create these entities. But if I understand correctly, the controller can create entity 1, 3 and 4, and the inverter 2 and 3. While if someone looked into the code in a year, one could assume that both the controller and the inverter can create 1, 2, 3 and 4. And even if they have the fixtures from their device, it\\'s sometimes difficult (with an undocumented API) to assume that the device you have, is representable for every device. And there are many ways to do this. Another way could be to add a list of devices that the entity supports to the entity description. (the downside here is that you can\\'t change icon, name or disabled by default per entity per device) or create a separate list for the other device (causing code duplication, but gives more freedom).\\r\\n\\r\\nIf there is a lot of overlap, I would pick the first one, but if it\\'s only 1-2-3 entities that are shared, we can just duplicate it The overlap is not yet huge, but it presumably will increase. I will therefore go for option 1. Oh I meant adding a type in code using an enum of some sort `devices=[Device.INVERTER]` or something along those lines. But now that I see that an inverter only has 2 entities with only 1 overlapping, I\\'d almost opt for just creating 2 lists \\r\\nShould not be needed This is not a broad except right? What\\'s extended_data? The general API only exposes basic data. Additional data can be accessed with specific configuration of the solarlog (in particular disabling password protection for user account). This also applies for the devices, therefore those can only be added if the user opted-in for this extended data. These 2 lines are probably too long, so can we assign the `f\"{coordinator.unique_id}-{slugify(coordinator.solarlog.device_name(device_id))}\"` to a local variable before using in both? That will solve the line length problem Doesn\\'t add anything noqa? What does this do?',\n",
       " 'I see no need to pre-parse any of this info for diagnostics. It just make it harder to debug things so output the full list.  repr is non machine readable. Would have been cool if it would have been a to_json() function that repr internally used. But this output is not for machine consumption so a stringified data is fine.',\n",
       " 'How about making a mapping up next to `COP_LEVELS`? It would also be nice to driver `_attr_min_temp` and `_attr_max_temp` using the LOW or HIGH constants to improve readability.   (As a reader it took me a few moments to understand the idea that there are these notions of levels, and they have specific numbers, and they have specific labels from the API etc so having it all together could help) Implemented all of this. Perhaps there is a way to phrase this in a way that the user might understand the implications of this? I\\'m not sure i follow what i\\'m supposed to understand from this.\\r\\n It\\'s a complex issue that\\'s also covered in the documentation.\\n\\nEssentially some vehicles require an extra layer of security that this integration doesn\\'t currently support using.\\n\\nExplaining that in the error seems too long. Could refer to the documentation maybe as I agree with Allen it\\'s very technical error `Command signing is required, please see integration documentation.`\\r\\n\\r\\nDoes this work? I think this check should be moved into `async_setup_entry` to avoid adding the entity. If none of the commands are supported or not allowed then let\\'s not add the climate entity.  My impression is there are already sensors for a read-only view.\\r\\n\\r\\n(Also I don\\'t think we need logic later to check `raise_for_scope` and `raise_for_signing` and to raise on a command given here we\\'ve already said the feature is not supported. My assumption is that the tests would still pass if those checks were removed given the climate integration won\\'t call the service if the features are not enabled?) There are not sensors for a read only view because they would duplicate the values exposed by the climate entity.\\n\\nThe intent is to use the correct platform so that a user can later decide to add the required scopes and the entity won\\'t have to change.\\n\\nThe approach used here is consistent with Tessie and Teslemetry. There\\'s climate_state_inside_temp which seemed like the important bit.\\r\\n\\r\\nEither way, my other point was there is complexity with these checks later in the entity and I don\\'t think it is needed. My impression is that if the features aren\\'t set the code in the entity for double checking these things won\\'t run because of the missing featuers. My assumption is the tests exercising those aren\\'t actually covering those code paths (could confirm looking at code coverage or the error messages raised). Some of the climate attributes are exposed as sensors yes (forgot about that), but this isnt true for the other platforms for example the lock platform is the only way to see if the vehicle is locked. I dont believe hiding the climate entities is the right outcome, because I know for sure I\\'ll have users raising issues that the climate entity is missing.\\r\\n\\r\\nThese cases are covered in tests `test_climate_noscope` and `test_climate_command_signing`.\\r\\n\\r\\n~I dont think I understand your core point because there is no \"double checking\". If there is a reason the integration knows a service call will fail it checks for that before trying to execute it, and only does that at run time.~\\r\\n\\r\\nConceptually this isnt new:\\r\\n#L293\\r\\n Ok I do think I get what you mean by \"double checking\" now. My challenge is that not all service calls can be disabled with support_features.\\r\\n\\r\\nIs your suggestion to remove the `self.raise_for_signing()` and `self.raise_for_scope()` on service calls that are removed with `ClimateEntityFeature(0)`? Ok so you can\\'t disable set HVAC mode since it\\'s not associated with a feature? Presumably because it\\'s a requirement to make a useful climate entity. There is lots of prior art of not creating dummy entities when the user doesn\\'t allow the scopes too fwiw (e.g. other integrations use oauth scopes to decide what to expose).\\n\\nPerhaps simplify to \"read only\" since the details of why it\\'s read only (scopes, code signing, etc) doesn\\'t matter and is set only once. > other integrations use oauth scopes to decide what to expose\\r\\n\\r\\nDo you have an example of what good looks like? Am I meant to created disabled by default sensor entities to cover every single other platform type just incase the user doesnt have scopes? I obviously cannot remove sensor entities based on scopes because that would be a breaking change when scopes change.\\r\\n\\r\\n> Perhaps simplify to \"read only\"\\r\\n\\r\\nNot all commands require signing, so I only `raise_for_signing` on the commands that do. > Do you have an example of what good looks like? \\r\\nThe ones i\\'ve had experience with (Nest, Fitbit, Google Calendar, etc) each follow the user choice during oauth / setup on what permissions are allowed then only expose entities based on that choice. They don\\'t expose placeholder functionality.\\r\\n\\r\\nI do not intend to suggest exposing disabled by default sensor entities -- saying the opposite, about only exposing entities based on what was allowed.\\r\\n\\r\\nI did see knx appears to have a notion of a read only climate entity. I noticed it returns a single `hvac_mode` for `hvac_modes`. That may have the side effect that it doesn\\'t allow you to change the mode?\\r\\n\\r\\n> Not all commands require signing\\r\\n\\r\\nWhich commands require only signing or only scopes? The logic looked the same everywhere in climate entity so it didn\\'t seem necessary to be specific and check both. Interesting idea about `hvac_modes` ill give that a shot.\\r\\n\\r\\nIn the climate platform everything requires signing, but there are commands in other platforms that dont, however looking at the list its rather small, and when checking the Tesla documentation they now suggest signing for all commands (despite some not being implemented in their own reference implementation), so I can probably remove this distinction.  My impression is that the current style preference is that you add typing on the arguments also given the response is typed too -- so add for vehicle? (We don\\'t do partial method typing).  This comment applies elsewhere also. Fixed, thanks. It seems like this method could be part of the coordinator since its overwriting state currently managed by `_async_update_data`. \\r\\n\\r\\n(Aside: This could also let you get a little fancier with the wake attempts and state related to that. Right now a temperature call may invoke the \\'wake\\' multiple times if it both sets a temperature and sets a mode for example and so you could avoid unnecessary calls to wake up if its been woken up recently already.) >may invoke the \\'wake\\' multiple times\\r\\n\\r\\nThat Isn\\'t possible because I am using an asyncio lock on line 15.\\r\\n\\r\\nIs it being outside the coordinator an issue? Its just going to be a bunch of work to refactor both this and Teslemetry to keep things consistent for maintenance.\\r\\n#L13C11-L13C26 I believe that stops them from running concurrently (good), but i think it will still run twice in a row when setting the temperature and setting an hvac mode. Your correct that `wake_up_vehicle` will get called twice but `while vehicle.coordinator.data[\"state\"] != TeslaFleetState.ONLINE:` will equate to false on the second run because the first was successful, did `vehicle.coordinator.data[\"state\"] = state`, and didn\\'t raise HomeAssistantError Ah of course, thanks for the correction. My impression is that turning off a preset mode should turn off a preset but not necessarily turn off the A/C. That is, it would just mean the A/C should be behaving normally without a special mode, but could still be on.\\r\\n\\r\\nIs there a specific reason for this or is leaving the hvac mode alone here right? I think this might actually be an edge case bug. Turning off the present shouldn\\'t turn off HVAC, but only if the user is still in the vehicle.\\n\\nIf they are not in the vehicle, the vehicle will turn off the HVAC when preset is off, which is why you typically use a preset like these anyway.\\n\\nI\\'ll rethink this. This line was removed, its a bug.\\r\\n\\r\\nI think most users would never run into this because they wouldn\\'t be using Home Assistant to modify the preset mode when sitting inside their vehicle, but its defintely possible and put the entity into the wrong state. Is `climate_state_climate_keeper_mode` preserved/remembered when the vehicle is turned on/off?\\r\\n\\r\\nGenerally, I\\'m trying to think through what can go wrong given the climate entity is using assumed state to proactive sets attributes that don\\'t come directly from cloud responses (e.g. data update coordinator is no longer the source of truth). I see here this is cleared when turned off but not re-instated when turned on so just want to make sure it works that way where the API clears it on its end also. Preset modes are only used to keep HVAC on after you leave the vehicle, they are never remembered and need to be instantly cleared when HVAC turns off.\\r\\n\\r\\nBy forcing both the HVAC mode and preset mode off at the same time we replicate how the vehicle behavies without having to wait for a coordinator refresh, otherwise Home Assistant would show an impossible state (preset on but HVAC off).\\r\\n\\r\\n Sounds good. Are users expected to know the 3 specific temperatures here? I\\'m curious how this is expected to work. Should set temp be supported at all or might more preset modes make sense here? The Home Assistant UI knows the minimum and maximum and step, so no the user doesn\\'t need to know what the possible values are because that information is communicated to them through the climate card UI.\\r\\n\\r\\nIf they are calling the service directly then I do expect them to know how to read entity attributes or already know about the three levels.\\r\\n\\r\\nI feel it\\'s better to communicate temperatures than Low/Medium/High because a user will likely not know what those levels translate to in the real world.',\n",
       " \"Should we just do an icon here instead of the channel icon? I think it can look strange if you add more sensors that they all have the same picture.\\n\\nWdyt? That's true, although it doesn't bother me. Not sure if there is an appropriate icon for both of them. I think subscribers is fine as is, but let's add one for the views, not sure if there is a viable icon for that. Please use the icon translations to add one  I'm wondering, what makes the `views` any different from the `subscribers`?\",\n",
       " \"\\n \\n Not needed Oh, why don't we store this in entry.runtime_data?\\n\\nYou can use a dataclass to store both Please use constants \\n \\n Idem Idem Please leave reauth for a follow up Don't create mutable objects on class level, rather create them on instance level in the constructor Idem Can we type info Why don't we add everything we find? We want to make the set up as easy as possible This should belong in the sensor platform Why the dict Please use translation keys and entity translations and icon translations What's a COP? Can we type the update coordinator with the return value of async update data?\\n\\n\\n Let's do this outside of the constructor tbh Typing Typing Typing Let's move this to a constructor with `_attr_device_info` Why do we set it if it's empty Remove empty fields Not really needed imo, because this can change in the future and it would run stale Typing Use an f string Why don't you just go for overwriting the native value property?\",\n",
       " \"You only have to inherit ApSystemsEntity If I do not inherit the `BinarySensorEntity` here, the tests fail and I get an unavailable state for all binary sensors. I *think* Joost referred to the `CoordinatorEntity` being unnecessary, because afaik ApSystemsEntity already inherits that No, `ApSystemsEntity` inherits only Entity from `homeassistant.helpers.entity`. If `CoordinatorEntity` is omitted, the binary sensors also cannot be set up successfully either. Okay, then my bad Ooh you're right\\r\\n\\r\\n@mawoka-myblock A nice follow up would be to maybe create a second `CoordinatedApSystemsEntity` base entity so you can avoid the double inheritance I think this is already in ApSystemsEntity  Make it a dataclass instead These aren't booleans right? Yes, the Apsystems python lib returns an IntEnum `Status` class here: #L164 Do you have a link to the Status intenum? Shure: #L8 I'm not sure why this is an enum and not just a boolean tbf That's right. But that's something only @mawoka-myblock can say something about. ðŸ˜‰  (it also wasn't a comment for you, just thinking out loud) Not really sure here, but I got the python api file from a beginner and started improving it from there while sticking as close to the api as possible. So that's how you sometimes miss things like that, right? But I'd say that it's not a huge problem, is it? No it's not, but it would be nice to eventually change this, this way you could remove the `bool` from `binary_sensor.py`. Because when you see an enum you automatically get the idea there are more options, but if its only true or false, a boolean makes more sense.\",\n",
       " \"Lambdas should not be multi line, if it doesn't fit on one line make it a function instead. This should be for network clients right? Not for infrastructure  It is infrastructure. Uplink MAC for my UDP is my modem MAC. Uplink MAC for my Switch 24 is my UDP MAC, etc. Make the two devices unique and combine them to one list and skip the `if not has_uplink` as we should refrain from using if-statements in tests This string is wrong\",\n",
       " \"Rather create a separate coordinator, I've been told Throttle isn't very optimized Would it be possible to add a test for it too? Instead of mocking the aioclient, shouldn't we mock the github library? I tried but i couldnt't get it to work. The github integration uses the same library and does the same, it mocks the aioclient.  i figured it out :D Would it make sense to have this set in `async_setup` and added to `hass.data` just like in `wled`? I know that it's more likely to have multiple `wled` devices than multiple irons, but I like to think that its nice to see it as a good practice.\\r\\n\\r\\nWDYT? (not seeing this as a blocker btw, just thinking out loud) You mean one single coordinator for all instead of per entry? Hmm, I think that makes sense but if it is not a blocker, I would prefer to do this in a follow-up PR Fine by me would it make sense to do this in init.py and make it a parameter to avoid to call it twice? Isn't `_async_setup` only called once during initialization? ðŸ¤”\\r\\n\\r\\nOh, right, it is called once per coordinator initialization. Good point! Thinking about it, now that firmware version is relevant for the update entity, it maybe be necessary to refresh the device info from time to time, in case it has been updated in the meantime, not only on integration setup ðŸ¤” Then you should move it to the update function Ok, never mind, just remembered the device_info is cached in the library, so calling it twice would not result in fetching the characteristics from the device again.\",\n",
       " \"We no longer allow integrations to add or change a platform YAML configuration.\\r\\n\\r\\nMore information on this can be found in Architecture Decision Record:\\r\\n\\r\\n- ADR-0007: <#decision>\\r\\n\\r\\nPlease note that this integration connects to a device or service, and another Architecture Decision Record applies that disallows the use of YAML configuration in favor of a configuration flow via the UI:\\r\\n\\r\\n- ADR-0010: <#decision>\\r\\n\\r\\nSee our developer documentation on how to get started creating a configuration flow for this integration:\\r\\n\\r\\n<\\r\\n\\r\\nAs these changes often involve a bit of work and some significant shifts in the current code, we will close this PR for now.\\r\\n\\r\\nWe (and our community!) would really appreciate it if you could start on the refactoring of this integration in a new PR.\\r\\n\\r\\nThanks already! :+1: OK that's interesting to know (after two months of waiting and hoping).\\n\\nSo that means this great integration will stay in current shape until someone starts to migrate it to a config flow version?\\n\\nUnfortunately, that's for sure way out of my skill level.\\n\\nToo bad, I thought spending some hours solving a problem I have and making the improvement usable for everyone would be a rather quick and helpful thing. Unfortunately with all the needed rework I won't be able to work on this any further. Probably this integration will die (no maintainer, no huge user base, zero changes for years... one breaking change in core and goodbye VoiceRSS ðŸ˜”).\\n\\nAnyway, it was interesting to see and learn a bit how things work in the developers building. I'll move back to the users building, enough PR experience for a long time.\",\n",
       " 'We should not use any calculation on the expected value as this could hide a conversation error.\\r\\nI use an online converter to get the expected value, and then the tests ensure that our converter works the same way.\\r\\n\\r\\n',\n",
       " \"Not sure if I can fix this easily. Error was:\\r\\n> homeassistant/components/homematicip_cloud/sensor.py:93:11: C901 `async_setup_entry` is too complex (29 > 25)\\r\\n In a separate PR, I think the function should be refactored. Maybe make a map between classes and entity objects? Not sure why this is failing in the tests. When can this be false? I think you can remove the hasattr check for valveState, because this is always provided by the class of the upstream lib. I think what helps with simplifying is to make this a single list comprehension @barryvdh You could use that comprehension (which also uses all Falmots): \\r\\n Done in  HI @barryvdh \\r\\ncan you please add imports AsyncFloorTerminalBlock6, AsyncFloorTerminalBlock10 and AsyncWiredFloorTerminalBlock12 to imports. All are nearly the same but with different amount of channels. This is done in  hasattr check can be removed, because the attribute is always available If I removed it, I get this error:\\r\\n\\r\\n> FAILED tests/components/homematicip_cloud/test_sensor.py::test_hmip_floor_terminal_block_mechanic_channel_1_valve_position - AttributeError: 'HeatDemandChannel' object has no attribute 'valveState' I was really confused why that error happened. The HeatDemandChannel could not be a HomematicipFloorTerminalBlockMechanicChannelValve Instance, because we defined in the async_setup_entry which channels are allowed.\\r\\n\\r\\nCurrently at a few points in the code (not just yours) the functionalChannels Array is accessed via the index (functionalChannels[channelIndex] which gets not necessarily the right functional channel, if there are more then 10 channels. So the array index differs to the channel.Index value. I hope I was able to explain the point.\\r\\n\\r\\nThe best way until I fixed it is \\r\\n\\r\\n\\r\\nIt's untested, but you can use that everywhere, where you are calling `self._device.functionalChannels[self._channel]` at the moment. \\r\\n So like this? #pullrequestreview-2370369548 Do you need that? Its not referenced somewhere (at least I couldn't find it) Correct, removed\",\n",
       " 'This should be a service instead, as it is a one-time action, and we don\\'t care about the state.\\r\\nAlso, if I want to play the same tone twice I need to set to a different option first otherwise the the option is already set and so HA will call the method to change it.\\r\\nAdding the service should be done in a follow-up PR so this one can be merged and included in the 2024.8 release\\r\\n\\r\\n Using a select gives a much nicer user interface where a user can just select the chime to play.\\r\\n(I could have used button entities, but then you get 9 button entities instead of 1 select).\\r\\nThe value is set to None always and when selecting a option, it will play the ringtone and also emedialtly go back to/stay on the None state (async_write_ha_state).\\r\\n\\r\\nI have tested this and you can select the same ringtone again to play it a second time.\\r\\nAlso you can use the select.select_option to play the same ringtone muliple times after eachother (you need a delay of the time it takes to finish the ringtone, otherwise it keeps starting the beginning of the ringtone).\\r\\n\\r\\nBesides the `key=\"play_quick_reply_message\",` entity works exactly in the same way and is already present in this integration. I think I agree with @edenhaus. Like, yes it\\'s a nice way to give the user a quick way to play a chime, but _what is the use case?_ I would assume most people only visit the device page when they are setting up or checking something, not for actually doing actions.\\n\\nI would argue that select entities would only be the best pick when it has a state. Otherwise a select entity could also be used as a remote, where all the buttons are put as options. While it works, its not ideal. So yea, I\\'d argue that playing a sound (and playing that quick text message) is an action and thus should be a service call (or buttons, but I think a service call is more flexible here when reolink adds more sounds or messages, otherwise you might have to add even more entities in the future) For the \"quick replay play\" I just added that entity below my camera stream so I can play a voice message when someone is at the door, no need to create something with services, just add the select entity.\\r\\n\\r\\nIndeed for the play ringtone off the chime it is less likely a user wants to trigger it, but more likely to be used in automations and scripts, but if you use the select.select_option or a custom service really does not matter much.\\r\\n\\r\\nBesides having it as an entity on the device page makes it a lot easier to find for users (in my opinion).\\r\\n\\r\\nI agree buttons would be a even better fit, but you end up with way too many buttons....\\r\\n\\r\\nI do like the select entity better, but if you ensist I will remove this entity and implement a service in a future PR. I removed it. Why can the coordinator be None? Because when it is None, the default coordinator will be used (almost all reolink entities use that coordinator).\\r\\nSee #L53-L54 \\r\\nYou can remove the list creation and use a generator expression  Thanks for the suggestion, I removed the list for all platforms of the reolink integration. Should we type `method` to be of return type Callable? Method is already typed as Callable, see line 53. Idem done Why would it be None? This is for the `play ringtone` / `play quick reply message` entities. they always have value None.',\n",
       " \"We should extend the typing of the config entry to make it type safe Is the email unique? I believe so yeah, I could call `.lower()` or `.upper()` on it if you'd like \\nThe moment you have the extended config entry type, this isn't needed anymore  Let's still try to use the normal rules and only add the cover in this PR why isnt the constant stored as vol.Schema? I'd invert it \\r\\n\\r\\nThis way you don't need multiple forms Let's leave reauth for a followup This function can be inlined imo So if I understand correctly the whole setup function is only for setting up for the first time? Use `_async_setup` that's a new feature we added this release Do they encode json into json? Yeah, it's weird Followup\",\n",
       " \"Please make the default propane to preserve existing use cases  Please use a different constant or bare string for the step since these are not the same  Please bump dep in a separate pr so I should not change the integration manifest dependency in this PR?  The integration changes require the new package version to build and once I change the manifest will not check in without the manifest due to the build script blocking the commit.   \\r\\n\\r\\nSorry, I'm new to this show so I'm not clear if you don't want me to update the manifest or your just asking for a separate PR to identify the requirement to bump. never mind  i think i understand, will do. example  @bdraco Can you plesae clarify.  Previously data={DATA_MEDIUM_TYPE: user_input[USER_INPUT_MEDIUM_TYPE]}, had the same keys.  In your review you said they were not the same so I changed them to be different.  It appears your new comment suggest a name change but to make them the same.  Personally, I kind of feel these are just keys and if they happen to be the same in both dictionaries that's OK but I'm happy to go either way.  thanks For clarity, my concern was about mixing the step names and the data.  There is no concern about using the same keys for the user data and the config entry data since they are ultimately the same data. This needs a bit more work though since `entry.data.get(CONF_MEDIUM_TYPE)` will be `None` for existing entries so it should probably be\\r\\n This looks unused Setup the entry here to make sure the entry reload listener works  Please revert the typing change on this line  you may have an older version, mine shows ConfigEntry Cleared browser cache and itâ€™s still there. Will double check it by pulling manually when Iâ€™m back at my desk  no my bad, i thought i had changed that but guess i didn't rebase.\\r\\n Please use the integration specific config entry type here  This was the concern about mixing step id with the data key. Please use a bare string or a named constant for the step id.   This schema could be a constant since it never changes. \\r\\n\\r\\nWe want to use the integration specific type for all instances where the config entry is a mokepa config entry\",\n",
       " 'Do this in a separate PR and link to the changelog  Reverted the version bump, PR for that here:  Nit: missing new line at the end of file Nit: missing new line at the end of file',\n",
       " '2 things\\n1. Translations (both entity name and icon translations) (i think this got migrated to had entity name so that would work)\\n2. Should this be disabled by default? Solved by:\\r\\n1. ef1275f87371ecb765b3c8a9cb4a0c3b62ca77ae\\r\\n2. f96363ae41395a9bd501a6d3284f34d62d46ad37 \\n',\n",
       " \"Is there an easier way to reset the call args, but preserve the current mock state?\\r\\nThis seems unnecessarily repetitive. If you just want to test the service call you can just remove the receive of the event. Is that what you mean? The sent commands depend on the current state (brightness / color) of the light, so having the correct state before calling the service is necessary.\\r\\n\\r\\nThese assertions depend on how many calls were done before, which introduces coupling between the sub-tests\\r\\n\\r\\n\\r\\nso I'm looking for a way to reset the call history, but not the entire mock state. You can use `reset_mock` on the mock attribute that you want to reset. Ok so just `client.async_send_command.call_args_list.reset_mock()`? No, `client.async_send_command.reset_mock()`. Ohhh, I think the issue is actually not related to that. I am using this call already, but I thought it was resetting the Z-Wave values aswell. However the test sets the `targetColor`, but there's no machinery in place to update the `currentColor` afterwards. Side note: We should replace the standard light entity attributes and properties with `self._attr_color_mode` etc in the future, where appropriate. I had to do this because `scale` is considered `float | None`, even after the definitive assignment here. The suggestion causes an error on the line where `scale` is multiplied.\\r\\n\\r\\nMaybe there's a different trick I'm not aware of, like TypeScript's non-null assertion? Ok. Please use keywords when passing a `None` value so it's easier to read what parameters we're using. Do we need to get this value a new on every call to turn off or can we store the value as an instance attribute?  I guess we can cache it in `_calculate_color_values`, but I was under the impression that this is just a simple lookup. If it's the same instance there's no point in looking it up more than once. I'm missing an assertion of the entity state after this event. Otherwise we can remove this call. This will error if the list is empty.\\r\\n\\r\\n\\r\\n\\r\\nIf we know that this light always supports red, green and blue colors, ie we don't have to worry about an empty list here, it's weird that we check `self._supports_color` in this class. The modified discovery scheme creates an instance of this class for\\r\\na) devices that only have a current color, but no switching capabilities\\r\\nb) devices that have a binary switch and a current color\\r\\n\\r\\nSo there should always be at least one color component, otherwise the scheme wouldn't match.\\r\\n\\r\\n> it's weird that we check self._supports_color in this class.\\r\\n\\r\\nDue to the discovery scheme, it might be that we end up with a white-spectrum light that cannot be dimmed, but turned on and off. I'm not sure how to match lights that have exactly RGB support, but nothing else, since the discovery scheme seems to match when ANY of the specified values are there, not ALL.\\r\\n\\r\\nShould the initial `if` in `async_turn_on` and `brightness` should defer to the parent class if there is no RGB support? That way we should avoid this problem altogether. `max_value` can't be `None` with the filtering above it seems.\",\n",
       " '\\r\\n\\r\\nNot needed as already tested with `test_number_entities`\\r\\nFor volume, the test `test_volume_maximum` was created as the maximum value can be changed dynamically by an event from the bot (as different bots support, unfortunately, different ranges). But in your case it is fixed and therefore not needed Thanks for the feedback on that one - have removed in the latest push',\n",
       " \"If this doesn't need to wait for the the callback to finish, `loop.call_soon_threadsafe` is much more efficent If this doesn't need to wait for the the callback to finish, `loop.call_soon_threadsafe` is much more efficent missing coverage Added test to cover this line Is it safe to create a session here?\",\n",
       " \"As mentioned in the previous PR, it is not relevant or meaningful to add all parameters to the entry. In fact, looking at your example, there should be a validation error and a testcase that disallow `CONF_PERCENTILE` without `STAT_PERCENTILE`... You're free to address that in an another PR but the initial implementation was based on the yaml-schema which has these as defaults hence it's added regardless if the user provides some input or not.\\r\\nThis PR is about adding preview. The second part was rather a point for myself. The percentile characteristic was introduced by me and I didn't consider this as a noteworthy anti-pattern back then. My fault, not your concern :) No worries. Would be happy to see a follow-up PR if you think it's worth fixing it (user experience)\",\n",
       " \"Can we keep the old one around and deprecate that one properly? Reolink did a PR a few days back where it had to deprecate one, so maybe that's a good inspiration  \\n I think uptime is still a valid and common name for the start up timestamp Hmm, something in me things uptime is viable for both, but I'm not sure what is best here I'm happy with both, so I can change it to use uptime for both if you prefer that. The only downside is that they'll both be called uptime so one will be appended `_2` > The only downside is that they'll both be called uptime so one will be appended `_2`\\r\\n\\r\\nAh, you're right, and we won't be able to tell them appart for `uptime_seconds_deprecated`... I've asked for a second opinion on this. \\n\\nBut also keep in mind, people could've renamed both the name and entity id, so it could but even be recognizable \",\n",
       " '',\n",
       " 'Is this PR missing a `strings.json` entry? Good find! :)',\n",
       " \"You could invert this to avoid having 2 async_show_forms I think this way is more readable because we return early, isn't it? I like the other way more because it's a bit smaller and you don't repeat the show form. (Some integrations have it so that they have it 3 times, so this integration isn't the worst) Updated Config flow has a `self.add_suggested_values` function that would help Updated \\nIs default for primary objects Don't we get anything interesting from the API to use as unique id? No, the API is very basic. Also, we may use several config entries for the same key (but different prompt, etc) Unused? Yes :) No need for this as this was only for old style integrations. THis one will only use the new entities.\\r\\n\\r\\n Removed You should make a copy or else the trace of older interactions with the same conversation ID will have the same list, including future messages.\\r\\n This is only used once, does it make sense to have it in an inline-function?  Should we move it outside of this function instead? Moved outside.\",\n",
       " 'Use runtime data instead No import? Why is this limited to a single entry? There were too much moving parts currently, I think this requires a bigger refactor at the moment Should move to `async_setup`? Broker is not available back there',\n",
       " \"We have the same thing here as in \\r\\n\\r\\nWe have a list of possible values. \\r\\n\\r\\nWould be nice if they was generated on the fly. \\r\\nBut I'm not sure how we can do it, as the device need to provide data before we can make them. How do you mean generated on the fly? In all cases we wait for data before creating entities That is what I mean. \\r\\nIt would be nice not to define those cases like `CPU`, `Local` and `PHY` here. \\r\\n\\r\\nI think we also briefly talked about it in #116737 that we could make those entities based on the data coming in. \\r\\nBut I'm not sure where and how to start. If you know the structure you could iterate on the content of them and use the keys as name I guess? If I understand you correctly.\\r\\n\\r\\nThinking again about it, as this is about generating the descriptions we can't be reliant on any runtime data as this needs to be setup before reading any data from UniFi See the changes to the sensor platform here  I think I've applied similar changes now Copy paste issue.\\r\\n\\r\\nI still think we can change _device_temperature method in such a way that we don't need this TYPE_CHECKING step > I still think we can change _device_temperature method in such a way that we don't need this TYPE_CHECKING step\\r\\n\\r\\n\\r\\nStill not 100% sure I understand what you mean here?\\r\\n\\r\\nDo you mean that `_device_temperature` cannot return `None`? If you can make it always return the expected container fo example If we do that, then the supported_fn need to verify that the container have a `value` I tried to return `{}` but that is not possible. \\r\\nIs there another way we can achieve this?  You could change the _device_temperature to return the value or None instead, then instead of type checking we could do `return temperature if temperature is not None else 0` or something along those lines If we do that `async_device_temperatures_supported_fn` will always return true. \\r\\nI think that is worse? Added something in b11c2b49a474599a40d0336fd74dfdb2ca7e9141 \\r\\n\\r\\nI was thinking something like this return 0 is not reachable here as #_supported_fn will make sure to not update the value see entity.UnifiEntity.async_signalling_callback\\r\\n\\r\\nMaybe something like this\\r\\n\\r\\n Still no coverage here \\r\\nLets make sure the deterministic part is first\",\n",
       " \"If it's a light, shouldnt it also be a light platform? It is a wall switch whose usage is for simple light : \\r\\nI am perhaps wrong thinking the correct platform is a switch for this type of device ? Oh then it is a switch Corrected. Corrected. Stale Corrected This should follow the logger in the library btw Done Done\",\n",
       " \"Can be set outside of the constructor  Make the step the parameter \\n There's a helper for this, don't know the name but I think `discovergy` uses it yep \\n\\nasync_update_reload_and_abort Self.entry is always none when its not a reconfigure  You can auto update iirc for what purpose? I don't want to abort if the IP changes but the mac is the same But you do want to update the IP address in that case and not create a second entry okay I think I did what you are saying but not really clear because its undocumented\\r\\n\\r\\nif the IP changes during reconfigure, it will always update the entry\\r\\n\\r\\nif its a new mac, it will update the unique ID\\r\\n\\r\\nI am not sure what else _abort_if_unique_id_configured should be doing since it only matters during a new configuration \\n \\n Rather split these tests up We should not mock this imo \\r\\nI think this can be removed since if we have a `self.entry` we are in a reconfigure flow for sure\",\n",
       " \"Make unit tests, put this in there. Profit. Unresolved  Comments are gone and I dont have the understanding yet to do unit tests and will run  of of time very shortlly Remove the comments Only have stuff in the try block that can raise Don't catch bare exceptions outside of the config flow \\n Please use an f string Honestly, just create the device info in here instead of creating it in init and passing it to every object We can remove this imo  Might as well just implement the `is_on` property. You can then remove the constructor all together  I think i still need to do this for self.async_write_ha_state() as auto update is off? That's the default implementation of handle coordinator update Why isn't this in the library? We can remove a lot of the comments and make it much simpler Surely the data presentation should be down to the integration? , The library does I would expect in this case and gives me the results of my query. But you could also argue that this is part of the protocol and the way the response should be perceived, and this belongs in the library You could , and you could argue this is good defensive programming and response should be perceived by the presentation layer not hidden by an intervening api as we might be able to use that subtlety to better present the data.  I have been bitten by the curse of the API hiding that to many times. comprise take it out of the _async_update_data cand all something to do from there it in the class in say _prepare_data  uncluttering  the Update and an being clear  on the data manipulation for presentation? I mean, i dont mind it being here, but we should not make it too complicated with alle comments and stuff. We should rather introduce unit tests to make sure the data is perceived correctly I think this code would still need to be there even with unit tests but I can take out the comments about the status Items I haven't used or manipulated for presentation, they were more an Aid for later.  Please don't do this, use translations Why don't we create the device here? Means taking stuff into the entity and it was how airgradient did it ;-)  Oh, but that's because we don't have all the info in all the entities because we have 2 coordinators. But I think you can just complete the device info here Yes think I might well end up there too, with more entity types, but having thought about It quite a lot last night this seem to be the cleanest approach as it contains all the server setup stuff(inc device) to __init__ and then I can just link/pass on to that. \\n ? I dont think the context is needed here \\nRecommendation  Let's make these more human readable \",\n",
       " 'This can be combined with a generator expression \\n\\n\\n I\\'m not overly familiar with python but from what I understand, your suggestion won\\'t work as-is. Can you elaborate on what you want me to change? updated What\\'s this for? Probably not needed. I\\'ll remove and re-test. Name is required. Fails to initialize if I remove it. Do we use it in the base class? (If so, could you please post the link because I\\'m on mobile) It\\'s used in the callbacks of this class.\\r\\n\\r\\n#L81-L84 Oh can we rename this to `zone_name`? `_name` kinda indicates that\\'s it\\'s the entity name done What\\'s a damper exactly? The [damper]( is how each zone controls how much air is allowed through it. It can be fully open, fully closed, or anywhere in between. AirTouch5 is a multi-zone AC. There is a central AC unit with ducts going out to each zone (usually a room), each of these ducts has a damper inline, the damper controls the rate of flow of air in to that area.\\r\\n[Damper example image]( Too fast ðŸ˜… Honestly, maybe a `valve` would also fit here. But I\\'ll leave that up to you two Oh never mind, apparently we have a device class specific to damper, so cover is the best I would assume It is okay (although not recommended) to manually control the damper for zones that have temperature sensors.\\r\\nI think we remove this test and always allow it, we should update the documentation to say this isn\\'t recommended because the AirTouch5 unit should be controlling them (assuming you have AT5 temperature sensors, which you really should have!) I\\'m happy to do that. I haven\\'t made the doco PR yet but it\\'s on my list of things to do. Now you can combine those  Is static, thus can be set outside of the constructor  Let\\'s use a translation key Good point! I\\'m missing a translation key in the class\\n\\n\\nAlso let\\'s call it something better I reused what was in the base class.\\r\\n\\r\\n#L12-L17\\r\\n\\r\\n#L3\\r\\n\\r\\nHappy to change it if you still want me too. Updated translation to \"damper\" but left the climate translations as they were.',\n",
       " 'Stale? Stale? And typo',\n",
       " \"\\n resolved \\n resolved Why do we remove the binary sensor one? because that translation key is not being used in the binary sensor (and it was me that added it recently) Also please overwrite the type outside of the constructor Hmmm.....I'm unsure what you mean by _the type outside the constructor_.  I can't really see which other types would need to be updated? You mean like this: `entity_description: HiveSensorEntityDescription`? We don't want to make these strings, because not all values are strings \\n Please also add the on and off ones, they should be references completed \\n completed\",\n",
       " '\\n \\n There\\'s not much I can do here, is there? The format is specified by ruff. I think it\\'s short enough to be on one line, but the comma at the end makes ruff go to the second line.\\n\\nBut it\\'s also possible that ruff adds the comma, in that case this can be ignored Stale Replace `_state` with `_attr_is_on` Only have stuff in the try block that can raise I think the update is run by default Not sure why we call async_refresh The API doesn\\'t have an `async_refresh` function. Lol Oops, sorry. All this async stuff is still partly \"magic\" for me and it\\'s not always clear to me when a function implies a certain functionality just by its function name and when what is executed where.\\r\\n\\r\\nBasically I just wanted to update the coordinator to get the current switch state after switching the switch.\\r\\nHowever, after thinking about it again, I think I don\\'t need to do this at all, as the update process is handled automatically via the `is_on` function.\\r\\n\\r\\nIf I annoy you with my trial and error commits, feel free to ignore the merge request for now. I will remove it from the draft status later.\\r\\nIf it still causes too much noise, I will gladly close it again to reopen it later.\\r\\n\\r\\nBest regards and thanks for your feedback. ðŸ˜Š  Why in the async_add_executor_job? I\\'ve never seen that, so just asking It\\'s for running sync functions that do blocking IO Okay, then it\\'s wrong, as the api is completely async, including this function. That doesn\\'t work like that, as the `self._api.get_device_power_status()` returns a coroutine, which doesn\\'t contain the value or anything, so you\\' have to add an `await` before that. In addition, this shouldn\\'t be needed, as it\\'s handled already And no IO here as well, as it\\'s a property Firstly, here\\'s the same with the coroutine, secondly, as mentioned in the docs, this function mustn\\'t run any requests and must only return from memory, thus making this obsolete. the update should be implemented in an async_update function instead.\\r\\n\\r\\n Idk, but running `await self.async_update()` may be needed here, but I\\'m not sure, another one will have to verify I have tested it locally in connection with my inverter. And it looks like it works without an additional `await self.async_update()` at this point. Yes, the other integrations also don\\'t call the update function Same with running update here (maybe) Finally runs always, so you\\'d be making the sensor available always Isn\\'t needed, implemented automatically Implemented automatically as well \\n ohh, that is nice. thx for the hint \\n',\n",
       " 'Moved `if old_major_version == 1:` out',\n",
       " 'Should we keep these alive for 6 months and raise an issue when added/used? We can remove them if someone disabled them > We can remove them if someone disabled them\\r\\n\\r\\nI don\\'t think that will work: the swich entity will not be set-up anymore, so it will always be unavailable.\\r\\nIf we do set-up the switch enity, removing it here does not work because it will be re-added in the next step when the platforms are set-up.\\r\\n\\r\\nWe could keep both entities around for 6 months, but it is a bit confusing to have 2 entities doing the same thing for new users.\\r\\nBesides, because my code uses the same class for all switch entities it is a bit of a pain to implement deprication code (raising the issue) specific for 1 entity.\\r\\n\\r\\nI guess I could make a seperate list of depricated entities and during setup check if it is enabled or not and only set it up if it is enabled and then raise a repair-issue. That would be the nicest, but also the most work to code..... hahaha You can set up both entities, but only if the switch has been added before as it is not disabled yet.\\n\\n I will write some code @joostlek alright, finished, could you take a look if this looks good to you?\\r\\nStill need to test when I get back home tonight, so do not merge yet.\\r\\nBut you can already approve if you think this is alright. It is deprecated and will be removed changed, thanks You already have HDR in the switch so you can reference done Can\\'t we just search for the entity directly? I don\\'t know how.... We know the complete unique id right? We can find the entity by the unique id iirc The start of the unique_id has 6 diffrent possibilities depending on how the camera is connected and what firmware the camera is running (if the serial number is available). Aah check, in that case its probably suboptimal to check 6 times \\n Thanks, I adjusted the spelling error throught the PR. \\n \\n Can we avoid adding more if statements to the tests? yea, sorry missed this.\\r\\nRemoved it now. I have a personal ick for the `const.DOMAIN`, but that\\'s personal preference I also find it very confusing that in entity_registry.async_get_or_create( the domain is supposed to be \"switch\" and the platform supposed to be \"reolink\".\\r\\n\\r\\nIn my head this is the wrong since I always though the domain is Reolink and platforms are switch, select etc....\\r\\nBut anyway.\\r\\n\\r\\nLets leave this for some other PR. It also confused me many times lol We shouldn\\'t create an issue just because the entity is enabled. We don\\'t know that the user is using the entity for anything. Praxis is to create an issue if an entity service is called or if the entity is referenced in an automation or script. I will keep this in mind for next time.\\r\\nHowever in this case this entity is disabled by default, so when a user enables it, I think it is safe to assume the enity is also beein used. Maybe they activated it and forgot about it?',\n",
       " \"Stale Do these all have an action directly? Or is it just a step in a series of steps to perform an action? all of these are direct actions But like, one is open settings, so does that open the settings menu and then you have to get the remote to do the rest? it opens the settings and the user can send the commands to navigate menus themselves via HA Yea but it's not an action on its own. I'd see this as a thing in a remote entity, not a button entity imo  okay np I removed the menu stuff Use the device class reboot and remove the translation key to use the device class name stale stale stale Please overwrite the type outside of the constructor These can be removed now right Do this in a separate test\",\n",
       " 'Can you give examples of what the state would look like? Does this help:\\r\\n\\r\\n![image]( If there are only 2 states (on/off), they should be binary sensors.\\n\\nI know we had this problem in the previous PR, but instead of trying to get into the same discussion, can we try getting into the constructive discussion on how we can get the integration on a point where we can add those?\\n\\nFeel free to message me on Discord? I\\'m happy to help out and support where needed. The reason I chose a generic sensor over a binary sensor is as follows:\\r\\n\\r\\nThe data returned from Hive contains a number of elements, which include `sensor` data and `binary_sensor` data.  Hive clearly makes a distinction between the two.\\r\\n\\r\\nAll the sensors that I added appear in the `sensor` data element (not `binary_sensor`).  Therefore, I suspect that the values may not be binary.  Even if they are binary at the moment, there\\'s a risk that this could change in the future. But we add entities to what they are today, and not on what they could be in the future. If in the future it returns, idk 5 different modes instead of \"ON\", we have to make a breaking change and adapt the integration  OK.  I\\'ve converted the binary sensor candidates, but they always display \\'On\\' regardless of the true state of the underlying entity.  (I haven\\'t pushed my changes.) That sounds incorrect. I was also quite surprised how the native value is acquired from the device in the sensor, can you maybe explain a bit how Hive works? I really have no idea on how Hive works internally.  I\\'m just a simple home user that\\'s trying to get some missing functionality working in the HA Hive integration. Do you have discord by any chance? yes, just joined. I see 2 ribbals in the HA discord, can you send me a message? These should be BinarySensorEntityDescriptions  Completed Please collect all entities in a list before adding them Completed It should still inherit BinarySensorEntity Completed Please add typing Completed \\n Completed What were the possible states for these? ON, OFF, SCHEDULE Can we make them lowercase and make these an enum sensor so you know what the values can be beforehand? Converted these to enums Temporarily removed the changes to this file, so that the rest of the PR can be progressed. This one is already done by the device class thus can be removed removed Please remove the `_icon` as they are still translation keys Can we move the services to the bottom?',\n",
       " \"This doesn't work. The scan interval can already be changed in the platform schema as pointed out in the discussion above.\",\n",
       " \"Slightly pedantic but maybe this should be called `async_update_last_restart` to match the other update methods that are named after the associated sensor type.  That's indeed a good idea. FYI: there's a new way to notate generics, so maybe that's interesting for you\",\n",
       " \"Thanks! Are you willing to commit contribute to the development and maintenance of the Overkiz integration or would this be a one-off contribution? My idea is to actively contribute to the Overkiz integration, at least to add support for some devices that I have which are not supported yet. I would also be glad to contribute and help maintain the repository. \\r\\nHowever, if you prefer that I am not listed as a code owner yet, that's not a problem. I added myself because I thought it was mandatory. \\r\\n\\r\\nPlease use the same style as the other line items. We leverage the UIWidget as an override, thus good to add which UIClass your device normally has. Can you move it up as well in the list? We sort this list alphabetically. Why not leverage the list here?  Absolutely This one was not resolved yet :) It seems my comment got lost, but why do you need this? Especially since you are only executing a single command? Iâ€™ve seen that there is a use of it in other atlantic devices. If I donâ€™t put it I see a strange behaviour when switching between modes: the device turns unavailable for a moment and then come back to be available again. With that wait, it works like a charm. \",\n",
       " 'Only have stuff in the try block that can raise Let\\'s use config entry typing  is there an example you can point me to please? \\r\\n\\r\\nWhen I was writing the review I was still on my phone so couldn\\'t give an example, thanks for asking I like, this is pretty neat, something I didn\\'t know about until now, thank you :) Please update the name \\n Please use `invalid_auth` as that\\'s a common name in the codebase Why do we warn here, we already know what the cause is right? Can you elaborate on what a device id is? device id is a unique identifier that identifies the connecting device on anglian water\\'s side, usually its a form of the device fingerprint that runs the android app. Leaving this alone will auto generate one in the background.\\n\\nIts needed to retrieve water data. So why does someone needs to set it? an optional step to use an existing device already registered to the account. A lot of this was copied over from my custom integration so in my case while I was testing it removed the need to perform a number of API requests to register the \"device\".\\r\\n\\r\\nI can remove for this though I have removed this, but it is still required otherwise we might overload AW\\'s API with fake device registration requests. Would it help if you remove the device if the user removes the integration? Please add the return type of `.data`\\n\\n\\n \\n The default function doesn\\'t have that parameter so let\\'s not do that You don\\'t have a reauth flow, so raise ConfigEntryError for now instead \\nPlease add the coordinator type in the entity typing \\n \\n Why does it have 2 loggers One is for the module that the integration uses, the other is for the integration itself.\\n\\nThe module has a seperate logging namespace. You don\\'t need to add one for the integration itself, just the libraries Please use icon and entity name translations here No need to add `anglian_water_` to the unique id  Please use constant UoMs for this Should we also add a state class? To use entity descriptions proper, let\\'s extend the sensor entity description with a `value_fn` ',\n",
       " \"Old config entries will not have the port field. You need to use a get() with a default. I suggest you dont set a default value here since then it matches old entries better. Thank you for considering my PR.\\r\\nModified the code accordingly, should be compatible with old entries that don't have a port field. This should be a constant variable Should be a constant variable as mentioned earlier. Idk how important that is, but maybe set the 2nd attempt to another port, so we can see that it accepts changes after crashes. We are not testing library here. So that type of test should go into lib \",\n",
       " 'Ideally, this would live in the library so other consumers of the lib have this data too. \\r\\n\\r\\nAlso, just an option, `hass.config.language` can be used to offer translated names. Works for me! Can pick that up in a follow-up!',\n",
       " 'Please assert the mock call arguments too.',\n",
       " '',\n",
       " 'It seems unrelated to this PR. Yes, I am honestly puzzled here. _I_ did not add this, however when rebasing on dev due to merge conflicts, these were a couple of them. I remembered that something with device assignments to template entities has been added in the last release and assumed that this was the change. Need to double-check that I guess. It seems unrelated to this PR. See above',\n",
       " 'Buttons are zero indexed, but humans want 1 indexed names It can use device class translations f8b77bd1e9d1de87c4d9c7b0558d3debd8a47505',\n",
       " 'I think if you change this to `token: str = oauth_session.token[CONF_ACCESS_TOKEN]` you can remove the type checking below Thanks! \\r\\nI think we can remove the \"obvious\" comments. Can we do this bump in a preliminary PR first so this PR only is for `tesla_fleet`? Please rebase now after bump is merged ðŸ‘  Done',\n",
       " 'We cant move this to `ShellyRpcAttributeEntity` because:\\r\\n- for `sensor` platform the type of `_attr_options` is `list[str] | None`\\r\\n- for `select` platform the type of `_attr_options` is `list[str]` We cant move this to `ShellyRpcAttributeEntity` because:\\r\\n- for `sensor` platform the type of `_attr_options` is `list[str] | None`\\r\\n- for `select` platform the type of `_attr_options` is `list[str]`',\n",
       " \"I fixed the types as they where not correct, I wonder why mypy did not catch the issue... Why do we need a service to list all the devices? We already have them in Home Assistant right? There are 2 reasons:\\r\\n - we do not have all the device types that the SwitchBot API provides (like Vacuum cleaner or curtains)\\r\\n - I did not find a way to get the _attr_unique_id from the device or entity when providing a selector for that in the service screen  > we do not have all the device types that the SwitchBot API provides\\r\\n\\r\\nYou mean implemented in HA? Yeah, not yet implemented in HA We should not create a send command service as that leaves the user without context. It's a waaay better user experience if we can contextualize the calls. So for example if you would use this service to activate something, rather create a service to do that activation via that. Or use entities to accomodate that action I am sorry, I am not sure I understood. Are you suggesting to add a service to for instance a plug to add additional commands ?\\r\\nI made the command service to be able to control devices difficult to adapt to Home Assistant like a TV (the interfaces were sto different that made me puzzled) and other non supported devices.\\r\\nI agree, making entities would be easier to use  though. Yep, looking at this list, these could all be entities, yielding a way better user experience\",\n",
       " \"Please remove all things that are not gathered device data. We should not include the execution state of the objects in the library, like what callbacks are connected. That the code logic works should be tested in the library. We don't need that in diagnostics.\\r\\n\\r\\nDiagnostics is meant for data that we can't test, like user specific data in the config entry or stored device state, that will vary between users and we need to be able to handle all kinds of user data.\\r\\n\\r\\nPlease explain more if you still think that this data is needed. So only keep `device['states']` and the entry? Type, name, timezone, rssi sound ok too. I don't know what connection_type means, but could be ok, if different devices support different connection types. Ie, data that is specific for the device is ok to include, but don't include data that just means something for the library and its logic. Done\",\n",
       " \"Can we combine the call? Async_add_entities is quite expensive iirc Done in f9c4dbb0f0b52442c7ef78ddb54e077c6cc62383 Please use the freezer as well Done in 4b66f3589be4cc44ef5298cb7c07c7f84c6a3b37 Can this be added on runtime? Or is this something that is there by default? \\n\\nYou could also make separate listeners for these and if the webserver is already set up, we don't attach the listener Actually you're right, so on a second thought I've removed the webserver and water heater from the listeners since those can't be dynamically added.\",\n",
       " \"This integration has quite a good test coverage, can we add test coverage for these lines as well?\\r\\n\\r\\n../Frenck > This integration has quite a good test coverage, can we add test coverage for these lines as well?\\r\\n\\r\\nThe coordinator is completely untested and I'm a bit stuck here since I'm not a pytest expert. Maybe someone can point me in a direction?\",\n",
       " \"I think these will never change so `@cached_property` can be used instead of `@property` Would be nice if 176/177 was a named constant from the lib or a function to tell its a ceiling light Yes, it would. I've asked LIFX to add this to their official products.json file, but in the meantime, there is no other programmatic way to determine what is (or is not) a Ceiling device besides the product ID. I could put this in `aiolifx`, I guess while I continue to push LIFX to improve their product definitions. > I could put this in `aiolifx`, I guess while I continue to push LIFX to improve their product definitions.\\r\\n\\r\\nThat would be a great solution for this case ðŸ‘  It would be a great solution for Home Assistant, but I'm not sure it's a great solution for `aiolifx`, to be honest. I don't want yet another technical debt because we've hacked something in before LIFX makes it part of the official spec, then I can't roll it back. I'd rather just do it here as a workaround so that other dependents of `aiolifx` don't use it. It looks like `update_products` is already adding/converting keys in #L31\\r\\n\\r\\nMaybe  `ceiling` or similar could be added in #L131 It's not adding or changing any keys. It's just creating a single more easily usable dictionary from the upstream production definitions:  Would be nicer to build local vars for the args that do not change inside the loop instead of doing the same get each loop To speed this up, wrap it in `create_eager_task` Does this need to be sped up? not required but will reduce latency There are a bunch of other places where this would be far more effective/noticable, I think. I'm not too worried about how long it takes to trigger a firmware effect in this instance, even across multiple devices. \\r\\n\\r\\nWhen I start doing some code quality improvement PRs, I'll pick it up then. \\r\\n\\r\\nThe default will already be filled in the UI if no value is entered since its defined in `services.yaml` \\r\\n\\r\\nThe default will already be filled in the UI if no value is entered since its defined in `services.yaml` \\r\\n\\r\\nThe default will already be filled in the UI if no value is entered since its defined in `services.yaml`\",\n",
       " \"Just a thought, we could just combine these steps into one, because the schema of the second step doesn't change Yeah that does make it a bit less complex. I've made the change.\",\n",
       " \"Newer model seem to support up to 128K, might be a good idea to change max to an even higher number (unless I'm misunderstanding something). Perhaps.  Mind suggesting a diff / patch in this PR?  I would happily increase it. The default size in ollama is 2048. So when DEFAULT_NUM_CTX is set to 4096 here it doesn't actually set a `num_ctx` so the 4096 is ignored and it still uses 2048.\\r\\n\\r\\nOne option is:\\r\\n- Don't set `DEFAULT_NUM_CTX` at all so that the default is `None` and only pass the context size when its not `None`\\r\\n- If you're trying to also increase the default context size, then this needs a different approach\\r\\n\\r\\n\\r\\n\",\n",
       " 'For discussion, not a request: Should the name be \"Last Observation Time[stamp]\", \"Latest Observation Time[stamp]\" or something like this?\\r\\n\\r\\nThere was a report from the very beginning of this integration that some stations provide incremental observations, e.g. temperature every 15 minutes but wind speed is only reported in the update every hour (I can\\'t remember the exact details, but something like this).  To solve this problem, pynws uses the most recent data from the requested time interval, and thus in this integration.  But I\\'m also afraid this distinction is too hard to convey, so also can see the argument for your version of the name.\\r\\n\\r\\nAs an aside, this is one of the reasons why I\\'m reluctant, but not outright opposed, to let users configure the integration asking for 24 hrs of data from the API, even when this sensor is available. I\\'m not wedded to any particular name. Out of the ones you suggested, I like \"Latest Observation Time,\" since \"Last\" sounds a bit final. I only chose the name as a literal concatenation of the API endpoint and key name for consistency.\\r\\n\\r\\nI know some observations are more granular in time resolution, but I don\\'t think we have to worry about that. If there is a desire to display all of the intervals within the larger timeframe, we can worry about that later (we\\'d have to modify how `pynws` returns information, anyways right?). > we\\'d have to modify how `pynws` returns information, anyways right?).\\r\\n\\r\\nMy comment was mostly about naming.  I don\\'t think we should add more complexity here.  I like \"Latest Observation Time\". This comment was addressed.  For some reason I cannot \"resolve\" this comment on GitHub.',\n",
       " 'Do we want to move forward with this dispite lacking ATTR_DATA support? Not sure how that is used. As we should keep the old service for the deprecation period we could deprecate the use of it? It has quite a lot of features in data: \\r\\n\\r\\nSo i dont think we can deprecate the old service untill we replicate some of that. Maybe the data could ve namespaced by some domain key.\\r\\n\\r\\n\\r\\n\\r\\nThat way it would work with group too. >So i dont think we can deprecate the old service untill we replicate some of that.\\r\\n\\r\\nRight, in that case it seems not we can deprecate the old service.\\r\\nWe could consider to implement both, the entity and legacy service?\\r\\nWe could deprecate the old service as soon as the new entity service is ready to replace it. Another option might be that the new entity based service implements templated notifiy entities that can be set up via a config flow. In that way the user can still send the message to the entity, but the formatting might be no longer part of the send_message service call. We likely need config sub entries in place for that, since the data to add would be quite custom. But the idea seems quite sound.\\r\\nThat said, i have never ever used any of these advanced features so not sure how they are used :)',\n",
       " 'This moved code, and is legacy from yaml when custom urls were supported.\\r\\n\\r\\nIt should be deprecated at some point.',\n",
       " \"We do we implement 2 methods here as we do not seem to use the empty label. Sorry i think i don't fully understand you.\\r\\nSo we have 2 methods here, one to add just a label and one to add the label with a locale. Because the _supported_modes attribute does only accept a label with a locale a placeholder is set as locale.\\r\\nLater when the _supported_modes field is added to the capabilities object the placeholder is replaced by the default locale en-US. See line 244 in resources.py.\\r\\nI did this because then there is only one place that uses the default locale. If you think that is confusing i can just replace the placeholder with the default locale. Same here\",\n",
       " \"\\r\\n\\r\\nWe should increase the minor version instead, as we were adding a new field.\\r\\nPlease adopt the rest of the code Can we add better typing for this function? So wait, in the config flow you add the option for users to select `HTTP` or `Serial` and in the migration we set it to `http`? Let's make the config flow also provide lower_case names and use translations to make it look nice for the user. No need for this. You can just check the `mock_entry`. It will use the same object Please use the constant\",\n",
       " \"You should probably reuse the reference from seat heater since I don't think there needs to be a new translation for Low, Medium, High Thanks for the quick review.  I've updated the strings.json per your advice.\",\n",
       " 'We already have this in the device info, no need for separate sensor We can add a frequency here It reports it as frame rate not refresh rate - 23.976p\\r\\n\\r\\nI can convert it, but seems hacky IMO because 23.976p has a specific connotation besides refresh rate (its a progressive signal) What are the possible values \\r\\nin order\\r\\n1. 422, 444, 420, RGB\\r\\n2. 10bit, 12bit, 8bit\\r\\n3. 601|PAL|709|DCI|2020\\r\\n4. PC | TV If these are all pre known we should use enum sensors to allow users to be able to preselect them in the automation editor and know what the possible values are if native_value is `None` it is rendered as `unknown` and that is a good thing imo. Please remove all the names to make use of the translations In this case, might as well just create one big data update and call this before the snapshot and make the snapshot snapshot all the updated states In the previous test I liked the old name better since it was more readable. `GPU temperature` looks better imo Please use the snapshot platform helper in this case This change is unrelated its not related but makes the code a lot easier to work with But it should go in a separate PR as its outside of the scope of the sensor platform  reverted Can we bump in a separate PR? no its required to fix how one of the sensors works No but please bump this in a PR before this PR why do we float(str(? fixed Just a thought, would it be maybe more useful to return width and height in a separate sensor? Like I am thinking of use cases for this entity, and I can only thing about a display use case or when the values are separated this value is commonly used to match to a know set of resolutions so it would not be useful if separate',\n",
       " \"You can assign the coordinator to `entry.runtime_data` This can be reduced to only returning the await Move this to the else block Do we know if it responds differently with invalid credentials? Then it will raise `AutarcoAuthenticationError` Let's also catch that and show a proper error for that the public key does not change at runtime, so might as well just asign it to a `self.public_key` to avoid a dict lookup every cycle use the typed config entry from `.` get it from the config entry can be merged and the list can be removed as the `async_add_entities` can get a generator expression not needed Let's make HA create its own entity id so the behaviour is consistent with other integrations You could also do\\r\\n\\r\\nAnd make both the entity description and this class `Solar` specific.\\r\\n\\r\\nThis will help when you add the inverters Should we use the public key as unique identifier here? Name can be static can we use `data_description` to add more context to the fields? if we only have one we don't really need to parametrize this\",\n",
       " \"What is the reason `name` is removed here? This file is generated. I don't think I manually removed it. I added it back but it was auto removed by `script.hassfest` I know it is generated, which makes it even weirder that it happened.\\r\\nMaybe the integration name change was what temporarily caused it. Why is it called twice? My bad. Removed. Can we use the `self.add_suggested_values_to_schema` helper? Don't log on info Personally think we should keep reauth and reconfigure out of the picture for now These can both be set outside of the constructor Don't log on info \\r\\nCan be omitted Is this an entity? Yes Then we should not set `self.name` directly Wait, are you sure? I thought Provider is not an entity. Sorry this is the legacy provider. The one above is the entity. Why do we set the state to a default? We should patch this where we use this \\r\\nPersonal ick Consider creating this a fixture as you do this quite a lot here We should make sure the tests end in either an abort or create entry to test the flow is able to recover On errors I don't abort but rather show the form with the error without moving to the next step: \\r\\n![image](\\r\\nSince this is the very first form and there is no state I don't think it's worth complicating the test setup and continuing the flow which will essentially retest test_user_flow_success Why the state? why do we do this?\",\n",
       " \"Please run hassfest again, it should also add the tests as codeowned done Is there a way we can detect the protocol by the host? How does the user know which one to pick? We can't detect the connection method, but it depends on how the user is connecting Iskra's devices. If they use a smart gateway (WiFi to RS485/IR Modbus) to connect energy meters to Ethernet, they should use the REST API. However, if they use a Modbus RTU->TCP gateway or any Iskra measuring device that supports Ethernet connectivity, they should use Modbus TCP. \\r\\n\\r\\nIn summary:\\r\\n-  REST API:  meters connected to Smart gateway \\r\\n- Modbus TCP:     meters connected to Modbus RTU->TCP gateway or Ethernet-enabled device But can we probe and try the other one if it fails? @joostlek I can do something for sure but i'm not sure it would be okay. I can probe if the device responds to the REST API. If not, I can assume it is using Modbus TCP and prompt the user to enter the Modbus address and port. If that's acceptable, I can proceed with that approach. \\r\\n\\r\\nHowever, we can't be certain it should use Modbus TCP in that case, as the user might just enter the wrong IP address.\\r\\n\\r\\nWe also support UDP broadcast discovery(not standard), which could later be added as a zeroconf method. This would work for all devices, except if the user sets the smart gateway to require authentication. In such cases, the user would need to enter credentials.\\r\\n Zeroconf works with mDNS instead of UDP I'll have a think about the rest any updates? changed Let's at least pick snake_cased names changed to snake_cased names This cant happen removed iskra aqara? Removed.  What entities does the gateway have? currently only number of connected devices, but i'will add more in follow up pull requests.\\r\\nIt also has pulse counter and temperature sensor user can use, tariff calculation and other status data.  Can't we see the amount of connected devices via the HA? true we can, will delete this entity as it's unnecesary Let's move this to `entity.py` moved Let's move the creation of coordinators to `__init__.py` fixed This looks very complex, can we maybe move this to a follow up so we can focus on the normal devices first? I agree, but this is a crucial aspect of our measuring devices. It is a bit complicated, so let me explain it further.\\r\\n\\r\\nAll our devices, including energy meters and power quality analyzers, have energy counters that measure electrical energy. These devices contain a few non-resettable energy counters, which users cannot reset, and a few resettable ones. This is why there are two `for` loops in the code.\\r\\n\\r\\n### Resettable Counters\\r\\n- **Customizable by User**: Users can configure each resettable counter to measure:\\r\\n  - Imported or exported energy\\r\\n  - Active, reactive, or apparent energy\\r\\n  - Total energy or energy for a specific phase of the meter\\r\\n\\r\\n- **Example Use Case**: This customization can be particularly handy. For instance, a user can set a load such as a central heat pump on one phase and a sanitary heat pump on another phase. They can then see the consumption of each load with one energy meter, as well as the total consumption for the whole heating system.\\r\\n\\r\\n### Non-resettable Counters\\r\\n- **Customizable by Buyer**: Larger companies or distributors that purchase from us can customize these counters. However, users cannot reconfigure them during the product's lifetime.\\r\\n\\r\\nThe code checks if the counter type is active energy and, if so, sets the device class to Home Assistant's `SensorDeviceClass.Energy` and the unit of energy to `Watt_HOUR`. Otherwise, it uses the API's units. This ensures compatibility with the Energy tab in Home Assistant.\\r\\n At this moment it's still a blur for me as the code isn't that readable and I can't completely link to whats going on. I don't think we can make 2024.8 (for which the beta cut is wednesday), so let's aim for 2024.9. so in theory we have enough time and I think it would speed up the process to get the way we fetch data and how we create entities straight in this PR and add the extra logic in followups (and then we can do it in understandable bit size pieces). This way we can go over each subject and decide on the best way to do it @joostlek so how do i proceed.  should i remove this part of code? For now I think that's best yes\",\n",
       " \"Lambdas shouldn't be multiline It's a single function call. Do you suggest I make the variable names shorter so it can fit on a single line? It gets formatted this way automatically. Im not exactly sure about the motivations here. But for me when I could t fit a lambda ok one line i needed to either short it or define a method separately I replaced the lambda with a function def, `_enable_charging` and `_disable_charging` Lambdas should be on a single line Done.\",\n",
       " \"Could just use the same `_TIME_TRIGGER_SCHEMA` and don't need to make a new one without the check for a template? I tried that at first, but when it renders after the template, it should only allow time and the entity domains.  It was allowing integers, and other types because cv.template allows those to pass validation.  I wasn't sure how to get past this fault without separating the 2.  I'm not 100% familiar with vol.Schema, is it possible to make a schema and extend it while adding a message to it?  I couldn't find a way to do that. Looking at the code <#L235>, msg is a property.  I could extend and change the message, however I still think I need the 2 validators.  Thoughts? I just looked into this more, it's not possible to extend the schema or use the same one.  I'd need to insert cv.template into the vol.Any object and it's not possible.  I'm going to leave this as-is. This would never be used right? So we could just set the dict directly on the `render_complex` call? I only added the access at the top of the method because everything else was accessing the trigger_info there.  I can access it in place.  \\r\\n\\r\\nI just followed the path of trigger info, looks safe to just access it in place without the or {}.  Template.async_render accounts for None.  Will move. \\r\\nSeems forgotten to be removed\",\n",
       " 'Let\\'s keep this alphabetical What do we have Ruff for? ðŸ˜…  Done For a lot of the checks. We also have a pylint rule that checks if `PLATFORMS` variables are alphabetical. But this is a dict, not a list, and it\\'s called `DOMAINS_AND_TYPED` hence there is no check for this. But I personally do really like when these lists are neatly ordered to be consistent with the rest I added it as the datetime platform and later just renamed it. Shame on me^^ Shouldn\\'t the entity be unavailable in that moment? Or are there other moments when this can happen I had the direct service call in mind. And at least during testing the device when Homeassistant first connected to the device (after bootup) it was available but no time was displayed, meaning the coordinator had to data yet.\\r\\n\\r\\nSomething I want to investigate and possible fix in a separate PR But why is that the case? you\\'re now raising an issue that the device is not connected, but from your response I also guess that it already was connected, so what should the user do to get the data? Removed \\r\\n_if_ you ever need to migrate you can just do `.split(\"-\")` Done Let\\'s name this entity BroadlinkHysenTime, as it is specific to the Hysen class, and we may want to add other types in the future. Do you think other device types would have a fundamentally different time platform? The data used is retrieved via the broadlink api `get_full_status` Yes, although we currently only have this device with day of the week and time in the API today, this structure could vary depending on the type of device in the future. Some devices might include day, month, and year, while others might include timezone information. Do we know of a device which is available today or will be available in the future? Or is this an assumption? It\\'s always an assumption when it comes to Broadlink. When we don\\'t know what is going to happen, we better keep it flexible. But I am totally okay if you want to leave it as is and change it later if we need to. Let\\'s add some flow control to ensure that if the entity is of type \\'HYS\\', then we add BroadlinkHysenTime entities. Otherwise, we do nothing. While I get the idea I think this would be different then how filtering is done for other platforms. E.g. #L95-L104 Even if we do a good job creating a unified interface in the library, we could still have at least two types of time devices: weekday/time and date/time. Moreover we do already filter the platforms by device type: #diff-de5887f91e2b6b4559fe8fe3c68b104fbbcc5048feb84a0db325be16527d87f0R39\\r\\n\\r\\nWhy should we do it again? It\\'s about making the code more robust. This function accepts a `ConfigEntry` in its signature. It should be able to handle _any_ `ConfigEntry`, without depending on filtering or validation by a higher level module.',\n",
       " 'Please import this one Use entity descriptions. That means you have 1 generic sensor entity, and then change what they return based on the entity description injected.\\r\\n\\r\\nYou can also reap a lot of beneifts of creating a base entity, which is just the CoordinatorEntity, which you can use as base entity for all your other entities, so you don\\'t have to set `device_info` and `has_entity_name` everywhere Can be removed  Why the bool I think we can assume coordinator.data and coordinator.client are always there will fail if its removed\\n\\nTraceback (most recent call last):\\n  File \"/workspaces/core/homeassistant/helpers/entity_platform.py\", line 598, in _async_add_entities\\n    await coro\\n  File \"/workspaces/core/homeassistant/helpers/entity_platform.py\", line 912, in _async_add_entity\\n    await entity.add_to_platform_finish()\\n  File \"/workspaces/core/homeassistant/helpers/entity.py\", line 1366, in add_to_platform_finish\\n    self.async_write_ha_state()\\n  File \"/workspaces/core/homeassistant/helpers/entity.py\", line 1005, in async_write_ha_state\\n    self._async_write_ha_state()\\n  File \"/workspaces/core/homeassistant/helpers/entity.py\", line 1130, in _async_write_ha_state\\n    self.__async_calculate_state()\\n  File \"/workspaces/core/homeassistant/helpers/entity.py\", line 1067, in __async_calculate_state\\n    state = self._stringify_state(available)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspaces/core/homeassistant/helpers/entity.py\", line 1011, in _stringify_state\\n    if (state := self.state) is None:\\n                 ^^^^^^^^^^\\n  File \"/workspaces/core/homeassistant/components/binary_sensor/__init__.py\", line 293, in state\\n    if (is_on := self.is_on) is None:\\n                 ^^^^^^^^^^\\n  File \"/workspaces/core/homeassistant/components/madvr/binary_sensor.py\", line 97, in is_on\\n    return self.entity_description.value_fn(self.coordinator)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/workspaces/core/homeassistant/components/madvr/binary_sensor.py\", line 60, in <lambda>\\n    coordinator.data.get(\"outgoing_hdr_flag\", False)\\n    ^^^^^^^^^^^^^^^^^^^^\\nAttributeError: \\'NoneType\\' object has no attribute \\'get\\' When is coordinator.data None?  pushed fix You can remove all the \"on\" clauses \\n Please remove not needed I think Sentence case please Don\\'t access the coordinator, please get the data push function via the mocks.',\n",
       " 'The option name and its definition are very unclear.\\r\\n\\r\\nPurely from an English or non-user perspective:\\r\\nRender = True will render it?\\r\\nSo templates do not work when render is false?\\r\\n\\r\\nWat does \"render\" even mean? ðŸ˜¬  Have any other suggestions?  I\\'m not too keen on the verbiage either.  It was the best I could come up with at the time. `always_evaluate`, `when_changes`, `on_new_value`, `always_trigger`? `extend`, `verbose`, `expand`, etc? > Wat does \"render\" even mean? ðŸ˜¬\\r\\n\\r\\nDecided to go with `trigger_on_new_value`',\n",
       " \"Let's keep this change for a separate PR This change seems unrelated to this PR. Please don't stack multiple changes in a single PR. I suggest to split this out in its own PR. Addressed in  Unrelated change? This integration uses a coordinator, shouldn't that be used instead? Commented out code Addressed in  I think we can eliminate the use of this method completely? If we store the device ID in the class, we always direct reference the values stored in the coordinator That is the default \\r\\n\\r\\n Removed in  You might be able to leverage entity descriptions for your all sensors instead. Addressed in  Why is a float conversion needed here? Omitting it causes `mypy` to report an error:\\r\\n\\r\\n\\r\\n\\r\\nLet me know if there's a nicer way to work around that. If your library is completely typed you should consider adding a `py.typed` file because then mypy can actually read the types from the library Unrelated change If we reference the name provided by the device class anyways, we can just as well drop the translation key and let the entity fall back to the device class translation automatically. Addressed in  Should this be a test fixture instead? This seems an odd place to do this, this affects all tests.\\r\\n\\r\\n Addressed in  Missing return type Addressed in  The `laundrify_sensor` fixture could be typed to make it complete Addressed in  Same comments as above Addressed in  Same comments as above Addressed in \",\n",
       " \"Shouldn't you test that it's now excluded ? added a few more cases in bb960634d1c512286c674afac9721f4fb5944a15\",\n",
       " \"Instead of using `hass.data` for this, use the new config entry runtime data:  Updated to use the new config entry runtime data. This doesn't seem to actually do anything to test the connection? You're right.  I removed it. What is the purpose of  the `online` property if it always returns `True`? It had no purpose.  I removed it. Same as above, what's the purpose of the `is_on` property if it always returns `True`? It had no purpose.  I removed it. The hub `test_connection` function just waits 1 second and returns `True` so this will never raise CannotConnect You're right.  I removed it. Please use the Platform enum instead #L39 \\r\\n\\r\\nWe can use the hub directly Can we somehow validate the token by doing a request?\\r\\nCurrently we are only checking if it's any jwt token, but not if the token is a TriggerCmd jwt token I added an API request to validate the token.  Not used I removed self._hass and self._name but I kept self._token for the token property.  Please return a `DeviceInfo` instead Please explain where you use the callbacks?\\r\\nYou are only adding and removing them, but the callback is never be called Good call.  I removed them. For new integrations, we require the following:\\r\\n- Support for [the new entity naming](#has_entity_name-true-mandatory-for-new-integrations)\\r\\n- Entities and their attributes should be [translatable](\\r\\n\\r\\nPlease adopt your code to add support for it. I think I resolved the new entity naming issue.  \\r\\nI'm not sure what to do about making the entities translatable because their names are based on TRIGGERcmd user data.\\r\\nI need to do something, I'll try to figure it out, but I'd appreciate any clues you can give me.     \\r\\n\\r\\nAlready set by _attr_name As this is assumed state please set `assumed_state` to True or implement a call to get it from the api I'm not familiar with triggercmd but from the variable names I think we should create a device per computer\",\n",
       " 'When returning datetime strings in Home Assistant, they must be ISO 9601 formatted.\\r\\n\\r\\nRef: <#datetime.datetime.isoformat> including timezone information.\\r\\n\\r\\nFor example: `2024-01-01T10:10:10+01:00`\\r\\n\\r\\n\\r\\n Test has been updated. Not sure how that ever passed...  Same comment as previously, I would have expected a iso formatted string here I had written it that way to match the existing assertion later in the file for `following_since`. \\r\\n\\r\\n#diff-b1ac5ab4e5ed3195f189b8d6a33d5b336fbc4de941bc5e2989ef1dbbd6bcc90fR93\\r\\n\\r\\nIs there a style guide for dates/times I should be referring to?  Aah check that makes it consistent I guess ðŸ‘ \\r\\n\\r\\n../Frenck',\n",
       " \"Let's store it in the config entry runtime_data Unused Removed. If we are not doing anything special here, let's combine the two flows as we usually do.\\r\\nso:\\r\\n The intention was to have async_step_pairing() as a common call for both the `user` step and `import` step to reduce duplicate code. My other two solutions would be:\\r\\n1) Duplicating connection logic (or making separate connection logic, which is what the pairing step represents) between the user and import steps.\\r\\n2) Combining user and pairing step into one, and calling user step from data passed from import step. I thought this might be visually confusing, so went with the former.  Oh I missed that this was also used in the import step. I personally always like to duplicate it, because it will be removed eventually, and you have to abort the flow in the case of an import flow instead of returning errors with the form. Yep, I did the abort to be able to combine the logic. If returning the errors is the expected behavior for the user step, I'll separate the logic. Logic has been separated.  I think we can support multiple integrations from the start tbh Let's do this in a followup Same for these changes Please extend the typing of ConfigEntry as seen in [the blog post]( Please type this no need for the extra When do we expect to get this? We will get a NoPrimaryControllerException when there is a connected controller that does not have an ID of one.\\r\\n\\r\\n**To provide context:**\\r\\nThe Russound MCA-C5 can be daisy chained (using their proprietary serial connection) up to six total units. On the rear of each unit, there is a dip switch to select the ID of the unit (1-6). Per the unit and API's instructions, only the first logical unit (Unit 1) can be interfaced over IP. In our use case, we treat all the daisy chained controllers to the primary one single device since that's how it's intended by the manufacturer. It's possible for someone to have a single unit on ID 2 that is hooked up to HA over IP. The API doesn't function properly (as expected) in this case so this is caught here to ensure that all controller stack-ups have at least the primary controller present.\\r\\n\\r\\nThis exception may become irrelevant when I pull the logic out of the try-except-else since I was using it as a way to reach the except block. Cleaned this up so that NoPrimaryControllerException is raised directly by the find_primary_controller_metadata method. Leaving this open for discussion / clarifications if there are any. Let's try to keep everything out of the `try` block that can't raise. If I am correct you can connect, enumerate controllers and close and move everything else to the `else:` Moved the set unique ID out of the method. You are correct on those three methods. I also made the find_primary_controller_metadata method return the exception directly so that is able to remain put. Let's not do this, because if I still have the YAML and I deleted the imported config entry, and created a new one, because I got a new IP address (its a bit tricky, but it explains it well), it would overwrite that entry with the YAML (old) info The homeasssitant domain already has the deprecation issue ready, so we should use that one. checkout the `mpd` `media_player.py` for a flow like that This is functionally identical to the MDP impl. I combined the two async_create_issue calls into one and use the logic above to determine the key.  yes and no, there's also a difference in domain, one issue is created using the HOMEASSISTANT_DOMAIN, other onenot Ah, yep I missed that. Will fix. Reverted to the style present in mpd Does the creation of this object raise? Let's use refernce keys to get these strings from the error Only helpers are allowed to have a settable name. Config flow intergations should set a name that is user recognizable, but not ask the user This one can be removed now\",\n",
       " 'we need to guard for invalid data here as we have seen devices in the wild with malformed data in the hardwareAddress field. So my proposal is to convert this entire block into a small helper util which guards for invalid mac addresses (or the convert_mac_address util erroring) Thanks for the review. \\n\\nI\\'ll look into it shortly. Hey, \\r\\n\\r\\nI looked into it and maybe there is more to itâ€¦\\r\\nMaybe you can elaborate on those _malformed addresses_ and what the concern is here.\\r\\n\\r\\nSince the matter lib will always return `bytes` for the `hardwareAddress`, a malformed mac address is not a problem, and you only have to check for excessive size. \\r\\n\\r\\nBut that leads me to another thing, namely: _What is a valid mac address?_\\r\\n\\r\\nLooking at:\\r\\n#L420-L437\\r\\n\\r\\nIt assumes a 48bit address. But IEEE 802.15.4 (or any other new standard) uses EUI-64, 64bit addresses, which is `CONNECTION_ZIGBEE = \"zigbee\"` in HA, although this is not exclusive to ZigBee and a device should either have a EUI-48 (traditional MAC) or a EUI-64. So there isn\\'t really a need to differentiate between the two. \\r\\n\\r\\nThere is also the `CONNECTION_BLUETOOTH = \"bluetooth\"` connection type, which is also a EUI-48 from the same pool of addresses. \\r\\n\\r\\n---\\r\\n\\r\\n**Back to the topic of malformed hardware addresses.**\\r\\nA problem would arise (that HA currently doesn\\'t seem to account for, and it\\'s not specific to the matter integration) if the device reports a mac address that\\'s not a valid identifier for an individual device. A NULL address, such as `00:00:00:00:00:00`, has the potential to match a bunch of devices. Also, at least half the mac addresses are multicast addresses, also unsuitable for device identification. \\r\\n\\r\\nSince this is not matter specific, this should ideally be handled by the \"core\" HA code.\\r\\nThese checks should be made by the device_registry.  This is a bit overkill and doesn\\'t belong here in an individual integration.\\r\\nFrom an architectural perspective I would propose this at the core level.\\r\\n\\r\\n I agree, that\\'s why I added the comment to your earlier review. #discussion_r1668494242\\r\\n\\r\\nCan you tell me where such discussions about architecture best belong? It doesn\\'t feel like a bug report or a feature request. \\r\\n\\r\\nIn the end, it\\'s not that important to me, I just noticed it and am bad at ignoring it. (As evident by the over-engineered code ðŸ™‚) Well, you could just make a draft PR against HA core and get feedback (or a merge that way) but if it needs a bit discussion first, its probably best to raise a discussion here:  This was all I meant with my review feedback - just a try..except around the code that reads the mac address into a mac address string (as that can be an empty string or malformed junk) to not blow up setting up a device `GeneralDiagnostics.Structs.NetworkInterface.hardwareAddress` are (possibly empty) `bytes`. I guard against `None` and empty here.\\r\\n\\r\\n`convert_mac_address` takes these bytes, formats and concatenates them. The result is a string in the format (`\"xx:xx:xx:...\"`).\\r\\n\\r\\nI check that the string has an appropriate length for EUI-48 or EUI-64 addresses and set the connection type accordingly. Further normalisation is done by the HA core code.\\r\\n\\r\\nAs far as I can see, there is nothing that can go wrong, except if the matter/chip library itself is buggy and doesn\\'t adhere to their types. \\r\\n\\r\\nI don\\'t know what to catch except a broad `Exception` and move on.  Let\\'s do it this way, you guard for empty values which is (imo) enough. If something unexpected can happen later, we will learn soon enough and can act on it then.\\r\\n\\r\\nBTW: I still like your proposal for the validation of the addresses so I advice you to try raising that discussion and/or open a draft PR to fix the device registry.',\n",
       " \"I think `@callback` is not allowed on awaitable functions (`async def`). Yeah ok, should I run the existing method as a Hass job then? For example:\\r\\n\\r\\n\\r\\nIt works, I'll just need to update tests.\\r\\n This is still relevant Just remove the decorator. The dispatch helper knows how to call coroutine functions as well as async callbacks. Please use constants Got it. I'll open a PR for the rest of the tests. How does an ID look like? For the Beosound Level, the built-in sound modes have ID 1, 2, 3 and 4 and user-made IDs start at 100. This would make the `Optimal` sound mode's label `Optimal (1)`. \\r\\nSo no huge numbers.  I think we should catch `KeyError` and wrap in `ServiceValidationError` since the base entity does not protect against trying to set a sound mode which does not exist: #L392-L397 I've added a check for if the sound_mode is in the integration's sound_modes. Please add a test which exercises this path Ah sorry. A test has been added now. We can remove `.keys()`. Copying a dict to a list copies the keys by default. Got it. I've created a PR to fix this \",\n",
       " \"Why do we enforce this? Why don't we allow if someone uses 2 deako bridges? Good question. We only need one device for a successful integration. A second bridge won't be beneficial or net any other devices. \\r\\n\\r\\nI tested removing this constraint and on larger installations, the discovered devices menu is flooded with all the devices that could be the bridge.\\r\\n\\r\\nThere's one instance I can see for two bridges and that would be separate installations on the same network. So you would have two sets of devices, but there's no way to distinguish what devices are a part of what installation from the advertisement data and even with the local API, there's no way to determine if a device is part of installation A or installation B without comparing the device list of multiple devices. Can you elaborate on this? \\n> the discovered devices menu is flooded with all the devices that could be the bridge. Yeah so I have access to a larger installation of Deako devices (>100) and due to their behavior with getting online to check in, there are always more than 10 online at a time roughly. \\r\\n\\r\\nBy removing the constraint that there can only be one active config flow via the DOMAIN, the discovered section in the integrations menu will now have all the devices listed as separate Deako integrations. We only need one to act as the bridge, so having all those listed there is misleading. And why should we connect to a bridge if we can also talk to the device directly? Not every device is guaranteed to be on the network and often most devices are not. The bridge device gives us two things:\\r\\n\\r\\n1. the list of all known devices, whether on the network or not\\r\\n2. access to the encrypted BLE mesh network for control requests\\r\\n\\r\\n How can we detect if the device is a bridge? Good question! Any device that's on the network _can_ be the bridge device. The device that _is_ selected as the bridge device (aka connected to with a socket) will no longer advertise I believe.  I would have to confirm with the firmware team. No but how do you know if the zeroconf message is the one sent by the bridge? All of the zeroconf advertisements are sent from devices that aren't the bridge, just ones that could be the bridge. This flow is essentially bridge selection where the first device that advertises is the bridge. Mind sharing the zeroconf debug logs? Like I think I start to know what you're getting at, but I want to be sure. So I talked to firmware team, device continues to advertise when it's connected to as the bridge, but I think that's fine for the integration's use cases.\\r\\n\\r\\nI'll get you some zeroconf logs on the larger installation that I have access to. Here are the logs:\\r\\n\\r\\n[2024-07-17 11:06:18.log](\\r\\n Can you do `homeassistant.components.zeroconf: debug` instead? You bet! Much easier to read. \\r\\n\\r\\n[2024-07-17 12:51:08.log](\\r\\n Let's use the `entry.runtime_data`, there's a dev blog post about that a month or 2 ago, I'm on mobile so I dont have a link Ooooo I like that. Thanks! Certainly cleans things up a bit. Can be merged Let's not retype unique id Got it, I'll throw in some asserts Can we type the dict better? Let's also add `single_config_entry: true` You don't have an unique id Good catch! What's this for? The tests should be more end to end. Aka, we should patch the library appropriately, start a config flow, and then check the results We should not patch this Not needed This test is strange because this will never happen in real life because init has a check for it  You can look into snapshotting, use snapshot_platform to make sure you snapshot the entity and the state\",\n",
       " \"We shouldn't use the event bus for internal communication in the integration.  Future PR is planned to get rid of the custom events. I havenâ€™t come up with a good replacement for the camera urls or logbook yet. Camera urls should be easy to move over.  The event entities and logbook need some more work with logbook in general as there is no way to describe them currently. Thatâ€™s not a DoorBird specific issue though.\\r\\n\\r\\nEverything in this integration has historically used events to communicateâ€¦. Itâ€™s quite oldâ€¦I could replace all the internal communication with the dispatcher in the mean time but it seemed a bit much to fire an event and also use the dispatcher. Its going to take longer than I had hoped to figure out the logbook so I'm going to open a PR to add the dispatcher. We will fire the event and dispatch until I can come up with a way to get rid of the custom events. We might have to bit the bullet on that one and do a breaking change to remove them in a few months after the event entities have been around for a while if they work out as planned\",\n",
       " 'Changing the key, means also changing the unique id (see #diff-58dcc591bbd6b0e56a5d7f1b6b1a4d38486cba28db575070dac071668ba9919aR220) therefore we need a migration for it. If you still want to change the key, you should please do it in a separate PR That is why the [`update_unique_id()`](#diff-d9ed91adf5c8ce40001603047a42a975ed0f7640a63d6af98b93d00784f56322) got extended (and the migration tests adjusted).\\r\\n\\r\\nWe cannot do this in a separate PR as migrating the keys before changing [`_handle_coordinator_update()`](#diff-58dcc591bbd6b0e56a5d7f1b6b1a4d38486cba28db575070dac071668ba9919aL210-R233) will cause failures. @edenhaus just thought about it again, would you prefer 1 PR for migrating the keys and the update function and a second PR for adding the tire sensors?  Created #121380 and will rebase this as soon as the other one is merged. Rebased after unique_ids are migrated with another PR.',\n",
       " \"Don't you need `slugify(coordinator.duid)` here, you use it everywhere else? Yes you are right! Next time I'm back at my computer I'll make the change. It's unfortunately not too easy to do on my phone Added! This code appears quite a bit\\r\\n\\r\\n\\r\\nMaybe make `coordinator.duid_slug`  Also since it never changes you could make it a cached_property so it doesn't have to execute every time\\r\\n\\r\\n Please split ternaries that span multiple lines into a normal if/else \\r\\n\\r\\nUse `.items()` to avoid looking up the key every loop Missing coverage \\r\\n\\r\\nLooks like a useless delegation  \\r\\n\\r\\nThis is a bit more compact, but personal preference, not strictly required \",\n",
       " \"Why is this needed? This is needed because i read the locale from the configuration.\\r\\nSince we should stick to the english locale in this PR (as you said in the next comment) this will be removed. I reverted the commit which adds this line. Let's stick to the English locale, in this PR. I reverted the commit which uses the locale from the config. Now every mode is using the default locale 'en-US'. A TV does not reflect a remote. The existing `media_player` entity would be a better match. Alexa supports media player entities to control your TV: #media-player You are right. There even exists a remote display category for alexa (#display-categories).\\r\\nI added the remote display category and used it for the RemoteCapabilities. I think we should not use the mode controller to turn the remote on The turn on is also implemented for the power controller.\\r\\nThis code here sets the new activity. To use the remote's turn on service was the only way i found to set a new activity. Is there a better way?\\r\\nEven though it looks a little bit strange i do think that it makes total sense to turn on the device of the remote when setting a new activity. I opened a discussion for this: \\r\\nPersonally I do not think we should call service `TURN_ON` here.\\r\\n\\r\\n You need some tests for the handler code as well I have just added that. I am not sure about the mode controller. It does not seem to be picked up. (But I may be wrong), I am not sure if i understand correctly what you mean. \\r\\nIt is definitely being used for the remote domain. I tested it, both with postman and Alexa itself and it is working just fine. I think this part should be implemented with an `InputControlller` instead (like we do for `media_player`). Yes you mentioned that before but i still think that this will not work. \\r\\nThe problem when using an input controller is that you can not specify 'generic' inputs, only predefined values by alexa (TV, HDMI, DVD, etc.). The input controller already tries to match the given source_list to the allowed values but this does not work for the activities of the remote, because those activities can be anything.\\r\\nThe mode controller on the other hand supports any kind of names for an activity. If you really insist on using the input controller instead of the mode controller we should think about a way on how to match an activity name with an allowed alexa input controller value.\\r\\nMy first idea for that would be to let the user do that themselves. The user could create a mapping in the configuration that maps an activity to an alexa value.\\r\\nThe downside is that the user has to know which values are allowed and that it does not work out of the box.     `remote.ATTR_PRESET_MODE` does not exist.\\r\\n\\r\\n\\r\\n\\r\\nMay be add a comment why we use a mode controller in stead of an input controller here.\\r\\n\\r\\nPlease also add a test case so this code covered. To add a test for this code i would have to add a test for the discovery response. I think this does not yet exists.\\r\\nShould i add this in this PR or create another one to add it?  I added a basic check if the discovery response returns all required interfaces for a remote entity. This test covers the code above. Please add cases with zero and one activity Done. \\r\\nTweak comment Please wrap the line to make it max 89 char long Please split in 2 lines Thanks current_activity\",\n",
       " \"Let's try to be more specific about the added option than \\r\\n> a combined entry specifying an Entity ID and an offset If we're anyway changing the comment, can we make it less misleading? We're not tracking all entities. unpacking a tuple like this makes the code difficult to read\\r\\n\\r\\nCould we use a named tuple instead, and something like:\\r\\n\",\n",
       " \"We don't have this list in the lib probably? Unfortunately not. They are only mentioned in a comment at #L424-L478 and #L323C9-L328 We don't need to suffix the platform domain to the unique id. The entity registry is aware of both the integration domain and the platform domain of the entity. I copied this from other STT entities such as #L56\\r\\nIf you are certain it would be fine and you prefer it without the suffix, let me know to remove it before the next release. Yes I'm certain. What we do need is to deduplicate each entity within the same platform type. Eg if two different config entries are used that creates two different STT entities, we need to have an id for that to deduplicate them (config entry id). If one platform creates two entities for every config entry we need to have another id for that. Addressing it in #126585 Missing return value typing. It doesn't seem to be missing. It returns `AsyncGenerator[speech_v1.StreamingRecognizeRequest]`\\r\\nBTW, I've enabled strict typing for this integration and there are no complains. Sorry, I misread.\",\n",
       " \"Could you maybe update the description of the PR to explain what this feature does and how it affects the integration?\\r\\n\\r\\nThanks! ðŸ‘ \\r\\n\\r\\n../Frenck Currently the component regularly polls the IGD (router) by calling several so called Actions (Action in UPnP terms, an RPC), such as `GetTotalBytesReceived`. In this case, these Actions simply return a State Variable (another UPnP term, speaks for itself I guess.)\\r\\n\\r\\nUPnP also specifies that State Variables can be evented. This means that a client can subscribe to a Service (which holds Actions and State Variables) and gets callbacks to when a State Variable changes. This prevents regularly calling Actions, saving some processing on the client side (in this case, the Home Assistant side.)\\r\\n\\r\\nPlease do note that not all State Variables are all evented. The example of Action `GetTotalBytesReceived`, which returns State Variable `TotalBytesReceived` is not evented. The State Variable(s) we are interested in are `ExternalIpAddress` ,`ConnectionStatus`, and `PortMappingNumberOfEntries`.\\r\\n\\r\\nHowever, some UPnP devices have a UPnP buggy implementation. Hence, we want the users to be able to fall back to polling for the mentioned State Variables. Generally I don't like options because they increase complexity.\\r\\n\\r\\nGiven the wide range of devices this integration is supporting with various levels of quality, and different implementations of the spec, I think its unavoidable in this case.\",\n",
       " '',\n",
       " \"\\r\\nidentifiers is not needed if connections is set unless you need to use `via_device` \\n \\nPlease use sentence case Move this to the base  \\n Should this be in finally? Not even required, the library does this already When is this not known? Was supposed to cache the value and only fetch on first refresh but is not needed, the library already returns a cached value But what if we can't find it? We raise why the context? Leftover from settings entities, will remove it for now and re-implement it again later in another PR when I need it for the settings entities. Overwrite the config_entry type in the coordinator.\\r\\nI would maybe suggest to do the same for device, but I think there is a reason you dont have this yet Let's try to omit the Unit of measurement here as someone could also set it to microvolts what unit of measurement? Voltage is a unit. but if the user sets it to microvolts, the name is incorrect. so maybe try to incorporate `potential`.\\r\\n\\r\\nLooks like a nitpick, it is, but its just a thing we have with naming But voltage is not a unit of measeurement, that's how it's called in english and what this sensor measures. And the unit  of measurement for voltage is volt (or kVolt, mVolt, uVolt...). That is true now I think about it Please use Sentence case We have a common key for this one Why the super? Not sure, was autocompleted by vscode and i just left it like that ðŸ¤· I think it's unset by default  it will just return None, so it's unnecessary anyway  Instead of snapshotting, just compare the status against STATE_UNAVAILABLE as now it's unclear what you're testing\",\n",
       " 'Moving `CONF_HATER` to `__init__.py` is necessary to avoid circular import between `__init__.py` and `climate.py`.\\r\\n\\r\\nIf you wish, I can create another PR to move all constants shared between `__init__.py`, `climate.py` and `confg flow.py` to a `const.py` file. Yes i think that would make sense. #120789',\n",
       " 'please use more descriptive names (new-record and result say nothing about the content) In general, not a fan of a seperate helper file, I think the functions can be reduced in size and moved to the coordinator Actually I had it on the coordinator first, but decided to make a helper (I\\'m more fan of smaller files).\\r\\nHowever, you\\'re the code owner, so I will do the change ðŸ‘  what is this by default? always UTC? or depends on wallbox config? hesitant about whether this should be something we do in HomeAssistant (or more upstream (or not))? Wallbox API returns always UTC time.\\r\\nI thought this quite a while as well, but I decided to covert the time to local for easier use in HA end.\\r\\n\\r\\nIf you see it\\'s better the other way around, it can be changed of course\\r\\n hmmmmmmm, let me think on finding a cleaner way I would like to skip the extra functions this can be a 1-liner I think, same for the other if\\'s Most probably yes. I\\'m not very experienced with python. Mind sharing an example how to do this as one-liner? I think that you don\\'t need to do anything if you just use the original dict right? but otherwise:\\r\\n\\r\\nconverted[\"max_energy\" = item.get(\"max_energy\") (this deals with missing values) why are we creating a new dict? we have a dict as input right? Same as above, not very experienced with Python (yet) :-)\\r\\n\\r\\nIn Python the input data is always mutable? a dict is, just change the attributes by setting them dict[\\'attrib\\'] = new_value\\r\\n One more thing about this:\\r\\nI\\'m creating a new dict since the service is not providing the full data received from the API.\\r\\n\\r\\nI\\'m mapping the get_services output and set_services input as same \\'model\\'. Currently API returns some extra data that is not required/accepted by the set schedules API.\\r\\n\\r\\nMeaning that you get easily get the schedules from the service, modify time and pass the same or slightly modified data to the set schedules.\\r\\n\\r\\nSo, if I would re-use the provided dict (item) it would keep the obsolete data keys as well :-)\\r\\n\\r\\nIf you think this is the wrong approach, please let me know and let\\'s think a better way of doing this\\r\\n just remove the key that has to go, item.pop(\\'key_to_remove\\', None). I think you can do this in the coordinator function. see comments above see comment above, should we do this in hass? not sure I think you can do this in a few lines without using a seperate helper file use better names again I think you can do this in a few lines without using a seperate helper file can this be async? i think you can skip this local time var, I think you are creating 2 idential datetime objects here. Suggestion: \\r\\ntime_obj = datetime_sys.strptime(time, \"%H:%M\")\\r\\nreturn dt_util.as_utc(time_obj).strftime(\"%H%M\")\\r\\n\\r\\nAnd then just move it to the main function\\r\\n i think you can skip this local time var, I think you are creating 2 idential datetime objects here. Suggestion:\\r\\ntime_obj = datetime_sys.strptime(time, \"%H:%M\")\\r\\nreturn dt_util.as_local(time_obj).strftime(\"%H%M\")\\r\\n\\r\\nAnd then just move it to the main function Went as that first, but bumped into an issue:\\r\\nThe time_obj received through strptime using hours and minutes only, the date will be set as \\'1900-01-01\\'\\r\\n\\r\\nUsing dt_util.as_local for 1900-01-01 date (including time) will not do the conversion to local timezone properly. \\r\\nSo I decided to make a new object from now() and just replace the hours and minutes. That solved the problem.\\r\\n\\r\\nSo, most probably dt_util.as_local have some restrictions about a valid date or alternatively a bug in implementation.\\r\\n\\r\\nPs. I think in your sample the timezone should be overridden as UTC though:\\r\\n  time_obj = datetime_sys.strptime(wallbox_time_str, \"%H%M\").replace(\\r\\n      tzinfo=tz.UTC\\r\\n  )\\r\\n\\r\\n\\r\\n\\r\\n ok, something like this: datetime.now().replace(hour=int(item[\\'stop\\'][0:2]), minute=int(item[\\'stop\\'][2:4]), second=0, microsecond=0) Pushed the changes requested.\\r\\n\\r\\nStill decided to keep the time conversion on their own function in order to keep the code more readable. \\r\\nThough the conversion code(s) are optimised, moved to the coordinator and helper deleted. Let\\'s not unload. We want services to be stable and not be dependent on a working config entry (hence you initialized the services in async_setup and not in async_setup_entry We should not make users create their own json to put to the service. I\\'d rather see something smarter that we can validate better. I think there is a risk here since you are editing the full schedule and not just a part of it, so theoretically someone could remove their whole schedule with a single service call (and maybe that isn\\'t a bad feature, but in the current form its too easy for someone to mess up their settings). The original idea was to pass the data easily from get_schedules to set_schedules for this exact reason: the user could get the schedules, modify one and pass it easily to the set_data. I\\'ll look into this and at least create models of the input data that we could validate.\\r\\n\\r\\nAnd what comes to easily over write the whole schedules, the Wallbox client lib and the API only supports set functionality at the moment. I think we should not create single schedule handling inside the Home Assistant component.. on this PR at least.\\r\\nIn an ideal case we should have insert, update and delete for a single schedule of course. Could this maybe become a calendar entity? I like the idea, but as you said on the comments below, let\\'s split it on another PR. :-) ',\n",
       " 'Use capitalisation consistently with the other sensors\\r\\n Yeah, sorry, my bad. Fixed!',\n",
       " \"Is this complicated config necessary? Why  not use the default config from e.g. line 65? It doesn't harm either ðŸ¤·  Well, it does not make sense. The mean_circular characteristic is super special, does not take percentile as an input and sampling size provided as a float won't break anything but sets a confusing example. :) I can simplify it, I just used a random case. I changed it to use average, but the config entry requires everything else... Function name and docstring do not make sense. Also, shouldn't these be split up into two-three test cases? Edit: I can see that the first half of this testcase is a replica of the test case defined in the other file. Was that necessary? >  Also, shouldn't these be split up into two-three test cases?\\r\\n\\r\\nCan you specify which three you suggest?\\r\\n\\r\\n> Was that necessary?\\r\\n\\r\\nWhat do you suggest? Deduplication? IMHO, that isn't needed for 2 occurrences. No I wouldn't spend that time. Many of the test cases start with similar initialization code.\\r\\n@dougiteixeira I would appreciate a minimal config and a better docstring. After that the addition lgtm!! ðŸš€ The sensor test only checks whether the device id of the source entity was linked to the helper entity.\\r\\n\\r\\nThe init test, on the other hand, cleans up links between devices other than the source entity (the user can rename entities and impact the integration). That's why the initial part is the same, as I need to link a valid device as done in the sensor test and some stale devices.\\r\\n\\r\\n I improved the docstring.\\r\\n\\r\\nAs I need to configure the integration to trigger cleaning, I don't see a way to reduce this.\",\n",
       " 'This is odd... considering... (see next comment) This is a fixed method.\\r\\n\\r\\nIf more entity description are added, this will not work.\\r\\n\\r\\nSo IMHO, we should either:\\r\\n- not use entity descriptions just yet\\r\\n- or, add this call to the entity description I think this will be the only button looking at the Plugwise webserver.\\r\\nSo no entity description then. That service call is already blocking\\r\\n\\r\\n Can we also remove the translation key? It would name it restart duo to the device class translations which makes it more in line with other integrations Plugwise calls is a reboot button. And I see other Integrations use \"reboot\" as well. We introduced this later, @joostlek is right, we can just remove it and let the device class handle the translations (which means everything will be translated immediately as well, as it re-uses an existing key).',\n",
       " 'I think that it works best if \"Responding to user\" is also a tool call. That way it only has to call tools. This means that all response text needs to be json-encoded (i.e. all quotes escaped, all line breaks replaced with `\\\\n`, etc). And I don\\'t entirely trust LLMs to do that correctly every time. When using a respond to user tool, how does the tool loop know when to stop? hard coded special case for the respond to user tool? (Are the other conversation agents doing this?) No, we are not doing it for other conversation agents, we let them to respond to the user natively.\\r\\nAnyway, the `TOOLS_PROMPT` was a workaround that we don\\'t need anymore as the ollama library supports the tool calls. We\\'ll keep the `type: ignore[typeddict-item]` until  is merged',\n",
       " \"Should this be awaited? This doesn't need to be a coroutine function since there's no await inside. Make it an async callback.\",\n",
       " 'We have a fixture for this already.\\r\\n\\r\\n#L45-L52',\n",
       " \"Currently the work_area_id is not exposed to the user in HA, so it'snot possible to enter it. Here are three solutions, I'm not sure, what would be best:\\r\\n1. Generate a service, which lists the work area ids and the human readable names: eg: `123: Front lawn`\\r\\n2. Add extra_state_attributes to the work_areas_sensor: #L338-L345 , which show the work area ids and the human readable names: eg: `123: Front lawn`\\r\\n3. Request to enter der human readable name here, and then search for the work_area_id. Problem: The names might not be unique.\\r\\n\\r\\nEdit: 4. Register all the work areas as Areas in Home Assistant and use the area selector.\\r\\n\\r\\nHelp welcome. Option 2 is fine in this case. Please exclude the list from the recorder \\r\\n\\r\\nServices should always be registered to prevent from unexcepted errors like service not found in automations and co\",\n",
       " \"This is not common so I think its best to keep this in the docs okay thank you for the prompt review, will fix these Comments dont add much Why the noqa Please use constants `CONF_*` Please use entry.runtimedata Please refresh the coordinator before assigning to entry.runtimedata uneeeded Only keep things int he try block that can raise why this doesnt this display the error in the UI? no the self.context why? The config flow is the userfriendliest way to tell the user they fucked up and thus something is wrong This specific part was added because it may be the case the device is not connected yet or set up but the integrator knows the connection info already, or maybe the device isn't plugged in, etc. I want to give the user freedom to move on and add anyway as they can modify the options after adding it We should confirm we can connect with the device before the user is able to setup. This way we can ensure everything works like expected. Why does `__init__.py` take into account that these values are optional as they always get a value from the looks of it Follow up You can then access `self.config_entry` afterwards Stale euh? I had a HA error unless I added it but could have been caused by something else. I will try to remove Please type the coordinator to the type of `data`\\r\\n Let's not use the event bus here, what are we doing here The point of this is to send events when these values change. This is what the docs say to do. Is there a better way to handle this? I am asking a more global question, what does this do and how does the integration communicate with the device and vice versa It opens a persistent connection to the device and the device pushes data to the integration. The integration processes that data in realtime and updates its internal state. So the integration reflects the real time state of the device\\r\\n\\r\\nThis code would fire events on the bus so users can create automations based on specific states of the device in realtime if they would like an event based system. I supposed they can also use sensor data (had to remove it because the bot wont let me add more than 1 platform but will add later) so I guess I will remove this for simplicity We should not add this. the user can set it up themselves This library is used to wake the device which otherwise is impossible to wake up. Is there a built in for this? Its unreasonable for a user to set up wakeonlan first then install this integration. Alternatively, I can bake this into my library and call it from the integration The user should use wake on lan for this. The library should not do this\",\n",
       " 'I\\'m surprised by this combined with `should_poll` not being overridden in the update entity class.\\r\\nIs the `matter` integration polled? No, the Matter integration is not polled.\\r\\n\\r\\nBut checking for updates is. The device don\\'t have a bulit-in update checking mechanism, so we don\\'t get a notification pushed when there is an update.\\r\\n\\r\\nWe *could* do the polling on Matter Server side. But it feels more naturally to use Core\\'s polling capability. With this, one can also use the `homeassistant.update_entity` service to force an update check.\\r\\n For the records: This turned out to be a bit odd in Matter in general: Matter entities generally get updated through subscriptions/push from the Matter Server. Yet, polling was enabled by default (since that is the Core default). With  Matter entities now don\\'t poll by default.\\r\\n\\r\\nI\\'ve rebased this PR to dev again, and enabled polling on the `MatterUpdate` class explicitly (see #diff-ac1ac949f539d395d65427ac886c148bf954020185229945fb6f1a87779ad811R73). Why does this method not just call `self._update_from_device` ? `_update_from_device` gets called on every attribute update as pushed by the device. We don\\'t want to trigger a update check whenever a random attribute changes on the device. What sets the entity picture in other matter entities? It is not being set in other places. This is more about overwriting the default behavior of the Update entity. Ok, then please rewrite the docstring to make that clearer.\\r\\nMaybe like this + remove the comment:\\r\\n Why is this needed? If the entity is polled, an update should be scheduled after service calls It usually takes 2-3s for the device to get the first update progress state changes. Pushing the progress state change here, really improves user expirience: With that, the frontend immeaditly switches into a \"in progress\" animation. Without it, the frontend doesn\\'t update, and it feels like the \"Install\" button is broken. OK, please add a comment explaining we immediately update the state to not have to wait for the real update state change. This is not needed\\r\\n\\r\\n Does this send a message to the Matter devices too or is it just a local update check?\\r\\n\\r\\nIf the update button on the \"Updates\" page or the \"Check for updates\" menu button on the HA settings page is clicked, `async_update` is called for all update entities.\\r\\nIf an \"image notify\" message is sent to each device (e.g. via Thread) here, this could cause the network to be spammed for a short amount of time.\\r\\n\\r\\nSo, if this sends a message to the device, maybe set `PARALLEL_UPDATES` to `1` or another reasonable number for the Matter update entity/platform? > Does this send a message to the Matter devices too or is it just a local update check?\\r\\n\\r\\nThis causes no communication with devices. It uses cached vendor/product ID and version information to check for updates. The update check is polling the http get requests to the CSA DCL REST API.\\r\\n\\r\\n Maybe explain why the update entity is polled Added. Thanks for the review! Why is this needed? This is not needed, I\\'ll remove it.',\n",
       " \"These strings are provided by the `humidifier` entity component itself. Got it, thanks! You can remove them completely as you have set the device class and it will use the name from the entity component automatically. I'm sorry if I wasn't precise. @jpbede I tried that first and it did not pick up the name from the entity component automatically. Ok, my bad, this is not supported by the `humidifier` entity component. Just a nitpick for later, maybe we could avoid those magic numbers and use some speaking consts for it :) Ya definitely a fair point. These are unfortunately somewhat magic numbers in the documentation itself, but perhaps I could think of a way to better describe them.\",\n",
       " 'I am not 100% sure what this attribute usually represents, but \"fan mode\" and \"preset mode\" sound like they are different kind of modes, so I\\'d suggest to call the label `mode` as well.  Sounds good to me; I changed it',\n",
       " 'Should this be added as default?\\r\\n Why is there a force poll option added in this PR ? ',\n",
       " \"We generally don't allow storing entity objects in a shared container It looks like you only need to know the `.key` so you could do it as\\r\\n\\r\\nself._features_by_entity_id: defaultdict[str, set[str]] = defaultdict(set)\\r\\n\\r\\nthan subscribe in async_added_to_hass with `self._features_by_entity_id[key].add(entity_id)`\\r\\n\\r\\nand return a callable that does `self._features_by_entity_id[key].remove(entity_id)` than drop the key from the dict when all are removed\\r\\n\\r\\nthan replace `_entity_description_keys` with something that returns the dict of subscribed `keys` Note that the entity_id is stable for the lifetime of the entity object and if it does change, it will be removed and readded (new object) ~~How should this be changed? Perhaps `hass.data` is a better place.~~ It fine to store it here, and its fine to store the `entity_id`. The concern is storing the entity object itself in the shared container especially when it might still exist after its removed from Home Assistant.\\r\\n\\r\\n I think this is solved now. Please review. If possible, I'd split the options flow into a new PR and let this PR handle the registering of the specific keys to update Dropped the options flow. Is this what you meant, or did you mean to completely remove the `force_poll` related parts, such as #diff-bf146bfe416cf0296a6c04f61fa6b8c1a9acb073dab44aab697d7f1eddc519d0R86 ? I think you do. Let me split it up a bit further. Done. It would be a bit lower risk of breaking in the future if you pass `entity_id` and `key` so the there are no accesses to the entity object properties outside of itself. Fixed. We should avoid accessing `runtime_data` in the tests, instead patch `async_subscribe_services` or if its already mocked somewhere else, assert using that mock. We are still accessing `entry.runtime_data` here Fixed1 Missed this one the first pass, but `keys()` can be dropped here since its the default Missed this one as well ðŸ¤¦ , but commented code \",\n",
       " 'This pattern is repeated in other platforms, consider making a `AirGradientDescriptionEntity` that subclasses `AirGradientEntity` and sets the unique id and description. Than you can drop `__init__` from some of the other platforms Will look into this when I merged all the platforms in for which I have a PR open :)',\n",
       " 'Oops this should fix indentation\\r\\n\\r\\n the types don\\'t match either so i just reverted it Is 0 a good indicator for this case? Is it allowed/ok to use something like \"unknown\"? ðŸ¤” Or even \"unavailable\"? I just used that as a defensive mechanism for the typing, it\\'s technically always an int but the `MetricValue` type is an union of `int | float | None`\\r\\n\\r\\nnot sure what\\'s a pythonesque way to do it, in typescript i\\'d just do `...get(...) as T`\\r\\n\\r\\n So could we return `None` here instead? Or maybe @joostlek can provide some guidance in this regard.\\r\\n\\r\\nMy concern is mostly that for the \"normal\" profile there is no concept of \"profile duration\", it will be active until one manually changes the profile, and it is the profile that is switched to once the duration expires for fireplace, boost or extra. So letting the sensor show `0` for the normal profile feels a bit misleading to me. so `None` for \"unexpected\" value AND default value? so that the value is `None` when none of the timed profiles are on? Yeah, I think that could make sense. Maybe a specific early return for the normal profile, and then we could even log something on debug for unexpected values, or WDYT? In any case, I really like this new sensor ðŸ‘ The thought that the Vallox unit could provide it never crossed my mind, even though I almost implemented something like it using template sensors in Home Assistant at some point ðŸ˜€ Hold on. I am moving this block to the lib. Use new method from  Could be an idea to bump the library version in a separate PR I guess. yes, lib version update needs to go in a separate PR. created #120395 for it',\n",
       " 'So I am wondering, would this be able to be split up to a select entity and a number entity? I think the select entity would work, but I won\\'t be sure if the logic around it could be reflected correctly, wdyt? `set_profile` method in the library supports setting duration. It works only for `fireplace`, `boost` and `extra` profiles. So I think a single set_profile service would be fine accepting profile name string and optional duration. Creating int mappings feels to be wrong. I mean its not about int mapping, its more about moving to a service or to entities, as entities are more user friendly and accesible, the only question is, is this a good idea for these not that familiar with python, is there a simple way of having the parameter be coerced into the matching int enum of `Profile` from the lib?\\r\\n\\r\\nor how would the mapping be done? e.g. from `\"Boost\"` to `Profile(3)` Oh but that\\'s not the thing I am worried about, you can indeed do `Profile(3)`. I am more wondering if it fits and if it can be done directly. two parallel conversations happening I think :)\\r\\n\\r\\nI\\'m not sure about either, my end goal is just to have a service to call from nodered to enable the programmable \"extra\" profile when my range hood turns on.\\r\\n\\r\\nBut the `vallox_websocket_api` makes interactions a bit easier by hiding some of the lower level stuff. Separating this into two entities might mean splitting some of the existing stuff to use the lower level modbus registers.\\r\\n\\r\\nLike all the modes that allow timing, have separate registers for timing, and also a register for enabling or disabling the timers. And when setting a profile, it clears the existing timers for other profiles. Out of the box there is a priority order the device runs down.\\r\\n\\r\\nI would keep everything close to the api which is less likely to change. Don\\'t use ints as profile. Pass in a string that you would map to a profile. any ideas why originally the `Extra` profile was not \\'settable\\'? It\\'s not included in `VALLOX_PROFILE_TO_PRESET_MODE_SETTABLE`, but I could add it there and cut down on the definitions in `const.py` and use it to map the param. It is some firmware limitation. Vallox\\'s Web UI does not allow to set Extra profile in 2.0.16 (which I currently use). does the HA side support some sort of conditionals based on the firmware version, it works fine on my .24 version\\r\\n\\r\\nif someone can verify how it works on .20 i could branch it to either >=.20 or >=.24 Why do you need that Extra profile? Isnâ€™t fireplace and boost sufficient for all the use cases? It\\'s a separate configurable profile that can be used via digital inputs on the board or via modbus or the websocket api.\\r\\n\\r\\nI\\'d use Fireplace for the fireplace, and a differently configured extra profile to compensate for my kitchen air extraction.\\r\\n\\r\\n![image](\\r\\n\\r\\nThis way i can avoid pulling a low voltage cable from the kitchen to the air handler, and just trigger the extra profile via a sensor on the kitchen range hood open/close relay.\\r\\n\\r\\nedit: my kitchen air extraction is not via the vallox unit, so it needs to be tunable separately Ok. Got it. I have that in Web UI as well. I just did not know where to find it. If you make the parameter settable are you able to turn extra profile on? Would be sad if it would turn off automatically, because we do not apply any voltage on digital input. yes, if i apply it for 5 minutes, the ui says \\r\\n\\r\\n![image](\\r\\n\\r\\nthen if you set for example home profile again, it just cancels the extra profile before the timer runs out\\r\\n and the same works from the fan entity as well\\r\\n\\r\\n![image](\\r\\n\\r\\njust like the fireplace mode it just doesn\\'t have a fan speed as it\\'s separately configured\\r\\n Let\\'s capture exception here if profile name does not exist in the `PRESET_MODE_TO_VALLOX_PROFILE` Actually I see that it will be blocked by setting in services.yaml Maybe it\\'s more clear to avoid an abbreviation here:\\r\\n\\r\\n does it get a label from some translation or is it just a literal that\\'s shown on the service page apparently latter, looking at other service definitions Can we use lower case here and use translations? Quite a big change in this context I think, could do separately if there\\'s some guidance for this It\\'s not that big of a change, but I would like to have it in this PR to avoid a migration path in the future.\\n\\nI think a global search for \"selectors\" in a \"strings.json\" file would probably yield some results. I\\'m currently on mobile so can\\'t check Looked a bit at this, and everything currently in the module code seems to deal with values like \\'Home\\'\\r\\n\\r\\njust changing this selector to use translations, would mean an extra mapping `home` -> `Home` -> `vallox_websocket_api.Profile.HOME` for this\\r\\n\\r\\nand i guess all previous state data is stored with \\'Home\\' etc, so not sure what this change would accomplish\\r\\n\\r\\ncan do what\\'s needed but need some guidance This change will add the ability to be translated. This increases usability for non English speakers. You would have to map the values between lower case and what the library gives and returns We should avoid if statements in test code I assume the true false is something that is for vallox? I just imitated the other code in the vallox module, maybe someone else can answer Hmm, not 100% sure but might just be a leftover from #56966.',\n",
       " 'This code is very inefficient  integration_entities is frequently at the top of template profiles I see from users. I think we should avoid repeating that pattern ',\n",
       " \"Pull this into a standalone if-statement and then conditionally add the FLOW_CONTROLLER_SENSORS and ZONE_SENSORS. Since the conditional isn't something related to what you're iterating over, it's weird having it in the list comprehension.  Good call. Fixed.\",\n",
       " 'We should raise `ServiceValidationError` instead, and preferably we also add a translation key to make all the errors translatable :) Is this something that is always available? Can we read the dehumidify value? This could also be a button maybe Thinking out loud here, so feel free to leave your idea of it as well Can we gett the state? Would this be a select entity? Not needed yet  Fixed Automatic can use a reference key to the other automatic in the file, (I\\'m on mobile, so I can\\'t type one out for you) Wouldn\\'t that then require referencing a different entity? You would essentially be referencing from fresh_air_mode to the air_cleaning_mode entity. Seems confusing. I would rather keep it as is personally. Yes, and that is no problem because it decreases the amount of unique translation keys\\r\\n You can make inverse mappings Updated What do we do with the unique id? Do we append something with it? It is used to generate the `_attr_unique_id` on the base entity. This was how it was decided to be done in the initial implementation of the integration. Looking from the code it looks like every select kinda has the same logic, but I don\\'t want to burden you again with \"let\\'s simplify it\", so I\\'ll try tinkering myself first before I jump to conclusions  Refactored. It\\'s a little awkward because each of them is dependent on two properties, but only one of them is actually updated. Hope the logic makes sense If we only have on or off, what about a switch? It\\'s not really an on/off. It\\'s off or automatic. Automatic isn\\'t really _on_, it\\'s more of a \"let the system decide what to do\". I think a switch would be confusing. It would also over complicate the code because it would be one of 4 of the same type of entity to be different. I\\'d like to keep it as is. I see so this is the ventilation mode (aka fresh air control) - which is not the same as the fan mode exposed in the climate entity.  This is different than a \"ventilate now\" switch that some hvacs have. While I proposed a switch in my initial comment, I do think a select is clearer. The `list(set(..))` was because in the sensor there were a lot of duplicate options, but in this case everythin is unique, so no need to do this now Updated when the item isn\\'t found, does that always mean the mode is off? Or can it be unknown because its not supported? Technically it\\'s not possible. Per the documentation, anything outside of the values we have is \"reserved\", which means that it theoretically is a value supported by the protocol, but doesn\\'t actually ever happen. The \"off\" is really just a failsafe. Stale Stale Maybe just create the inverse maps as a constant outside the class as well That would require adding a new parameter as well. Is there any real benefit to having the inverse maps as constants that then get passed in, as opposed to just generating the inverse map in the init? Can be combined',\n",
       " \"We create a task if its going to be awaited? Hm not sure why I awaited it. I use a background task since apply_options calls set_permanent_connection, which connects to the motor If the intent is to wait for it, than it should be awaited directly.\\r\\n\\r\\nIf you don't want to wait for it than its fine as-is except please use `entry.async_create_background_task`  Sure. I don't think it makes sense to make the setup of the entry wait for the connection of the blind in case a permanent connection is enabled, which is why I use a background task The permanent connection option makes sense given its BLE.\\r\\n\\r\\nFor the disconnect time, why would the user need to change this? How does the user know what a good value is here?\\r\\n\\r\\n > For the disconnect time, why would the user need to change this? How does the user know what a good value is here?\\r\\n\\r\\nIt defaults to 15 seconds which I would say is a reasonable time for normal-sized blinds, and it gets refreshed every time an action is performed (like opening, closing of the blind etc). However, I can imagine some users would like it to be a little higher, maybe because their blinds are bigger thus requiring more time to open/close fully. Also, it is an *option*, and I would say it is never bad to have the option to change it to your liking\\r\\n\\r\\nSee this related issue:\\r\\n\\r\\n Please add some some descriptive text explaining why you would want to increase the value.\\r\\n\\r\\nSomething like:\\r\\n\\r\\nThe default disconnect time is 15 seconds. If your shades take longer to perform an operation, increase the disconnect time by counting how many seconds it takes for a full open-to-close operation to be performed and adding 5 seconds. Where and how can I add that? Is it possible to add a description to each of the options? Usually thats accomplished by extending the `description` field or for less important options, its added to the docs (but users don't usually see those)\\r\\n\\r\\n#diff-67d46204179e211a11e8bffe64c02f3799c7f8bbcf8a1248013bf6b232f3691cR27\\r\\n\\r\\n What about adding it to the `description` of `vol.Optional`, or won't it be translated in that case? Updated the description field to:\\r\\n\\r\\nThe default disconnect time is 15 seconds, adjustable using the slider below. You may want to adjust this if you have larger blinds or other specific needs. You can also enable a permanent connection to the motor, which disables the disconnect time and automatically reconnects when the motor is disconnected for any reason.\\r\\n**WARNING**: Changing any of the below options may significantly reduce battery life of your motor!\",\n",
       " \"The logic to connect to the device should be encapsulated in a package published on PyPi. > The logic to connect to the device should be encapsulated in a package published on PyPi.\\r\\n\\r\\n\\r\\nCan I simply remove the requirements from manifest.json and use the `aiohttp==3.10.0b1` version that is already a dependency in Home Assistant?\\r\\n No, you need to create your own library with all the calls to the device/service and publish that to Pypi and use that Not needed Why the comment Not needed Please use entry.runtime_data. Check airgradient for an example. You should extend the ConfigEntry type with the type for the runtime_data. Use constants Not needed for now EV? Please add typing can be combined if both are required, why do you always use `.get()`? Use constants instead We should check if the data is valid. The config flow is the best way to tell the user they did something wrong, so we should try to connect with the device to verify the data Please keep this for a follow up PR ? The coordinator should not be in charge of creating and removing entities. That is the task of `async_setup_entry` in the platform files. Check Withings for an example, the best example in there are the measurement sensors This sounds like some library specific things, can we move this to the library? Only have stuff in the try block that can raise The library is not licensed properly, please add a valid OSI approved license Remove empty fields Why is localizing a thing? Don't use state This is device specific, please move to the library This is an abstraction, we want to provide the device to HA as raw as possible Don't add extra state attributes Euh, why? Please check other integrations for how they do their config flow tests\",\n",
       " 'Would be nice if this came from the lib in a future update Yeah, we discussed about this in private and agreed that it\\'d be fine to access the feature by its ID (which are now de facto a part of our stable API) to fetch the information from it.\\r\\n\\r\\nChanging this is not necessary for getting this in as there are no other fan devices, so this is just something we should improve on in the future releases.  opened and assigned to 0.7.1 \\r\\nMakes it consistent with the base class which accepts only device & coordinator as positional args. That\\'s done This shouldn\\'t be anymore required, as the parent class implements `async_added_to_hass`? Removed That\\'s done although I\\'m still not convinced about dropping these prefixes as it\\'s inconsistent with all the other names like descriptions, coordinators and config entries and now we get name collisions with the kasa module names. We can change that in a single PR for the whole integration, if needed. Consistency is the key, but we can rename all of these if needed. Would this approach also fix #114752? The issue that aimed to solve was \"partially\" provisioned power strips where the individual sockets were not named, leaving the children with an empty name. Yes it would fix that Move the comment above the line, this will make the code itself a oneliner. Done This reads odd, when the `super()` is called with `parent` directly after the statement, indicating that this should probably be done on the base class. Fixed, wasn\\'t needed This could use a comment why it\\'s necessary to pass `wait_background_tasks`. I typically always do this in tests as I\\'ve experienced intermittent issues without it and I think it\\'s good practice.  I can add a comment referencing the 112726. Comment added to `setup_platform_for_device` in init. I need to remove this',\n",
       " \"I just picked values here that I thought made sense, but the API allows for up to 100 days of activity, so these can be adjusted if we think more or less is better. This is pretty conservative as well, with 2 base stations Iâ€™m only hitting around 1100 API calls/day, but I donâ€™t see any reason to go less than 15 min intervals.  You can use `itemgetter` here instead of a lambda #operator.itemgetter \\r\\n\\r\\nIf its always one `/` \\r\\n\\r\\npreference here, but I'd probably write it like this At some point, in a different PR, this integration should migrate to use runtime_data\\r\\n\\r\\n\\r\\n Avoid fetching time twice by saving `dt_util.now()` and than adding the timedelta to it.\\r\\n\\r\\nAlso can `utcnow()` be used here or does it need to be in local time? Good question. I don't know that it couldn't be UTC, but I guess I'd prefer it be local for events that fall on the edge of the time frames that might be omitted otherwise. For example an event 7 days ago where the current UTC time has moved to the next day would be left out, if I'm thinking about that correctly. \",\n",
       " \"This should be `EntityCategory.CONFIG` since it's an entity that allows changing something about the feature. Then maybe the notification idle buttons should be changed too? Yes, good. :+1: \",\n",
       " '',\n",
       " \"Why don't we remove these devices automatically during config entry setup? We don't know during setup the status of the device. Devices are added during runtime when we get a broadcast from them Ok.\",\n",
       " \"could be a set to avoid a linear search but won't matter unless this list grows quite a bit\",\n",
       " 'The unit and formula for calculating value are modifiable by the user during runtime, so we do not add a unit and state class for this sensor. Should this be diagnostic ?',\n",
       " \"Could we add a testcase for this? I take it, it's not possible to set holiday or summer via the integration?\\r\\nIn that case we should maybe raise an error here instead to tell the user they need to turn off holiday/summer via the app (or whatever) as it's not possible here. exactly - holiday and summer mode are configured via the device hub, but not the integration.\\r\\nAt the moment his PR includes code, which changes the list of available `hvac_modes` and `preset_modes` - based on the configured holiday or summer mode - to only each one available mode, so it is not possible to select any other hvac mode or preset for the user.\\r\\nBut we could change this to not changing the list of available hvac and presets, but raise an error to tell the user, that a change is not possible (_as you suggested_) after some thoughts about it, I think we should still change the list of available hvac modes and presets based on the holiday/summer mode, so the user can't select any unavailable hvac/preset, but should raise an error when needed Could we use `is False` instead as I read it initially as the attributes was removed while they are not\",\n",
       " '\\r\\nthose variable are only used once anyways \\r\\nis this the main feature of the device? If yes, set the name to `None` I didn\\'t quite follow this comment. One device can support multiple systems and zones. Each (system, zone) pair maps to one ClimateEntity. If a devie publishes only one entity - the `main` entity - which it looks like you\\'re doing here, we set the name to None, so it follows the device name \\r\\nrequired for new integrations \\r\\nno need to save them if you set the unique id here Actually, there is no self in scope here? dealt with this in the __init__ \\r\\nno need to set to `None` use the `_attr_` instead also please the `attr` you didn\\'t address this one what are you doing this for My understanding is that not all of these attributes are valid in all HVAC modes. I.e., the _high and _lo attrs only make sense in HEAT_COOL, and _target_temperature is used only in HEAT and COOL. So, I\\'m clearing them to enforce the invariant that target temperature attrs are only set if actually being used. \\r\\n\\r\\nI\\'ll add a comment to that effect if this makes sense to you. \\r\\nis default since you\\'re only using this once, move it inline, so you also can get rid of the exceptions if I do not catch the exceptions, then the config flow tests will fail -- I had taken them from the skeleton generation tool IIRC. Thoughts? sorry, I meant do catch them, but if you move them inline, there\\'s no need to define custom exceptions, but you can catch them directly remove any empty keys is this really a hub, or a single device I *think* it\\'s a hub, but I\\'m happy to discuss.\\r\\n\\r\\nThis is a single piece of hardware. It can connect to one or two different HVAC systems. Each system can have multiple zones. A (system, zone) maps to one ClimateEntity. \\r\\n\\r\\nIt feels like a pice of hardware that exposes two different HVAC systems (say, an upstairs and downstairs furnace) would be a hub? the question is whether you setup the integration once per HVAC device, or once per system and the integration adds all climate devices at once. If at once -> hub, if one device -> device. You are currently only adding one climate entity per config entry, so imo it would be a device in the current implementation. please make your errors translatable, by settings `translation_key`, moving the text to `strings.json` and setting `translation_placeholders` if you want to pass values to the string \\r\\nyou shouldn\\'t need this \\r\\njust preference, to not define variables we only use once anyways \\r\\ncan we add device info? why are you mapping \"auto\" to heat_cool instead of \"auto\"? (temperature range is supported by both)',\n",
       " 'I\\'m not a fan of this as many users will have no idea what \"EP\" means and most devices will only have a single endpoint. Also hardcoding it like this will make translation impossible. Maybe there\\'s a better way, but I put that in to avoid two same-named numeric inputs. A particular example came up while I was working with the Inovelli switch which has two lighting endpoints so you get two OnLevel attributes. See image:  \\r\\n<img width=\"235\" alt=\"image\" src=\"\">\\r\\n\\r\\nSome thoughts ...\\r\\n\\r\\n- I wanted something to distinguish between the two  and I thought that, at least with an EP designation, this could be explained in a user\\'s manual for the device.  \\r\\n- My \"EP\" approach also has the weakness that it doesn\\'t clearly associate the numeric input with the specific control. Is it possible to relate the name of the numeric input to the control it relates to. I.e., if the user names the control \"Living Room\", is it possible for the numeric input to have that appended like (\"OnLevel for Living Room\"). That may be the least confusing if it was possible.\\r\\n- Another approach that is likely better than using the \"EP\" would be to do what you did with events and see if there is a matching FixedLabel and append that value if a match can be found (or use the first label in FixedLabel as a default), but only append the \"EP\" if no match and the device has multiple endpoints.\\r\\n- Longer term, I had thought there needs to be some kind of naming \"helper\" function as a more general naming function that does something like : See if there is a semantic value taglist and, if so, translate the semantic value to use in the entity name, or see if there is a FixedLabel and find one matching target labels  [X, Y, Z], or if no target label match in FixedLabel, use the first label as the name, or if nothing else, return an endpoint number.\\r\\n\\r\\nAnyway, I agree with the point that that I put in isn\\'t ideal, but less confusing than if there are duplicates with no way to distinguish.\\r\\n\\r\\n\\r\\n\\r\\n Opened a PR with a more generic approach to postfix the entity name, but only if the device actually has multiple endpoints:\\r\\n\\r\\n This needs to be changed to avoid a rounding issue.\\r\\nShould have been :\\r\\nmeasurement_to_ha=lambda x: int(x / 2.54 + 0.5)\\r\\n\\r\\nAs is, if you entered the value of 54 percent, it would get converted to the native value 137, and that would then get reported back and coverted as Int (137/2.54) = 53.  Adding in the extra 0.5 results in proper rounding. we just need to use round instead of int This seems like a todo? Its a comment on all our tests, maybe we should just not replicate it everywhere Ok lets ignore for now. Lets clean it up at a later stage (all at once) if we have confirmed with Martin what\\'s needed Please separate words with underscore, `send_value`. We need to test the set value service of the number entity too.',\n",
       " 'use a translation key in the entity description (and strings.json) this is dead code Imo it would be better if we can make a mapping table to translation keys so the modes have a nice localized label I\\'m still thinking we should do better and make this generic\\r\\nThe options (translation keys) can be added to the entity description and then we need a way to map the supported values If you want to guarantee that they all work the same, you could just define all types here and type checking will verify they remain all the same.  yeah but that becomes an awful long list  ok maybe it was the setting of the moon yesterday but today it works. Weird.\\r\\nSo adjusted it with a type alias Shoould all these clusters have the same translation key ? I could expect a device to have both energy mode clusters.  Yes, it\\'s just \"mode\" unless a description exists Can this change be reverted?\\r\\n`Generator` should be imported from collections.abc. OK, I think that slipped through in the original PR. Lets address that in a follow up PR. @epenet ',\n",
       " 'I think this need to maintain same unit to allow it to be changed. See here: #diff-d6bb8150a2868b6dd04145e6bfcc804b99e27e9f2abf100c8483ff60bcaf5bbfR60 Done! Should be updated to use new helpers',\n",
       " 'This will match the same as before, so no breaking change will occur here. Can we use icon translations? you can do that with the other one as well iwth .extend()',\n",
       " \"I'm worried the naming will be confusing, and will result in people using this sensor instead of the `Price` sensor.\\r\\n\\r\\nCan we change `Actual` to `Previous` We should not put all this information in the state attributes. Ideally the old data should be migrated to either new entities or using service responses to allow the user to view the data and do their own processing to it.  I don't see how the old data should be in new entities. I'm basically just following what the integration is already doing for forecast data. idem What are you trying to say?\",\n",
       " 'typing typing typing? Done',\n",
       " \"It doesn't seem this needs to be a coroutine function?\\r\\n This code is copied from `homeassistant/components/automation/__init__.py`; we should instead move the common code to the condition helper. Deduplicated in 2d9928d Type annotations are missing. What does `None` mean as the return value? `None` is returned by condition checkers when the condition is disabled.\\r\\n\\r\\n#L119\\r\\n\\r\\n#L242-L249\\r\\n\\r\\nThe function returned by `async_conditions_from_config` does not return None though, maybe it should not use the `ConditionCheckerType` Is context `Any`? Well, the `_handle_triggered_with_script` is passed as `action` to `trigger_helper.async_initialize_triggers` which is just typed as `Callable`.\\r\\nHowever, when the action is called, `context` is `Context | None`:\\r\\n#L279\\r\\n#L292\\r\\n\\r\\nI guess it makes sense to do the same typing here to prepare for future typing improvements of the trigger helper. `run_variables` is still not typed. It is now. This can't return `None` as far as I can tell.\\r\\n Good catch.\",\n",
       " \"Does this match the meaning of the feature? It should indicate if the door latch is retracted. It is not if the door is physically ajar. Yes this is ok I misunderstood the state. If open state indicates a retracted latch, then I agree, it doesn't match and door open/close state should be exposed with a binary sensor entity. I had to go back to the arch discussion to understand it. The dev docs where unclear :)\",\n",
       " \"There's only one integration for this brand, can be removed  Can be removed Use `entry.runtime_data` instead Don't log on info level Comment doesn't add much Why current password This can be inlined Please add reauth and reconfigure in a follow up Although this is vital code, I've removed it from this PR. To be added back & reviewed in the next PR. Together with the SemsoterraSensor object this feels like code that should be in the library rather than here  I've simplified the code. The library uses a slightly different data model (a probe has a set of sensors, where HA uses a flat list of sensors instead), so some work needs to be done here. Please remove empty fields  \\n Please type the Coordinator entity\\n\\n\\n Can be set outside the constructor Please use entity descriptions Please use the DeviceInfo object \\r\\nalso, replace `ConfigEntry` with this custom one everywhere else \\r\\n\\r\\nis the default \\r\\nkeep only code in `try` that can throw \\r\\nis only used once can we make the expiration offset a const? if you only use the `validate_input` once, just keep it inline, makes the code clearer imo this class adds little value, except complicating the code make this an instance attribute can both of those throw? \\r\\nuntil you implement reauth can we move this to a models.py make this an `Enum` or `IntEnum` maybe use a `StrEnum` for the type\",\n",
       " 'Can we move these constants to `const.py` ? The test only assert updating the state via an MQTT message, can we also test setting the `target_temp_high` and low. Probably you can use this from the climate tests. Had to remove the command topic anyway, as setting via service is (currently) not supported by the water heater component. We could set those as a config option instead. This test does only test setting the state after a water_heater has updated its state.\\r\\n',\n",
       " 'These tests are not valid, as the state for time entities are not matching.\\r\\n\\r\\nA `time` entity only contains a time, and not a full timestamp.\\r\\n\\r\\n../Frenck',\n",
       " \"I would prefer that if we want to switch to the default of Ollama, we should just not pass in the option at all and also not offer it to the user.\\r\\n\\r\\n@synesthesiam since you picked this current default, thoughts? Understandable that there are many, many knobs that could be turned on Ollama and its probably better to not overwhelm the user.\\r\\n\\r\\nMy thinking on this one was that different users could have pretty substantially different setups and usage patterns. I did a decent amount of testing, and at least on my hardware (1080ti, i7-4770K, SSD), the latency from loading the llama3 model into memory was surprisingly negligible. However, having 44% of my GPU RAM tied up by something only used a handful of times per day was much more limiting. I'd can imagine at least 3 classes of users:\\r\\n\\r\\n1) High performance seekers: potentially serving many users and likely using dedicated hardware. Current value of -1 probably best fit.\\r\\n2) Hobbyists/recent adopters: probably deploying on a desktop computer they use for daily work/computing. Having a big chunk of GPU RAM tied up probably infeasible if they ever want to play a video game or other intensive tasks. Values of 0 - X minutes probably ideal.\\r\\n3) Budget homelabbers with either a raspberry pi or mini pc. Potentially deploying Ollama using CPU instead of GPU. I'm actually not sure what the performance characteristics would look like here. I'd _guess_ values of -1 or 0 would be undesirable here but not sure.\\r\\n\\r\\nI also wanted to leave room for customization as new models come out. Even if llama3:8B loads up quick, it's possible models in the next few months get unwieldy. I can envision someone running a massive model on a device with unified memory wanting to avoid reading from disk.\\r\\n\\r\\nLeaving it up to the configuration of the Ollama instance could make sense, as this can be easily adjusted with the `OLLAMA_KEEP_ALIVE` env variable. So I am leaning to just letting users use `OLLAMA_KEEP_ALIVE`. Mike is currently out so let's wait until he is back next Thursday. I set the keep alive to -1 with the assumption that for HA users would not want to pay the cost of loading a model every time it wasn't used for 5 minutes. When used in a voice pipeline, the delay of a few seconds is a bit annoying.\\r\\nI'm fine making this configurable, but I'd like to keep the default at -1 even if Ollama themselves use 5 minutes. But we could let users configure Ollama with -1, instead of having this option in HA We could, but I would argue Ollama's default is not right for HA. I was confused when first building the integration because my models kept getting unloaded. Ultimately deferring to you both, my two cents is that Ollama can be used by multiple users for multiple services. The right default behavior for a Home Assistant only setup won't necessarily scale to other configurations. Having Home Assistant impose an immutable default behavior that impacts the whole system running Ollama might be a bit overkill. \\r\\n\\r\\nThe other edge case is that setting -1 in the Home Assistant request doesn't actually guarantee the model will remain indefinitely in memory. If the Ollama host receives a Home Assistant request is followed by another request (e.g., Open Webui), it will overwrite the -1 with with the value passed by the other service. Which can put you in a situation where the defaults of each service ping pong and overwrite each other. In Open Webui, keep_alive is [configurable](#L634)\\r\\n\\r\\nPerhaps being user-configurable like Open Webui is the more congruent approach? I'd be happy to modify this PR to simply switch the default from 5m to -1. If that is desirable, should I rebase and force push overwriting this branch? Or merge in dev, then commit a change moving 5m to -1? I'm fine with making the keep alive configurable, but I think we should default to -1 in HA I've pushed two commits to this PR:\\r\\n1. Pull in the latest dev branch \\r\\n2. Update default value to -1\\r\\n\\r\\nI've also updated the documentation PR to reflect this update in the same way: \\r\\n\\r\\nPlease let me know if you need anything further. Additional instructions should go into the `data_description` section (not `data` which are just plain field names).\",\n",
       " \"This type hint is likely redundant  Updated This was added because:\\r\\n+ `async_step_lock_key()` needs model to run `verify_encryption_key()`\\r\\n  - `model_name` is initialized in `async_step_bluetooth()`, a different function, hence the class variable\\r\\n+ `verify_encryption_key()` needs model to run `lock.get_basic_info()`\\r\\n+ `lock.get_basic_info()` uses different command for the two lock models I'll push a suggestion in a moment CONNECTABLE_SUPPORTED_MODEL_TYPES probably needs an update? Already added, check `homeassistant/components/switchbot/const.py` Let's make this a constant called `LOCK_MODELS` since its used in two places Added. Called it `SUPPORTED_LOCK_MODELS` so variables in const.py looks more consistent.\",\n",
       " 'Why not make the fault_code None instead `-`? Then the attr state becomes `Unknown`. But it is not. You mean:\\r\\n\\r\\n\\r\\n\\r\\n?',\n",
       " 'Do we really need a separate flag given that we could perform the check inside the ctor? The flag is needed for the sensor platform because it\\'s currently created without a feature being passed but it\\'s \"non-primary\" and there\\'s no way to tell inside the `entity` constructor without introspecting `__class__`.  I\\'ve removed it for now and the emeter sensors are now on the parent but with  they should go back on the children.',\n",
       " 'Let\\'s avoid the use of Pydantic here and just use normal dataclasses instead Fixed in 761f2c8db09d4dde5ef9d666a8795ecc4c60a19f Is the rule \"no Pydantic in build infrastructure and support scripts\" or \"no Pyndatic in general\"? Code doesn\\'t directly depend on Pydantic. No reason to rely on a dependency if it isn\\'t needed.',\n",
       " \"Instead of just the magic number `2.00`, calculate it or add a comment explaining it at the second thought...\\r\\n* I don't want to calculate it because it would duplicate the implementation in the unit tests. I want the tests to be calculation-free as much as possible so that they're independent of the algorithm.\\r\\n* There's no need to comment because the test is already clear. My existing comment isn't unique to this unit test but applies to the entire component. The existing web documentation pointing to Wikipedia should suffice.\\r\\n\\r\\nTherefore, I will remove this comment in the next commit. Wdyt? Let's extend with another sample to test the behavior of the state update after a discarded sample\",\n",
       " 'Why is this? Seems a bit strange as we have entities? For example, I don\\'t, because I have a wall connector but do not not a Powerwall or Solar, so none of the entities under this device get created for me. Can you extend the comment a bit explaining that so future reviewers isn\\'t asking the same thing? As I haven\\'t tried myself but you tested that this works fine and you get a location selector? Yes the location selector works. Sounds to me they should be required by the schema then and unnecessary to handle separately? But it\\'s conditionally required, you only have to specify a time if you enable that feature. I can\\'t do that with the schema AFAIK. Ok. Let me take a look then ðŸ‘  Could we rephrase it slightly so the user understands the \"condition\" required. I have tried to reword this using the name from the service translation. `ServiceValidationError` should have translations, also below Ive decided to remove the log. errors should be `HomeAssistantError`. Also please use translations. This error has unknown values, so I cant translate it. You can pass it as a placeholder so the string could look something like `Service returned error: {error}` or something similar to make it a bit more user friendly than just the hard errors Oh yeah good idea. This seems very strange to me?\\r\\nWe typically don\\'t allow to mock internals and also can this even happen as I would think the integrations would not even start then?\\r\\n\\r\\nMaybe you\\'re intending to do tests for the services if the config entry is not there at all or unloaded? The helper function that finds the specific part of the runtime data for a device id has failure cases if it can\\'t find the specific VIN. I can avoid this type of test if I also remove that safety from the code.\\n\\nI think this specific test has found the device, found the config data, but cannot find the VIN in the config data.\\n\\nYou\\'re right that it should be impossible. Should I remove the failure case from the code so that it doesn\\'t need to be tested?',\n",
       " \"Define `integration_type` and `iot_class`  This file will get generated later on and receive the translations from lokalize. Does this change? If no, set `_attr_device_info` in init directly. Can be omitted if you set `_attr_unique_id` and `_attr_name` instead. Can be removed if you set `_attr_oscillating` directly. reuse existing function: #L385-L388 Can be removed if you set `attr_preset_mode` instead. Reuse existing function: #L446-L454 Use `Platforms.FAN` from `homeassistant.const` I wonder if this is better to be maintained in the library. Do static inits outside of constructor. Raise `ConfigEntryNotReady`\\r\\n\\r\\n#integrations-using-async_setup_entry Can be defined as a constant Raise errors as `HomeAssistantError` Order imports You can use list comprehensive here\\r\\n\\r\\n What about moving the fan handling to `fan.py` and store devices here only?\\r\\n\\r\\n set `_attr_percentage` in `update` and reuse existing function #L361-L366 Is it valid to set `_available` to `false` if status is `None`? `_try_command` can now never return false but will raise an exception, so I guess it's safe to remove the condition:\\r\\n\\r\\n\\r\\n\\r\\nSame for the other `_try_command` calls. This will not change, so set `_attr_speed_count` in  init and reuse existing function instead:\\r\\n\\r\\n#L368-L373 This will not change, so set `_attr_preset_modes` in init and reuse existing function instead:\\r\\n\\r\\n#L456-L464 Set `_attr_available` in `update` and reuse existing function:\\r\\n#L823-L826\",\n",
       " 'Reuse existing error message\\r\\n\\r\\n This file will get generated later on and receive the translations from lokalize. When setting `_attr_unique_id` you can omit `unique_id` function, same for `name`\\r\\n\\r\\n Set `_attr_device_info` in `init` directly. can be removed if you set `_attr_oscillating` directly. Can be removed if you set `attr_preset_mode` instead. Can be removed if you use `attr_is_on` instead I wonder if this is better to be maintained in the library.',\n",
       " 'why are you patching the `async_setup_entry`, is there a reason it shouldn\\'t run? Because it\\'s not needed for the test. This tests is only verifying that the configure flow works as expected. what\\'s that for, you already blocked in L108 Not needed, removed. Personal opinion, I don\\'t like snapshots in config flows because they completely abstract away the thing that you want to test. The assertion becomes something like \"the result should be something along these lines\", but doesn\\'t specify the critical points which do matter like `CREATE_ENTRY` or things like that True.. But I don\\'t really care too much about what it returns. It\\'s an internal feature of the of flow. I suppose i could maybe switch to props include, and just list one or two entries. I\\'ve reduced the snapshots so they are much easier to review and only include what we want to test. You\\'re doing the exact assertion twice can we use `CONF_*` for this? I\\'ve changed it. But for me i see a reason to avoid constants in tests, since if somebody where to change the value of this constant, the test would succeed, but users installs would crash. In the template and scrape config flow, we also use the name device class iirc. Should we stay consistent? The annoying thing is that our select selectors only allow string values. So if we do that we would need to adjust the  config structures. I very much dont want different structures for yaml and flow.\\r\\n\\r\\nIf our selectors allowed bool values, it would have been easily solvable, but they dont just yet. I think you\\'re missing my point, I mean, now the name of the field is \"type of device\" (which could be \"device type\" imo), but should we stay consistent with HA naming and just name it \"Device class\"? Ah sorry. I got mixed up with climate that uses a boolean switch. Sure lets change that. Honestly, at this point this is just the same as\\n\\n\\n\\nIt\\'s not that we assert huge data objects any more, so imo we should just not use snapshot here, but I won\\'t block this\\n It would be a few more checks like not none, title and stuff. Which is sort of what snapshot is for. Now the snapshot is quite readable. I would prefer to keep it like this for now.\\r\\n\\r\\nI will take your objections to it into consideration though.',\n",
       " \"This is not using an index and will be very inefficient. Shouldn't we add a secondary alias index so we can call `areas.get_by_alias(name)` ?  This should be added as a a new function so we don't have unintended side effects.\\r\\n\\r\\nWe should then update template method to call it. Probably also update suggested_area processing in device registry to use it. \",\n",
       " 'There\\'s a helper for this, withings uses it What do you mean? Withings uses oauth2 flow handler It uses a helper for these 3 lines in the reauth  Found it ^^ Why is this a placeholder? The string used is `\"title\": \"[%key:common::config_flow::title::reauth%]\",` and the corresponding text from home assistants strings.json is `\"Authentication expired for {name}\"`',\n",
       " 'If `min` is 0, it will get `min_mireds`, which might be `None` You are right, but it is consistent with current `ColorTempSelector` behavior: #L430-L438\\r\\nI will fix both. This should be cached. Done',\n",
       " \"Doing what? You're right, that was a big brainfart ðŸ¤¦ðŸ¼ ! Note: since the library seems to hold the return value, maybe you should use the result instead.\\r\\n\\r\\n\",\n",
       " 'refresh_api_data also updates traffic rules, no need to call this Why is this needed? Turns out it\\'s not. My mistake. During my testing I had trouble getting updates to appear. I added this and something else and it worked; I didn\\'t see which change fixed it. There are no old unique ids for traffic rules,  this can be removed Default value, can be removed Default values, can be removed Default value, can be removed Default value, can be removed \\r\\nAlphabetical order :) I guess since using the data update coordinator it could be used here to force an update and reset the timer to keep it aligned from \"last\" call, I guess this would warrant one update coordinator per api long term How will the update coordinator behave with an update from a different cadence? Will it reset its timer for polling the data next time? Should be removed\\r\\n Still here Is this relevant? Without `update_callback` the update coordinator won\\'t start the schedule for refreshing data. We can skip the append json addition if we just validate the path\\r\\n\\r\\n\\r\\n If its only one iteration of the test you can hardcode the entity id inside the test Stale code \\r\\nPlace it between `fixture_system_information_data` and `fixture_wlan_data` I don\\'t understand this one, there are no web sockets related to traffic rules, is this just stale code doing nothing? Just a copy/paste. My first time in this codebase (and I\\'m not a python dev IRL) > Just a copy/paste. My first time in this codebase (and I\\'m not a python dev IRL)\\r\\n\\r\\n\\r\\n![](\\r\\n \\r\\nThis is default, can be removed \\r\\ndescription is already a string \\r\\nCopy paste thing, should be named traffic_rule or something As there is a name property in the test data for traffic rules, why did you go for description over name?',\n",
       " 'To avoid unused variable, I suggest that you move it to the decorator (and the same can be applied in test_init)\\r\\n This change should not be needed for config_flow tests.\\r\\nIt seems that you are missing a path on `async_setup_entry`\\r\\n\\r\\nLook for `mock_setup_entry` in the code for a sample fixture (usually it is auto-use in the config-flow tests)\\r\\n You mean that i added recorder_mock? The statistics import is triggered in async_added_to_hass and does an initial statistics import, that\\'s why the test fails if the recorder isn\\'t initialized first. Tests for config-flow should be patched to avoid calling `async_added_to_hass` altogether.\\r\\n\\r\\nLook for `mock_setup_entry` in the code for a sample fixture (usually it is auto-use in the config-flow tests) Oh, i understand now. async_added_to_hass is in fact patched out but i found out the reason the test fails is because the recorder is defined as dependency in the manifest.  If I change it to after_dependencies the test runs without the recorder fixture but not quite sure if that makes any difference for the functionality of the integration. I don\\'t see where `async_setup_entry` is patched out.\\r\\nCan you point it out? it\\'s in the conftest.py \\r\\n- #L29-L34 The fixture is declared - but it\\'s never activated.\\r\\nYour are missing `pytestmark = pytest.mark.usefixtures(\"mock_setup_entry\")` or equivalent in `test_config_flow.py` Sorry - cancel everything I said - I was looking in the wrong place!\\r\\n why don\\'t we overwrite the type in the coordinator? Indeed a very good question ðŸ˜¬ \\r\\nAlso improved typing for device_entry while i was at it.',\n",
       " 'Why do we need to have two different tuples if the check for adding them is the same?\\r\\nUsing only one tuple will reduce duplicated code Because the entity class is diffrent:\\r\\none tuple contains all entities that receive pushes and subscribe to those\\r\\nthe new tuple contains poll only entities with a diffrent entity class (excluding the subscribe, unsubscribe and callback methods). In my opinion, we should change the name as it\\'s not clear what an entity named \"Sleeping\" with the state \"Active\" means. It could mean that the camera is currently sleeping, but from the options below it probably should mean the opposite True, do you have a good suggestion for the entity name/states? Maybe \"Sleep status\" as name and \"awake\" and \"sleeping\" as the two states?',\n",
       " 'Moved to  Moved to  Moved to  This is most likely a bug. I\\'ll open a PR to take this on out. Seems it is a side effect with the new code, it does not seem to happen when using in a manual cleanup with 2 single discovery topics (test added) It seems to be race with device based discovery. The condition will avoid removing a device that already has been cleaned up. We add `device` here to ensure we subscribe for discovery updates. The integration that provides the entities and migrates them, is also resposible for cleaning up. Considering the suggested protocol for upgrading existing devices to the new discovery message format, I would expect SUPPORTED_COMPONENTS to be converted to a tuple, with `device` either first or last, and a test to ensure the order. Converted the set into a dict now. As we also use it to check if the topic is supported, a dict or set is the fasted way to do that. The wildcard discovery topics for `device` based configs are subscribed first now. A nit, but\\r\\n Why is this log added? Removed it, I think it was there to help debugging If we\\'re anyway messing with this:\\r\\n Please explain in more detail in the docstring what this does Added more detail Please explain in more detail in the docstring how this works\\r\\n\\r\\nThe idea is to generate component config from the device config, right? Then explain that. done Please explain this too Maybe this should be \"regenerate\"? Also, please improve the comment to explain when the cleanup config is generated. changed, also added more detail in the comments Why is this check added? If a device based discovery is triggered to be removed and all components removed, lets say 2 components, then this check will be done twice, as we do not await anything and the actual cleanup is processed later.\\r\\nFrom the tests it seemed this would cause issues. With single components the updates have more time to process, and this race does not occur. This was moved because the fixture was needed for some added discovery tests with device-based discovery This key is no longer added, see:\\r\\n#diff-189ecd07b98c2a9602a647f97dfe63e919c95af2d3856701044958b230591ef1L274 The `platform` is is no longer added to the discovery message, see:\\r\\n#diff-189ecd07b98c2a9602a647f97dfe63e919c95af2d3856701044958b230591ef1L274 Should we pluralise the abbreviation in case there\\'s a need for a \"component\" key in the future?\\r\\n How come no abbreviation for the mandatory key `platform` is added?\\r\\n\\r\\nI think we should add one, `\"p\": \"platform\",` Is this change really correct? How can we know `payload` is a dict of strings or a string, this function is called before any validation, right?',\n",
       " \"better to use `entry.runtime_data` nowadays ok, sure \\r\\nis default done if you call super().init first, the `self.config_entry` will already be filled, so you don't need to pass it if not required otherwise, I always prefer instance attributes remove empty keys I don't know your next platforms, but since this gets a coordinator: Maybe inherit from the `coordinatorentity` here? Will end up with two different Coordinators (one for local device data, and another for internet based data such as available firmware updates), but can probablty inherit here and handle update sensors differently when they come. logger is defined and imported already use that idem idem idem pass in `x.sensors` to the `value_fn` is there a reason why the first two `key` and `translation_keys` are different? Might lead to confusion are you planning for non diagnostic sensors in the future? otherwise could move this to the description definitions 1. I think all sensors will be diagnsotics will move move this to base class base class I would move the whole uptime stuff to a separate sensor class that is independent from the standard sensors, would make the code clearer to read imo \\r\\nuse sentence case (also for rest) compare those with `is` no `.get` necessary on those always finish the tests to terminal states, to show we can recover (create entry/abort) by fixing the error and continuing I believe we'll need a fixture here to avoid all those individual patches access directly `[]` I don't really like snapshots in config_flow tests. Imo it's better to test the data directly probably better in a fixutre as well\",\n",
       " 'I wonder if you should lowercase instead, to make it future translatable? Actually, we should make this translatable from the get-go. This topic has been discussed previously for this integration. Entity names, enum sensors and option values are created from the metadata in the API. However there are huge numbers (number of supported heat pump models * (20 to 600 entities) of possible entity names in the API, they are normally easy to understand for a user that is interested in using them. E.g. \"Discharge (EB101-BT14)\". There is no official documentation of the data points (=entities) in the API and you need access to each and every appliance model in your account to harvest all possible values. \\nThus, the decision up to now has been just stay with the english terms and not enable translations. I would rather continue this way in this PR, which by the way probably is that last platform needed to get a complete user experience. If we should enable translations fully in this integration it should be done in a separate PR or series of PR:s. > Thus, the decision up to now has been just stay with the english terms and not enable translations. \\r\\n\\r\\nLet\\'s document that in code using comments, so we don\\'t have to discuss this in reviews in the future again ðŸ˜‰  Since this comment will be applicable to all platform modules I think it is better to make it in a separate PR. Use the already calculated options dict to reverse the doct. Like this? You always intify in the options code. Seems you should always do that here too. option_map and option_rev are set up when instantiating the class. That should be enough IMO. Or am I misunderstanding something? I dont see why you do the isinstance check is my point. Aha, I misread \"intify\" above and did not see your point. Type-checking complains if I always make int(value_t). value_t can have a number of different types depending on context. Here it can be int, float or None. I don\\'t know if there is a better way to override the type checking. @elupus OK, this way int() is used without any complaints from mypy. Let\\'s combine this one with the one above. \\r\\n\\r\\nThere is no need to separate these (another test will basically reset/set up everything again, which is mostly a waste of CPU cycles at this point ðŸ˜„)\\r\\n\\r\\nAlternatively, you could snapshot the state instead of asserting it. Parameterize with a single value? Why parameterize in that case? Same as the above, also, this test and the above test could be combined?',\n",
       " 'We have this helper:\\r\\n#L1737',\n",
       " \"Something isn't properly mocked These values aren't in the diagnostics test right? based myself on existing tests and assumed to much ðŸ˜“ \\r\\n\\r\\n<removed>  The coordinator data is already present in `coordinator.data` right? It is, but after the failed mock (previous review comment) I realised this is a better solution - it will force a refresh which is actually more useful during debug Sure but then you are not creating a diagnostic from the current state. If something goes wrong at a given moment and you want to capture that, snapshotting would refresh the lib and you would get new data that maybe doesn't have the same issue. The important aspect is to capture the differences between the `raw_data` and the `TrydanData` \\r\\n\\r\\nThe coordinator also updates quite often, it will be very difficult to time a diagnostic download with an ephemeral error.\\r\\n\\r\\nBut if necessary I can change back But with what is raw_data filled then? raw_data is literally the JSON coming out of the EVSE (the physical device) without *any* processing my the underlying library (pytrydan)\\r\\n\\r\\nThe objective is to detect whenever the manufacturer changes the JSON and be able to easily provide an update to the integration I agree with @joostlek : we prefer current coordinator data than a fresh one.\\n\\nPlus, if API changes you will still see it ðŸ˜Œ reverted Not used ? Can we bump the library in a separate PR? In a separate PR, migrate the integration to store the coordinator in `entry.runtime_data` instead The pytrydan library guards against the raw data not necessarily being valid JSON, I think we should do that here too? Or maybe just dump the content without trying to decode it? indeed it guards the `data` but not the `raw_data`\\r\\n\\r\\nwill change Is the title composed of the host name? If so, should we redact it too?\",\n",
       " \"Please move the function body of `async_send_command` to this function and call this function from `async_send_command` so both function behaves completely the same Can we return also for the legacy bots the response? The original sucks library does not provide the command response. I don't know if we can change the library behaviour and I don't have a Legacy bot to test it. Move this fixture to the test file This test does not test if the parameters are passed correctly to the command. I would suggest that the fixture is returning the command name and it's params as response, so we can make sure that the params handling is correct As params can be inserted as yaml we should convert the example to yaml Why did you include `custom` and not only `send_command`? The vacuum integration already has a vacuum.send_command. I don't want to confuse user with two services with the same name: a specific ecovacs.send_command and the original one. \\r\\n\\r\\nCommand response parsing should not be done in HA but in the library.\\r\\nHowever, as your use case is very rare and returning also the parsed response, requires a big refactoring in the library. I would suggest that we return the raw response for now.\\r\\n\\r\\nWe can always add later a parsed service, if the use case is bigger. For that reason I added `raw` Is there a specific reason for the double underscore in const? Nope only a typo :) \\r\\n\\r\\nSorry for the typo. \\r\\n\\r\\nAs Ecovacs has not only vacuum bots but also mowers and co, we should use device instead of bot Can be removed\",\n",
       " 'Would be good to have multiple connections and than verify it can be replaced with no connections or a single connection Can we add a message. \\r\\n',\n",
       " 'Preliminary PR => can this be moved to `attr_name`? New PR as suggested\\r\\n*  Preliminary PR => can this be moved to `attr_native_value`? Preliminary PR => can name and token be typed? Why are you generating a new token if it is not provided?\\r\\nThe yaml currently requires the token. \\r\\nWe should not add new functionality in this PR. It can be added in a follow up PR to keep this PR as small as possible The documentation already describes the manual steps how to do this ( so i thought the config flow can do this for the user. It is just 2 lines of code but i can add this functionality in a separate PR if necessary Removed that for now and will submit it in a follow-up PR Why do we generate a QR and ask the user to add it to the authenticator app?\\r\\nNormally the website where you are activating asks to insert a generated code to verify the setup It is to verify the OTP generation is working as expected. If the user somehow typed in the wrong code they would not know because OTP would still generate codes, any string is a valid token to generate OTPs, so this is the only way to validate that the token is correct.  removed OTP verification Seems i was wrong about this, it seems to be possible to insert an invalid code that raises en error. Added some basic validation but leaving out the verification with an OTP code Unused Please verify also that the repair issue was created added the test to `test_sensor.py` as the issue is created in `sensor.py` \\r\\n\\r\\nAlready tested in `test_init` Can we automatically get the name from the token?\\r\\nIf you scan the QR code in the authenticator app, it will automatically suggest the title The Token itself does not have a Name encoded, only the QR Code has. As you can see in this codesnippet from the first commit were I had the QR code generation, the QR code contains a provisioning_uri, which is constructed from the token, a username and an issuer name. When configuring the OTP sensor from the Token, there is no additional metadata that can be extracted from it. But it could be a really cool feature, if the Config flow would access the camera to scan such a QR code and setup the sensor from it ðŸ˜Ž\\r\\n\\r\\n',\n",
       " \"Either cover it, or don't... don't hide it :)\\r\\n\\r\\n\",\n",
       " \"I would imagine two of the same for loops are easily mergable right? I'm not sure what you mean, this creates a generator chain where each element is an awaitable that can be run simultaneously. Sure it could be a for loop with await but that would be slower.\\n\\nEventually it will also have a third generator for the vehicles. What's island status?\\n\\nCan we have a list of options here? There is no documented list of possible values, so the risk of making it an enum is that I'll miss something that isn't seen often. Is there a way we can find out what these values are? Over time from user feedback probably, but not immediately. I dont have a Powerwall myself. What's the state? An integer which we do not have documentation for what the value means. Why do we have this? The device info could have version? I agree, I'll remove it. This is the default right? Or do we overwrite it somewhere? These entities use the base description. Have you considered creating a base coordinator? I have this in `withings` I did this previously in Teslemetry but it caused a bunch of typing issues and there really wasn't that much overlap. It ended up adding complexity rather than removing it. \\r\\nEssentially does the same, but I think this is just a better practice :) I am now thinking, these 2 classes don't really differ, except for the fact that one uses a different coordinator. But because these are 2 different classes, we also need to have 2 sensor entities, and they also look exactly the same. Would it make sense to merge these 2 and make the `data.id` and `coordinator` a parameter solve this? For the device, you can make use of `dr.async_get_or_create` to just create a device with the properties, and then having `self._attr_device_info = DeviceInfo(identifiers={(DOMAIN, data.id)}` would link everything together. For an example check lidarr (got merged today) or aosmith As I see it, having two classes means I am sure what type of entity it is, type checking will ensure it has the right coordinator, and the code is easier to understand because there is a clear distinction between the two similar but different data sources.\\r\\n\\r\\nIs there benefit in reducing 14 lines of code in the entity file to make all the other platform inits a touch more complex?\\r\\n\\r\\nThe only other aspect from a maintainance point of this, is if I make this change here, I probably need to make it in Teslemetry too otherwise the code patterns will be unique in subtle ways that will make it harder to maintain both (since they are functionally equivilant).\\r\\n\\r\\nI can make the change if you think its the best outcome. I have just pushed a change implementing this. \\r\\nPlease use the freezer when changin time idem Let's keep this out for now. It doesn't make sense to add an enum sensor without options, Removed This could be an `Enum` Can get an enum by key? `TessieWallConnectorStates(0)` => `TessieWallConnectorStates.BOOTING`\\r\\n\\r\\nfor the options dict in the next review comment:\\r\\n`[state.name.lower() for state in TessieWallConnectorStates]` We should provide a list with all the options and provide translations for them in strings.json\",\n",
       " '',\n",
       " '\\r\\n\\r\\nI think the new variable name makes it easier to understand what exactly it is doing. Since in Python3 False is a keyword for 0 and True for 1 I suggest to use a Boolean here to make it clear that only two values are allowed. As you can see below the sensor value is not a boolean, the value can be 2. ~~True. Let me create a new suggestion.~~\\r\\nI cannot resolve this discussion so will continue here:\\r\\n\\r\\nAdd an Enum like this:\\r\\n\\r\\n\\r\\n\\r\\ncan then be used like the following:\\r\\n\\r\\n\\r\\n\\r\\nCan be combined with a `SelectEntity` for the sensor_mode I think the new SelectEntity or SensorEntity should be introduced in a separate pull request. This is incorrect, as the data will not return an enum member defined in HA.\\r\\nYou probably wanted to return the value of the enum member like\\r\\n\\r\\n\\r\\n If `sensor` is not part of the data an error will be raised as `SensorMode(None)` will raise the `ValueError`\\r\\nAre we sure that `sensor` is always included in the data?\\r\\nIf yes, than we should change it to `data[\"sensor\"]`\\r\\nIf not we should only update the value if sensor is included As @eifinger already mentioned, can we create parameterized tests out of it to reduce duplicated code? \\r\\nTo align with the codestyle of the lines below Disagreed. I need a None check. The lines below are 0 check, so it would be false if sensor is 0. Please make sure that the correct api functions are called too \\n',\n",
       " \"\\r\\nonly have code in `try` that can fail \\r\\nis default move that before the try can we move that inside the `else` (same reasoning as before) can this throw? otherwise move out of `try` maybe IndexError or KeyError if something is wrong in the json response but didn't happen till now while the sensor tests are not a hard requirement, a suggest you add them regardless. It's easily done with `snapshot` tests, look at tedee for an example Added snapshot tests for the sensors but still need tests for the statistics import part \\r\\nor is there a specific reason I missed, why this should be indeed a class variable? \\r\\nsince `getUUIDs()` has no IO ðŸ˜ \\r\\nnot using that one atm \\r\\nI don't think there's a point in that being a dict. First refresh then assign Which reauth the one that i had to remove xD Idem Maybe this can be a separate function to make this clearer I am not sure how many times this for loop runs, but we don't want to spawn a lot of executor jobs. So we should try to put the whole for loop in the executor at once usually only 1 time, depends on how many flats you own or rent ^^ Configentryerror Enums? \\r\\nPersonal ick Please use the snapshot_platform helper does it snapshot also the device registry? Oh no, you have to make that one yourself. I usually put that one in `test_init.py` as its platform undependent ok, will move the test to there\",\n",
       " 'if you redact all of those, how would the user (with multiple  devices) know which device it is? Yes, you are right. I got confused by the naming.\\r\\nLooking onto my own Inverter, I checked that these keys are not the keys used for registration on the ZeverCloud.\\r\\nSo it is no security issue to show them, I have removed the complete redaction.\\r\\n\\r\\nJust for clarification:\\r\\n\"SerialNumber\" means the serial number of the inverter.\\r\\n\"DeviceId\" points to a \"device\", that groups up to 3 inverters. The \"device\" is registered into HA by its IP address.',\n",
       " \"Euh, isn't the supported features to tell what features the entity has at all times? E.g. if its not showing progress it doesn't mean the progress flag should be removed. You're correct about progress, but the install capability needs to be removed until an upgrade can be installed. There was a change recently that allows capabilities to change dynamically, I'll see if I can find the reference. Why should the install be removed then? It should only be removed if there is an update that can't be installed iirc As discussed, for the records, because it cant be installed why downloading, which can be common if the vehicle doesnt have WiFi were its parked. This was also discussed for Tessie as is identical. \\r\\nThis isn't correct. The flags should be removed if an update can't be installed for some reason in that case. They should not be removed just because there isn't an update available. The update can only be installed when the status is available or scheduled. The only difference between the code and what you describe is that yes, INSTALL is also removed when there is no update at all.\\r\\n\\r\\nThis implementation matches Tessie: #L43\\r\\n\\r\\nTo be clear, there is an update when the status is anything more than a empty string. Still seems a bit odd but I guess that makes sense somehow. The comment in the code was misleading, I will adjust that to be clearer that you can only install when downloading is finished. Are we missing to assert something here at the end of the test? Yes but I couldnt figure out what to asset as nothing actually changes after running the service call, I'll snapshot and see if any attributes are useful. If progress is supported it should be in the attributes. Maybe that?\",\n",
       " 'sorry - forgot to remove these, fixing now webplant? sorry that was my working title, will fix  updated \\r\\nis the newer way this can\\'t be here, but needs to be in a separate pypi package should all the external-calling functionality be in a separate pipy package? or should I wrap this into the coordinator instead? it\\'s just one http call.  everything that\\'s communicating with device/3rd party/API should be wrapped into a library outside of HA, so HA only uses the lib. ok, no worries, let me factor that out in a new pypi project \\r\\ndefault is there a reason why you don\\'t have this inline? It seems to be only used once I just kept the structure as templatised, will simplify should be in the library please use `SensorEntityDescriptions` instead, this will make your code a lot cleaner \\r\\n\\r\\nto type the `runtime_data` correctly, also replace the `ConfigEntry` with `SunsyncConfigEntry ` in `coordinator.py` \\r\\njust preference \\r\\nappear unused \\r\\nmakes it clearer for those not knowing sunsynk, because it\\'s weird initially we have a \"Plant\" please remove any empty keys think this comment is incorrect \\r\\nrequired for new integrations \\r\\n\\r\\ndon\\'t set the entity id, but the unique id \\r\\nshould be typed automatically now, when we type the class (please double check) you could extend the `SensorEntityDescription` (by building your own dataclass, look at e.g. `lamarzocco` for examples) to include a `agg_function` key, making it a bit easier to read imo move all the names to `strings.json` and set `translation_key` instead',\n",
       " 'I would also keep the \"This smart home is controlled by Home Assistant\" part by default I have it now as part of the API text: \\r\\n\\r\\n> Call the intent tools to control Home Assistant. Just pass the name to the intent. It feels a bit weird to instruct it to know it\\'s controlling a smart home if we don\\'t actually expose an API.  I mean, previously LLM used to know who it was (Home Assistant) and how to control HA (using the app).\\r\\nNow it knows how to control HA (by enabling or using tools) but does not know who it is.\\r\\n\\r\\nIt is fine with me as long as it is intentional. Do you have any plans to actually use the tool_input here?\\r\\nI would like the LLM to know myself (i.e. `hass.auth.async_get_user(tool_input.context.user_id).name`) and my location (i.e. `device_registry.async_get(hass).async_get(tool_input.device_id).area`, `device_registry.async_get(hass).async_get(tool_input.device_id).floor`).\\r\\n\\r\\nIt would be useful for both controlling and not controlling Home Assistant.\\r\\nWe can do this in a separate PR. I was expected your PRs to be updated to change this prompt :-)  Ok, I will :)',\n",
       " \"Let's remove `user_id` for now, since this is not really the id of the user speaking. We don't have a mechanism yet for identifying speakers. You are right, speech recognition will have no user_id for now.\\nBut what about writing to the assist chat in the app or calling the conversation service some other way with right context?\",\n",
       " 'If this is going into debug logging, could you please make the debug message a bit more expressive? Especially, if this will cause the \"Someone logged in...\" emails (which we all loathe).   This message is related to updating devices.\\nIf it kicks in a re-authentication (due to expired token), it will send that email, but i don\\'t think this is the place to log that...\\nI think \"Updating devices\" is quite clear for when devices are being updated ðŸ˜ƒ \\nThis is mostly to make sure that polling is not happening (ie: this message does not show up in logs) But maybe it would be nice to have that message (logging in) to match the emails, though debug logging is disabled after some time, in integrations, so it probably needed INFO level.\\nI\\'ll let one of the owners comment on that before using this PR for that Since there is duplicate coded below, this should be moved into a new function.\\r\\n\\r\\nIt also looks like there is a bug here that the callable that `track_point_in_utc_time` returns is never saved or used to cancel the fetch if the integration is unloaded before it can fire Does 1 line of code really count as duplicated code though?\\n\\nI thought about doing it but then looked slightly uglier as the new function still needs to take some parameters.\\n\\nRelated to the return value, probably better to leave it for a different MR, as I\\'m not confortable changing something I didn\\'t introduce nor detect ðŸ˜€  > Does 1 line of code really count as duplicated code though?\\r\\n\\r\\nYes\\r\\n> \\r\\n> I thought about doing it but then looked slightly uglier as the new function still needs to take some parameters.\\r\\n> \\r\\n> Related to the return value, probably better to leave it for a different MR, as I\\'m not confortable changing something I didn\\'t introduce nor detect ðŸ˜€\\r\\n\\r\\nThe bug should be fixed in a separate PR ðŸ‘ \\r\\n\\r\\n âœ… ',\n",
       " \"Right now `CONF_STORAGE_KEY` refers to a specific ics path above based on `STORAGE_PATH`.  (In other words `CONF_STORAGE_KEY` is effectively already `CONF_ICS_FILE` but limited to a specific location.)\\r\\n\\r\\nCan the config flow place the file into that destination? \\r\\n\\r\\nThis can also allow validation at upload time to verify the file parses when its moved into the final location.  This also can let us import from a URL as well and have the same behavior. That makes sense, I think I've reworked what I had to instead move the file to where `CONF_STORAGE_KEY` points. I also see how this will allow for easier implementation of importing from a URL.  i think this patch is not used/needed as setup only happens once below on the second step, so this should be omitted. I think we should just keep this in the config flow file for now rather than making a separate directory. Let's use `HomeAssistantError` here which is more standard/expected. Very nice test! Can you also exercise the case where the ICS content is invalid and fails to parse? I think this is not needed?\\r\\n This also needs to raise an config flow error and show an error message.  This string should be capitalized.\",\n",
       " \"It feels more natural if device_id is first parameter.  Should we call this `no_timer_support` ?  (and update all variables/classes/errors) why would we allow a device to have 2 timer handlers?  I don't think it can happen. Changed to a single All functions in `TimerManager` should raise if action is for an unsupported device ID.  That check shouldn't happen by the caller of these methods.  oh this is a test, never mind You don't need this wrapper anymore as this error handling now happens in every timer function?  I'm using it to reduce the amount of repeated code. Removed Prioritise device checking. If the device can't handle timers, we shouldn't consider anything else. \\r\\n I can't get `timer.device_id` if `timer` is `None` `timer.device_id` will always be ok, otherwise it couldn't have been created.  I can't get `timer.device_id` if `timer` is `None` I can't get `timer.device_id` if `timer` is `None` This is an internal function and doesn't need the check. We shouldn't call this method unless the device can handle it.  this is a little weird.  Removed\",\n",
       " \"We should not expand YAML configurations. Why can't you use the VLC Telnet integration instead?  This integration is only for a local Python environment, so it probably wouldn't make sense to add a config flow to it. I've been using this to test out media players, and thought I would share.\\r\\nIt seems kind of silly to leave the integration almost non-functional without a unique id. This violates our ADRs, it should migrate to a config flow instead.\",\n",
       " \"This is not the case for BooleanState, also we don't need to invert as we have to in Occupancy sensing. So I think you can just not provide a lambda to `measurement_to_ha`.\\r\\n\\r\\n Thanks for the code review. This matches the device type:\\r\\n\\r\\n I think you also need to add something like\\r\\n\\r\\n\\r\\n\\r\\notherwise detection will conflict with the door schema higher up, since both are matching on the same attribute (`clusters.BooleanState.Attributes.StateValue`). do you have the fixture for this fake leak sensor ? At the moment I don't have any idea how to correct this test. You need to supply a diagnostics dump of a device containing this cluster/attribute, without that, this PR is not complete If you have the diagnostics dump, I'm willing to finish the PR and add the test but at minimum we really want that dump Here is the dump:\\r\\n\\r\\n[matter-2a4bd9d95d966aefd2521cccecaf2a8f-Waterleak-b356679fe5052ff13e1f5ebe00498252.json](\\r\\n ![image](\\r\\n\",\n",
       " 'Please change these to `kw_only` and drop the mixin',\n",
       " \"Please keep this file alphabetically sorted This shouldn't be controlled by the integration.\\r\\n\\r\\n `login` seems to be unused otherwise.\\r\\n\\r\\n - Should this raise an exception instead?\\r\\n- This should ideally differentiate between an network/connection error and an authentication error (username/password doesn't match). Different exceptions can be raised for those cases. Shouldn't we just set up all platforms instead? And let the platform decide if it should add entities for a given device? Please store runtime data inside the config entry instead. For more information see: < - Since Python 3.7 dicts are ordered, the use of OrderedDict is no longer needed.\\r\\n- This schema is static, lets put the schema in a constant instead\\r\\n The code doesn't need these.\\r\\n\\r\\n Please use the `single_config_entry` manifest option instead: \\r\\n\\r\\n<\\r\\n Additionally, why is there only a single instance allowed? I think the hashing of passwords should be a functionality that the library should do. Is it? Couldn't it be a connection error? Integrations should only provide translation strings (`strings.json` file).\\r\\nPlease remove this file. Integrations should only provide translation strings (`strings.json` file).\\r\\nPlease remove this file. Wouldn't it be more beneficial to have information like this in the Python package? So everyone using that package has this information available? This file should be renamed to `entity.py` Ideally, you should just pass down the device & config_entry. Name is set to None? But in the base entity (`DreoEntity`) the property is implemented. What is the right one? These should raise an `HomeAssistantError` instead. Versions are not used by built-in integrations.\\r\\n\\r\\n Who is kane?\",\n",
       " 'Please revert this change and fix it in a follow-up as it has nothing to do with this PR',\n",
       " 'Could this use `entry.runtime_data` instead? ',\n",
       " \"There's a helper for this, can't remember the name, but I think someone already applied it at Withings Funnily enough, I copied that code from [Withings](#L71-L75) ðŸ˜†  LOL #117727 Please bump in a preliminary PR Is that advisable and safe? The new version adds the new exception that this PR handles I mean it would cause a problem now anyway when the authentication isn't right, sooooo #117730 Isn't this already in there? I don't think so? I mean, by default.\\r\\n\\r\\nNow that I say this I check withings and we also have it there. Lovely. I am missing the new abort strings Please use the FlowResultType enum and replace `==` with `is` I _think_ I made this a fixture in conftest.py, so you can just add that to the parameters of the test I can't see an async_update_entry mock in tests.conftest or tests.components.conftest - it might've been something else? Maybe that's a nice one to add as well, makes it cleaner :) oh wait, I looked wrong We shouldn't patch this at all, I thought this was async_setup_entry What does this do? Wraps the async_step_reauth so that I can check it's been called without intefering with the function and causing it to raise an exception I mean, why do we need to check if its called? we can test the result of everything This was to keep the scope of the test small and specific - it doesn't really care if the reauth succeeds, only that the AuthorisationExpiredError triggers it you can then just check if there is a new flow created and that the config entry state is set to SETUP_ERROR Sorry, how do I check that without a patch or mock?  You can setup the integration, and when the client is mocked to raise an auth error, you can check the state of the config entry It looks like the state never actually gets changed. It's not changed by the [DataUpdateCoordinator](#L363C1-L378C64), [`start_reauth`](#L992-L1008) or [`init_reauth`](#L1010-L1049). Am I missing something? I think you can find this test in some test_init.py instead of the test_config_flow.py, This was at withings because the user_id an int in withings, just FYI yea so we should not patch this, we can just check if the token in `polling_config_entry` is still the old one\",\n",
       " 'Please add a docstring explaining what this function does added Why the `len(t.keys()) == 1` check? I wasn\\'t sure if there was hypothetically some other real trigger that could someday contain the \"triggers\" field in its object. This ensures this special behavior is for objects which have _only_ the triggers key. \\r\\n\\r\\nBad idea?\\r\\n\\r\\n Not a bad idea, I think your solution is good ðŸ‘  I gave you the wrong filename in a previous comment; I meant for this test to be added to the existing file `tests/helpers/test_config_validation.py` resolved Please add a case which shows we don\\'t flatten if `triggers` is not the only key ~Wouldn\\'t that be a validation failure, as there\\'s no current valid trigger we can write that would have that form?~\\r\\n\\r\\nNevermind guess that isn\\'t checked by TRIGGER_SCHEMA\\r\\n\\r\\nadded It\\'s enough with `len(t) == 1`. Fixed by ',\n",
       " \"i'm not sure if a json string should be used for a user visible sensor state in the UI ðŸ¤”  I can replace the JSON with a comma separated pair of values (like x,y). A sensor state should be one value, which can directly be used and shown in the UI.\\nIn your case the state is combined with multiple values, which is not allowed What do you suggest for this specific case? A sensor with datetime as value (last update) and coordinates as attribuites can be a possible solution? This exactly describes an event entity ðŸ˜‰  we want to avoid any extra attributes as far as possible, especial when they should just represent the entity state We shouldn't add any custom commands to the `send_command` service.\\nYou can use `update_entity` service on the sensor entity instead\\n Please revert as described above This entity should be disabled by default as most users don't need it.\\nThis entity can spam your instance as the pos event is send a lot during cleaning\\n Can you please move the const to the event file as they are used only there Please add translations for the types too and create a const in HA for the supported types similar to lifespan Icon missing Revert changes in this file The positions in `PositionsEvent` are on purpose a list as someone could have multiple charges, which this entity currently does not support.\\r\\n\\r\\nPlease don't make any changes to this PR until I have discussed it internally and come back to you. So we don't waste your time ;)\",\n",
       " 'In my opinion the following is more readable and more strict.\\r\\n Agree',\n",
       " 'This is already part of the constructor of the `DataUpdateCoordinator`\\r\\n\\r\\n',\n",
       " 'Typo in value Fixed',\n",
       " 'Should we make `\"none\"` a constant in the LLM helper? Since it\\'s not a value we ever pass to the LLM API, I am not sure? We wouldn\\'t want to just have a stub API returning no tools, as that is a waste of compute.  As noted in another comment, the request will fail if `tool_spec[\"parameters\"][\"properties\"]` does not exist. Solved in voluptuous-openapi==0.0.4',\n",
       " \"I changed this because when I had configured a bad model, the config entry refused to startup Why is that bad? Isn't it better to fail as soon as possible? The config entry wouldn't set up and the user couldn't change the model anymore ðŸ™ˆ (happened to me) Could also put `tools=tools or None` below in the constructor call. My suggestion would be to put a limit on # of attempts here, but its uglier. Pull the tool creation out of the `try` given i think it won't throw `tool_input.tool_name` Do the tools need to be constructed on every interaction with the conversation entity? How about constructing them in init once and maybe even share them among the multiple conversation entities? It's up to the LLM API objects to decide if they want to cache them. Here we just fetch them.  const to improve readability? Update PR description to mention this new functionality. I'd remove the free in US. It's free and rated limited only if the linked cloud project doesn't have billing. It's currently the same for 1.5 but that will switch to paid starting May 30. Thanks for including this. We need to figure out how to exclude the vision models too. Those won't work with text only. Not sure if the API is translating the display name. Seems safer to check `api_model.name` instead. Please break long strings around max 88 characters per line. Addressed feedback in  Make a parameter for the data to update the options instead. Empty dict or `{CONF_LLM_HASS_API: llm.LLM_API_ASSIST}`.\",\n",
       " 'Favorites should be exposed as media sources and not as sources. Media sources are fetched on demand, so the sync service should be removed. Thanks @balloob .  That\\'ll take changes to the python library as the browse methods don\\'t support favorites at the moment and these libs don\\'t seem to have been touched in quite a few years.  @rajlaud, are you open to a PR on the python library if I can figure out the changes to add favorites as a category?  PS, I quite liked the favourites being on the main UI of the cards as I\\'d seen on a couple of other (custom) components, but understand they should really be in the media browse. Hi @petes-uk, yes, PRs are welcome to the python library. OK @rajlaud I\\'ll take a look.  Favorites work pretty differently to other categories I think, so from a quick glance there\\'s going to be quite a bit of \"if category==\"favorites\" .... else .....  Anyhow, I\\'ll take a look. You can \"fake\" a favorites folder in the media browsing inside Home Assistant and just list the same content as you do here. That\\'s also how we do it for some other integrations ðŸ‘  Ah c\\'mon @balloob , you can\\'t tease us like that.  Any pointers at which others might do it this way - seems much more sensible than burying a whole separate path in the browse. Sonos adds [an entry for favorites](#L299) in their root payload. And then when a user browses it, it will list data from [a specific endpoint](#L157) @peteS-UK hows this going? Hi @pssc I haven\\'t had a chance to look at this lately - my laptop died and my old laptop isn\\'t upto running a dev container so I\\'ve been without a dev environment.  I\\'ll try and revisit it (although I still use the sources option at present as they\\'re then on the main UI of the media player component, but I do understand the desire for consistency as well).  Hi @pssc OK - I\\'ve made the changes to add a basic favorites category to the media browser  rather than using source - it doesn\\'t support folders as yet, but I don\\'t think they\\'re that widely used in LMS world - I\\'ll look at that for a v2 - messy bit is there isn\\'t a call to say \"what favs are in this folder\".\\r\\n\\r\\nThe only issue I have atm is that the media browser doesn\\'t display the favorites in grid view, but works fine in list view - which makes no sense to me.  I\\'ve posted a question in discord for now.  Once I have an answer, I\\'ll likely close this PR and raise a new one since the baseline has moved such a lot since this original PR. @peteS-UK happy to help if I can.  I too would like to see this available via HA.  was looking to add Favs to the underlying browse code in the supporting library, think I got as far as the unit tests. @pssc Attached are the 2 files - very minor change to media_player - just on the playing - then modifications to build_item_response and library_payload in browse_media.\\r\\n[new.zip](\\r\\nReally odd that it actually works fine in list view and I\\'ve got no idea where the media browser window code lives so don\\'t know where to look.\\r\\n Once I can figure out the problem, I\\'ll submit a new PR, or you could make the changes in the lib as well @pssc If you get a chance to try these changes out, I\\'d be very interested to know if you see the same issue with Grid but not List view - if so, I might submit an issue around it as it doesn\\'t really make sense that the same code would work for one view but not another. Ok.  I found the problem.  media_class has to be one of the predefined values.  No idea why list view works but grid doesn\\'t but hey ho.  \\n\\nI\\'ll tidy it up later and post a new PR. @peteS-UK sure I can pull it down and give it a test @pssc  - take a look at \\r\\n',\n",
       " \"The name of the method suggests the expiry date can be edited, however the method allows disabling expiry This means we bump the expiry time every time this method is called, is that intentional or should it only happen if expire_at is None?  Same comment as above, the name of the WS command is not aligned with the functionality I'd suggest to make the parameter positive: `enable_expiry` instead\",\n",
       " '\\r\\nIf user_input would ever be None, the code would fail \\r\\n\\r\\nValidation is done in user step Took this over with as less changes as possible. But your simplification is much appreciated! I noticed that with the above change, the result of the test against double entries has changed: Before, in `async_step_import` the setup was aborted if the entry already exists (`return self.async_abort(reason=\"already_configured\")`), now with the test only being performed in `async_step_user`, the user is shown the form to change the host name. I therefore added the host validation again with  Can you please create a private function to avoid duplicate code? done Why did you change the key?\\r\\n\\r\\nAs the key is used for the unique id, you can only change it if you provide also a unique_id migration for the old entities Is it ok to add the migration in `async_migrate_entry` (below L49)? \\r\\nWhen searching for examples, I found several integrations performing the migration in `async_setup_entry`, which I deem less appropriate in the case at hand. @edenhaus : Made a suggestion. Let me know your thoughts. You should update the config entry after the migration Done. What is the reasoning behind this? The migration will be only executed if the version doesn\\'t match.\\r\\n\\r\\nIf an error occurs during the migration, the migration will never be executed again as the config entry has already been updated. Why are you needing this variable?\\r\\nThe coordinator set the variable `last_update_success` automatically. See the base class Can you also test the entity\\'s migration?',\n",
       " 'No such entity? I removed these from the PR, obviously missed icons. Could be `None` instead to bail early instead of looking for a key in the data each time? Done that and refactored the descriptions a bit to avoid mypy issues. Not in entities? Can we type this? Idem',\n",
       " 'For integrations that connect to devices or services, we no longer accept new YAML configurations or changes.\\r\\n\\r\\nThis integration needs to be refactored first to use a configuration flow and config entries first.\\r\\n\\r\\nMore information about this can be found in Architecture Decision Record:\\r\\n\\r\\n- ADR-0010: <#decision>\\r\\n\\r\\nSee our developer documentation on how to get started creating a configuration flow for this integration:\\r\\n\\r\\n<\\r\\n\\r\\nAs these changes often involve a bit of work and some significant shifts in the current code, we will close this PR for now.\\r\\n\\r\\nWe (and our community!) would really appreciate it if you could start on the refactoring of this integration in a new PR.\\r\\n\\r\\nThanks already! :+1:',\n",
       " 'I\\'m not sure if this is needed.\\r\\nIs there a benefit to showing \"Unavailable\" instead of \"Unknown\"? I think it\\'s just semantics for me. If someone wants to filter and not display entities that are unavailable, it makes sense to me to mark things as available or unavailable. Unknown almost seems like a temporary lack of data. But I don\\'t know if there\\'s a home-assistant approved way of thinking about this. #generic-properties\\r\\n`available`: Indicate if Home Assistant is able to read the state and control the underlying device. Okay, reverted that commit.',\n",
       " 'Can we use a reference? Yes',\n",
       " \"Please use proper formatting. For instance: `CONST_FAN_LEVEL_1`. Yes, it's done. My bad. Why is this order reversed and what does it do? It's because I changed the order of insertion in swing_modes.\\r\\nI can reverse it. My bad. Can we reduce the nesting here? Can an early-return principle be used here? Yes you're right. I think I can merge it in a single if.\\r\\nI don't think I can use a return because I don't want to skip the call to set_zone_overlay for that reason. Feel free to let me know when you committed these changes and I need to review them again. It's okay. Let me know if you want some other changes.\",\n",
       " 'I would not hard-code this. Snapcast could be anything, not only music. I understand where you\\'re coming from as the stream could be a broadcast, notification, etc,\\r\\n\\r\\nBut\\r\\nA. `MediaType.MUSIC` is required for `artist` and `album` metadata to be parsed.\\r\\nB. Snapcast doesn\\'t currently provide a means to specify this.\\r\\n\\r\\nOf the available MediaType, `MUSIC` and `PODCAST` might be the only relevant types.\\r\\n\\r\\n\\r\\n\\r\\nWe could attempt to deduce the type by checking the metadata. If an `album` or `artist` property is present set the type to `MUSIC` otherwise leave it empty. Good point, didn\\'t know that. For me both solutions are fine.\\r\\nMaybe it is easier then to set it to Music as you suggest. Unless anyone else feels strongly I would prefer to leave this set to Music. I would not hard-code this. Snapcast clients could also run on a TV/kodi. And for groups it does not apply, does it? ( Ok. I went with speaker because even if running on a TV Snapcast can still only play audio.\\r\\n\\r\\nSince that issue has not been addressed and no client type information is passed back to the server, what would you recommend? Leave it unset? I guess if there is no need to set it I would leave it unset. If there is a benefit of setting this to speaker we could also go that way, as it is the most common case. Understood. I\\'m in the middle of a move right now so I\\'m unable to determine if it\\'s necessary or not. you could simplify to `return self._get_metadata(\"artist\", [None])[0]` you could simplify to `return self._get_metadata(\"albumArtist\", [None])[0]` Thanks for catching this',\n",
       " 'It is usually recommended that dependency bumps are done as standalone PR.\\r\\nOnly the changes directly linked to the dependency bump (for example when a property has been renamed) should go in the dependency bump PR.\\r\\n Thanks @epenet for taking the time to review my change.\\r\\n\\r\\nYes I saw that in the instructions, but wasn\\'t sure this one made sense.  Curious to hear your feedback about this one and whether it\\'s the right way to go.\\r\\n\\r\\nMoreover, adext now exposes a new API to async/wait when it\\'s done initializing.  The AlarmDecoder extension now wait for the object to be created before initializing.  The only way I can think to slice it would be to do the API bump and add the API async/wait call in AlarmDecoder and do no other change.  In isolation, that change would seem rather odd because there\\'s currently no reason to wait for the initialization to happen given the old implementation.  It only really makes sense in light that I need now information from the initialization in order to create the entity in the extension.\\r\\n\\r\\nIf you believe that\\'s still the way to go, I\\'d be happy to make the change accordingly, but it didn\\'t quite obvious that it was the intention of the rule vs a simpler case of API bump where the API changes with no actual net effect on the code for example.\\r\\n\\r\\nPlease advise. It\\'s still good practise, you can indicate that the bump is \"just to keep to up-to-date\", or that it is \"preliminary for follow-up PRs that will make use of the functionnality\". Ok no problem at all.  Here\\'s the relevant PR that I submitted to handle the bump only:\\r\\n\\r\\n[ That is a lot of duplicate code.\\r\\nI suggest that you create a base entity in a new `entity.py` module.\\r\\n\\r\\n Ah yes.  Fair point.  Let me make that change Should be moved to the base entity\\r\\n Should be moved to the base entity\\r\\n I think you can also set `entry_type` on the device_info Not needed I think, as it comes from the base entity.\\r\\n You\\'re correct.  I verified that it still works with this change I think actually we don\\'t need to make `_client` accessible anymore, as it was only necessary for the `device_info`.\\r\\n It\\'s used for more than just the registration.  I need adext functionality across child entities.  As a reference, see alarm_control_panel which calls a couple functions on it. Indeed!\\r\\nWe should still use the local variable directly inside attr_device_info:\\r\\n Yup that seems fair & more readable. Weird ruff didn\\'t catch this one. By changing the integration type here, it is failing `hassfest` CI.\\r\\nPlease ensure that you run `python3 -m script.hassfest` to also update associated files. I ran it, but didn\\'t notice the error.  It came back with the following:\\r\\n\\r\\n> Validating manifest...Traceback (most recent call last):\\r\\n>   File \"<frozen runpy>\", line 198, in _run_module_as_main\\r\\n>   File \"<frozen runpy>\", line 88, in _run_code\\r\\n>   File \"/workspaces/HAcore/script/hassfest/__main__.py\", line 250, in <module>\\r\\n>     sys.exit(main())\\r\\n>              ^^^^^^\\r\\n>   File \"/workspaces/HAcore/script/hassfest/__main__.py\", line 172, in main\\r\\n>     plugin.validate(integrations, config)\\r\\n>   File \"/workspaces/HAcore/script/hassfest/manifest.py\", line 400, in validate\\r\\n>     subprocess.run(\\r\\n>   File \"/usr/local/lib/python3.12/subprocess.py\", line 571, in run\\r\\n>     raise CalledProcessError(retcode, process.args,\\r\\n> subprocess.CalledProcessError: Command \\'[\\'pre-commit\\', \\'run\\', \\'--hook-stage\\', \\'manual\\', \\'prettier\\', \\'--files\\', PosixPath(\\'homeassistant/components/alarmdecoder/manifest.json\\')]\\' returned non-zero exit status 1. Any insight into what is tripping it up? Ah! indeed.\\r\\nThe issues seems to be that you didn\\'t insert it in the right place.\\r\\nIt should be ordered and moved under \"documentation\"\\r\\nThen script should run correctly. You actually have to run it twice in your case:\\r\\n- once to sort the manifest (which will fix the incorrect order)\\r\\n- then a second time to update the `homeassistant/generated/integrations.json` generated file Ah yes perfect.  That\\'s it.  It was generated the second time and I see it now :)  Thanks.',\n",
       " \"Is there an English word that could be used here? (I assume 'class' would be used if it wasn't a reserved word).\\r\\n Actually, now I see klass used in several other places in the code base, so I don't think this is an issue. Although I was expecting it, I didn't see `_attr_latitude` and `_attr_longitude` defined as cached properties in the base class for a `TrackerEntity`. They are in `GeolocationEvent`, but not in a `TrackerEntity`, not sure why.\\r\\n\\r\\nEither way, does that make these just plain instance variables, in which case do they need initialising, and possibly renaming to avoid being confused with cached attributes?\\r\\n\\r\\n I've removed these attributes and put them back into the properties directly. I think if you want to check for `None`, you need to not have the default `False`\\r\\n The default for get is None, but I am looking for a literal value of None, so I do need to set the default to literally anything other than None. Ok, so if I understand correctly:\\r\\n\\r\\n\\r\\nI don't understand how the value can be missing, trigger the `get` default of False, but you want that scenario to be reported as 'available'. Have I misunderstood something? When a value is missing, its not unavailable, its unknown.\\r\\n\\r\\nself.get(self.lat_key, False) == 12.3456  # Tracker is available\\r\\nself.get(self.lat_key, False) == None # Tracker is not available\\r\\nself.get(self.lat_key, False) == False # Tracker is unknown, but avaliable, likely because the vehicle is asleep when home assistant started. Ah ok, that makes sense now. I didn't realise there was an 'unknown', 'available' state. If that's what you need, looks good to me. Are there any occasions where the return type would be `str`? I just copied the parent property, but I've removed `str` now.\",\n",
       " 'I\\'d simplify this message for all the service calls. We don\\'t need to explain the implementation details of the library in the error message.\\r\\n Done in  , I also used a decorator ( so we don\\'t have to much duplicates. I can use the decorator in another PR for the other platforms. This will always be true. Done in  \"Start for\" doesn\\'t sound good. Maybe \"Mow for\"?\\r\\nAlso, consider a common service which allows overriding the schedule for a certain duration, where the mode is set to mow or park. I changed it A maximum of 60480 minutes is a bit ridiculous, it\\'s 42 days.\\r\\nWhy not a duration selector? I didn\\'t know, there is a duration selector. Added in  Please add translations for the options of this selector, here\\'s an example of how to do it:\\r\\n#L44-L49 Instead of moving the exception text to a constant, move it to `strings.json` and inject the error via translation_placeholders:\\r\\n done in  I missed that',\n",
       " 'Would it make sense for the \"age check\" to live in the library instead?\\r\\nSeems a bit weird to parse the VIN in the coordinator. Sure, I\\'ll add this line as a prop in the library. It\\'s still here? Must have snuck back in during a rebase or something. Its removed. We\\'re already setting this in `__init__`? I need to reset it to its default value every time the coordinator runs since it can be modified. Why? The value is conditionally changed here: #diff-1b78433d89fdfa4f0ff3be14baf64fa89c3e68b30bac2bd5a8bc31a95882ae84R107\\r\\n\\r\\nBut that 15 minute time period only should occur once before the interval is reset back again. What if the user turns off polling and use an automation instead to update the entities (or possibly in the future somewhere the user can change the polling frequency directly)? If the user uses an Automation they are taking responsibility for letting their vehicle sleep.\\n\\nIf the rules change and users are allowed to change polling intervals then I\\'ll need to address that based on how it\\'s implemented.\\n\\nIf you can see a better way let me know, but I need a way to stop polling for 15 minutes under certain conditions. Could I turn off entity updates myself and schedule them back on? The context that may be missing here, is the Tesla Model S and X with older computers will stay awake constantly if Home Assistant polls the vehicle API. In December 2023 an update was rolled out to fix this for every other type of vehicle, so I only need to account for these older vehicles by pausing updates for 15min when it appears the vehicle has been idle for 15min. My point is only that if a user turns off polling and does it himself by using the `update_entity` service this disregards from whatever you\\'re setting here internally in the integration.\\r\\nTherefore my thinking is if you should handle this in another form than using the `update_interval` variable. As example maybe just look at the datetime of last refresh and then don\\'t allow another update until time + 15 minutes. I\\'m okay with, and would prefer the user is able to override this behavior using `update_entity`. Before this code was implemented (in HACS version) i was advising people to use automations to handle this themselves, and there very well may be people who want to keep doing that so they can have more control over when the sleep is attempted. TLDR I want `update_entity` to work when someone calls it regardless of this code. Should we add a new car instead of modifying the existing (so there\\'s another set of tests specifically for \"old\" cars? This VIN is an old car, this also fixes the `model` in the device entry, so its cleaner to just use this VIN everywhere IMO. Ok. But we also have a newer car so we\\'re testing both? There is added functionality for older cars, but everything else is the same. The only thing I could test with a newer VIN is that the pre2021 code block _doesnt_ run, but its just a boolean IF, so that seems to have limited value. Ok ðŸ‘ ',\n",
       " \"Update the comment to explain that we want to keep the legacy notify service around during the deprecation period, even though we now support notify config entry. Why do we make a copy? We don't modify the data. A future improvement could be to make a helper method that both the notify and sensor steps can use since most of the logic is the same in those steps. I'll open a follow up PR for this\",\n",
       " 'Im not sure if we should consider this data for this sensor So my initial thought is that I want to know how many devices is on the network now.\\nIf I understand it correctly, when removing the number will only increase when devices join the network right ? It would presumably just take a bit longer before the number decreases. I think its better to start without this tweak and we can then add it if people are unhappy with the representation Just to be clear and I fully understand it ðŸ˜…\\r\\n will the number always increase and never decrease then?   Remove it and test it out :)\\r\\n\\r\\nI would assume it would decrease (but maybe in a lower fashion) as well but if it doesnt we keep it in Removed ti So you tester it and it still works? Sorry for back and forth here, I saw that the same thing was done on the wlan client side, so lets keep it as it was considering the last seen as well.',\n",
       " \"Please add this in a separate PR battery_power sensor only ? Both, then we can merge the fix of the intergation in a hotfix and add these 2 sensors as a new feature next release already split the version bump (fix) so this PR is only about the new properties made available by the new firmware version You can use a minor version migration for this I must have backwards compatibility with firmwares that don't provide the device ID Unneeded now What are the possible values? #L23 Can we make a transformation map in the integration that translates the enum to a str (snake_case) and then we can make this an enum sensor with the options provided. This allows the states to be translatable done! Thanks for a great suggestion :) Maybe these should be fixed in the lib instead Version bumped  Unused This all can be replaced with creating a MockConfigEntry with the same unique_id and adding it to hass Done This one can now be removed Should this be called slave status? (Or maybe use a different name for slave if possible). Since a state can be no error, while the name assumes it's an error I'm following the manufacturer documentation, changing this would be inconsistent with the manufacturer documentation But reading the states, not everything is an error, reading, writing etc isn't an error  ![IMAGE 2024-05-11 22:46:42](\\r\\n\\r\\nexcept for the first state, everything is an error  the first 2 bytes indicate the slave brand/model and are not provided via HTTP only show up in the display\\r\\n![IMAGE 2024-05-11 22:48:19](\\r\\n\",\n",
       " \"\\r\\n\\r\\nWhat is the unit care? Unit Care is an care counter for the whole bot.\\r\\nThere are a few todo's in this timeslot. For Example wiping/cleaning the sensors, wheels and the whole station parts.\",\n",
       " \"You can use [config entry runtime]( data instead. Is this an oauth2 integration? Unfortunately it's not, it's authenticating through AWS cognito libraries same as the mobile app does. While cognito does also support OAuth2 I haven't managed to get this working. Can the user change their email address? It looks like that's not possible atm. There's no possibility to do that through the app. Let's have reauth in the follow up to keep this one small and simple Why is it always available? Please put the coordiantor first Why are these assigned to `self.` first? Please remove empty fields.\\r\\n\\r\\nAlso, don't forget to set the `loggers` Please use icon translations Does aioaquacell contain enough typing? Consider adding a `py.typed` file to enable mypy to read the `aioaquacell` types right? Could use device class duration This is all stored in the device, we should not add this as sensors This is already stored in HA per state, so we should not add this one either What are the possible states? It's reporting in a string type, for example currently mine is 'high'. I haven't mapped out all possible states yet, probably something like high, mid, low. I'll add icon translations for that in a next PR. Sounds like a true/false sensor, this should be a binary sensor All these can be removed We should combine the unique_id with something unique from the device. if I understand someone can add more softeners, so we should add something softener specific to the unique_id You can omit the battery translations since the device class handles this\",\n",
       " 'Is this a breaking change? Strictly you are right, added a breaking change section. Under ideal conditions a locks state is updated by the device (`pessimistic` mode).',\n",
       " 'note to self: Still need to check this\\r\\n Ideally we use `FrozenDateTimeFactory` instead of patching `utcnow` I was trying to keep PR semi-manageable.  This was changed to accommodate the change in location, not a change in functionality.  I agree that these tests needs to be updated in the future.',\n",
       " \"Why should it be a lock and not a switch entity?\\r\\nAlso the class documentation specifies it as a switch I copied the already existing KebaLock from above (see line 31) and modified it for the user auth. That's not an answer to my question.\\r\\nCan you give me a reason why this should be a lock and not a switch?\\r\\nIn my opinion this is a switch, which enables/disbales something Ok, sorry. \\r\\nThis could also be a switch..  \\r\\nIt authorizes / blocks the charging of a EV connected to the KEBA wallbox. Lock entities should only be used for real locks (like the things that block people from coming in your house), all other use cases should be a switch I can change it, but this would be a braking change for the old implementation? We should deprecate it and migrate it to a new entity then\",\n",
       " 'Please use `entry.runtime_data` instead Why are you adding `@ajohnston1219` as code owner and not yourself? I tried changing this, but every time I commit the pre-commit scripts change this back to @ajohnston1219, which is my personal GitHub account. This has something to do with the multiple SSH keys on my computer, but I am not sure how to get the pre-commit scripts to use the work username instead of the personal one. If you are aware how to fix this, let me know and I will change it. Nevermind, I think I managed to get this to work this time. Why are these sensors being removed? Not all devices support this value, and there is no model number currently included in our partner API, therefore it requires modification of our API to support knowing whether or not to include this value. you are creating a config entry here that is not matching the data format that OAuth2 config entries follow. You can see the format in your test instance by checking the file `<config>/.storage/core.config_entries`  All config flows need to be tested. OAuth2 config flow tests are automatically generated when you use the scaffold script. You can see the template here:  Okay, I was trying to fix tests from the previous integration, but those appear to be incompatible. I have used the scaffold script to create a new integration and generate the tests. The tests are now passing. This is not used. Not used How do I set the scan interval for polling? The documentation says this:\\r\\n\\r\\n> You can control the polling interval for your integration by defining a SCAN_INTERVAL constant in your platform. Careful with setting this too low. It will take up resources in Home Assistant, can overwhelm the device hosting the API or can get you blocked from cloud APIs. The minimum allowed value is 5 seconds.\\r\\n\\r\\n\\r\\nWhere should I define this constant? you need to define it inside `cover.py`  The default scan interval for covers is every 15 seconds, which is what is being used now.  Can be moved into `cover.py` and assigend directly, no need to push into const.  You can omit the data here, it doesnt add value to store it as a new dict `cast(str, self._oauth_session.token[\"access_token\"])` is better to use here as it doesn\\'t create a new string One major thing I am missing is, can we set some unique user id as unique_id for the config flow? This now creates the situation where someone can break their installation by logging in with the wrong account. We should prevent that. Can we move this to `cover.py`? session is always used to create a `AladdinConnectClient`. Let\\'s move this to `__init__.py` so we don\\'t have to create this twice. runtime_data should be used if the ConfigEntry is typed. Please type it,. We can move the door fetching to `__init__.py` to prevent it fetching the doors twice. This can be removed I am not sure what the idea is here, but currently you only add garage doors that have been added previously. This should be revistied and fixed',\n",
       " \"Why are you doing manual unit conversions if Home Assistant has support for it built in? Please adopt your code to use translatable names. More info can be found in the developers docs Hello, I don't quite understand.   Are you referring to _attr_name?   Can you explain it in detail Here, I referred to Shelly's. Adding translations for new entities is required. With translation placeholders ( it should be easy to add support for them.\\r\\n\\r\\n> Here, I referred to Shelly's.\\r\\n\\r\\nThe shelly integration where added before we had translation support therefore they have more time to migrate to translations thanks Numeric values should not converted to strings. The user can change how many digits are shown in the UI and therefore we should always return the value as number This should be moved inside of the value function `fn` of the entity description as it applies only to two specific entities\",\n",
       " \"\\n\\ndocstring sshould start at the first line. Also only add comments if they add valuable context to the code, this one only describes what is already obvious from looking at the code. Personally, I wouldn't add a comment here, but according to the checklist, the code must pass the check using the `python3 -m script.hassfest` command, which requires docstring on methods.\\r\\nIn this state the test passes without any errors. \\n\\nUse cv.port to validate port number \\r\\n\\r\\nPlease change all references to Hello World or the Awesome light example integration \\n\\n\\nImports are unsorted, by pressing Alt+Shift+O VS-Code will organize the imports for you. Done \\n\\n\\nReturn type should be ConfigFlowResult Done \\n\\nRename to something like LedScConfigFlow to prevent overloading base class.  \\n\\n \\n\\n\\nno need to rewrite as you are comparing all values in user_input \\n \\n \\n\\nCan be removed, your integration doesn't have options  No need to move the `PLATFORMS` here, just leave it in `__init__` \\n Can be removed. Setting up integrations from configuration.yaml isn't allowed anymore for new integrations. \\n\\n\\nNo need to outsource the setup to another function \\n\\n\\nAlways use the constants to access the config variables like you did in the config flow \\n \\n\\n\\nMaybe something more meaningful like LedScLightEntity that also describes that this inherits from LightEntity. Also please adjust the docstrings  I think hostname and port are not allowed as unique id for integrations. You can alternatively use config.entry_id as unique id\\n \\n\\n\\nJust assign the unique id to _attr_unique_id. Also your integration should not log too much if not necessary. They might help during development but should be removed before commiting. You can log data to debug though that might be valuable for debugging errors. OK, this log informs about loaded devices that could be useful for debugging. I will change the level of this log to `DEBUG`. Done This is not the error message that is displayed, it is a tranlation key and the corresponding message is looked up in the `strings.json` file. Please add a `strings.json` file to your integration.\\n Use the entity_description attribute instead and use strings.json for device names instead I can use `entity_description` for more detailed device information, but the entity name is dynamic based on the WebSC configuration. \\n But device is not the right category. It is really a hub. The integration is connected to a single device using Websocket, but this device controls any number of lights.\\r\\n\\r\\nThe individual devices are configured in the WebSC application. Advanced LedSC properties can be configured in this application. The integration connects to WebSC and loads the configured devices. So it is not necessary to configure the individual devices separately in the integration configuration. \",\n",
       " '\\r\\n\\r\\nTo be future-proof changed This sets the state to unlocked and not to open.\\r\\n\\r\\n changed Please add the `is_open` property too otherwise, the state will never be opened `is_open` property was added now. Please add a test where the state template return `open`. Please test also optimistic case',\n",
       " 'This is energy returned to the grid, but with the LED-impulse version you\\'re using the same key for its lone usage channel. Not sure if this is as intended. I have replaced it with the ESI_TYPE_ENERGY_COUNTER_USAGE_HIGH_TARIFF type. One, I don\\'t think it makes sense to expose this value as it\\'s a static configuration that\\'s used by HmIP to convert \"number of impulses\" (which it doesn\\'t expose) to volume. Without the raw impulse data there\\'s not much we could do with this value.\\r\\n\\r\\nTwo, it\\'s not in mÂ³/h but in mÂ³/impulse. So removing the GasVolumePerImpulse Sensor is okay? I\\'d say yes. I see no use case for it. It\\'s a user-supplied config value that tells the ESI how to interpret its raw sensor data. People set it once in the app during initial installation; that\\'s it. It certainly isn\\'t a measurement and won\\'t change on its own.\\r\\n\\r\\n--\\r\\n\\r\\nSome background on the hardware:\\r\\n\\r\\nThe sensor is a hall sensor (or reed contact, I haven\\'t broken it open to check which one they use) that gets activated by a small magnet on the last digit of the meter dial. The ESI counts those impulses internally and multiplies them with this config value to derive current and total consumption, which it then reports to the server.\\r\\n\\r\\nThe LED variant is the same, just that there it\\'s a photo-resistive diode/resistor/transistor (again, I haven\\'t cracked one open to check which one) that watches a blinking red LED on the meter.\\r\\n\\r\\nOnly the IEC sensor is a bit more involved, as the meter sends its data as a digital signal using an IR LED.\\r\\n\\r\\nIn all three cases, the actual HMIP device is identical, it\\'s just shipped with a different sensor in the box. That\\'s why you get that \"everything mixed together\" reading. Thx for the input. I removed it.',\n",
       " \"After dep to ensure its updated before loading http on core installs does this work? http is loaded as one of the first things and it won't pull in after dependencies You would have to add it to #L143 I think? So it gets promoted if the user wants to set it up.  I fixed pre-stage1 after deps in \\r\\n\\r\\n\",\n",
       " 'I think this warrants a specific check for the monitor_target as well I might need some help here @Kane610. \\r\\n\\r\\nSo I know the `uptime_stats` is not None and it\\'s a `dict`. But how do I tell mypy that?  I think I got it, but not sure if it\\'s the right way? I don\\'t think it. \\r\\nCan it be because that `TypedDevice` is missing `uptime_stats`? We should add a proper uptime stat to the library so typing is correct  @Kane610 It\\'s pretty much duplicate work here. \\r\\nWas considering making a def that return the three sensors. \\r\\nThen we could at the end do something like `) + make_latency_sensors(\"WAN\") + make_latency_sensors(\"WAN2\")` etc.  I was not possible, at least of that I tried, to get use methods that had `wan: str` as parameter.  @Kane610 I\\'m not sure I\\'m on the right path. \\r\\nWill you please guide me?  \\r\\nSomething like this Should return a tuple\\r\\n For future safety, it would be good to make sure the key is present.\\r\\n\\r\\nYou could do:\\r\\n\\r\\n If you update the previous function to return None if there are no latency values, you can instead disregard this function and replace it with something like `async_client_wan_monitor_latency(...) is not None` Do you mean removing it or? \\r\\nSignatures are slightly different?  Either removing it and using a lambda or something to go from hub to device or updating it to use the hub to get the device and then call the latency function. Exactly combine those functions into one that take which stat to look at and you will remove a lot of duplication I see, it\\'s applied now. Thanks!  Last thing is probably to combine these into one method that takes the source as input You can make this an internal function within make_wan_latency_sensors You could probably change this to return the full dict of entity descriptions and not need to input WAN/WAN2 I have a little hard time do figure this out. \\r\\n\\r\\n\\r\\nWill not work, as `make_wan_latency_entity_description`\\'s wan is a `Literal[\"WAN\", \"WAN2\"]`\\r\\nSo mypy will complain saying `Argument 1 to \"make_wan_latency_entity_description\" has incompatible type \"str\"; expected \"Literal[\\'WAN\\', \\'WAN2\\']\"  [arg-type]`\\r\\n\\r\\nSo is there a way to either loop over `Literal[\"WAN\", \"WAN2\"]` or fix it somehow else?  Pushed the code to see :)  \\r\\nNo need to use factory as you don\\'t want to prepare any state prior to starting the integration and you don\\'t need the config_entry so lets make it a fixture with config_entry_setup We could deduplicate quite a lot in this test if you input entity_id, state, and the updated state in pytest parametrize, similar to the test_client_uptime I think I achieved it This won\\'t work, you should do something like, as the supported function is expected to only get `Callable[[UnifiHub, str], bool]`\\r\\n\\r\\nThis is probably the reason the coverage fails on async_client_wan_monitor_supported_fn Not sure `partial(async_client_wan_monitor_latency, wan, monitor_target)` will work, as the signature of `value_fn` and `supported_fn` are different. \\r\\n\\r\\nI at least get this locally `Argument \"supported_fn\" to \"UnifiSensorEntityDescription\" has incompatible type \"partial[int | None]\"; expected \"Callable[[UnifiHub, str], bool]\"  [arg-type]`\\r\\n\\r\\nI think it\\'s better to add the supported function again. This is currently not in use Something like this should fix it\\r\\n\\r\\n\\r\\n\\r\\nor\\r\\n\\r\\n\\r\\n',\n",
       " \"Since this is common to both `if` and `else`, could it not be before the if/else? Good point. We'll throw 404 for non-existing images with invalid sizes that way, which is probably better than throwing 400. We should keep this line as it checks that the file is saved correctly.\\r\\n\\r\\nYou could create a variable for `TEST_IMAGE.read_bytes()` so you read it only once\\r\\n I found it redundant since when we return the original image, we check its contents already. Are you sure we want to check it twice, once on the file system and then via the API? Yes I would keep and check it twice I re-added it ðŸ‘ \\r\\n\",\n",
       " \"Please unpack multi-line ternaries into if blocks   Done As above  Done As above  Done Maybe this should be a utility function that returns the unique id ? For the light platform specifically or for all platforms? I'd say for all platforms, so we can have it all concentrated in a single place that we can test thoroughly? So something like a util function like `get_unique_id(entity, feature=None, ..)` that will contain all the logic to make it easily testable, instead of letting individual platforms to perform their own choices. Now resolved by latest  We should read the range from the lib. It's not currently exposed by the library. If I add it to the interface is it sufficient to have a simple range like this or better something more generic with `min`, `max` and `step` We have the information there in the feature. Perhaps we should just read it from there, given the feature is always there with the same identifier?\",\n",
       " '- The schema can be inlined, no need to create a constant in this case. \\r\\n- Any reason this is limited/coerced to strings? 1. I created a constant because it\\'s used twice, once in `TIME_RANGE_SCHEMA` and again in `STORAGE_TIME_RANGE_SCHEMA`. Should I inline it even though it will be repeated?\\r\\n2. I coerced everything to strings because I wasn\\'t sure how to represent \"any scalar\". Using `typing.Any` would theoretically allow nested dicts and lists (assuming the attribute code can handle that) but voluptuous didn\\'t want to validate anything when I used it. Would `vol.Or(bool, str, int, float)` be more appropriate? 1. if it was a huge schema used many times, I would agree; this is overkill imho.\\r\\n2. your suggestion seems acceptable I replaced the string coercion, so now it\\'s\\r\\n\\r\\n\\r\\nExpanding this would give:\\r\\n\\r\\n\\r\\nThis feels redundant and more fragile to maintain, as it\\'s not clear that these have elements that need to match each other. If you\\'d still prefer this I can change it, but I think it\\'s worth avoiding the repetition. I agree it\\'s better to avoid repeating ðŸ‘  This one is a little confusing IMHO, sometimes it is added to the attributes, or otherwise it is stored in a `data` key.\\r\\n\\r\\nIMHO, this is magic we should avoid. Let\\'s either always store it in a data key (or not).\\r\\n\\r\\nHonestly, I think we should always use the data key, mostly because it would allow us to exclude it from the recorder (which is an change that should be added to this PR as well). I like the idea of excluding a single key from the recorder history, but my goal with the \"flattening\" of data attributes into the entity\\'s state attributes was to make it easier to build automations. How do you select, for example, `data.brightness` in an automation trigger?\\r\\n\\r\\n![entity attributes](\\r\\n\\r\\n![automation trigger]( Accessing those is harder indeed. Alternatively, we do flatten them, but exclude all attributes from being recorded in that case. I just pushed a new commit that adds any custom attributes present to `_unrecorded_attributes`. Is that the preferred way to do this? That approach should not work, you\\'ll need to also set the `Entity` class\\' private attribute `__combined_unrecorded_attributes`:\\r\\n\\r\\n\\r\\nI wonder if there\\'s something wrong with the test you updated, because I don\\'t think the approach in the PR is valid. The test update is not correct, the state set by the test is just this, i.e. no `data` or `party_level` state attributes:\\r\\n\\r\\n\\r\\nThe test should assert the state has `CONF_DATA` and `\"party_level\"` state attributes, and then check those state attributes are not recorded. I think this approach is valid (or at least, it also appears at #L49).\\r\\n\\r\\nI just pushed a new commit that updates the Entity class\\'s unrecorded attributes like you suggested and adds assertions that the attributes are present on the entity to the test (in addition to the existing assertions that it is not present in the recorded states).\\r\\n\\r\\nUpdate: the test failed because it doesn\\'t appear to override the current time, so the data attributes may or may not be there depending on which schedule block is active (if any) when the test runs. I will figure out time travel and push a fix soon! I\\'ve tried a few different ways of mocking the current time that I found in other tests and none of them seem to work.\\r\\n\\r\\nI\\'ve tried this:\\r\\n\\r\\n\\r\\nAnd this:\\r\\n\\r\\n\\r\\n(both with and without `tzinfo=dt_util.UTC`)\\r\\n\\r\\nBut following either of those methods with this:\\r\\n\\r\\n\\r\\n\\r\\n...results in this output, which says Party mode @ the wrong time:\\r\\n\\r\\n\\r\\n\\r\\nIs there any documentation on mocking times like this? I couldn\\'t find any, and there seems to be no consensus among the other time-based tests that I can make sense of. Thank you for any help you can offer :) Passing a datetime object to `async_fire_time_changed` is the old way to implement time travelling in tests, it is very hard to get right because `async_fire_time_changed` only patches a few select time related functions.\\r\\n\\r\\nUsing freezegun is much preferred because it is much less likely to work since freezegun searches all modules for imported time functions and patched them.\\r\\n\\r\\nWhen you use freezegun, you need to distinguish between the time zone on the machine running pytest and the timezone configured in the fake Home Assistant instance configured when running tests. The former is not predictable, the latter is `-07:00` unless the test is configured otherwise.\\r\\n\\r\\nIf you don\\'t tell freezegun what timezone to use, it will assume the time zone used by the machine running pytest, which is not what you want.\\r\\n\\r\\nThe next problem is that the `schedule` enity sets up a listener for a future time, which won\\'t fire if you travel backwards in time.\\r\\n\\r\\nAll in all, something like this should work:\\r\\n\\r\\n\\r\\n\\r\\n Ahh, that explains it! I tried specifying UTC because I thought the UTC-7 was coming from my computer\\'s time zone, so I didn\\'t realize that was _supposed_ to be the time zone used for testing.\\r\\n\\r\\nI just pushed that change (with some tweaks to the asserts to make them more specific). Thank you again for the help! Let\\'s use `vol.Any`, that\\'s almost exclusively used throughout the codebase\\r\\n',\n",
       " 'Please use the `json_loads` helper `from homeassistant.util.json import json_loads` done You could narrow this with `json_loads_object` instead and drop the type sounds good, done added the import for cast too',\n",
       " 'Where does the max length come from? The gateway has a 16 byte RX buffer.  (#L571)\\r\\n\\r\\nSubtract the command, equal sign and terminator from this buffer and you will have room for 12 argument bytes. Should the dependency update be split into a separate PR? This PR has a dependency on pyotgw 2.2.0. How is this normally handled? As I remember it, it is customary to update the requirements first before adding new features that depend on them. See also the [development checklist](#5-make-your-pull-request-as-small-as-possible), especially item 5. Ok clear, will create a bump PR for pyotgw 2.2.0 When you do, please specify that it fixes  #113443  Done, I also reverted the requirement change within this PR. I believe `sent` is the correct spelling here. Same as above.',\n",
       " \"Honestly, that function is small, might as well inline it Would cannot connect be better? Is this a single config entry integration? No, you can configure several instances. \\n(Am in the train, excuse the formatting)\\n Oh, didn't catch this, thanks! Can be set outside of the constructor  Maybe it makes sense to create a separate function for setting the `_attr` but since you only have one attribute you're setting, why not use the native_value property directly? You're right, we can just use the `native_value` property here.  Entry doesn't have unique id Never mind Suggestion: mock out the whole ImgwPib lib and just attach stuff to the fields, checkout analytics insights for an example  This is testing setup, not only getting the form I think having a global client test fixture would optimise this because you don't need all these patches \\n(Personal ick) \\nPlease replace all enum == with is\\n Should we test this with checking the config entry state? Ah yes, this is already testing a successful setup \\n Use freezer here too  We are already testing this in `test_unload_entry`, so imo we could remove this one Can we remove the side_effect again and make this test end in a CREATE_ENTRY? this way we also test that the config flow can recover an exception Also the unique_id This one is left Ops sorry, missed that one. \\r\\nI think we can now do without\",\n",
       " 'As a double check, is this standardized? The most command definition is\\r\\n\\r\\n\\r\\n\\r\\nIntegrations sometimes use the constants from MediaType or their own strings or a mix of both.\\r\\n\\r\\nWe could populate the list with the constants? I am not sure if this is possible, but it would be a good start I think From what I can see - If we provide a list; then the user can only select from the list. There is no way to allow them to select from the list or enter their own string.  Since there is no single standardized list that all integrations support, we should leave it as a free form text field and provide examples in the docs (which I will work on next). I find that a strange example, it would fit a \"play_media\" service more Can we make a better description? Can we use constants for the keys?',\n",
       " \"I don't think we need a constant for the schema if it's only used in one place.\",\n",
       " \"I don't think the coordinator should know about platforms. It's up to each integration to implement the coordinator entity or not do that. Comes from the side-discussion [here]( in discord.\\r\\nIt just creates unnecessary overhead by registering listeners for entities which has no use of it. Integrations shouldn't use the coordinator entity if they shouldn't use it.\",\n",
       " \"I don't think this needs to be checked, it should not be possible to call the service if the `LawnMowerEntityFeature.START_MOWING` feature flag is not set.\\r\\n\\r\\nIf mypy complains, we should do this instead:\\r\\n\\r\\n\\r\\n\\r\\nSame for the other scripts What does this mean? It's copied from template vacuum obviously, is it still needed in this new platform? Should be sufficient with\\r\\n \\r\\nDon't think we should add deprecated keys Could we type this Already in from `LawnMowerEntity`\",\n",
       " \"OpenAI doesn't have this. My impression is that this is an additional omission from the Open AI PR and that this is mandatory: #has_entity_name-true-mandatory-for-new-integrations\\r\\n\\r\\nOpen AI doesn't set a device so its a no-op, but I think it should. For consistency with OpenAI move this after init? For consistency with OpenAI move this into const.py? I didn't originally also copy this because the log messages would be weird:\\r\\n\\r\\n\\r\\nI went ahead and copied it but updated to use `__package__` instead of `__name__` which I think was intended and will include in my openai cleanup PR. For consistency with OpenAI move this into const.py? You should delete from here to the end of the file. These are testing the service which isn't part of the conversation agent entity. FYI OpenAI PR didn't remove this and I did here since it seems like an omission. I was going to remove from OpenAI in a followup.\",\n",
       " \"I think this is stale. Use a more meaning full key, and do not forget to add it to `strings.json` Thanks. I've cleaned this up and included the strings.json updates. The repair platform already provides this so why have we included it here? I wasn't able to find any issue creation specific to aux_heat deprecation in the repair platform. Is there an example I should model this after? Sorry, I meant that `async_create_fix_flow()` is already included by the `repair` platform automatically so the whole `async_create_fix_flow()` is not needed. But maybe it wasn't added by yourself so let's leave it as is ðŸ‘  Stale comment? Cleaned up in switch entity refactor I think perhaps it would be good to make a base entity in a preliminary PR and then add it here to reduce duplication I've created a base switch entity and a auxHeat switch inheriting from the base. Refacotred based on newly added switch code. \\nAlso below\\n These changes are no longer needed. Have been able to revet these back to the original test assertions. Move this to `__init__.py`, there's no need to implement a repair platform since we don't implement a custom fix flow What do you think about removing the migrate_aux_heat_issue callback and just calling async_create_issue() directly in the two aux_heat locations that trigger the issue? That feels like it may be a bit cleaner with all the rest of that code going away. I've updated the PR to call async_create_issue() in the deprecated methods. Let me know if there is a reason that approach would be a problem. Remove this\\r\\n repairs.py has been removed. We don't have to depend on repairs anymore.\\r\\n\\r\\n Two comments on the name:\\r\\n\\r\\n- The name should the added to the `strings.json` file instead and set a translation key on this entity. This will the entity name translatable.\\r\\n- Entity names should be sentence style capitalized. So, in this case `Aux heat only`. Done. Thanks. The fact these services are called, is already part of the debug log.\\r\\n\\r\\nTo me, this seems a bit duplicate.\\r\\n\\r\\n The service call above is already blocking.\\r\\n\\r\\n This integration uses a standard repair with no custom flows. There is no need to test this part for that reason (that responsibility is already satisfied by the repairs integration itself).\\r\\n\\r\\n The service call is already blocking\\r\\n\\r\\n Hmm wondering why `http` a dependency right now actually?\\r\\n\\r\\nI think this can be removed.\\r\\n\\r\\n\",\n",
       " 'This isn\\'t used for anything, so you can just remove it. Fixed. There\\'s a `now()` function in `homeassistant.util.dt` that does the same thing. Maybe just use that instead? Ah. Fixed. Add an empty `ControllerWaterUseSummary` for the controller before this branch. That way there\\'s always one populated for the controller, even if there\\'s no sensor. Then you don\\'t have to call `.get()` when fetching it from the dict later. Fixed. This is unused. You can remove it. Fixed. This is getting a bit unwieldy. I think we should make a method for each sensor type that returns the native value for that sensor type. Then the conditional here can either just be a conditional with `self._attr_native_value` assignments, dynamically dispatch to the methods with something like `getattr(self, f\\'_get_{self.entity_description.key\\')` or via a manual dict mapping like `return {\"daily_active_water_use\": self._get_daily_active_water_use, ...}[self.entity_description.key]()`\\r\\n\\r\\nThat at least reduces so much nesting of this logic. Good idea. Updated. This isn\\'t reachable. `getattr()` will throw a `AttributeError` if the attribute doesn\\'t exist. Fixed. I\\'m not a fan of all the side effects being introduced by these. I\\'d rather them just return values and have `_update_attrs()` assign the value to `self._attr_native_value`. Fixed. I think this always returns a float? Let me play around with that some more. I had it like that before but I couldn\\'t get `mypy` to play along. `mypy` doesn\\'t seem to recognize `ControllerWaterUseSummary`. Maybe because it is not exported [here](#L13)? The library doesn\\'t have a py.typed file, so mypy interprets the library types as Any practically. If the typing in your lib is on par, consider adding the py.typed file and enabling strict typing here This returns `float|None` same as above `-> float|None` same as above `None` should be a valid value, which means you can reduce the method body down to:\\r\\n\\r\\n`self._attr_native_value = getattr(self, f\"_get_{self.entity_description.key}\")()` Fixed If you put this condition first, then the controller water use only needs to check for `self.sensor is not None`.\\r\\n\\r\\nOr are there sensors that are associated with zones that we\\'ll want to handle later? Fixed can we use icon translations? I am not sure how many entities you\\'re going to add, but a common pattern is to extend the entity description to provide a value_fn. This will then make sure all logic is written at the same place as the rest of the sensor definition. Would it maybe make sense to make this a base base entity, and then create a HydrawiseZoneEntity and a HydrawiseSensorEntity? This way you aren\\'t combining everything into 1 object, which gives you the freedom of changing the behaviour of these entities without the need to keep adding if statements Icon translations',\n",
       " \"This statement makes the valve appear open.  Is there a way to wait for feedback from the controller, and have the state reflect what is reported from the controller?  That way if the command succeed but the valve is still closed, it won't be falsely reported.   I would expect the API to return an error if the valve couldn't be opened, which would mean you wouldn't get to line 59.\\r\\n\\r\\nI can remove that, but it also makes the tests a bit more annoying since you then have to wait on a data refresh to check that the state was updated. (which I guess is fine since the side-effect of validating the API was called is the important part?) Done Same comment here.   Done\",\n",
       " \"Please don't change this file in this PR. If the change is needed, please make a separate PR with it. Sorry, I did it to test locally with the api by manually copying and installing the wheel package locally.\\r\\nI removed this change from this PR. What do you think about using a coordinator and use `async_set_updated_data` to pass the update to the rest. This avoids using the event bus (or the dispatcher, as that's also frequently used for this) The design of the API is not REST based but it is based on a permanent connection via Websocket (established just after login).\\r\\nI tried to explain it here in the design principle : \\r\\nThis callback function is asynchronously called from the websocket server side (for example when a cover is manually moved) and it helps keeping the state in home assistant coherent.\\r\\nWhen homeassistant starts, it will logs in and establish the websocket connection permanently. This callback is linked to received server side events whenever they arrive.\\r\\nIt was inspired by the plex integration implementation and its plex_websocket_callback.\\r\\nThe EVENT_DIO_CHACON_DEVICE_STATE_CHANGED is send to all platforms (this pr does not contain the switch one) and the event is effectively used to update the cibled entity.\\r\\nI am not expert enough but I don't find how to use a coordinator in this situation. You can use a coordinator as the data owner, where you let the websocket update the data of the coordinator, which efficiently updates the other entities  Implemented it with a coordinator : it works correctly with my local tests. Please use entry.runtime_data OK, changed it. We should unsubscribe this listener on unload OK, added it. We should leave services for a follow up pr OK, removed it I think the flow would look way smaller and less complex if you inverted this\\n\\n\\n\\n OK, changed it Unique id is unique for the domain, so no need to prefix it If I do not prefix it, the default name of the integration is quite surprising from my point of view.\\r\\nWithout this prefix, I have only my user id and itseems not really clear as meaning for me.\\r\\nHere is the result (I stroked the user_id)\\r\\n![screenshot_integration_config](\\r\\n Small function, might as well inline it  OK, inlined it. This would be something to do in `__init__.py`, but maybe the coordinator would be nice for that too, but i need more context for that This code is present in case I have two dio chacon accounts and one has not covers but only switches.\\r\\nWithout it, I had an error at startup of homeassistant because the list_devices was empty.\\r\\n\\r\\nI don't know if a coordinator can help for this. I have to search for examples and better understand the coordinator usage. But we can still move that to init and query the devices in there Indeed, with the implementation with the coordinator, this code has disappeared.\\r\\n Can we type this Done Not needed, is already logged Unneeded We should extend our ConfigEntry type to stay typesafe, check airgradient for an example  Comment doesn't add much imo I think this is also logged already  \\n\",\n",
       " \"Let's type credentials as str, Any.\\n\\nI think it's safe to assume expiration is typed as date time. As improvement point you could look into creating it an object in the fyta Library Can we use constants for this? CONF_ACCESS_TOKEN is in homeassistant.const\\n\\nI think you have to define the expiration yourself  FYI, minor version's default is 1, so this should be 2 Don't define this dict at class level, define it in a constructor instead. Otherwise this will have side effects which are hard to debug Please don't log on info level Why do we use the get here? That adds the possibility that the field is None Let's also add a test for the migration, where we insert a minor version 1 entry and then setup the integration, causing it to migrate to minor version 2 \\r\\nYou can expect an access token to be present Why do we do this? Wouldn't it be better if we saved the expiration as epoch? This way we don't have to trouble ourselves with the timezones, since its all UTC I had to introduce this, as otherwise I had problems with the reading of the config entry on line 41:\\r\\n \\r\\nI assume, in case of the setup or the migration the data is in the cache and without the conversion on line 82 would be available as datetime. Consequently, line 41 throws an error. Once saved in the file, it is read as `str` and therefore I read it in with `fromisoformat`. Instead of checking the type in `async_setup_entry` I thought it is more efficient to convert it in the config-flow (and now also in the migration).\\r\\n\\r\\nWith regards to saving the epoch, I do not yet see how this could be realized, as one would then also have to save the starting date, otherwise we do not know when the epoch ends. Or am I missing anything? You know the epoch is x miliseconds after 01-01-1970? > You know the epoch is x miliseconds after 01-01-1970?\\r\\n\\r\\nNo, I was not aware that you are referring to this. \\r\\n\\r\\nIs there a difference in the result? I guess the datetime would have to be saved as `timestamp()` and then read with `fromtimestamp()`, but besides this I don't see an advantage. An advantage could be, if the whole logic would be adapted from current local time to UTC, but this would require a rewrite of the client and integration, and I'm not sure if this is reasonable in the case at hand. The biggest advantage is that epoch is in UTC, so you don't have the whole timezone mess as it just works So instead of saving `2024-12-31T10:00:00+00:00` you're saving `1735603200`.\\r\\n\\r\\nI always find to have a love hate relationship with iso date strings. Yes, it's a little less readable, but it saves some headaches with timezones and people switching timezones probably I agree, that if I would start from scratch, UTC might be easier. But if you agree, I would prefer to keep it as is (and perhaps adapt the logic in a separate PR at a later stage). The only point I don't get is why you say it would affect the library? (If I understood correctly).\\r\\n\\r\\nAlso keep in mind, if all users now have an iso string in their entry data, a migration is required to migrate that to an epoch, so it would be benificial if we can avoid that migrationcode If I look at the changes, we could just replace the way to serialize the timestamps. Unless the expiration isn't always of type datetime, but then I am interested in why this type can be a different type. > The only point I don't get is why you say it would affect the library? (If I understood correctly).\\r\\n> \\r\\n> Also keep in mind, if all users now have an iso string in their entry data, a migration is required to migrate that to an epoch, so it would be benificial if we can avoid that migrationcode\\r\\n\\r\\nMy point was, that at the moment the whole code is with localized datetime. The benefit of saving a UTC time (epoch or datetime-string) only applies, if the whole code would be converted from localized datetime to UTC (which would require an adoption of the library as well). As long as we have localized datetime in the middle, we have to handle conversion. > If I look at the changes, we could just replace the way to serialize the timestamps. Unless the expiration isn't always of type datetime, but then I am interested in why this type can be a different type.\\r\\n\\r\\nI think you are right. But in my view this goes beyond the scope of this PR (which according to my understanding should be as narrow as possible), as said above, it would also need an adjustment of the library. To make my question a bit more explicit: Where does the timezone affect the library? I think I am missing that point here. If I understand the code we get a `datetime` object back, and we do the check if the token is still valid on the integration side, so I don't see where the lib should change.\\r\\n\\r\\n(Oh and I am with the intentions of getting this in, I'm just trying to do my due dilligence) Oh wait, you are passing the tz and expiration to the lib. I am wondering why, since we always refresh in the coordinator. > If I understand the code we get a `datetime` object back\\r\\n\\r\\nThe datetime returned from the library is local time (`datetime.now()`). For consistency purposes this should be amended to UTC, otherwise we still have to convert. Right I think I see the problem. Let's do it this way.\\r\\n\\r\\nBut now the next thing I was wondering, why do we have the `isinstance(credentials[CONF_EXPIRATION], datetime)`. Can it ever be not a datetime object? > Oh wait, you are passing the tz and expiration to the lib. I am wondering why, since we always refresh in the coordinator.\\r\\n\\r\\nI think you are right. This would not be needed to be passed on. > Right I think I see the problem. Let's do it this way.\\r\\n> \\r\\n> But now the next thing I was wondering, why do we have the `isinstance(credentials[CONF_EXPIRATION], datetime)`. Can it ever be not a datetime object?\\r\\n\\r\\nYou got a point, at this point it should always be a datetime. Can we do without this check or does mypy complain then? In that case I would suggest using a `cast` mypy seems to be fine with the omission.\",\n",
       " \"This does blocking I/O in the event loop Ah yes that's a pretty silly thing to just forget.\",\n",
       " 'This is not correct. Instead, either override the `options` property method or set the `_attr_options` attribute. Done The device class should be set in the entity description Done Should it be more clear this is year/month/day according to the Hebrew calendar, or is that immediately clear to the user? Done',\n",
       " 'Please also test that the entity for the other endpoint is created as expected and gets a state in the state machine. What do you mean exactly with \"get the state in the state machine\". This is my first pull request and also first touch with home assistant development. I tested it with my physical device here as a custom component, everything is working as expected. Is it enough to get the state from the first entity with \\r\\n\\r\\n`state = hass.states.get(\"cover.wave_shutter\")`\\r\\n`assert state`\\r\\n\\r\\nlike in the other test functions.  Yes, exactly! ðŸ‘  Please add a code comment and explain what we\\'re testing here since the docstring is only talking about the other disabled entity.',\n",
       " '',\n",
       " 'What kind of value is signal? What does it represent? It is the signal strength of the WiFi signal received by the WiFi interface. \\r\\nCould even be rssi in dBm. That should be implemented as a separate sensor entity.\\r\\n\\r\\n#available-device-classes',\n",
       " \"Probably need to double check that this doesn't fire when you reload the integration Yeah looks like it does\\r\\n![2024-04-24_11-22-54](\\r\\n Actually I am not so sure. I have not changed anything but it wont trigger now. Tried in debug mode to to trace the execution to `_on_state_update` but its not being called on reload. AFAICT `_on_state_update` is only ever called when a state message comes from the device which does not happen for an event entity until it is actually triggered so there should be no duplicates.\\r\\n The code looks fine otherwise. If you are confident its not a problem, it seems good to merge\",\n",
       " \"Note sure if it makes sense here but `self.add_suggested_values_to_schema` exists now This is probably an existing problem, but I think we need to call `self._async_connection_result(False)` before the return  But I guess we also need to not start the reconnect loop if the auth is wrong so may need to split that function into two  If we know its failing we can resolve the available future right away so nothing else is waiting for failed connect as it would otherwise wait the full 30s timeout\\r\\n\\r\\n For security reasons, I think we shouldn't reflect the password back to the UI Moved in a sentinel to allow re-auth with the same password.\\r\\nOpened   to ensure we always reload. \\r\\n\\r\\nDo we need to pass this at all?  I'm honestly not sure I want it to make easy to let users try the current password, but it must be clear it is set or not. The option flow also allows to update the password and also sends the password to the UI.\\r\\nWe could use a similar flow there. We do not want users to re-add their password if it was not changed. I wish we could use a better sentinel but I guess we don't have a way of telling the difference between no password and empty password. Users can show their password, so it should be something understandable I don't have a better suggestion at this time. This one is easier enough to change in a future PR if someone does however I think its to call `entry.async_start_reauth(hass)` here as its an exposed api See: #diff-454ebc7d7d7827598c55e6611dd5af8a2409744ab7bf06c3c4923867b8d7788fR1114-R1115 It would be cleaner to check for active flows vs patching `async_start_reauth`\\r\\n\\r\\n If we don't set this before calling `_async_connection_result` it will start trying to reconnect.\\r\\n\\r\\n`async_disconnect` will do it but there is a chance it could suspend so it isn't set in time before we reach `_async_connection_result` _reauth_config_entry isn't used. Fixed with \",\n",
       " \"Except for the line\\r\\n\\r\\nthis is essentially what `async_reauthenticate_client()` does. Would it be considerable to pass username and password to that function instead of `user_input` to have a common handler for the same thing? Maybe even move it out of the class as a helper function as it doesn't use `self`? Good suggestion, which is also fine as follow up PR \\r\\n\\r\\n@erwindouna as pointed out correctly above, some refactoring could improve this code here.\",\n",
       " 'Why don\\'t we create a time entity for this? Gives way more flexibility to the user so we don\\'t really have a chance to set it. \\r\\n\\r\\nTLDR: this specific line is only changing local data, not sending to Ecobee Server. The only thing you can send is `set_ventilator_timer` which set a 20 min (fix) timer. \\r\\n\\r\\n\\r\\nContext:\\r\\n\\r\\nThe real setting is `set_ventilator_timer(id, True)` this will force the Ecobee server to set `ventilatorOffDateTime` at a value of now + 20 min. \\r\\n\\r\\nThe reason we set `self.thermostat[\"settings\"][\"ventilatorOffDateTime\"]` to an approximate value, is to get the local value in Home Assistant so the switch don\\'t flick back on/off until an update is done. \\r\\n\\r\\n When the ventliation is on, are there other entities that reflect that? no, not currently implemented. \\r\\n\\r\\nAlso. If this would be implemented there would be 2 things. \\r\\n\\r\\n1) if the 20 min timer switch is on or off\\r\\n2) if the ventilator is on or off\\r\\n\\r\\nThe ventilator can be on for other reasons than the 20 min switch being on. (exemple the `min ventilator time` number in the integration) \\r\\n\\r\\nBasically the way the device works is. You can configure it to be on x min/hour. `min ventilator time`  and then the ecobee turns it on/off to match that number. \\r\\n\\r\\nBut if you want to give a boost of ventilator, you can turn on the `20 min switch` on the ecobee interface to run it for the next 20 min (regardless of the `min ventilator time` ). The ecobee behaviour is that switch stays on for that 20 min and go off after. \\r\\n\\r\\nThis last piece is what I am adding today.  For what\\'s it\\'s worth, if we wanted a binary_sensor to say if the ventilator is on/off it would be done by another data point call `enabled equipement` which is a coma separated list of all the things on. ex: `fan,ventilator,heat` \\r\\n\\r\\nThe reason I assume nobody ever modeled it, is because of the bad refresh rate of the ecobee device (3 min) it makes it very un-usable Because the thing is, we generally dislike when the integration is assuming the state, so for example if I turn on this switch via HA and then turn it off manually, they are out of sync. Would it maybe fit to be a button instead to avoid keeping state ourselves? tbh, in this case I can just remove that line. The behaviour will be like the rest of this integration, aka the switch will flip to an \"old\" position based on latest data. Then will get updated in the x seconds after. \\r\\n\\r\\nLet me fix the code and remove that part. \\r\\n\\r\\nIt should not change the functionality. \\r\\n\\r\\n\\r\\n\\r\\nAlso, I would like to keep the switch beacuse it is useful to know when the 20 min is done. So folks can use Home Assistant to build timer longer or shorter than 20 min (which is limiting right now with Ecobee HW)  Yea but that\\'s what I meant with the question if we can see the switch being on in other entities, and if I understand correctly, we can the other entity would be on `enabled equipement` and we could not distinguish if the 20 min timer is on. (vs just the ventilator)  I don\\'t really see a reason to differentiate on the reason why the ventilation was turned on. Let me ask someone else to also take a look at this so I\\'m not unneededly pushing this in another direction. > Would it maybe fit to be a button instead to avoid keeping state ourselves?\\r\\n\\r\\nYes, that seems like the best solution.  As we\\'d want the state to be consistent regardless of where the action is taken.  Meaning if the 20 minute vent is initiated / canceled from the panel or HA the state should be the same.   If the ecobee can provide remaining ventilation duration then this could be done; but it appears it does not?  If so, the best is a button to initiate and a binary sensor to report ventilation State.   So the value that we set here get configured by Ecobee servers regardless where the switch is flipped. \\n\\nIn the device or in HA. \\n\\nThe reason we modified that value was for getting a better responsiveness. I will remove the change to this. \\n\\n The thing with a button will be in-ability to turn off the 20 min timer. This is why I think the switch makes more sense.  So if the 20 minute ventilate is set on the panel.  Then the value of \\r\\n\\r\\n \\r\\n\\r\\nwill contain the off time? Yes exactly  In the switch code you set it to 20 minutes in the future.  If you set it to +40 would that then run it for 40 minutes? No.\\r\\n\\r\\nthis line: \\r\\n`self.thermostat[\"settings\"][\"ventilatorOffDateTime\"] = (datetime.now() + timedelta(minutes=20) - self._time_zone_delay`\\r\\n\\r\\nis never leaving HA. it was only added to enhance user experience. \\r\\n\\r\\nThe only thing that leaves HA is `set_ventilator_timer(id, True)` (or false)\\r\\n\\r\\nWhen Ecobee receive that command they:\\r\\n- Start the ventilator \\r\\n- configure thermostat[\"settings\"][\"ventilatorOffDateTime\"] to now+20 min. \\r\\n- when that delay is done, they turn off the ventilator. \\r\\n\\r\\n\\r\\nwe could have skipped the `self.thermostat[\"settings\"][\"ventilatorOffDateTime\"] = (datetime.now() + timedelta(minutes=20) - self._time_zone_delay` this is not in any way setting the real value it\\'s just an estimate so HA has a temporary value until we get a refreshed value (up to 3 min)\\r\\n Now I understand, that line is an anti-pattern. So I will remove it. But it will not change the behavior of this new switch. (simply the refresh time of it)  and if we send `set_ventilator_timer(id, False)`  then Ecobee server stop the ventilator and set `ventilatorOffDateTime` to \"\" Got it, apologies for it taking so long.  To summarize\\r\\n\\r\\na) there is an api command to turn the \"20 minute ventilator\" (20mv)there are no other options for different time amount.\\r\\nb) there is an api command to stop an in progress 20mv\\r\\nc) the remaining time on the 20mv is reported by the thermostat, the update period is 3 minutes\\r\\nd) the purpose of setting the remaining time in the code above was to make the switch be on while the system is waiting for the update in (c) to come through. \\r\\n\\r\\nTo make it consistent with the panel UI, we\\'d want a way to turn the 20mv on / off, display whether it is on or off and display the remaining time in minutes?\\r\\n\\r\\nRegarding (d), I can see why this is useful in order to prevent this scenario:\\r\\n\\r\\n1) user initiates 20mv\\r\\n2) there is no UI feedback that it succeeded (or the UIs optimistic switch reverts back to off after a timeout)\\r\\n3) user does 1 again and again and again...\\r\\n4) eventually 3 minutes later HA shows the ventilator running \\r\\n\\r\\nA question, what happens for other control points in the integration?  For example setting temperature setpoints, hvac modes, etc.   Are these reported faster? Are they set optimistically by the integration while waiting for an update? What\\'s the current convention?  Sometime when there are technical limitations (like poll times), the best we can do is have a consistent convention. \\r\\n a) exact\\r\\nb) exact \\r\\nc) exact (3 min is a mix of HA polling rate + very bad API from Ecobee) \\r\\nd) exact \\r\\n\\r\\n\\r\\nother input for this integration)\\r\\n- numbers: After you change the value, it flips to the old value for few min (until an update) then you get the value you wanted. \\r\\n- Climate: as I look I found their workaround. \\r\\n\\r\\nI will try this: \\r\\n#L361C7-L364C49\\r\\n I just pushed a new commit that replicate the logic/behaviour of the climate platform and it works great (After this PR, I will make one to fix the number platform) \\r\\n\\r\\nWhat do you think > To make it consistent with the panel UI, we\\'d want a way to turn the 20mv on / off, display whether it is on or off and display the remaining time in minutes?\\r\\n\\r\\nTo make it consistent with the panel, I want the switch to be on for as long as the 20 min timer is on. This switch shows if the timer is on, not if the ventilator is on.  It\\'s a whole lot cleaner this way.  @joostlek - what do you think?\\r\\n\\r\\nThe only functional item I\\'d like to see, to get the same functionality as the panel is how many minutes / seconds are remaining.  Consider adding an attribute to the switch that contains the remaining seconds or minutes?  I think this will be easier to use from a display than the time stamp which requires some conversion? Before doing that let\\'s see what @joostlek thinks about the current progress / direction.  >how many minutes / seconds are remaining.\\r\\n\\r\\nThis is NOT available on the device. It only says `Ventilator (20 Min)` and the value does not change. It does not go 19-18-17-16 etc. It is just a static label. Caching the time zone delay will cause problems for a system that runs across a daylight savings time boundary.  We should calculate this when needed.   Not sure I follow you. The way I see this it will match whatever time the Ecobee is operating on. Since all the timestamps comes from the device It looks like you are calculating the time zone delay from UTC.  This delay changes when daylight savings time engages / disengages.  In New York time the offset right now is 4 hours.  But on 11/4 that becomes 5 hours. If I start HA on 11/2 it\\'ll record 4 hours in the __init__ for the entity.  Two days later that calculation would yield 5 hours but 4 is cached.  As a result the switch will reporting will be off until HA is restarted.   ooo, I see your point, I can move that calculation in every update. What do you think. \\r\\n\\r\\nI assumed it would be a lot of unnecessary recalculation. But you are right, this would get broken twice a year. \\r\\n\\r\\n\\r\\nDo you think it\\'s worth moving in the `async_update` Based on our discussion I have proceed to move that logic in the update function',\n",
       " \"This entry contains a username and a token. These should not end up in diagnostics.\\r\\n\\r\\nDiagnostic data must be stripped from personal data.\\r\\n\\r\\nWhat would be interesting about the entry data in this case that it is useful to put it into the diagnostics?\\r\\n\\r\\n../Frenck Oops, indeed! That has been properly redacted now.\\r\\nOther than making it more _complete_ for diagnostics, there wasn't a particular property that I wanted to expose. Overall  I wanted to add diagnostics to help around after this [issue]( where MELCloud silently failed. Having the opportunity to see the `last_reported` timestamp will help to see this behaviour, if help is being provided via Github.\",\n",
       " 'could be `not in`',\n",
       " \"Honestly, this is extremely long...\\r\\n\\r\\nI wonder if we even should show the mac address at all. I think we still need to show the mac because I see quite a few cases where they have multiple of the same brand of adapters and the only way to tell them apart is the mac.  It's also a commonly needed item when we collect debug data from the user to figure out which adapter is being flakey or which adapter can see a specific device. I think we could drop the usb id from the title though. Thats probably not so useful if we have an adapter model and manufacturer \",\n",
       " \"Please split multi-line ternaries into if blocks Please split multi-line ternaries into if blocks Fixed in ad582b2 Please use `f-strings` here Fixed in 9bc2c92 Please make `[STATE_OPEN, STATE_OPENING, STATE_CLOSING]` a constant `set` Fixed in 61ddb28 With all the branching here, it probably makes sense to subclass `Valve` so we can do all the branches in each subclass That was also my initial thought but went eventually for this implementation as the switch with type valve is already there and should continue to work. In opinion this is the cleanest solution without requiring larger code changes.\\n\\nOf course we can create a base class type for shared functionality and subclass switch and valve, but I think it's bit overkill here. I would prefer not to have to maintain the branching long term especially since valve and switch are completely separate platforms it's likely they may diverge more in the future.  Please split the classes with a base class. Ok, I understand. I expect to have time to do this within 1 or 2 weeks. @bdraco - Please check the latest commit.  I adjusted the classes to reduce duplicate code.\\r\\n\\r\\nPlease see the comment I added about the test.\\r\\n\\r\\nThanks I have split the tests. Merged with your last commit. And did some quick testing from within HA/HomeKit.\\r\\n Please split this into two tests as we aren't allowed to have `if` branching in the body of new tests I have split these tests.\",\n",
       " '',\n",
       " 'Why don\\'t we just create 2 entity descriptions?\\n\\nAlso, I see that there is one for hours and one for days. You know that when you have a device class of type duration, you can just change it in the entity settings? If both have the same value I don\\'t really see any benefit in providing two entities for the same value. Now I\\'m reading the PR description again I\\'m assuming the days means \"days this has been installed\" and hours means \"hours of active use\". I think we should make this clearer in the names. Preferably the names should not contain the unit of measurement, because like said, that is changeable by the user and looks strange to suddenly measure \"Filter Used Days\" in weeks. I was mimicing how the existing \"runtime\" devices/attributes are. Is there a better way to do this?\\r\\n\\r\\nI\\'ve added a commit changing the names to what I think is a better description of what the values track How do you mean runtime? Oh wait never mind.\\n\\nI mean, this feels like adding a lot of abstraction for something that feels really simple I think we can do this smarter, but let\\'s await the other question first To describe my issue with this btw, let\\'s add a way to do static unit of measurements without adding all kinds of untyped parameters to a function.\\n\\nSomething like the default implementation would work\\n\\n\\nIf you add this as the first line of the function, you could have 2 entity descriptions for the new entities and just set `native_unit_of_measurement`.  Let\\'s split this entity description up into 2 Let\\'s wrap the lambda in paranethesis Please use sentence case',\n",
       " \"\\r\\n\\r\\nUntested, but I think this will work ðŸ‘ I'll give it a try That works, probably could make that same change to the switch as well In theory that line could be moved out of binary sensor and switch to the base class constructor in `entity.py`, let me try that. This is ok now, but if we get more of these, we should switch to BinarySensorEntityDescription. \\r\\n I was thinking the same thing, will switch if I add any more.\",\n",
       " \"Could this number be automatically discovered from the PDU (eg if 8 and 16 are the only choices,  try to query outlet 16 and see if it works or not). Sure, now it polls the status and instantiates that number of outlets. I don't have one of these units to test if it's intended behaviour, but here #L34 it appears that the string generated will be one digit too long. E.g. outlet index 1 on an 8-outlet PDU would generate `010000000` (9 digits). I can't believe I missed this. Good catch thanks. I am not sure if the outlet name is user-configurable - would the outlet index be a better (more stable) choice? Agreed, probably more stable. Changed. Is there a difference between `get_name()` and `name`? No difference; should have used the getter. Changed. Please don't log on warning Please use [runtime_data]( Why do we create the device here? Function is small, might as well inline it Please type the update coordinator with the returntype of `_async_update_data`\\r\\n unused \\r\\nNow you can use `self.config_entry` after calling the super constructor If we're retuning nothing valuable, just don't return and type this to return `None` You can add `_attr_has_entity_name = True` here and the device info would be nice as well Please remove empty fields Unused The default is already present in the schema Not a nice title imo I always prefer to have the coordinator first Let's also give this a better name speicifc to the integration This is the default for coordinator entities, can be removed\",\n",
       " \"`query_str = Template(query_str, hass=hass)` so you can skip the later assignment on line 87. Still need to have that one in case it's already a Template I moved the assignment into `else` and put the initialization into the constructor. Same here, assign `hass` variable at the `Template` initialization. Maybe debug logging level here. same here. hass as an argument in the constructor. Seems unrelated to the purpose of this PR?\",\n",
       " \"Why do we call `lower` here, isn't lower case already guaranteed by the schema?\\r\\nI think we should also, in a separate PR, remove the call to `lower` for the project name above. Sure, I'll update my PR to remove this. I'd gone with consistency, but you're right it's overkill. Also break out of the for loop when handling the project name above\\r\\n This should be a `ServiceValidationError`, with translation in `strings.json`. Same for the project name error. Let's not add the unnecessary lower-casing to new code.\\r\\n I've removed `.lower()` from `section_name` as initially asked, because it's already lower-cased by the schema. But because the user-entered data is lower-cased, then the section names from the Todoist API need to be lower-cased for comparison?\\r\\n\\r\\nEither this `.lower()` needs to remain, or lower-casing should be removed from the schema definition. I am not a fan of the case-insensitive comparison, but since it's happening for the project name I followed the principle of least surprise. You're right, sorry ðŸ‘  Would something like this be more natural?\\r\\n\\r\\n\",\n",
       " \"Why not?\\r\\n\\r\\nassert mock_setup_entry.call_count == 1 copied from above\\r\\n\\r\\nswitched both in b9c48d92998ee7b80696b9499286636fa8331787 Do we need to verify this new password percolates into the config_entry? b9c48d92998ee7b80696b9499286636fa8331787 This is cool, didn't know that could be done\",\n",
       " 'Stale docstring',\n",
       " 'I won\\'t add the suggestion but generate the file locally instead after the other comments have been resolved Aight, done now! Is there a reason that you don\\'t use the async version? (And that the client object is each time newly created) Kinda? I derived this TTSEntity from the `google_translate` integration and the `gTTS` entity is created with every single request as well - but that\\'s mostly since there is no such thing as a client there. Thus, I will refactor the client-init into the creation of the Entity.\\r\\n\\r\\nRegarding the async version: I\\'d be happy to provide the async version if that\\'s better practice, just let me know and I\\'ll add it :) Yeah, I understand, but here it should be possible to move it into the `__init__` function.\\r\\n\\r\\nAnd yes, async should always be used where possible because Home Assistant is running in async and every sync function adds overhead to it. I saw that the library has a async client interface available, so that should not be a big problem. Do you not want to put yourself as a code owner?  Done! Can you rename integration ot just `elevenlabs` Changed it :) It\\'s cloud poll, as we have to request data from the cloud.\\r\\n Not needed\\r\\n Can you set the title to the voice ?  Done! This is not possible as the schema marks it as required\\r\\n Errors should be keys that refer errors defined in `strings.json` This is not possible so instead use assert\\r\\n Just name it after the voice as it\\'s already linked to ElevenLabs integration.\\r\\n validate the API key still works before forwarding entry setup This changes the semantics a bit, though I\\'m sure this is not too bad. Instead of calling both and awaiting afterwards, we await the first and only then call the second. I can still implement the new behaviour though. This might end up with 2 voices being called \"Unknown\". Can you use their ID instead?  Same. Not possible so just use assert to satisfy typing.\\r\\n This makes little sense. You now allow a user to pick a voice \"Unknown\", which you cannot resolve. Instead, you should make sure `voices` is a dictionary mapping id=>name',\n",
       " \"Why do we make this abstract? We could implement this twice and enjoy the type safety it adds right? Do you mean two separate classes of data update coordinators? What's a TimestampDataUpdateCoordinator? This is a `DataUpdateCoordinator` which keeps track of the last successful update:\\r\\n#L453-L463\\r\\n\\r\\n`WeaterEntity` uses it:\\r\\n#L147-L155\\r\\n Can we make this a generic so we add the return type annotation? I think this can be a generator expression We can retain this coordinator type I don't understand, why do you want to use `SingleCoordinatorWeatherEntity`? I assumed the `CoordinatorWeatherEntity` also takes in a coordinator in the type `CoordinatorWeatherEntity[AccuWeatherDataUpdateCoordinator]` (but then the new coordinator) Huh, how does this constructor work? #L1086-L1114 Oh cool :) Snapshots would be a nice improvment for this test As you wish ðŸ˜„\",\n",
       " 'Perhaps provide some logging here or something for the user to get the error? From the config flow it looks like this can raise other errors than this? All those errors are children of TeslaFleetError, so there is no need to handle them separately, to do the same thing.',\n",
       " \"please use `CONF_HOST` and `CONF_PASSWORD` Fixed do a `await coordinator.async_config_entry_first_refresh()` before adding it to the entry Fixed Fixed \\r\\nis default Fixed are you planning to re-use validate input? If not, just do it inline, can also save you the extra exceptions can this not throw errors? idem idem idem add those later in a separate PR Removed this.  why the generics? firstly, I'm not sure I like the decorator just to avoid a single `self.async_request_refresh` call, because I'd argue that call is clearer than the decorator. Secondly, do you really need to do an update after each call? Can't you assume that value was set if the call didn't throw errors?  use the `attr_` here instead Fixed I think we can also use the `attr_` for brevity Fixed but you are updating something here? If you really don't need to can't we just stop the polling? where is the push happening? The Swidget API client creates a websocket to the device. The device will automatically push change notifications back to the Swidget API client over websocket (so you don't have to poll it for changes).  \\r\\nneeds to be set for new integrations Fixed what if the device is not a dimmer? It doesn't have any entities? Why even add it at all please fix the exception and continue the test (if in a non-terminal state) to show we can recover from errors. I'd suggest you switch to parametrized tests for the exceptions While (afaik) tests for your platforms are no hard requirement atm, I would suggest you add test cases for them. \\r\\nI think this method is preferred, instead of directly accessing the event loop\",\n",
       " \"These actually countdown (as in become a lower value as time passes, making them timers). This is not allowed. They are set and do not change during the runtime of the irrigation process. They reset when the switch turns off. That is probably specific behavior of your device, but defenitly normal behavior for this data point. My original comment remains. The documentation linked, does not have the DP codes that are used here; indicating this is a non-standard device.\\r\\n\\r\\nWe don't support non-standard devices. At minimal, we should support the standard (documented) instruction set.\\r\\n\\r\\n So based on this comment, you are rejecting this PR? Or do you think there's something which can be done to make this acceptable?\\r\\n\\r\\nSince you do not want to support this device, how are people meant to use it? Is it possible to have this device working in Home Assistance Tuya integration?\\r\\nIt's disappointing that I cannot integrate it in my automations.\",\n",
       " 'We shouldn\\'t do this. The TrackerEntity is originally only meant for GPS trackers. If we want to use it for other things we need to discuss that in an architecture discussion. I felt like it kind of fitted because GPS coordinates were optional. But I\\'ll remove it. I can\\'t see another similar entity type that might make sense for the nearest AP. Perhaps if scanners had a way of changing areas? You can open a discussion and get ideas. Let\\'s just remove this for now. We shouldn\\'t need an options flow since device tracker scanner entities are disabled by default. Yeah, I didn\\'t really want to flood the list with disabled entities, and I wanted to be able to choose what type of tracking to do. I could remove the flow, but I sort of prefer to choose in advance which entities to track. Also, I\\'m going to add a poll frequency option for device tracking. So I\\'d rather keep this if that\\'s ok? No, we\\'ve made the device tracker entities disabled by default so we don\\'t need any options.\\r\\n\\r\\nPoll frequency option is also not allowed. The user can turn of polling for config entries and automate it themselves with the `homeassistant.update_entity` service.\\r\\n\\r\\n#defining-a-custom-polling-interval OK, I\\'ll remove the options flow too... I\\'m a bit confused how the manual refresh polling automation plays with the Update coordinator, which updates the whole list of entities. Would the user just select one entity and that would have the side-effect of updating them all? How would they know to do that?\\r\\nI assume the update coordinator is clever enough to not poll if there are no enabled entities listening to it, even if I call the initial load method, and also clever enough to not poll twice if two entities ask for a refresh at almost the same time. It\\'s ok to add a section to the tplink omada docs of how to automate the polling if you think that\\'s needed.\\r\\n\\r\\nThe first explicit refresh by the integration will fetch data.\\r\\n\\r\\nThere won\\'t be any recurring refresh by default if there are no listeners.\\r\\n\\r\\nThere\\'s a default refresh debounce of ten seconds in the coordinator. It means that if there was a refresh, any subsequent request for refresh within ten seconds will not be executed but scheduled to run after the ten seconds have passed, and only one refresh will be scheduled.\\r\\n\\r\\nEg if three requests for refresh come in during the debounce time, only one refresh will be scheduled to run after the debounce time expires. The debounce can be customized by the coordinator. See the debounce helper for details. We shouldn\\'t use entity descriptions for the device tracker platform since the base device tracker entity doesn\\'t support that yet. Ok. I based this mainly on what Unifi\\'s integration was doing - it has Entity Descriptions. I can simplify. Commented code. Please break long comments around max 88 characters per line. We can remove this. We can remove this. Should we add both wireless and wired clients? I don\\'t think so. Maybe if someone requests it? I think wired devices are unlikely to be portable, and reporting a turned-off computer as \"Away\" is a bit misleading. Please use the `entity_registry` fixture that is available.',\n",
       " \"If those variables are not used outside this module, user `_` prefix to mark them as private: #private-variables Annotate the variables as `: Final` This line seems to not be needed. Same above Tests fail because of socket.socket if I don't have that.\\n\\n Some points I believe might be missing on this class:\\r\\n\\r\\n* Annotate with `device_class` for these sensors (unit of measurement is already implemented)\\r\\n* In case of being a numerical sensor, stating the `StateClass` so statistics can be properly stored for this sensor.\\r\\n* Adding tests for sensors created by this integration (this should increase the test coverage) Not sure what you mean by annotate with `device_class`\\r\\nAlso not sure what you mean by stating the `StateClass`\\r\\nI don't actually know how to test sensors that are created by/use an API. All the integrations I know that do a similar thing don't have tests on their sensors, so I don't know where to look for examples. Any suggestions? Sorry. Been a while since I've worked on this. State class is set in the sensor descriptions. I'm still not sure about device_class... Why not using the option to suggest the precision at which to render the sensor's value: #L464 ? This logic seems to be best suited on the init method by overwriting the `_attr_native_unit_of_measurement` property of the class. Then the parent SensorEntity class would pick the value and cache it: #L475 better to raise `ConfigEntryError` here until you implement reauth that looks like something that should be moved to the coordinator probably no need to add it to the config_entry, as you can retrieve it from the coordinator \\r\\nyou don't need this move it to its own file \\r\\nis the default \\r\\nthis is constant just a bit shorter this should be part of the entity_description, to avoid the `if` here. Can there be different pressure units? delete this file and folder, this will be auto-generated for core integrations\\r\\n\",\n",
       " 'Not needed Is there any way we can check if the API key is valid?',\n",
       " \"\\n Looked this up, makes sense! Thanks! Or just overwrite it in the sensor.py (continues from last comment)\\n\\nIt would make a lot of sense to use entity descriptions here. That means you create one generic sensor, which is changing shape depending on the entity description you put in. Change made. Code is much cleaner! Thanks! There is an issue about increasing the scan interval, you can find more explanation about that limitation there: #discussion_r1557326343 Yeah seems like it can definitely be a problem if the user has a few devices. I think it should be up to the user to decide so I've added it to the config with a default of `600`. Thanks for your review! Oh, nice idea I am not sure if __future__ is used or not Removed I think Meter, MeterPlus and Outdoor meter can all be handled the same way looking at the API. Can we handle the 3 types ? Yes good call! I've added support for all three. They essentially behave the same so we can treat them all the same. Maybe add in the message that there is a limitation of 10000 calls a day ? I've added it to the documentation PR. I think adding it here would be too verbose unless there is a way to add helper text or something like that? I couldn't see a way. Ok ! We don't allow exposing/modifying the scan interval. They should be set to sane default values.\\r\\nIf the user wants a short update interval, they can use the service [`homeassistant.update_entity`](#service-homeassistantupdate_entity) Fair enough. I've reverted this. \\r\\n\\r\\nIt will use the device class name Either extend SensorEntityDescription to add a `value_fn` or do\\r\\n One thing I am wondering: When can coordinator.data be None? That would mean the coordinator update failed, but then the entity would render unavailable, right? I think you're right, if the code gets here then we should have data I take that back! I believe if the SwitchBot API request fails, we can get a `NoneType` here so we need the short circuit. It does seem to fail occasionally. Just tested and observed this happening. What error is it raising? We should catch that in the coordinator and raise `UpdateFailed`, which then renders the entities as unavailable A timeout error during the fetch. It does render the entities as unavailable in this case. oooh wait, I think I know what's happening. This is using the coordinator callback.\\r\\n\\r\\nWhen an entity turns unavailable, the callback is called, and then this guard is needed. If you would use the native_value property like below, it would just try to get the available property (which is implemented in the CoordinatorEntity, which sets the entity unavailable when the coordinator fails), and then proceeds to not request data from the native_value property. So tldr; I think we can use the code snippet below. But this is a code style question, since both are used in core, and the current setup is used in switchbot_cloud. I personally like the native_value property when there is little to no logic involved into setting values, but there is no preference. Ahh ok well I think the `native_value` solution is cleaner too so let's go with that. Thanks! \\r\\n\\r\\nOtherwise this might be a good alternative that's a bit cleaner Seems like we need the short-circuit above\",\n",
       " \"We don't allow overriding a builtin service. That would be confusing to users. If there's no message to send the integration shouldn't implement a notify platform.\\r\\n\\r\\nThe other PR that implements a custom service is ok. But the service is not overriden ðŸ¤” Instead an additional service with a custom service schema is registered alongside the builtin service from the notify platform. This is currently required, as the notify entity service does not allow extra data keys like the legacy notify platform (required for item field). I also changed notification_type to message, as that is basically the message that is sent, just that only 4 predefined keywords are allowed. In contrast to other notification services, bring does not have a free text input for the message. The custom service schema does therefore define the message field as radio input.\\r\\n\\r\\nI know the new notification entity component is still a work in progress, @joostlek asked me if i could implement this feature with it. Maybe this can serve as some kind of use case for the further development @jbouwh ^^ Please use `ServiceValidationError` instead Raise `ServiceValudationError` and move the error message to the translations (`string.json`)\",\n",
       " 'Use `caplog` to very log behavior during tests I think this test can be omitted. I might think we prefer not to allow this yet and explicitly fail. If there are use cases that need this perhaps its a followup discussion? (Similarly, then registration can fail if the tool isn\\'t registered) Remove asserts (not a pattern used in production code). The rationale here is that for something like this if the specification is None its kind of undefined behavior so let it fail naturally (the caller had to do something really weird and it is a shouldn\\'t happen case. But also, i think it does something different in production code) I think `specification` should be its own `@dataclass` passed in during registration of the handler, then it gets functions like being converted to a dict or `__repr__`.\\r\\n\\r\\nA common pattern used for other registration is to separate the arguments needed for registration vs the arguments needed for the implementation of the handler. Have a look at [Services]( for example.\\r\\n\\r\\n(This allows the handler implementation to avoid inheritance and prefer composition)  I have changed the Tool.parameters to be a `voluptuous.Schema`, this matches what we have for the services. I don\\'t know how to dynamically create a `@dataclass`, but the `vol.Schema` should do the job. Can this be limited to the conversation domains or do we need to support arbitrary domains here in the `platform` field? I think right now the only expected value is literally `conversation`, but I can imagine that this field could be useful in the future. Please let me know if I should remove it or make a white list, etc Consider a scenario where one AI agent asks another AI agent to do something What is the text input if an LLM invokes the tool? would `text_input` be one of the intent tool args or not used? This is the user prompt. It is not really used, but intent handler expects it. I could use None, but then I thought there could be use cases in the future to have both user prompt and LLM arguments. Please let me know if I need to remove it. We talked on discord about potentially extracting an input class for a number of input arguments, similar to how conversation agent inputs or how intent inputs work.\\r\\n\\r\\nNote that there can be different APIs for these two use cases if it helps:\\r\\n- how llm tools are called\\r\\n- how llm tool handlers accept inputs Done, please check The conversation agent integration that is calling the tools should take responsibility for:\\r\\n- exception handling: if the tool call fails (they catch `HomeAssistantError`)\\r\\n- json serialization\\r\\n- json deserialization\\r\\n\\r\\nSimilarly, the tool implementations are responsible for being well behaved and throwing exceptions (e.g. `HomeAssistantError`) on failure. Done Remove since this is not used, and having a default seems reasonable I\\'m not sure what is happening here with the pre processing and looking up areas and floors. Wouldn\\'t the intents themselves handle all of this? No, intents (the `DynamicServiceIntentHandler` specifically) expect area_id and floor_id. We are doing here a resolving of area_id and floor_id from its name or alias, replicating what is being done in `helpers.intent.async_match_states`. Consider using `_slot_schema` or exposing it as public so this doesn\\'t have to get into the specifics of specific intent handlers. I tried, but `_slot_schema` adds additional `{\"value\": validator}` layer that we don\\'t want.\\r\\nThis is a weird thing about intents, they have a slot_schema of, for example,\\r\\n\\r\\nBut what they actually expect is \\r\\n\\r\\nSometimes even `{\"value\": cv.string, \"text\": Any}`. Ok, I can use `_slot_schema` and remove the extra layer in the `IntentTool`. Done My impression is that tool agents expecting an openapi description of the tool would want to have a description of the response as well: #openapi\\r\\n\\r\\n(We could also consider responses as a second pass if that helps make incremental progress.)\\r\\n No, the Python API only uses input parameters:  Also LLMs are quite good at understanding structured json tool output in any format. I think we should tackle returning data in a follow up PR. I think the API needs some additional consideration. In the [architecture discussion]( the proposal was to tackle querying entities in follow up work. I agree that giving the LLM useful data about attributes is a good idea, though i am not sure yet that this should be a set of attributes defined in this file. It is not only for querying. Some intents return the list of states it affected and the list of states id could not.\\r\\nReturning `state.as_dict()` is too expensive in terms of input tokens, `state.name()` is too little information, so this was a compromise I\\'d come up with. I also don\\'t like the hardcoded list of \\'meaningful\\' attributes.\\r\\nI will remove them completely for now, and I agree, let\\'s leave it for a follow-up PR. I believe this is equivalent to:\\r\\n\\r\\n\\r\\nHere and below you can pass the default argument to get to save some lines of code. When does this happen? I was considering this a \"shouldn\\'t happen\" case and the idea behind throwing the exception was not to silently repair it. Consider raising when tool name doesn\\'t exist. I believe the `slot_schema` case is always non-none except in tests? If so then i suggest removing the constructor and doing any other schema update work in the caller when creaeting the tool\\r\\n\\r\\nIf this does need to be optional, then I think its fine to just allow the schema to be `None` and handle this when validating the schema like how it works for the tool',\n",
       " \"Shouldn't this be the default on `NotifyEntity` ?  It is the default:\\r\\n#L131 removed Are these things tested in the notify integration? Otherwise we need to test it there. I'll remove this. I added the tests to the notify entity platform tests:  I was mostly thinking about the legacy service. We still need to have test coverage for that. > I was mostly thinking about the legacy service. We still need to have test coverage for that.\\r\\n\\r\\nSee \",\n",
       " '\\n What could effect ever be? In WLED effect is the current light routine.  It could be solid or one of any choice the controller supports.  These are already exposed in the light via the state_attr(entity_id.effect_list).',\n",
       " \"We don't need to update the internal state here, the coordinator will push the first state to the entity. We can move this block to _update_state(), checking if data is None before and returning in case it is. Here we can assign self._attr_native_value = value directly instead of calling this method. Let's try to eliminate this function. Can we type this datetime is a bit broad. maybe `device-datetime` or something would at least explain more what the entity does. (not that anyone ever looks at the unique_ids, but if you are going to add more datetimes in the future, having one that is literally called `datetime` is strange types Did they write their backend in javscript or something maybe matlab?^^ Let's just compare as dict Can we also test this part?\\r\\n\",\n",
       " 'I think I\\'ve actually fixed this so I can remove all these late imports Nope, still circular This is only for testing to see if the CI can catch anything For a future followup PR; Since most of the events (state events) come in via _async_fire, I think in this case we might even consider that it\\'s worth the performance tradeoff here to always check even without debug mode since it\\'s frequently the place where a CC gets this wrong  Also in the future we can rename _async_fire to async_fire_internal and change all known safe high volume usage to use that\\n\\nThen we can make the length validation a separate function and call it in fire as well and update fire to use the internal function since we know it\\'s passing through a call soon threadsafe\\n\\nFinally we turn the threading check on in async_fire since it would only be rarely called from integrations now as all our internal usage would avoid the check.  At least on my production, `_async_fire` is called orders of magnitude ore than `async_fire` so this seems like the overall performance impact will be minimal and it seems worth that tradeoff \\r\\n\\r\\n<img width=\"591\" alt=\"Screenshot 2024-04-23 at 11 57 48\\u202fAM\" src=\"\">\\r\\n Started working on that in  In the future, we could add a fast check to entity sources to see if it\\'s a custom component and always do this check if it is \\n\\nWe would also need to make sure we aren\\'t called from a call soon threadsafe if we did it by default for cc since it would be a waste in that case  I very much like that idea.  And it will be easy to search the code of custom components for calling anything `_internal`.  will implement that Can we default this to the debug value in [`RuntimeConfig`](#L55) Yes\\r\\n\\r\\n18e88c20d9d53f0ce45e12b667d66e7df4c478a6\\r\\n',\n",
       " 'As discussed elsewhere, I think I\\'d prefer if we can also check if the add-on is either running or auto start is enabled. Just in case we have folks which have the add-on installed but don\\'t use it. Looks like we don\\'t need an explicit type annotation.\\r\\n Do we need to reload the config entry too? By my testing, after the config flow completed, it shows the \"Home Assistant SkyConnect\" config entry correctly:\\r\\n\\r\\n![image](\\r\\n\\r\\nWhat would a reload do here? :thinking:  This is the end of the options flow and normally we want to reload the config entry so that it can use the updated config / options. I didn\\'t find a listener for config entry update that reloads the config entry. The PR empties the implementation of `async_setup_entry`, so a reload won\\'t do anything as I understand it. Ok. Why do we do a major version bump? Can\\'t we do a minor version bump instead, where we add `\"product\"` and `\"firmware\"` but keep `\"description\"`? I\\'ve implemented a minor version bump. If there\\'s a reason for the major bump, we can always do that later. Why is the implementation of `async_setup_entry` removed? The old implementation did two things:\\r\\n\\r\\n1. `check_multi_pan_addon` which essentially started the Multi-Protocol add-on whenever it was installed. This has some problems, like if multiple SkyConnects are used, or if the user migrated away while still having the Multi-Protocol add-on installed. As we recommend dedicated Thread firmware nowadays, Multi-Protocol is seen as self managed (the user should control the add-on, e.g. make sure it is configured to auto start etc.).\\r\\n2. The USB scan created a ZHA discovery for the Multi-Protocol add-on. For now, the user will have to manually configure the ZHA integration when using the Multi-Protocol add-on. The plan is to add a hassio discovery to make this process automatic again, so it will be quite easy again to install Multi-Protocol.\\r\\n\\r\\nSo essentially, for the current focus on Thread/Zigbee, these Multi-Protocol related things are no longer required. Since this class is only for installing SkyConnect firmware, maybe we should name it accordingly? This comment does not seem relevant, we bail out at the beginning of this method if the correct firmware is already installed? I don\\'t understand what this means. What does stalling addon startup have to do with detecting what firmware is on the device? By design, add-ons which are used by Core have the startup type `service`. This means the Supervisor starts them before Core. And conversely, this means the add-on might already use this particular radio, and we should not talk to it as it would interfere the add-on\\'s operations!\\r\\n\\r\\nUnfortunately, we don\\'t have a global serial port management (yet), so we have to query the usual suspects manually here. OK, I see, that explanation is clearer. Can you make a suggestion which makes the comment equally clear? This seems non deterministic since the zha config entry may or may not be loaded when this function is called. Could we make `zha` an after_dependency of this integration? Or check if the config entry is enabled instead of if it\\'s loaded? Why do we not just jump straight into the `pick_firmware` step? Why do users need to confirm first?  I don\\'t think that we should confuse the user with words like \"border router\" and \"coordinator\".\\r\\n\\r\\nMaybe something like\\r\\n\\r\\n- Use for Zigbee\\r\\n- Use for Thread (this includes Matter over Thread) Why would we tell the user this specific? Can we just say that we\\'re updating the ZBT-1 to the latest version?  And if that includes installing add-on, installing the actual firmware or removing the add-on. That doesn\\'t matter for the user. The user sees it as a single thing. ',\n",
       " 'supported should be used to determine if the unifi object is in a state to report the relevant information. If the data is always expected to exist then supported can be omitted and it will always be True\\r\\n\\r\\nAllowed is the proper one to check configuration settings supported should be used to determine if the unifi object is in a state to report the relevant information. If the data is always expected to exist then supported can be omitted and it will always be True\\r\\n\\r\\nAllowed is the proper one to check configuration settings',\n",
       " 'This could be set in _on_static_info_update Thank you! ðŸ»',\n",
       " \"This line raised an error:\\n\\n\\n\\n(Positioning failed and so my roborock created a new map) that should be self.coordinator.maps.get(self.coordinator.current_map) will fix. Thanks for testing! Out of curiosity, did you just see this PR and decide to test? Yeah, there is this checkbox when you submit a PR, that encourages to review 2 other PRs and as I own a Roborock, i thought that could be my first review :D (still need to review another PR though) what's this for? tbh - I don't typically create an entity without a description - I just assumed it needed the key specified, does it not? the `key` of an `EntityDescription` has no use other than for identification. Integration use it in their unique_id and stuff I don't like the implementation of the new sensor, as it is dependent on the image entity.\\r\\nThe new sensor will never update if the user disables the map image entity.\\r\\n\\r\\nEntities should not depend on each other to work. Unfortunately it has to - there is no where else that contains this information other than the map parsing. I'm not sure how I could avoid dependency. \\r\\n\\r\\nI guess I could potentially move the logic for getting the map and parsing it to the coordinator? And then the image would just have to grab from the coordinator? Would that be better? That would be a better solution indeed. The nice thing about coordinators, is that they stop working if no listeners (entities) are active as well.\",\n",
       " \"Added Sorry, I accidentally commented on the wrong line and, the `wait_background_tasks` should be a parameter for the `async_block_till_done` Noticed after committing your code but didn't had time to fix it.\\r\\nThx ! I'm not sure if `Motion active` is a clear term for the end user. Maybe `Motion detection` would be better. What do you think? Done\",\n",
       " 'Set this as class attributes (outside of `__init__`) instead of instance attributes',\n",
       " 'To be consistent with the other services registered here, this string should be \"partymode\" Please rename to partymode so that the function name is consistent with the service name. While this looks like it will work, we shouldn\\'t have to do anything.  The mock should absorb the service call and then report whether it is called via sock_mock.partymode.call_count.\\r\\n\\r\\nThere are other example is test_media_player.py\\r\\n\\r\\n Remove the trailing comma; this is why the format check is failing., Imports need to be sorted alphabetically, running black will fix.  So this needs to be moved in front of\\r\\n\\r\\n Here i think you have a formatting problem.  There should be one blank line at the end, are there?',\n",
       " 'Please use the websocket client instead to test this API. Example:\\r\\n\\r\\n#L17-L62',\n",
       " \"As mentioned on discord can we cap this if it's a crazy amount of hosts Added `MAX_RESULTS` and have set to 12. Seems we're not using the `nameservers` in init so I guess you can move the results[0] here too to make it consistent. I've updated the QueryResult class so we can initialise it with an IP which should be cleaner. Sorry for coming back late on this one but could we change the attribute to `ip_addresses` and then also add a translation in `strings.json` ðŸ‘ \",\n",
       " '`select`? Hah, its wrong in the file I copied from too.\\r\\n#L15\\r\\nFixing this now. What is `abc-123`? Unique identifier for the wall connector. Doesnt need to be redacted.',\n",
       " 'You shouldn\\'t need the `cast` here since it already occurs in `simplisafe-python`: #L255-L265 Don\\'t nest thisâ€”make this service a top-level one inside this object, then do the service registration in `async_setup_entry`. That\\'ll be consistent with other integrations. Same. If we don\\'t know whether this integration supports indoor motion cameras, too, why not avoid subclassing and just put this all in a single class? We\\'re registering a service for every camera? Well, this does not error, but it does not work either ... my handlers do not get called.  Can you suggest something else I could try?:\\r\\n\\r\\n My service handlers need a \"self\" that points to a specific camera. `self` will be provided by the entity platform. Take a look at how RainMachine does it. Here\\'s where the services are registered:\\r\\n\\r\\n#L182-L196\\r\\n\\r\\n...and here\\'s an example where the handlers are registered:\\r\\n\\r\\n#L348-L357\\r\\n\\r\\nCrucially, note that I don\\'t register the service for every entity. I believe I am following that pattern exactly, but my handlers are not being called. What calls this method? Also, we should unregister the services when unloading the config entry, not when destroying a singe camera. Why don\\'t we use `self._websocket_events_to_listen_for`? `EVENT_CAMERA_MOTION_DETECITED` is not included in `WEBSOCKET_EVENTS_REQUIRING_SERIAL`, does it mean every camera will trigger when there\\'s a motion event?',\n",
       " 'I filled `REGISTRY` based on entry points. (For those who don\\'t know, I authored  Entry points have names, I intented HA to use the entry point names instead of class names.\\r\\n\\r\\nAlso, this looks identical to `REGISTRY_HASH`. ah yes, I am learning python (I am an ex-java dev) and did not realize the entry points could be used that way. You are right, then this hash is redundant. \\r\\nI am willing to try to improve it (to learn) but cannot get to it before this weekend. I pushed some changes to do as you suggest Won\\'t `invset` remain empty for people who would upgrade to a HA version which includes these changes?\\r\\n\\r\\nEither use\\r\\n- `entry.data.get(CONF_SOLAX_INVERTER, REGISTRY_HASH.keys())` or `(entry.data.get(CONF_SOLAX_INVERTER) or REGISTRY_HASH.keys())`\\r\\n-  or implement `async_migrate_entry()` yes good point\\r\\nasync_migrate_entry() is a good approach - I did not know about this callback\\r\\nthen I guess I can do this and test it. Not before the weekend :)\\r\\nIf you already have some code, happy to reuse. You are unconditionally providing the `inverters` kwarg, `discovery()` could receive an empty set this way. `discovery()` will use the `inverters` value if provided, even if empty. If that is what you intented it is fine.\\r\\n\\r\\nPS. What I envisioned was to have `entry.data` store one solax entry point name, not an iterable of names. Again, I would prefer using `importlib.metadata.entrypoints()` to build this dict since I consider those keys more stable. I made the change in the latest commits, see if this looks better? Not that familiar with `voluptuous`, it prevents `data[CONF_SOLAX_INVERTER]` from being en empty iterable, right?\\r\\n\\r\\nI would prefer passing `return_when=asyncio.ALL_COMPLETED` to `discovery()` here and making sure the set it returns contains only one inverter / only inverters of the same class. not sure I understand?\\r\\nwhy not FIRST_COMPLETED? The problem with my inverter (X1HybridGen4) is that it crashes randomly when going through the full discovery. Ideally I want the discovery to stop as soon as one class works (and only the one I configure in the config_flow)\\r\\n\\r\\nI could test both approaches on my installation (this weekend...) I should have fixed the main cause behind the randon crashing during discovery in 3.1.0. But since [X1 Mini V34 can also handle the response from an X1 Boost](#issuecomment-1646691601) it would, in my opinion, be best to detect such cases and have the user deselect X1 Mini V34 in this example. I forgot to mention I only want to use `ALL_COMPLETED` only during initial configuration / [reconfiguration]( In `async_setup_entry()` I want to use `FIRST_COMPLETED` and pass it a single Inverter class. ALL_COMPLETED does not work on my installation, I get timeouts with the following code I use to test the upstream solax library:\\r\\n`    inverters = loop.run_until_complete(solax.discover(\"solax.home.arpa\", 80, \"XXXXXXXXXX\", return_when=asyncio.ALL_COMPLETED))\\r\\n`\\r\\nI think my inverter (X1HybridG4) crashes in this case. With FIRST_COMPLETED it works.',\n",
       " \"The reason the scan interval is only once every 10 minutes is because of the limitation of the Switchbot API to 10000 calls a day: #request-limit\\r\\n\\r\\nCalling the API every 600 seconds means that we can have up to 10000 / 24 / 6 = 69 devices (only for polling, we also want to actually control the devices so the actual number of devices we can handle is reduced, devices not requiring a feedback like IR devices are fine).\\r\\n\\r\\nCalling the API every 30 seconds means that we can only have up to 3 devices.\\r\\nWith only 1 lock, it means that just for polling, we are using 2880 calls, for 2 locks, it is 5760 calls.\\r\\n\\r\\nSupposing that a house only have 1 lock, using a lock with the current settings leaves 7120 calls, meaning up to 49 devices with the current scan interval. We are supposing that we are not controlling any device.\\r\\n\\r\\nI believe the best solution is to add the ability to receive pushes from Switchbot. I fully agree with the reasoning regarding the poll intervals. If there is any way to hook into the Switchbot webhook system from a Home Assistant integration, I'd be happy to implement it. From my understanding of the API, it isn't easy to facilitate, since it would require the Home Assistant server to be reachable from the wider internet (and have a somewhat IP address/DynDNS setup). If there is some native integration available for this, please let me know and I'll take another look.\\r\\n\\r\\nAs an alternative/immediate solution, I would suggest setting the default intervals to 600 seconds for both locks and other devices but expose this setting to the user. I'm indifferent to whether it should be configurable per device or per device category, but I think it does make sense to have some things like locks be updated on a higher frequency. I am sorry, I do not have the knowledge about this, let us ask @joostlek as he often reviews this integration if he has an idea, @miterion Seems like [laurence-presland]( found a nice way to handle it  in  > As an alternative/immediate solution, I would suggest setting the default intervals to 600 seconds for both locks and other devices but expose this setting to the user.\\r\\n\\r\\nWe don't allow exposing/modifying the scan interval. They should be set to sane default values.\\r\\nIf the user wants a short update interval, they can use the service [`homeassistant.update_entity`](#service-homeassistantupdate_entity) \\r\\nWould avoid code repetition. Please split the dependency bump into a new PR as we require that the PRs are as small as possible.\\r\\n\\r\\nKeep this PR in draft until the other one is merged. The advantage of splitting is that it allows us to ship dependencies bumps in patch releases. \\r\\n\\r\\nNot needed as the lock don't sets `SUPPORT_OPEN`. See  How come we optimistically set this here? Do we know the command succeeded if `send_command(LockCommands.LOCK)` did not raise? If not, should we request a coordinator refresh instead? Essentially yes, at least from my local tests this command will raise an exception if the locking/unlocking fails for any reason. Same comment We should not touch internals here Removed Why do we fire this event? I copied them from another test, seems like they are not needed; removed\\n\",\n",
       " 'Process fetch service call. We could also put flags similar to  in the service call and return only the selected items. My aim is only to return text and some basic items as the rest can be retrieved from the event info. Further the info needs to be serializable. Maybe this should become an async context manager since its used in quite a few places? May you have an example on how that can be done? Then I can open a PR for it. BTW it is intended to have a seperate session for the service calls apart from the base service of imap integration it self',\n",
       " \"We prefer to have the entities under the `tag` domain, please move the entity class to `__init__`. How can the user make use of the device id attribute?\\r\\nAlso, maybe instead of calling it `device_id`, I think it should be clear from the attribute key it's the ID of the device which scanned the tag. > How can the user make use of the device id attribute?\\r\\n\\r\\nAs also noted in the tag documentation you may want in an automation to have different actions depending on the device that triggered the tag.\\r\\n\\r\\n> Also, maybe instead of calling it `device_id`, I think it should be clear from the attribute key it's the ID of the device which scanned the tag.\\r\\n\\r\\nNot sure what it should be called then? `device_id` is already in the documentation with an explanation #tag-scanned-events Yeah, but with a `device_id` key inside a `tag_scanned` event, there's context which is lost when the device id is a state attribute.\\r\\nI think the attribute should have `scanned` in its name, for example `last_scanned_device_id` or `last_scanned_by_device_id`. Makes sense ðŸ‘  This sets the entity to `unavailable` because the entity is in the entity registry, then, just below, the entity is removed - twice - from the state machine.\\r\\n\\r\\nThis all seems odd, what do we actually want to happen when the tag is removed? With the current code, the entity will be back after a restart of Home Assistant, with the state set to `unavailable` because the entity is in the entity registry.\\r\\n\\r\\nIf we want the state to be removed, we should remove the entity from the entity registry instead of removing it from the state machine. Some copy/paste errors from previous attempts when this was in the entity itself. Corrected shortly These entities are not recorded in entity registry. Do we want that? Why does this default to the empty string instead of to `None`? Why do we default to the empty string for device id instead of to `None`? We should probably let the existing tooling pick the entity id This doesn't set the `entity_id`, this allows the integration to influence the `entity_id` picked by core.\\r\\nAt the same time, we should of course not do this unless it's needed. Right, but do we need this as isn't it nearly the same as what #L749 does already? Similar to `sun` this is not setup with `async_add_entities` so neither will it set an entity id nor will it run `async_added_to_hass()` We don't usually pass hass when creating entities as its gets set by `async_added_to_hass` See comment above. This is not run through entity platform helpers. \\r\\n Let's move this cleanup to another PR which does not add functionality Prel PR for cleanups is  We should not add more according to this pattern, instead we should use `HassKey`. This can be done in a separate PR which does other unrelated cleanup \\r\\n Why is this needed? If we get warnings about the entity being created without a platform, something is wrong and we should now hide it IMHO. Isn't it an error if we get an update for an unknown tag?\",\n",
       " 'Please don\\'t change the internals here. Guard with `has_service` instead Perfect, this answers my comment in the PR. Thanks :) (not sure what you mean by \"changing the internals\" though -- this function never behaved the way its documentation implies) The change to this function has been reverted and will be implemented in a separate PR. Change applied. This is going to have a completely different return type than if its not called with `return_response`.  I think this should be a different API Let\\'s chat about this in the architecture repo. The architecture discussion is approved, it\\'s OK to have a different shape of the data when returning service call response. Let\\'s not conflate directives to the service call with service call data, it\\'s enough with a query parameter:\\r\\n\\r\\n Sure, it was mostly for flexibility: depending on what the user is doing, it might be easier for them to change the JSON payload rather than the query string. Done, please take a look. We should return a dict with the response and changed states:\\r\\n Cool, that\\'s what I had suggested in the latest version of the architecture proposal. Done, please take a look and resolve if it\\'s all good. This looks like an unrelated formatting change ? Ah, that was probably Black auto-formatting the file because I had it open in IntelliJ. My bad. This looks like an unrelated formatting change ? \\r\\n\\r\\nboth sides are an enum Until `hass.services.supports_response` has been improved, let\\'s check the service exists\\r\\n Let\\'s restore this test\\r\\n Let\\'s improve the test to also check the response and status code\\r\\n\\r\\n',\n",
       " \"maybe it would make sense to add a `has_system_stats` to a device inside the aiounifi package? For now just make it a method as lambda shouldn't be multiline and I think this suggestion doesnt get short enough either\\r\\n I think you can skip device here, there are nothing else that can report cpu so I think cpu utilisation is name space enough :)\\r\\n\",\n",
       " 'Please define this as class attribute instead of disabling the pylint rule\\r\\nJust below `VERSION` add: `_entry: ConfigEntry | None = None`  Thank you for the helpful instruction! Use `async_update_reload_and_abort()` Will do. Argument would be the same (`reason=\"reauth_successful\"`)? That reason is the default so you don\\'t even need to specify it.  Should it be possible to change the username? Yes, as the user may change the username in the App as well. This isn\\'t needed in the user step so why we need to merge in credentials in reconfigure? I also added it for the user step (line 72).\\r\\n\\r\\nIt is not yet read in `async_setup_entry`, as I understood this should be added in a separate PR. Not sure I understand. If it wasn\\'t needed before why it\\'s needed now? I removed the lines in order not to withhold this PR. Still in `async_auth` Sorry, missed this. \\r\\nNot used? \\r\\nNot used?',\n",
       " 'These 2 can be merged now, as in, there is no technical reason anymore to split them Might as well just keep this one out of scope for the event entity Why is this a date? Is there a datetime data class equivilant? os should this technically be converted to a timestamp? I think timestamp is the way to go idem We can just make build a parameter for the `AzureDevOpsBuildSensor` and just pass that in together with the description',\n",
       " 'Side note: I think we need to add `\"repairs\"` as a dependency in the manifest. Hm good catch ',\n",
       " 'Thanks, applied all changes',\n",
       " \"\\r\\nYou can simplify that with a number selector.\\r\\nIn addition, the input should follow the model of the other services when dealing with temperature and take the temp argument in HA's configured units. See the create_vacation service, for example. For consistency, this service should take the temp in HA's configured unit and convert to F, in the same way other services do. See the usage of TemperatureConverter in create_vacation() I've implemented this, but I'm not sure I like it. Ecobee seems to pick the closest value. They allow changes in increments of 5F, and working in C it gets a little fuzzy and I worry that might introduce some instability. However - it works.  Thanks. This substitution is referencing itself.\\r\\nIn this case, since this is the only aux cutover service, the entity_id description could be a plain string describing what they're selecting. Something like; \\r\\n Looks like `aux_cutover_threshold` is no longer used here and can be removed. Thanks. If we know the current value, why don't we make this a number entity instead? That way, we do not need a service and we have an actual entity to work with.\\r\\n\\r\\nWe surely do not want to introduce more state attributes, especially when they are not needed to be introduced.\\r\\n Why not a number entity? Because I copied the code from the fan runtime. (SERVICE_SET_FAN_MIN_ON_TIME). I think this is because of the upstream library? Iâ€™m very much learning how this all works (python and HASS) so my apologies if itâ€™s obvious. \\r\\n\\r\\nI donâ€™t have the ability to test this code for a little while.  > I think this is because of the upstream library?\\r\\n\\r\\nThe code shows the upstream library has the features.\\r\\n\\r\\n> I donâ€™t have the ability to test this code for a little while.\\r\\n\\r\\nWell this is not about testing, but about implementing a number platform for this integration.\\r\\n\\r\\nWe, unfortunately, cannot accept the PR in the with the current implementation, simply because we are moving away from state attributes for cases like this.\\r\\n\\r\\nWould you be able to implement that?\\r\\n\\r\\n../Frenck Iâ€™ll give it a shot. I suspect thatâ€™s a whole new PR what with updating documentation. \\r\\n\\r\\nThe principle is that the aux heat threshold shows as a wholly different entity as part of the overall ecobee integration, instead of a property on the climate entity, correct? Similar to `sensor.home_assistant_host_os_agent_version` in the Supervisor integration for example. Yes, except the example you gave is the `sensor` platform, in this case I'd expect the `number` platform to be used (as sensors are read-only, while this aux heat threadhold can be set as well).\\r\\n Number Entities are the way to model read/write numerical data.  This is the same feedback provided in April.\\r\\n\\r\\n#issuecomment-2041280235\",\n",
       " \"\\r\\n\\r\\nCan the current humidity be `unknown`? In that case we should return `None` or we should change the return type. We don't want conditions in tests. Please parametrize the test instead. Thnx, missed that one. You are right: \",\n",
       " '\\r\\nIs `async_create_task()` required? I am unsure if its required, but this is how its done in adobe, airvisual, apple_tv, cloudflare, and so many others. Testing to see what difference it makes now. This has been removed. Is this not already covered with test_reauth_errors (in particular lines 181 ff.)? The intent of this test is to cover when everything goes right, the intent of `test_reauth_errors` is to test when something goes wrong. I dont know if there are any conventions for this, but in my mind, if `test_reauth` fails you know its an issue with the reauth logic, but if `test_reauth_errors` fails its in the reauth error handling. Agree and I also don\\'t know if there is convention how to do it. My approach was that if the error-test passes and you get 100% coverage, all should be fine and you need no additional test. A wise @joostlek once told me \"I hope you\\'re not just writing tests for coverage\", which I usually am, but in this case the success test isnt just for coverage, it\\'s for testing the users expected path, the success case.\\n\\nThe reason the failure tests also resolve to success is because that\\'s a Home Assistant unwritten best practice. No need to stringify as it\\'s done by itself Use `self.async_update_reload_and_abort()` It\\'s only a test but change something here and not use the same config which is already in place in the config entry so we can see it changes Done Use the parameters. Not sure why this is here. @joostlek and I were speaking about this a few months ago, its a testing performance thing, using a for loop doesnt require the integration to be completely setup for each loop.\\r\\n\\r\\nI have no issues going to back to parameters instead. Oh no, I have both? thats a mistake As you made a comment tests are not only for coverage so I prefer parameters as it\\'s more realistic than having all errors in the same flow. \\n\\nI don\\'t think the advantage in performance is that significant it outweigh the use of parameters. ',\n",
       " 'In that case the sensor itself would also be unavailable I guess so maybe bail out early if the sensor is not available as then this service call won\\'t work either? True, with a bad config the sensor should never be available. @gjohansson-ST Is there a standard error to throw when a sensor is not available? I just came across `ServiceValidationError` but don\\'t know if there is a standard `translation_key` for example? I tried to look for something like that in the code, but could not find it. #exceptions\\nYou need to make the error yourself from that the sensor is not available.  Just re-raise makes more sense IMO\\r\\n This is not an OK way to test, use `pytest.raises` instead.\\r\\n\\r\\nEither split the test in two, one with the happy cases where we assert the service passes and one with the bad cases where `pytest.raises` is used, or pass in a context manager as parametrized test parameter; here\\'s an example of the latter: <#L532-L540>\\r\\n\\r\\nSplitting the test in two makes more sense since there\\'s no response to check in the bad case. Should raise `UpdateFailed` I think and we can remove the logging. Or perhaps better to use a try...except block in `async_update_data` instead as this method is also used by the new service. It\\'s a bit confusing to prefix with `SENSOR_` when the new service is no longer an entity service, Maybe just `CONNECTIONS_MAX` or `MAX_CONNECTIONS`? yeah, makes sense Why is this changed? was needed for the sensor service, but not anymore for a integration service --> reverted I think we should consider adding this to `homeassistant/const.py` to make services more aligned across integrations (in a separate PR though) will make a PR I\\'d suggest to have the translation key technical, `config_entry_not_found` This error message could see some improvement, maybe:\\r\\n`\"{integration_name} integration instance {target} not found\" or `\"{integration_name} instance {target} not found\" Do we want to say \"integration\" or \"instance\" here? I don\\'t mind whichever, but it would be nice if it was aligned across integrations. Switch to instance like for `mealie` I don\\'t like the word `instance` as it immediately sounds more technical but it\\'s nothing for this PR in particular. As discussed on Discord:\\r\\nEither the name of the integration should be translated, or we should inject the untranslated domain name here. As discussed on Discord:\\r\\nEither the name of the integration should be translated, or we should inject the untranslated domain name here. Coordinator already does logging so these should be removed (can be done in a separate PR) separate PR Why is default `date.today()` It should be some integer? Add test without limit provided by the user',\n",
       " \"Hi, as you are creating entities I don't think you need to create a separate device registry entry as it will be created from the entity. Generally it is better to create your own base entity in entity.py and set the device info there.  Then you derive from it in each platform. #automatic-registration-through-an-entity.\\r\\n\\r\\nAs I see you are planning to add the binary sensor afterwards you might as well create the base class at this stage. Hi @sdb9696 tanks for the review!\\r\\n\\r\\nGreat, I removed the separate device registry and defined a base entity to use in sensors and later in binary sensors entitites. A side effect of this change I made is that when reloading an integration, if there's any field of the device data that changed, like the firmware version, then that's not longer updated in the device page. I will research how to fix this. Did you get anywhere with this? The device info on the entity should be read when the config entry is loaded. Done, now the data is updated properly, thanks! These seem to only be used by the config flow so I'd suggest defining them at the bottom of `config_flow.py`.\\r\\n\\r\\nYou could move MQTTNotEnabled to `__init__.py` or maybe drop it altogether and just allow the error from mqqt to bubble up.  i.e. Do you know that problems coming from mqqt are always because it's not enabled or could there be other types of error that you're masking? Yes that's better. I removed the exceptions module and defined the exceptions where they're used. Regarding the `MQTTNotEnabled` error, you're right, there are other errors that may break the MQTT communication, like the broker being down, so I created a more generic` MQTTEerror` to show. I think this is only used by the device registration so should be defined where that happens, i.e. `entity.py` or `__init__.py` Yes, I moved those constants to the `entity.py` module. Do you need this wrapper or could you just create the library class directly elsewhere? No, it's not required. I simplified this by directly instantiating the library class where it's used. Could this live in `__init__.py` as it's not actually a device and it'd be easier to see what's going on in the one file. Yes, much better. I moved this to the `__init__.py`.\",\n",
       " 'What is the point of this? self.data is the old stuff right. Why remove devices lf we dont have any? this is to ensure, even after a restart of the integration, that we check if there are any obsolete devices in the registry left With the above change i think you should always run the cleanup. the condition `(not self.data.devices and not self.data.templates)` will only match on first coordinator data fetch, because there are no previous data, but we already collected the current/new data, so we are able to check the device registry for orphan entries ... on every upcoming coordinator data fetch, we only check for orphan device registry entries, if there are no more existing `devices` or `templates`. Ok. I would probably just always do a check on first refresh inside async setup instead of coordninator. But okey. mhhhh ðŸ¤”  sounds reasonable ... will add a async setup method to the coordinator ðŸ‘  I think there was some proposals for a init method for coordinator. Called only on first refresh. Not sure if that got merged yet.\\r\\n\\r\\n b4decb18b3da2b4f26d4cf189be0341166747e77 Pre calculate the accepted set at the start of the function so you dont need to redo that.\\r\\n\\r\\n\\r\\nThen you should be able to do:\\r\\n\\r\\n\\r\\n efa950af8385ac222d5124b9829647e88f73bcff available ðŸ¤¦ thanks ðŸ˜ will create a PR soon',\n",
       " 'Please use lowercase variable names',\n",
       " 'Should we really allow to turn the heater off by setting target temp to 0?\\r\\nIt\\'s not really logical + we can already turn off by `turn_off` or by `set_hvac_mode` This is inside the async update, so testing for target temp equal to 0 is testing if the heater is turned off. That is how the heater API reports that the heater is off, by reporting target temp equal to 0.\\r\\n\\r\\nIf you look inside set_hvac_mode, the actual way it is turned off is by setting target temp = 0 (line 167) Yes, I looked incorrectly. Thanks @gjohansson-ST Here you can see how the heater is turned off, by setting target temperature 0. This is simply how the local API of adax works. The way I discovered this was by physically turning of the temperature on the device (by pressing down arrow until the display reads \"-\") and discovering that it was returning target temperature 0. \\r\\nUse Ã¬cons.json` to set icons for states The non-local AdaxDevice longer up in the code still uses attr_icon, look at lines 125-132. Therefore, I have implemented it the same way. I suggest to accept this non icons.json for now for consitency, and then rather move to icons.json for the entire file as an improvement in the future? I guess we need to change both at the same time so it would be great to see a folow-up PR to fix that ðŸ‘  The non-local AdaxDevice longer up in the code still uses attr_icon, look at lines 125-132. Therefore, I have implemented it the same way. I suggest to accept this non icons.json for now for consitency, and then rather move to icons.json for the entire file as an improvement in the future? There is a bug in the code that I discovered through this suggestion.\\r\\n\\r\\n self._attr_target_temperature is keeping track of the temperature when the heater is off (i.e. when the heater is reporting 0), so that when it is turned on it is turned on at the last set target temperature. Will make a new commit that fixes this. Not familiar with this coding style. Presumably it sets target_temp inside the if-statement and uses that down the line? If it is only cosmetic I am fine with the change. It assigns a variable as it computes the statement and hence we can use it further down the code.\\r\\nSee for some explanations ',\n",
       " \"Why do we remove this? It isn't used anymore since the unit tests moved to snapshots a few months ago.\",\n",
       " 'You could move this inside the if statement and move both session.close to on finally clause We should not close the clientsession we got from Hass, this is a shared session :) Ah, OK. I closed the session as the unit test complained about an unclosed ClientSession. This should be removed, why wouldn\\'t you want to validate config Why is this block preventing the config from being validated? On line 38 it is `if user_input[\"check\"]:` Oh, okay, my bad. GitHub only showed  me lines 14-17, so I got a bit confused ðŸ¤¦\\u200dâ™‚ï¸ I could have been more clear. I thought it was clear it was about the utilization of the bool. I think it should be removed altogether  Oh, I was mistaken. This block should stay, as the inverter is only available when there\\'s sunlight. The user can disable the check, so they can set this integration up, even when the inverter is offline at the moment. I don\\'t agree with this, if the setup fails then you have no way to reconfigure it either and would have to remove it and set it up later on If you say so I\\'ve now removed the option and modified the test accordingly You should patch the lib instead of mocking http calls. The unit tests should also be way more complete. One for the happy flow and one for every bad one. But the example wanted me to create a test making sure the flow can recover from an error and it just wouldn\\'t make sense copying the failing part. Please look into sensor entity descriptions, it will decrease the amount of code duplications by a lot! Can you remove this Please change the domain to `apsystems`  Just to double check, is Sonnenladen in the loop that they are added as a maintainer of this integration ?  This is not used and can be removed\\r\\n stale comment Why is this total, but for `today_production` it is total_increasing?  Can device names be changed by the user? If so, they cannot be used as a unique ID.  Don\\'t override state, that\\'s managed by the sensor class.\\r\\n\\r\\n what warning are you ignoring ?  you can use existing `self._attr_native_value` property instead of creating your own property function Don\\'t expose the update interval to the user. That should be set by integration author. Are you not able to get the name from the device? How is it shown in their app ? If the app has a static name, we should adapt that too.  just hardcode the interval, don\\'t allow configuring it.  Don\\'t override internal methods. Either override `_async_update_data` or set `self.update_method`. ',\n",
       " 'Isn\\'t used anywhere, so this can be removed removed now \\r\\n\\r\\nYou already do a `await coordinator.async_config_entry_first_refresh()` in `__init__.py` which fetches already fresh data As the buttons look pretty similar, maybe consider create some press functions and extedn entity descriptions like e.g. `tailwind` The code structure is the same as in alarm_control_panel and binary_sensor, so I\\'d like to keep it the same within the integration if that makes sense. Honestly, looking at the binary sensor platform, i would advice to do the same change as well, since its a lot of code duplication that could be avoided I spent more than an hour this morning trying the other way and still don\\'t have it working.  I appreciate wanting to make the code better, but I don\\'t have that much time to keep working on it.  I hope we can move forward with the currently functional, though not fully optimized code. Can we bump this independently from adding the button platform? The bypass functions require the updated total_connect_client. We can bump this in a preliminary PR before merging this PR. This way we dont have PRs that do too much Moved to   \\n When can the serial number be None? Some of the other older TotalConnect hardware does not report a serial number.  The `zoneid` is unique (but just a database key).\\r\\n\\r\\n \\n Shouldn\\'t the device identifier be used in the unique id? The only thing that rests is to make a list of SENSORS, that contain a list of TotalConnectButtonEntityDescription (which is a class that extends ButtonEntityDescription and adds a `press_fn: Callable[[<type of location or Any], None]` attribute. And then just loop over that array when adding entities. Oh and please bump this in a separate PR Even when bumping is required for this PR to work?  If the \"bump PR\" gets approved later, the bypass functions added here will fail. This PR would fail without that bump, but they are usually approved waaaay quicker We should use translated names here idem This can now inherit the TotalConnectZoneEntity With inheriting that class, this class can be a lot smaller since a lot of code is already shared with the base entity. You could consider extracting the entity description like I\\'ve updated in `binary_sensor.py` with `SECURITY_BINARY_SENSOR`.  This one can now inherit TotalConnectLocationEntity and also remove a lot of its code since it\\'s already in the shared entity Instead of running tests like this, you can use `@pytest.mark.parametrize` and then you can create 1 test and have the data as a parameter. Please patch the library at the place where its used Please checkout the snapshot tests I added to `test_binary_sensor.py`. If you add it like that, you can run `pytest ./tests/components/totalconnect --snapshot-update` and it will generate the `test_button.ambr` files for you.',\n",
       " \"If they have multiple config entries this might not work since the service will already be registered Added a guard Integration services should be registered in `async_setup` since we want them to be available even if there's no config entry loaded. The service handler should handle a missing or not loaded config entry. See:  Services should not be removed on config entry unload. See: \",\n",
       " 'It might be a bit clearer to refer to this as a state map.\\n\\nIf I understand correctly, this is mapping states from the integration to states within HA, and the actual mapping to icons happens later with `icons.json`.\\n\\nInitially I was confused because I was looking for these strings in the MDI library.\\n\\nIf you agree, the same change might apply to the docs PR. What do you suggest for a name?\\r\\n `STATE_MAP`? Done! :)',\n",
       " \"According to the diagnostic dumps, this is not a sensor but a setting. Shouldn't it be a number entity instead? These seems configurable and thus shouldn't be a sensor? The are exposed as functions according to the diagnostic dump provided in the linked issues. Same as above, should this be a number entity?\",\n",
       " '\\r\\nwouldn\\'t something like this be enough?\\r\\n Sure, I didn\\'t see this suggestion in the stack overflow link you provided, I went for the accepted answer. xD\\r\\nBut 32? Isn\\'t it too much?\\r\\n\"The argument for token_urlsafe is number of bytes. On average, one byte is 1.3 characters (base64 encoded)\"\\r\\n\\r\\nSo 32 will generate a 42 characters password.\\r\\n\\r\\nMaybe 15? That will generate a 20 characters password. I just copy pasted an example on the phone, you seem already to have read more about it so whatever you see fit and usable Gotcha! \\r\\nI think this is more explicit, change sounds like something that can take an input, not sure if regenerate is the best word but it shouldn\\'t be change :)\\r\\n\\r\\nShould also be reflected in key and unique id You are totally right, my mind focused on \"change\" because of the old service I created. I like regenerate. This fits better with the specific test. This function is mostly to make the integration setup easier Ok',\n",
       " \"Copy paste?\\r\\n Yeah! ðŸ˜… Provide a `supported_fn` that validates `x_passphrase` is reported, this would otherwise fail on non-admin accounts Is this related to my previous question, to circumvent the sensors not passing requires_admin=True? You need the supported_fn to make sure there is a value  I've performed a test with a non admin account, the x_passphrase attribute is still returned but with value `None`, so it's shown `Unknown` as value in HA interface. This means it wouldn't fail, but still I've created the async_get_password_supported_fn to guarantee the `x_passphrase` is present.\\r\\n\\r\\nP.S.: I didn't check for the value itself because a Guest WLAN might have an empty password, in this case the sensor will still be shown.\\r\\n\\r\\nWhat do you think? Make supported_fn be x_passphrase is not None then > Make supported_fn be x_passphrase is not None then\\r\\n\\r\\nDoing so will make the sensor for WLAN Guest with no password not be shown as well, even for admins, and I think it should be shown, that's my point.\\r\\nI know a sensor with no value isn't important, but maybe it doesn't have a password now, but will have, and this sensor can be used in some automation, I don't know. Do you get my point? Every restart that will be reevaluated so I think it's fine. Why show a sensor with no value hmm.. ok then! This will always return true as it's a property method #L288\\r\\n\\r\\nYou can probably make this a lambda in the entity description if it fits on one line Done!\",\n",
       " \"Assuming `_on_update` is being called when the device state changes, it would probably be better to assign `self._attr_available = self._unit.is_available()` in there? See #entity-class-or-instance-attributes â€“ your call though, this looks otherwise good to me.\\r\\n\\r\\nBtw, it's a good practice to use properties instead of methods for information that do not cause I/O, this makes it easy to see if something is safe in contexts where no I/O is wanted. So you could do something like this in your library in the future, no need to change it for this though.\\r\\n\\r\\n``\",\n",
       " \"Should the group only support HVAC that are available for all climate entities? Done Should the group only support swing modes that are available for all climate entities? Done Should the group only support fan mode that are available for all climate entities? Done Should the group only support presets that are available for all climate entities? Done Should the group only show supported features that are available for all climate entities? Done Would we not get this from the entities? I don't see why the user should configure it? Done Why would we not just call `async_update_supported_features()` directly which would set `_attr_supported_features`? Because as other group implementations, this dictionary is holding the entities in the groups that support each features or service, and then use to just call the service on top of the entities that support the feature (rather than call the service on top of all entities in the group). If it's unavailable we can probably bail out early? Checking at the rest of group implementations there is no early return in case the entity is marked as unavailable. Also conceptually, availability and working attributes of the group entities are independent attributes (if unavailable the entity should not be marked as not having any other attribute). On this one and remaining below. Should we really return the most common one instead of having a sort off priority of states?\\r\\nExample: One is heating and two are off. Should we then not return `heat` instead of `off`? HVAC modes used as state of a climate entity can be seen as an binary state with multiple ON states. Here the logic is filtering out the negative stats (OFF, UNAVAILABLE) so if any entity state is active (or ON state) those values are taken into account. Then similarly on how some enums attributes are being aggregated across entities in other groups, taking the most common enum value has been the consensus at the moment. Ok. So perhaps I took a bad example so let's do another one.\\r\\n3 entities, one is `heat` and two are `fan_only`. With your logic the group state would be `fan_only`.\\r\\nIs that really what is wished here instead of returning `heat`?\\r\\n\\r\\nBtw: Don't resolve until we agree, it's annoying to have to unresolve to continue the discussion  > 3 entities, one is heat and two are fan_only. With your logic the group state would be fan_only.\\r\\nIs that really what is wished here instead of returning heat?\\r\\n\\r\\nYes that was my intention since the beginning. I think the logic behind of why `heat` might be more important than `fan_only` could be driven that could be a more costly mode. This issue was raised on the discussion of the original  docs PR: #discussion_r973765098\\r\\n\\r\\nThat being said, I believe that most common mode might be the fairest approach as ranking can be really hard to do. `heat` might be ranked higher than `cool` or `fan_only` on colder countries, while it could be the other way around on much more hot countries. This can be a matter of perspective depending on how costly each mode is on different climate environments, therefore having a more uniform approach looks the right solution to me by taking the most common mode across all working modes (excluding `off`).\\r\\n \\r\\nI suppose something like this should do? (and the `merge_modes` function is not needed?) Note that `find_state_attributes` would return a list (one entry for each state) of lists (with all the modes). The suggested changed would yield a list of lists (note that lists are hashable and can be used inside a set). For that reason the logic `list(set().union(*modes))` is used. Wrapped it in a simple method for readability purposes given that it is also being used multiple times. Right, my point was more that this needs to be able to be set as an empty list.\\r\\nNow if nothing comes back it will just skip it and `swing_modes` will be the previous list. Done I wonder a bit about this one as we can send temp-range to entities which doesn't support it.\\r\\nShould we not be more explicit about only sending what is actually supported? Given that we are at the end calling the same method/service for all entities with all data (target value and range), each entity implementation would consume the values it needs ([example](#L703-L707)), we can have here a simple logic that would call the same service with all the available data to all the entities in the group I don't think you entirely understand my point.\\r\\nLooking at `sensibo` as example it doesn't support `target_range` and therefore it would raise if you call it with range values, see #L321\\r\\n\\r\\nI don't think that's very user friendly Agreed that would not be very user friendly, but I would argue that here we are talking about a more fundamental API problem. Having a method that contains a freeform of arguments being passed (through the `**kwargs`) without any guarantees about which parameters are being passed independently of the supported features of each entity type, leads to individual implementations handling their optionality in different ways.\\r\\n\\r\\nWith some [search]( you can see that there are different implementations handling the presence and missing of parameters in different ways:\\r\\n\\r\\n1. If not getting the value you need, do nothing: [code](#L395)\\r\\n2. Silently raising a `KeyError` exception: [examples](\\r\\n3. Pass the target temperature value or `None` down the line to the underlying coordinator: [code](#L86)\\r\\n4. And others around how to handle the temperature range I did not went too far to dig in....\\r\\n\\r\\nThe point you just raise about the exception being raised would have also happened if we were to make a service call to a list of entity types and providing all parameters in the schema (at the end a group is doing that when its service is being called).  If we call a `sensibo` device with an `ecobee` with all parameters in the schema, we would get the methods called, but because [of this line](#L996) we would not be calling the methods to update the state in the state machine, which again is not very user friendly.\\r\\n\\r\\nMy point (and preference) here is that in an ideal world, logic should be simple everywhere rather than complex. Specific climate platforms should not raise Exceptions if not supported parameters are being passed, as well as the group should just forward whatever parameters have been given to all the entities in the group (more future proof in case the schema of the call gets extended).\\r\\n\\r\\nI can update the logic and make it more complex to take into account the supported features for each entity in the group so we make a targeted call for each entity, but this would not solve the bigger underlying problem that set temperature in a Climate entity ID already has and this change is not enlarging.\\r\\n\\r\\nLet me know if I should proceed with updating the logic.  I didn't see any preview method in the climate entity Added the preview and also test it\",\n",
       " 'Device class should be set to `distance` I believe  CI is also failing and needs to be addressed  fixed device class',\n",
       " \"If you're only going to use the values, why bother making the `BUTTON_TYPES` a dict? Probably copied that over from one of the other platforms where I needed it but you're right don't need it here thanks Why would it not be? Good question, I wanted to remove it but forgot icon translations Thanks! There are references you can use `[%key:common::action::connect%]` There isn't one for disconnect right? There is, just add `dis` Where can I find a list of these references?\\r\\n\\r\\nI can't find any reference to [%key:common::action::disconnect%]? Same for favorite Homeassistant/strings.json\\n\\nThere isn't one for favorites, hence I didn't include it in the code this comment is attached to Thanks! Thanks!\",\n",
       " 'nit: This comment about the special cases seems to be incomplete. Perhaps \"also exists **as** a resource\"?\\r\\nSame comment is also in three other places. Done ðŸ‘  nit:\\r\\n nit: \"an device\" -> \"a device\"\\r\\n nit: \"an device\" -> \"a device\"\\r\\n',\n",
       " 'I think the docstring should explain the special treatment of lists too I added a line for explaining the list treatment. The function returns the empty list *in case of any error*, is that wanted instead of erroring out? Why don\\'t we want to blow up instead? I changed this so it blows. I think we should fail on attempts to use `sort_by` when the response can\\'t be sorted This is already guarded that it needs to be a dict and also below it will raise if the key provided does not exist in the dict. Maybe we can be a bit more specific, perhaps `f\"Key \\'selected_key\\' missing from response\"` I find it hard to understand the expected test outcome when the input is in the test and the expected output in a different file. I\\'d suggest to keep the expected output here, or have both input and expected output in a separate JSON file accessed with the test fixture helper. Both response and render is now in the snapshot file (sorted) Same as above, we should probably fail if we won\\'t be able to pick a key Same answer as above Please add a comment explaining which lists will be given special treatment (why we require the length to be 1 and so on) Comment provided but I\\'m not entirely sure it\\'s self-explanatory enough for an outsider to understand ðŸ¤·\\u200dâ™‚ï¸  Please explain why we break out of the `for value_key, type_response in entity_response.items()` loop Provided explanation (as logic is handled below for when it\\'s not a single list with dicts.',\n",
       " \"Maybe you could use those states for the min/max temps:\\r\\n I tried making _attr_min_temp and _attr_max_temp as properties with those attribute getters\\r\\n\\r\\nbut pre-commit told me that I cannot do this :(\\r\\n\\r\\nadding setters for them didn't help...\\r\\nI looked at other examples and these fields are always constants. I don't know why... Use `def max_temp` and `def min_temp`, cf. `domestic_hot_water_production.py`\\r\\n\\r\\n`_attr_` prefix is the default one when it's static, however it should be common for all instances. done! thank you! \\r\\n\\r\\nLet's use the full name (if that is allowed by the pylint checks etc.) since your device is very specific. Does this state change? If not; please set the `attr_max_temp` in the constructor. I have just recently added those getters as @Tronix117 requested in #discussion_r1537705518\\r\\nOther devices that share the same controller_name can have different max_temp and min_temp than the one that I use.\\r\\nSo do I make them static or leave them as getters? :) Are these states present for your device? If so; you can retrieve this attribute or state directly in the constructor. These states are present on my device, of course.\\r\\n\\r\\nIs this what you mean? Yes!  Done. Sorry for my poor understanding, I'm a non-native English speaker and non-programming engineer :) Same \\r\\n\\r\\nYou should always return a valid operation mode, you can't just return the `self.dhw_mode` value. Can the fallback (in this case STATE_OFF) happen? Sorry, I saw no harm in returning a custom mode that is not supported by exactly this device. This device reports ManualEcoInactive for Manual, and ManualEcoActive for Eco, but there can also be Eco+ mode that can report something else, that I couldn't find out, or any other mode, that is not described in this particular device, but shares controllable_name with it. Any other mode not supported here would report STATE_OFF instead of the actual mode name. I will do as you say, of course. \\r\\n\\r\\nGood to not use other constants/enums, even though the underlying value might be the same (at the moment). um... there's no such field as PERFOMANCE in OverkizCommandParam. Than we should add it ðŸ˜‰. Using `STATE_PERFORMANCE` for both sides can cause unintended side effects when Home Assistants changes a constant. Small chance; but still good to have constants reflect the reality. Done  Waiting for pyoverkiz 1.13.10 prerequisite in HA core now, I guess. @iMicknl Ok, I'm tired of refreshing the overkiz manifest.json contents manually :) subscribed to its updates, but I can miss one, so if you happen to remember that this PR exists after you bump HA python-overkiz-api version - please ping me :) thank you @ALERTua will do! Let's try to get your PR in for next months update. Created \\r\\n\\r\\nDo you plan to make more contributions to the integration? Feel free to join our Discord  Is this required? You only use this once? I would just add this to current_operation function. Done You should import LOGGER from `const.py`. Sorry. Forgot to delete the logger after debugging. Done\",\n",
       " 'Please add tests which test also the other supported services I tried to add further tests but as in the [other pr](#issuecomment-2103223337) I do not know how to do that in the end. I removed the tests for now. This is not great, I\\'d suggest to open an architecture discussion suggesting to add FanEntityFeature.TURN_OFF + FanEntityFeature.TURN_ON\\r\\n\\r\\nAdding those should not block this PR though. Is it useful to log an error here? Maybe either fail the service, or set it to the lowest possible fan speed? done, rely on `percentage_to_ordered_list_item` You can not compare with is not here. You have to use != \\r\\nThe same applies to the other comparisons We can also show the active percentage in the Modes VENTILATION and SENSOR_OVERRIDE. The app shows also the four different values in this modes.  done Perfect. Can you change the comparison to `        if self._attributes[\"active_vicare_mode\"] != str(VentilationMode.PERMANENT):\\r\\n` because we have two different types of objects here. So comparing with is Not is always false. After your commit IÂ´ll give it another try.  During my test I noticed that the API sometimes needs several minutes to deliver the updated value after changing the fan speed. Is this due to the limitation of Viessmann or the implementation of the Vicare library? The API response cache is invalidated after a *set* command. This should pull the newest data from the API. But it\\'s known on other occasions that the API is not updating that fast:\\r\\n\\r\\n#L134-L136\\r\\n Probably we would need to have some kind of blackout period where the entity reads the values not from the api but *remembers* that it was set to a certain value. Same here: Should be `if self._attributes[\"active_vicare_mode\"] != str(VentilationMode.PERMANENT):` Please move the side effects out of the constructor for the entity and into the function that runs in the executor.\\r\\n\\r\\nWe want to avoid side effects in `__init__` Generally we donâ€™t add extra state attributes to new entities. They should instead be first class sensor entities with proper device classes and descriptions  For context: Unless, there is a good reason to keep them here (which generally only means they have no meaning on their own as a separate sensor). These are the causes of the effects bdraco is talking about Should this be handed into the constructor instead or rather handled in the `update` function? Removed for now, I maybe can add this as a real entity later on (this applied also to other platforms). Translations for the extra state attributes are missing As hassfest pointed out, these are not valid translations keys.\\r\\n\\r\\n The key in this case comes from the api, so I need some kind of in place translation here, right? Is there some helper available to do this? There is no helper for this. You\\'d need to define a mapping between API and HA in this case. There is a +- sign in the editor where you can directly do(suggest) the changes in the code.  I canÂ´t change the code directly in your pull request. ',\n",
       " '\\r\\n\\r\\nSince we have both sync and async code in this codebase, please prefix coros and callbacks that are safe to run in the event loop with `async_`  This one probably should be another PR though as it looks like the base class is expected it to be explicitly named Yes, this is a base class abstract method. It is more appropriate to create an independent PR. This can probably be a set, which would be more efficient.',\n",
       " 'I think \"user\" is supposed to be \"use\" here(?)\\r\\n thanks',\n",
       " 'Change reverted. [Casting is required](#step:9:28).  Can you get rid of the branching in the test? Not unless I stop testing the name of the camera or go back to a more basic camera entity name (which a lot of people complain about being confusing). The package camera channels are bundled in with the normal ones, so there is no really easy way to identify them other than the name of the channel.  I could abstract the core code I use to [generate the base name](#diff-b819c8e3744961cb309ae3feb57a14ebbfc3a62284a1aad26d16ec1109a6c33fR196-R198) and use it in both `camera.py` and the tests, but it would still have a branch regardless. That would be a bit better as it avoids the complexity in the test  It does not really change anything since the branching would just be moved from a test helper function to a shared helper function.\\r\\n\\r\\nThe branching is not actually in the test itself. ',\n",
       " 'It looks like the fallback changed from `https` to `http` here. Is that what you wanted? Yes, as I introduced that parameter just the other day, I realised when doing the tests here as the port would still be whatever configured before and that would mean \"http\" protocol I changed back to http in this specific case. Once its been populated it should always be known what the user has configured. I\\'m not sure why you just wouldn\\'t change the default in that case.\\n\\nIf the user is reconfiguring and hasn\\'t previously set the protocol, the default is http, but in all other cases the default is https?\\n\\nProbably I am missing something. Reconfigure should present the opportunity for the user to change the current configuration, thus it should use the current parameters unchanged. So either the case would be that the integration is set up without a configured protocol and it would mean http and whatever port currently configured or the user has selected protocol and its corresponding port and everything is ok.\\r\\n\\r\\nDefault for setting up new devices will be https and 443.',\n",
       " \"Is trouble a word used within the risco system? Yes, that's how it's described everywhere in the Risco ecosystem Would the battery low device class fit? From what I understand this means a general problem with the battery, either it's empty, or defective, or not working for any other reason. Not sure if that fits the Battery class, but happy to change if it does. I think keeping it this way best reflects the risco use case ðŸ‘ After looking at a couple of Risco docs, this is usually described as low/no battery, so I'm going with your suggestion Please add entity translations and add icon translations Since these are the names by Risco, does it make sense to translate them? I think it still adds to the user experience. When a French company creates an integration we also translate the names to English in the code and back to French again via translations. Otherwise your English dashboard would be polluted by French names. I think the same can be said the other way around here. We usually just create one list and extend that and pass it to the function. Not a blocker, just wanted to let you know \\n\",\n",
       " \"In a future PR it would be nice to make these named constants / enum so we don't have magic numbers here\",\n",
       " \"Both of these are always positive values? Yes, they should be always increasing in life. But it is still Enphase... This could be replaced with `attrgetter('energy_delivered')`\\r\\n\\r\\n`from operator import attrgetter`\\r\\n This could be replaced with `attrgetter('energy_received')`\\r\\n\\r\\n`from operator import attrgetter`\\r\\n Since this pattern is existing, lets adjust this in a followup PR and do them all at once\",\n",
       " \"Note, I excluded this line from code coverage as it covers a hypothetical future scenario where a user downgrades from a future major version to this version. Any test that covered it would be a work of fiction.\\r\\nIt is included in the first place because it exists in the [example developer documentation](#config-entry-migration) See #L238 as example on how to test this. I will do this, but the reason I didn't was that in a future major version, by definition, both the code and the config entry will be of a significantly different structure, so we are not actually testing anything 'real', and the in that context a passing or failing test will not add any clarity.\\r\\nBut either way I will add the new test. Implemented in [ed7237d]( \\r\\nAs there is no change it's not needed As there is a default in the schema there will always be something here so no need to use `.get()` to specify a default value Also below I will make the same change to the two lines above as well Removing the .get() defaults \\r\\n\\r\\nCauses test_form to fail\\r\\n Should we have a default here too so the user can't leave the field empty and thereby not get a value? I was following the lead of  where defaults were removed here.\\r\\n\\r\\nPresumably because they were unnecessary duplicates as defaults are defined here: #diff-f7e2ef265b774da4533e59e774aad087920f82fc97c3b9e7801f15537360bb5dR47-R51 You're probably right so let's not have the default in the schema for the options flow. Just have a check so if left empty we set it to `53`.  Isn't that achieved by: #L176-L180\\r\\nAs user omitted inputs are replaced by defaults? \\r\\n\\r\\nN.B this is not the same as Line 118 which is discussed in the thread above Tested at [c9e6f5b](\\r\\n\\r\\n\\r\\n\\r\\nAnd this scenario is indeed tested by #L249\\r\\n We could just use the same constant right? We could. I didn't because I couldn't find an RFC that said 53 is definitely the default port for IPV6 and its not a fully implemented standard so I wanted to give scope for things to be easily changed.\\r\\nThat being said, it wouldn't be hard to make the change in the very unlikely event it changes to something other than 53 so I will make your suggested change Done in [fabfea5]( \\r\\nA bit odd to use the parameter name only for the last one, also below for ipv6 \\r\\nNo need as we have a value always\",\n",
       " 'Why not use a [`deque`](#collections.deque). No trimming necessary. The list isn\\'t uniform. There is one system message followed by pairs of user and assistant messages.\\n\\nI could use a deque if I broke out the system message and made the list contain pairs instead... Oh right Why do we offer this to users?  Also not ask on initial creation, maybe even never. Unlike OpenAI, context window size is a factor you have to take into account locally.\\nModels like phi become almost useless with too much in the context, I\\'ve found. But how will a user know?  Looks like they can\\'t currently:  yuk We should not ask this on initial creation of the config entry.  Removed model options for now Not for this PR, but it should be interesting to explore if we can have an error message that is for humans, and an error message with tech details.\\r\\n\\r\\nDo you want your voice assistant to say: \"Cannot concatenate None + Str\" ?  Why copy this ?  With this, in the tests the mocked `client.chat` call args all had the same value because I append to the message history after the call. So every `call_args[\"messages\"]` had the full history instead of just the history up to that point.\\r\\n\\r\\nI figured this would be better than working around it, since the Ollama client could technically store a reference to the list for some reason. One day ðŸ™  Why do this?  By default, Ollama only keeps a model loaded in the GPU memory for a few seconds. From what I read, this is because people use it on rented GPUs and it costs them money. Since our goal here is local, it ends up just requiring a significant amount of time to reload the model if you don\\'t constantly use it. Don\\'t forget to also log this error.  let\\'s rename the integration to `ollama`. I don\\'t know why I added `conversation` to `openai` but let\\'s not repeat that mistake ðŸ‘  This can become 1 big if-statement no?  I don\\'t think that we should ask these in the first form. It should just be the URL. For model, maybe has 2nd step when we could query available models ? Or maybe we just defaullt to llama2 ?  \\r\\n  Should we allow changing URL? That is not an option but an authentication thing? This should be a reconfigure flow and out of scope for this PR. Booleans are numbers\\r\\n `from functools import cached_property`\\r\\n\\r\\n These should all be removed from initial user setup.\\r\\n',\n",
       " \"Please also implement `async_unload_entry` to allow a config entry to be removed without requiring Home Assistant to be restarted. Please change to use this pattern instead of storing in `hass.data`  I think this pattern means only a single config entry will be created? Should we not instead create one config entry per discovered device? The benefit of creating a config entry per discovered device is that it allows us to leverage zeroconf to update the IP address of the device. @dukeofphilberg can you rewrite this integration to be based on a single device per config entry. The pypi page does not link to the repo at  also the repo does not have tags for any of the releases. Is this something that can be fixed?\\r\\n\\r\\nThe repo has a [release workflow]( is that not used to make releases? Move this and the other constants which are used by the media player platform to media_player.py This will trigger on any UPNP devices, is it useful? Is it really user friendly to make the entity_id default to the UUID? If you don't set it, it will be a lower case version of the device name which seems better for users?\\r\\n\\r\\nAlso, set the unique_id to just the uuid please. Move these and the content type below to class level The way this is handled is weird, it's set to MUSIC here even though the media player's state is unknown. Then it's set to `None` forever if the media player is stopped Why do you set this? I don't see where such a device is created? If this log should be user visible, make it more descriptive. If it's intended for development, decrease severity to debug. Also set available flag to False.\\r\\n\\r\\n Please remove this comment, it's intended for the implementer of `async_browse_media` It is possible to browse the media through the LinkPlay API, though it is not implemented yet in the `python-linkplay` package. I'll remove it for now. Dispatcher signals are global. \\r\\n Set media player to track device name:\\r\\n This is not a web UI for users to use. So should not be offered.\\r\\n I don't know if it is specific to the media player I'm using, but when you browse to the endpoint you have several options to control the media player and its settings. \\r\\n\\r\\n![image](\\r\\n Can this raise a `LinkPlayException` ? If so, let's create a decorator around the command methods to turn those into HomeAssistantError All API calls raise `LinkPlayRequestException` on error so I'll re-raise them as `HomeAssistantError` ðŸ‘  Why guard this? What if our state is not up to date This does not seem to be able to discover a Wiim Pro that I have here for testing.  Which is another reason relying on zeroconf will be helpful. \\r\\n How often does this fire? We don't want to have the state updated all the time just because the time is elapsing. \",\n",
       " \"Same comment as was already linked, we should not ask for comma-separated input. That is not a good user experience. Ok, thank you. As Is aid, it's my first PR. I thought it was a good idea to implement it in the samw ay it's done in the API, the PVGIS tool and all other tools I checked when I tried to wrap my head around the horizon feature.\\r\\nI'm sorry for causing you inconveniecne. I guess I'll eventually figure out how to get this functionality into homeassistant in some other way.\",\n",
       " 'Nit, align wording with the one used in the more info page (\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       " 'Whoops no',\n",
       " \"\\r\\nDon't forget the walrus!\",\n",
       " \"This function shares a lot of code with `_find_referenced_areas` and `_find_referenced_devices`.\\r\\nCan we create one private function out of it and reduce the duplicated code?\\r\\n\\r\\nInto the new common function, we need to pass in `ATTR_FLOOR_ID` and `Script._find_referenced_floors` I've merged the floors/areas finding.\\r\\n\\r\\nI've not merge it with devices & entities at this point. While they are similar, they are different (e.g., handling of condition logic). I didn't want to put that refactor into the scope of this PR\",\n",
       " \"no need to redefine this, this can be imported `from homeassistant.components.lock` \\r\\nis this really true for every August lock? As in, some people might have doors that don't have a latch. You probably need to check if this is enabled for this lock in your library first We should only set this for devices that support open  Looks like we are missing coverage for these  Please bump this in a separate PR. Usually we ask it to be split, but only when there are no breaking changes.\\r\\n\\r\\nIt ok to bump in the same PR as there are breaking changes as there are new lock states that need to be handled \\r\\n Please don't change the common constants. If you need a constant define it in the August integration. This line looks like left over testing? use `pytest.raises` with a match here instead \\r\\n\",\n",
       " \"This looks unused\\r\\n Please remove commented code There is some duplicate code here. Please refactor the `LutronCasetaCover` to have a base class so it can share so we don't have duplicates actually i think this wasn't correct anyway, stop and tilt stop are separate methods Its unexpected to call `async_update` here... this may be an existing bug that was copied ..  will dig into this Looks like it does update `self._device` in the base entity class.\\r\\n\\r\\nThats a bit messy but an existing issue `ATTR_TILT_POSITION` is required so this can't be missing. Please remove the guard\\r\\n\\r\\n#L224 This guard is not needed since it can't be missing #L181\\r\\n\\r\\nThis is an existing problem though no problem I can clean it while I'm here Looks unused now\\r\\n\",\n",
       " \"We set the `self._attr_assumed_state = True` in #L124 which cause the frontend to display seperate Play & Stop buttons since we don't know the play state, when you know it, we should set it to `False` so the frontend will display the correct Play/Pause state.\\r\\n\\r\\nSee  for more information about it When a TV supports `foregroundAppInfo` does it support if or all apps or we need to fallback to assumed state if we don't get information? I am sorry this is slow and taking time I don't have a TV that reports this so it is hard to me to understand what we should do. It's supported for every streaming and media player app that I've tried (youtube, netflix, amazon, spotify, built in media player app, jellyfin), so I assume it is for all. The PR is still marked as draft, if I understand correctly it is ready for review? \\r\\nTo be on the safe side, It would be better to set it to True so if a source will not support it we fallback to assume state\",\n",
       " 'This looks wrong, if the swing_mode register do not respond, the swing_mode should be set to unknown or something similar, so the user sees the problem.\\n\\nA log entry would also be good, since it might be a bad configuration. @janiversen  Tried to fix it:    I removed the test against None because it seems that in case of missing answer, the bus answers -1. and it is never None. \\r\\n\\r\\nIf you like this way, later (other PR) I could apply the same also to fan_mode and hvac_mode.  This is not documented. Doc updated You need to test with all addresses in the configuration (check_config).\\n\\nWhat if one is a list and the other an int. @janiversen I was managing this request related to the function `def check_hvac_target_temp_registers`, function written at the time when no central validation of the modbus entities existed. I wrote that function to check if the new target temperature registers overlap with some.. \\r\\nNow, instead to fix that, I was checking how your function `def validate_entity` works, because **in my opinion** it could be the best way to manage also the conflicts inside the same entity. \\r\\nI found 2 main problems: \\r\\n1) that function doesn\\'t consider the possibility to have `[CONF_FAN_MODE_REGISTER][CONF_ADDRESS]` as list and `[CONF_TARGET_TEMP]` as list. \\r\\n2) it doesn\\'t recognize conflicting registers inside the same entity. I tested this also in my production server, updated at the last core. \\r\\n\\r\\nI may suggest to work only with  `def validate_entity` fixing the bugs and removing my previous function `def check_hvac_target_temp_registers` in order to simplify the code. But as maintainer, I kindly ask to you how you want to proceed. Thanks. \\r\\nLet me know.\\r\\n Check_config existed when you made your first modbus contribution, but you might have overseen it. the validate functions equally existed (but are now no longer inline functions).\\r\\n\\r\\nThis PR is about swing mode, so please do not mix a lot of other changes in that, make a new PR instead.\\r\\n\\r\\nMid term I am removing all voluptuous validators and add them to check_config, since this allows to create an issue and thus be a lot more user friendly. Ok. So, at this time I\\'ll improve `def check_hvac_target_temp_registers` only.. Then, we\\'ll see.  Fixed the case where swing_mode register is a list. ( `CONF_TARGET_TEMP` is always a list. \\r\\nThe goal of the function was to test only if `CONF_TARGET_TEMP` is overlapping with some other registers.. \\r\\nThis function and `validate_entity` will be fixed in a another PR to check registers conflicting into the whole entity.  Are you testing that a list only contains 1 entry. This piece of code is not related to this PR, anyway the list cannot have more than 1 entry because it is checked at line 313 `def register_int_list_validator(value: Any) -> Any:`  and a proper warning is raised. \\r\\n This need to be different for a list. Dear @janiversen , you\\'re right. But the same should be for ` loc_addr.add(f\"{hub_name}{entity[CONF_FAN_MODE_REGISTER][CONF_ADDRESS]}_{inx}\")` as I tried to tell you respectfully at #108906 (#discussion_r1467787468)\\r\\nSimilar (but not equal, because for hvac modes you could have duplicates) case in `loc_addr.add(f\"{hub_name}{entity[CONF_TARGET_TEMP]}_{inx}\")` . \\r\\n\\r\\nMoreover, IMHO it seems that the check_config and validate_entity work bad. In example, from line 537 of the test_init file:\\r\\n`[\\r\\n            {\\r\\n                CONF_NAME: TEST_MODBUS_NAME,\\r\\n                CONF_TYPE: TCP,\\r\\n                CONF_HOST: TEST_MODBUS_HOST,\\r\\n                CONF_PORT: TEST_PORT_TCP,\\r\\n                CONF_TIMEOUT: 3,\\r\\n                CONF_CLIMATES: [\\r\\n                    {\\r\\n                        CONF_NAME: TEST_ENTITY_NAME,\\r\\n                        CONF_ADDRESS: 118,\\r\\n                        CONF_SLAVE: 0,\\r\\n                        CONF_HVAC_MODE_REGISTER: {\\r\\n                            CONF_ADDRESS: 119,\\r\\n                            CONF_HVAC_MODE_VALUES: {\\r\\n                                CONF_HVAC_MODE_COOL: 0,\\r\\n                                CONF_HVAC_MODE_HEAT: 1,\\r\\n                            },\\r\\n                        },\\r\\n                    },\\r\\n                    {\\r\\n                        CONF_NAME: TEST_ENTITY_NAME + \" 2\",\\r\\n                        CONF_ADDRESS: 117,\\r\\n                        CONF_SLAVE: 0,\\r\\n                        CONF_HVAC_MODE_REGISTER: {\\r\\n                            CONF_ADDRESS: 118,\\r\\n                            CONF_HVAC_MODE_VALUES: {\\r\\n                                CONF_HVAC_MODE_COOL: 0,\\r\\n                                CONF_HVAC_MODE_HEAT: 1,\\r\\n                            },\\r\\n                        },\\r\\n                    },\\r\\n                ],\\r\\n            }\\r\\n        ],` \\r\\n\\r\\nHere the second entity is discarded because the hvac mode register of the Entity 2 overlaps with the conf_address of the entity 1 and it should be not an error, because they are 2 distinct entities.. \\r\\n \\r\\nIt is reasonable to think that the centralized_validation should be adjusted, don\\'t you think? \\r\\n\\r\\nPlease, advice me in case I\\'m missing something..   \\r\\n\\r\\n The central validation do take input_type in account, but NOT entity, and that is correct.\\r\\n\\r\\ne.g. A holding register address must be unique across entities. My bad, excuse me. The discriminanting parameter is CONF_SLAVE.\\r\\nI\\'ll add an if for the list. In another PR I\\'ll address the same wrong behaviour for `{entity[CONF_FAN_MODE_REGISTER][CONF_ADDRESS]}_{inx}\")` I have no idea what you say.....you should not the address as a list, that will not compare correctly against other addresses  [1] and 1 should both be added as 1 in order to detect if 1 is used by another entity,\\n\\nwe use slave+input_type+address as key Yes, undestood: \\r\\n Remove the \"else\" and define it before \"if\" that simplify the \"if\" section as well, and is less confusing. Apart from that I am not sure that SWING_OFF is a correct default ! because it will be missing in the the 2 mapping arrays ?? I think that it is not required to initialize the `self._attr_swing_modes ` and ` self._attr_swing_mode = None` in that phase, because at that time, swing support in not available, so the only thing to initialize is the register.  STATE_UNKNOWN is used later, so either None or STATE_UNKNOWN is not correct. Yes STATE_UNKNOWN is used later, but it is reasonable to think that STATE_UNKNOWN is correct also at that time, I suppose, because at that time the component doesn\\'t know its status yet...\\r\\nAnother way could be add STATE_UNAVAILABLE later, but only in case the pymodbus answers with a negative value, else it should be unknown.. But this latter makes the code more complex without a real adavntage, I think. \\r\\nSo, I initialize it as UNKOWN ',\n",
       " 'I think its reasonable to change the default in the future when not set, so perhaps not set this?\\r\\n\\r\\nAs an alternative: I am curious what you were planning to set the # of days? I was curious if we should just increase the default.  I saw this before at 7 and thought that it was pretty low. Not sure if it would solve your problem to increase the default and not offer this as an option.\\r\\n\\r\\n > I think its reasonable to change the default in the future when not set, so perhaps not set this?\\r\\n\\r\\nthis is just to add a value to the config entry options if there is no one, yet.\\r\\n\\r\\n> As an alternative: I am curious what you were planning to set the # of days? I was curious if we should just increase the default. I saw this before at 7 and thought that it was pretty low. Not sure if it would solve your problem to increase the default and not offer this as an option.\\r\\n\\r\\nThe default for YAML config is [1 day](#L70) and changeable by the user on demand.\\r\\nWhen configuring via UI, than we actually set 7 days which might be enough for many (_most_) of the users, but sometimes it is to less (_see #108003_).\\r\\nSo i thought to make it configurable again, would offer the most flexibility to the users.\\r\\nMy own use case is my birthdays calendar - i don\\'t have much friends, therefor not much entries in there ðŸ™ˆðŸ˜ so it happens that next date will be a few more days/weeks far Would there be a down side if we just set the default to 30 days? or 60 days? yeah, i think it might still not be enough for some users. tbh the link issue is the only one i know complaining about it, so i think the 7 days is already ok for most users. Maybe we should just mention the 7 days and the possibility to change it in the docs? one downside of statically increasing to 60 or 90 days, it might result in higher load on CalDAV servers, especial on well filled calendars ðŸ¤”  If we can find a default that works for most folks (e.g. 14 days, 30 days) that seems like it be ideal to not need extra configuration options. please don\\'t get me wrong, but why not give the user the possibility to change this on it\\'s own preferences or needs?\\r\\nSure, we can also increase the default to 30 which might be also good for most users, but also might increase the load on their caldav servers (_since more events might be returned_) and and their HA instances (_since more events needs to be checked which is the very next one_).\\r\\nFurther i think most users are already satisfied with the 7 days, since we we got only the one issue till now. My general impression is we want to not offer additional configuration options unless needed, and not necessarily support use cases that are far outside the norm. If we can find a balance of end user simplicity and performance then that would be ideal. If its not possible to find that middle ground because its too expensive, then its not possible i guess.\\r\\n\\r\\n(Perhaps bad idea: could also be adaptive (first try 7 days, then 14, then max 32 if no events are found).) @allenporter: I am the one who opened #108003 and I certainly would not call said garbage reminder once a month \"far outside the norm\". In fact, I initially was happy with the HA update that made the CalDAV integration available via GUI only to spend days wondering why my calendar did not work until I found out about this limitation of days which was nowhere documented.\\r\\nBesides: just because I\\'m the only one who opened a bug report does not mean numerous others also fell for this limitation and silently just gave up and reverted to the manual YAML way. If you read my above responses I\\'m not against solving this use case.  I just don\\'t want to add more configuration options. Instead you\\'d be surprised it didn\\'t work and have to hunt down a config option you didn\\'t know existed. We should just make it work for you out or the box with no additional action on your part.\\n\\nI\\'m in favor of solving this in a few ways proposed above... either increasing the limit (is this really an efficiency problem? I\\'m skeptical) or doing something adaptive and more efficient. \\n\\nHappy to be overruled here by other code approvers, that\\'s just my 2 cents. The logical solution would be the one initially supposed by @mib1185: an options dialogue letting the user decide how many days to check, maybe with a note that too many days might increase the server load (which of course depends on the infrastructure, overall number of calendars and individual entries to check and such). To top it: a separate days chooser for each calendar, maybe as simple as entities after the initial setup.\\r\\nAnyway, it should be emphasized in the docs that only one single day is taken into account. Currently, it is only mentioned in the [manual configuration steps]( and very easily overlooked, especially if someone uses the GUI integration and thus will most likely never get the idea to check these manual steps. At least that is what I did or better did not before I opened what I believed to be a bug report.\\r\\nI will happily update the current docs accordingly, but it seems more efficient to wait for the outcome of this proposed change to avoid the need to update the docs again shortly afterwards. :wink:  I\\'m still on the point, that having this option does not overwhelm our users, because it is not part of the integration setup phase (_config flow_), but can later be changed by the user if needed (_options flow_).\\r\\nAlso, as mentioned before, I think the default setting of 7 days is suitable for most of our users, so only a few users will need this option and then have it. Last but not least we could describe the options in the docs (_eq. we do in [AVM Fritz!Tools](#integration-options)_) - i\\'m happy to update the docs accordingly ðŸ™‚ \\r\\n',\n",
       " \"The total sensor, in general, is by far the most common sensor to use on the energy dashboard. Why is it disabled by default? Good point, I simply didn't want to flood the users with a bunch of new sensors. Considering this being a total, it might make sense to set the suggested unit of measurement to KWh? So we would need to convert here on the fly, right?\\r\\n\\r\\nDoesn't the energy dashboard do that in the end to have better readable values? > So we would need to convert here on the fly, right?\\r\\n\\r\\nWell, Home Assistant handles that. Just set the suggested unit of measurement property additionally to the native unit of measurement.\\r\\n\\r\\n> Doesn't the energy dashboard do that in the end to have better readable values?\\r\\n\\r\\nNo, this won't matter for the energy dashboard at all. This only affects the display of sensors. Ok, nice.\\r\\n\\r\\n\",\n",
       " \"We should instead import this yaml configuration and automatically create a new config entry from it. Check `streamlabswater` and `suez_water` for examples Although I like these steps, let's keep them for a followup PR Why do we only support one instance? You only have 1 step, no need to make errors a class variable I think you can just inline this into the flow instead of creating it a separate function. This will save you using the class variable raise a ConfigEntryError instead.\\r\\n\\r\\nIn the future we should create an issue of some sort for the user to act on. (I can assume that Rova will gain new areas and lose some areas in the future, causing existing setups to fail) Thanks, updated but added small change to pass tests (got a `UnboundLocalError` for `is_rova_area` otherwise) Why do we strip? Instead use `self.add_suggested_values_to_schema` \\r\\nDeprecation period is 6 months, let's aim for it to go in this release \\r\\nYou don't want to use the name for the unique_id since we want to use translation keys here and then name will be None Would this not result in a breaking change as `description.name` is referring to the values in `SENSOR_TYPES` (e.g., `sensor.[address]_bio` will change to `sensor.[address]_gft`? Unique id != Entity id, so unique id can for example be a serial number, while the entity id just a normal `sensor.device_something`.\\n\\nBut since all these entities are already in the entity registry, it won't change the name (but that's with entities with unique id, that is, so I expect it will change, but we don't consider that a breaking change) I'm missing a few strings. Cannot connect error and the text for the issues I'm missing the strip here Why the default Without default, when left blank/not provided by the user, it'll result in a `KeyError: 'house_number_suffix'` at `suffix = user_input[CONF_HOUSE_NUMBER_SUFFIX]`. Please move to `conftest.py` Please patch at the place where this is used. Checkout the `epion` tests for a nice way to patch the lib. Shouldn't this test fail because the suffix you passed in is not the same? Please use parametrize for this. the tests should always end in either an abort or a create entry to also test that the config flow is able to recover. either `suez_water` and `streamlabswater` has some good examples for this I am missing the import flow test to abort if the entry already exists Please update the test name and docstring This test now only needs to repatch the lib to not raise the side effect and to show that the integration is able to set up after an error This one also should be made to succeed afterwards\",\n",
       " \"I don't think think this is a proper name that is generally reflected in Home Assistant. This is about importing energy, right? I agree with you, however, I decided to use the same name as on smarlife. I will send an image of smartlife.\\r\\n\\r\\nFeel free to suggest another name!\\r\\n\\r\\n![WhatsApp Image 2024-03-18 at 13 37 21_9081a7dc](\\r\\n\\r\\n\\r\\n![WhatsApp Image 2024-03-18 at 13 37 21_6fac042a](\\r\\n\\r\\n Changed the name as recommended, it really looks better within Home Assistant.\",\n",
       " 'Should we only do this when enabled is true? I was going to say that there is no reason to call the service if its not already enabled, but someone will do that of course ðŸ˜† \\r\\n\\r\\nadjusted',\n",
       " \"Instead of logging, should we fail the service by raising `ServiceValidationError`, or it's more logical to just go ahead when the volume is unknown?\\r\\n\\r\\nWhen can this happen, is it only when the media player entity has just been created, or could it happen also when connection with the remote device has been severed? I think the approach is to just go ahead with the service, even if the absolute volume can't be determined. The overlay will then play at the device's current volume level.\\r\\n\\r\\nself._volume should pretty much always be known and would only really be unknown if the device is not behaving as expected, so this check is probably not necessary.\",\n",
       " \"We should retain the old config, else the boot would fail since I marked ALLOW_EXTRA below I was able to import with the old configuration from v2 - since the settings are not useful with v3 they are not useful anyway.\\r\\nAny other reason to keep them? I think it would be nicer to implement diagnostics in a follow up to get debug information  good idea - should I remove the debug logs for now or keep them for now and replace them with diagnostics in a follow up next PR? Instead of assigning the coordinator to the entry, please assign it to `hass.data[DOMAIN]`. If you support multiple instances of the integration, please use `hass.data.setdefault(DOMAIN, {})[entry.entry_id]` to store the coordinator  yes, I support multiple instances. Most users will likely only have one but each TheThingsNetwork application would need a different instance.\\r\\n\\r\\nI will use `hass.data.setdefault(DOMAIN, {})` . I would also need to use this for other information saved at runtime in `entrySettings.py`. Please do this before setting up the platform or assigning it to hass.data Please check other integrations what they do (`epion` for example) Unneeded There is no options flow, so we don't need this yet Everything can be done in one function that would clean up this config flow a lot. Please check `youtube` for an example.\\n\\nAlternative is to add reauth later on. If we can make this nice and neat in a few cycles we can keep the reauth in, otherwise we can split it This sounds like something stored in options, which we don't do at the moment right? right - removed all the unused const Please have a static update interval. It sounds like you wanted to make it configurable, we don't allow that. We steer people to use the update_entity service instead. After the super() init the config entry is stored in self.config_entry ok, I will switch to use config_entry \\nPlease type the Data update coordinator the return type of async update data Please stop using `__`, we only usually use `_` (it's throwing me a bit off ðŸ˜‚) uhm,  `__` means private vs `_` which means protected. I can switch to use only protected if this is the style here. Please let me know. What's this? before removing the options menu, this was used to allow configuring the refresh value. Since the feedback was to remove the support to configure it then I will remove this option. I think it would be way cleaner to keep the coordinator responsible for fetching the data and have separate methods in the async setup entry in the platforms responsible for adding new entities. An example of this can be found at `withings`, especially the sensor platform.\\n\\nWith that approach it would create a listener, and I believe you mentioned something about not always polling, can you maybe give more information on when you exactly want to poll? \\nPlease add the coordinator type as type generic to the coordinator entity Also, please use CamelCase for the name. TTNEntity or TheThingsNetworkEntity would both work for me Not sure why this has to be a static one (I have not encountered the use yet so maybe I will in a few moments) Yea this is why I think moving the creation to the platforms would be beneficial as you can keep track of the created entities there (in the withings example, I keep track of all measurements I created sensors for, and if I get data for a point I haven't yet, I will create an entity) What do we do here? I don't think this field is needed since we don't have an options flow at this moment Where do we handle this  There is nothing to handle - I will remove the method.\",\n",
       " '\\n',\n",
       " '\\n',\n",
       " \"May be this should become a config option as well so we can suggest `https` as the default protocol? No I don't like to expose this kind of config over options, if it works it works and they don't need to change anything. If they want to limit to https traffic on device it will trigger a reconfiguration flow \\r\\n\\r\\nI does not seem to me this should be part of the unique set, same applies to `CONF_PORT`, but that can be addressed in another PR. This is the reauth flow, if the user chooses to change to https this needs to be part of it. I do not understand why. Removing port and protocol here would be better. This command validates the already registered unique id and if it matches it will update the config entry data with the input you see Should be consistant with the other check No, this is from discovery and it always provides HTTP port, so we only want to update the address if it changes, but we can not trust the port information now as HTTPS is in play. Why whould you want multiple enties to the same IP with the same user? It is enough to have IP + Usename unique IMO. This command validates the already registered unique id and if it matches it will update the config entry data with the input you see Thnx for explaining.\",\n",
       " 'I think you used the refactor button and forgot to check what else it changed I searched and replaced. Thanks. I changed it. \\r\\nNot sure if there is a big difference here And the docstring is not correct',\n",
       " 'This is an average. Averages cannot have a state class.\\r\\n\\r\\n Thank you, I removed the state class. Instead of adding a name here, it should be added to translations. Moved to strings.json I think the second word should be lower-case to follow [HA style](\\r\\n\\r\\n\\r\\n\"Entity names all start with a capital letter, the rest of the words are lower case\"',\n",
       " 'convert_temperature_if_needed doesn\\'t accept a None if you\\'re confident your `self.coordinator.data` is present you can use `self.coordinator.data[Attribute.INDOOR_TEMPERATURE_CONTROLLING_SENSOR_VALUE]`\\r\\n\\r\\nsince `current_temperature` can return a None, and likely will when first polling I\\'d do this:\\r\\n\\r\\n\\r\\n\\r\\nif mypy complains you can explicitly check for the key with an if statement.\\r\\n\\r\\nMy 2Â¢, avoid casting whenever at all possible @EvanSchalton Thank you for your feedback. The `cast` is because `self.coordinator.data` is `dict[str, Any]`, so I am casting specifically to a `float`. Technically the data itself can be `str | float`, but in this case it is always `float`. I updated the type hint on `convert_temperature_if_needed` to be `float | None` (which was already handled). I see in your other comment that we said the same thing. revert same same may be sensitive to value = None, consider turnery \\r\\n\\r\\n @EvanSchalton Mentioned above, but `convert_temperature_if_needed` does handle `None` so this should be fine. You could ignore a lot of my earlier feedback if you update thie function to handle the None `temperature: None | float`\\r\\n\\r\\n\\r\\n @EvanSchalton Thanks for your feedback, done. I think I asked before on the last PR, why did we do this again? Like the whole status thingy @joostlek It is getting all of the possible sensor types and including them if either:\\r\\n\\r\\n1. `status_key` or `status_sensor_exists_values` is `None`, indicating that the sensor should always be added\\r\\n2. The coordinator data for the `status_key` is one of the allowed values in `status_sensor_exists_values`\\r\\n\\r\\nThe reason for the slightly clunky logic with the `status_sensor_exists_values` is that the thermostat returns a value for the status for which multiple may correspond to the sensor being available. For instance, the Indoor temperature controlling sensor should show in the UI if the `INDOOR_TEMPERATURE_CONTROLLING_SENSOR_STATUS` value is either 0 (normal) or 1/2 (installed but in an error state). What do you think about maybe splitting the classes into the different sensors you are providing here? Even tho this works, you have a shared entity (And entity description) that doesn\\'t have that much overlap.\\r\\n\\r\\nFor the controlling sensors `status_sensor_available_value`, `status_sensor_exists_values` and `value_fn` are all the same, while for the status ones, `status_sensor_available_value` are all the same.\\r\\n\\r\\nAlso since the `available` property is based around the difference in both sensors, would it make sense to maybe split the `AprilaireSensor` into 2 classes? (You could add a third to have 1 class inheriting both `BaseAprilaireEntity, SensorEntity` and then have the two other classes inherit this superclass). I think this way, the code is more clearer on what it does and when it does something and is easier for extending in the future.\\r\\n\\r\\nBut let me know what you think (don\\'t see this as a must, just throwing an idea) @joostlek Personally I think that would introduce more complexity than it\\'s worth and it would reduce the flexibility, especially considering future uses that are possible. In terms of the cases where the values are the same, the `value_fn` won\\'t be the same once we reintroduce the temperature conversion that I removed. Also, if this were to be extended to have more of the sensors supported, then the `status_sensor_available_value` and `status_sensor_exists_values` wouldn\\'t be the same, requiring refactoring at that point.\\r\\n\\r\\nI\\'m _open_ to changing it up, but I don\\'t see a great way of doing it that wouldn\\'t just add a lot of bloat for no real benefit. But keep in mind you can then introduce the conversion in the abstraction for example. So you put the unit conversion in the `native_value` function of that sensor.\\n\\nDo you already know what you want to add in future sensors? Maybe I can give it a shot.\\n\\n(Feel free to message me on discord if you want to have some chats about it) @joostlek I have made some changes, I think it addresses what you\\'re thinking. Let me know if you\\'re meaning anything else. A \"controlling\" sensor sounds strange, what does it reflect? The setpoint?\\n\\nThe name indicates that it\\'s configurable, but it isn\\'t, otherwise it\\'d be a number entity The \"controlling\" sensor is what the sensor is called on the Aprilaire side. I believe it is named that way because it is what is \"controlling\" the behavior of the thermostat, as opposed to auxiliary sensors which are only informational. In this integration, only the \"controlling\" sensors are supported. Would you mind rechecking the naming? Maybe the info \"In this integration, only the \"controlling\" sensors are supported\" would be good to add to the docs and then the sensor naming can be more simplistic.\\r\\n\\r\\nBecause otherwise we have an entity name like `sensor.device_indoor_temperature_controlling_sensor` and that looks strange @joostlek Did you mean adding that to the home-assistant.io documentation? Or were you referring to adding a clarifying comment to the code? To the integration docs yes  Move this up to before the entity classes, and add `from __future__ import annotations` at the top of the module so the type checker allows forward references. make `BaseAprilaireSensor.exists` a class method so we don\\'t instantiate objects only to immediately discard them Instead of the cast here, we can declare the type of the status maps as `dict[StateType, str]` to show that we intend to index them with any `StateType` Why do we have this check? There\\'s no subclass which doesn\\'t set `self.status_sensor_exists_values`\\r\\nSame comment for the availability method I will remove. For `available` there is in fact a subclass (`AprilaireStatusSensor`) where `status_sensor_available_value` is `None` (because it is always available if it exists), so I am leaving that one. Instead of the cast, can we annotate `AprilaireCoordinator.data` to be a `dict[str, str | int | float]`? Shouldn\\'t this case be first? Or should the fan status sensor, which is the only sensor which doesn\\'t have a status_key, never be unavailable? @emontnemery Yes that is correct. The fan status sensor is always available. Consider simplifying:\\r\\n\\r\\n\\r\\nSame comment for the availability method',\n",
       " 'Thx. I\\'ve just copied them 1:1 from here:\\r\\n\\r\\nAnd in my mind they had to stay \"original\".\\r\\nBut you\\'re right, they deserve some improvement Doesn\\'t `None` mean there is no error rather than `unknown`? Yes, it means, that there is no error. And the python `None` is translated to `unknown` by Home Assistant. Should I use a custom string instead, like `no_error`? If `None` means no error it should return as \"none\"/\"no_error\"/... that can be translated into something that means no error. I already had it like this, but I changed it. See comment [here](#discussion_r1545754481). Should I change it back? I already had it like this, but I changed it. See comment [here](#discussion_r1545754481). Should I change it back? Is this list not available in the library to pull instead of listing explicitly here? Yes, it\\'s available from the library. I got it from the library [here]( But I was asked [here](#discussion_r1530778803) to literally list the options. So I expanded this to this PR. Should I change it back? No, let\\'s leave it as it is. Should not break anything but for translations etc. I guess it\\'s better to have it controlled.',\n",
       " '\\r\\nis the default \\r\\nshould be the same \\r\\nshould be the same I\\'m getting an error, while trying to push the file with the changes above. Here is the error: homeassistant/components/arve/config_flow.py:37:4: W7432: Return type should be ConfigFlowResult in async_step_user (hass-return-type) I think that\\'s not directly related to my change. Just the `FlowResult` return type was recently migrated to `ConfigFlowResult`. Yes, sorry, refactored the code and was able to push the changes porbably better to at least log a warning here please remove any empty keys info is for core only, use debug instead you can also set this as attr during init store this in a variable to avoid duplicate code this can also be a function btw we require the code to be hosted in a public repository in GitHub or GitLab and I couldn\\'t find it, could you please share a link? Hello, thanks for your comments, do you mean public repository of the python library ? yes exactly Here is the link to the public repository:   thx! that\\'s really often, is it really required to query that often? So the device sends the measurements each 10 seconds, if there is any restriction about scan interval, I could change it  Currently you are polling the device every 10 seconds. If the device _sends_ the data you should move to a push style approach (but that could also be done later as an improvement). ~~I\\'m not aware about any limits~~, Limit is 5 seconds, but 10 seconds is still quite often and you are putting load on the system of your users. The question is, if there is really a benefit in doing that, or, if the data doesn\\'t change that much, wouldn\\'t less frequent polls be enough. Also, since you say it\\'s a `cloud_polling` integration your also putting load on the vendor\\'s system It works so that the device sends the data to our web platform and the integration gets the data from this platform, not directly from the device. In that case should I define the type of integration as `cloud_push` or stick with `cloud_polling` ? ah understood. In that case stick with `cloud_poll` I suggest you move to a `DataUpdateCoordinator`. That way you can get an update for all entities at once (since they all appear to be using the same endpoint), and don\\'t need to do updates per entity. Thank you very much for your suggestion, does it mean that I will need to get rid of the Entity descriptions, or only from value_fn field in this descriptions in sensor.py ? no, it has nothing to do with that. You\\'d basically add a separate file `coordinator.py` and move the update logic from both the sensor and here to there. Here\\'s the offiicial documentation: #coordinated-single-api-poll-for-data-for-all-entities and here\\'s an example for a simple implementation  Thanks for the information Hi, I\\'m trying to implement `DataUpdateCoordinator` as you suggested, but to be honest I\\'m having difficulties with it. I looked into the documentation that you provided as well as into simple example. I\\'ve also found a couple of other examples. In those examples it seems that the Python client takes no place in entities generation, however I would like to have both of the coordinator and Python client in this process. The reason why I would like to do it is because Python client has some attributes that need to be passed into the entities and device itself. And here comes the problem that there is some kind of conflict between the coordinator and Python client. Sharing the screenshot with you: \\r\\n<img width=\"1176\" alt=\"Bildschirmfoto 2024-03-15 um 15 42 01\" src=\"\">\\r\\nThank you very much for your help! Please let me know if you need the source code and how can I share it with you. \\r\\ndidn\\'t notice your parameters are named differently\\r\\n\\r\\nyou could also try\\r\\n I\\'d advice against your last suggestion of the `*user_input.values()`',\n",
       " \"There's already a pressure sensor reporting in bar, is this the same data, just with a different unit? Yes, I made it this way so that the specific equipment pressure sensor will display the value with same unit as in the myUplink App. Just to double confirm, we create multiple sensors in Home Assistant for the same data but with different units? Or will the backing hardware EITHER have a pressure sensor reading in Pa OR a presure sensor in bar?\\r\\n\\r\\nSame question for the duration sensors. Nope, the API exposes 20-100 datapoints (=sensors) for a typical heatpump. The API will for most sensors send metadata describing the type of data (=device_class) and unit (=native_unit_of_measurement) in addition to the actual value There can be many different pressure measurements. Some pressure sensors measure internal pressures value across e.g. a fan and some could represent athmospheric pressure or water pressure in floor heating systems. So the entity_description will assign an optimal set of arguments for the specific measurement type.\\r\\n\\r\\nSame applies to duration measurements. Some sensors will tell you how many seconds the compressor has been running in the last cycle. Another sensor can display for how many days the compressor has been running the last year.\\r\\n\\r\\nI think it is reasonable to use the units that the API suggests as defaults in HA. OK, and the user can differentiate between, for example multiple pressure sensors, because the name of the entity is set to `device_point.parameter_name` which is descriptive enough to make sense? Exactly. These are the auto-generated sensor names for my Nibe F730 heatpump.\\r\\n![image](\\r\\n There are already multi sensors reporting time, are the ones added in this PR the same, just with different units? Same reason as above. This is to keep the default unit the same as in myUplink app for each datapoint. The API can expose many different points of duration data, in some of them seconds is the relevant unit in others days are relevant. I think it will be a better user experience if we stick to the defaults that the API suggests in the metadata.\",\n",
       " '\\r\\n\\r\\nfrom homeassistant.const Hey,  thanks for your review!\\r\\nIn another [PR](#discussion_r1505566658) I was explicitly asked to remove the DOMAIN from hass.data.\\r\\nIs there a specific reason why you want to keep it?  because I read it wrong, ignore this one \\r\\nis the default use the attributes `attr_...` instead attribute also can those throw? oh yes true, when the device is not connected anymore, there should be an exception when calling. open for discussion: If you are getting all connected devices anyways, wouldn\\'t it be easier for the user to just add all of them in one go and switch the integration\\'s type to hub? It\\'s an interesting idea to let the user add multiple devices at once, but I am not sure how often it will happen that someone adds multiple USB Power-Sockets at the same time. For me a hub is a component which uses one physical connection to manage several devices. In this case each device is connected via USB to the host.  \\r\\njust a bit shorter any reason why you\\'re not using the one from const here? I should do that, you are right \\r\\nI believe style guide suggests a new line after docstring since recently \\r\\nI _believe_ is the correct way to call a blocking function \\r\\nwill be handled correctly by HA. I\\'m not 100% about the \"f\" string, but ruff will tell you raise HA exception here too and here getting nitpicky here, but since this is not really the config enty, I\\'d prefer `DEMO_DATA` or something along that lines I\\'m not sure I like this approach, because it depends on the switches being added successfully and feels a bit error prone. Can we maybe switch to parametrized tests and snapshots?',\n",
       " \"You can overwrite the type in the coordinator by just setting\\n\\n\\nOn class level Snapshot testing? ðŸ‘€ \\n I don't think this item is used as intended. This is the url for the application settings, not for the mower device settings. It's not possible to configure the device at this url. Please remove this item.\",\n",
       " \"Usually we would put the index in `DeviceRegistryItems`  See the entity_registry for an example My bad, I simply copied the functionality from an [old PR]( and failed to notice the entire paradigm has changed since then.\\r\\n\\r\\n[This](#L791) is what I've found. Apparently, there is no search by name in the `entity_registry`. I have [found something](#L117-L118) in the `area_registry`, though.\\r\\n\\r\\nDo you mean I should simply move the index part in the `DeviceRegistryItems` class or that I should leverage the already existing [`DeviceRegistryItems.get_entry`](#L448).\",\n",
       " '\\r\\n\\r\\nEmpty keys can be removed addressed, thanks for the hint! I would use `device_info` instead of `devinfo` to avoid confusion makes sense, renamed Please move all the connection logic into the library.\\r\\n\\r\\nWe want as little code as possible in Home Assistant that communicates with the device\\r\\n\\r\\n thanks for your help! Addressed, please check Can be removed please clarify what exactly, VERSION var ? Has to do with migration, see #config-entry-migration\\r\\n\\r\\nI was told it can be removed since `VERSION = 1` is the default Use `CONF_NAME` and `CONF_ADDRESS` from homeassistant.const for these keys, I would use these everywhere you use `\"name\"` and `\"address\"` Here you can use `CONF_DEVICE` from homeassistant.const, for the device_info and is_disconnect_by_request I would create your own constants in const.py like CONF_DEVICE_INFO = \"device_info\" and use that everywhere I wouldn\\'t use an assertion here. What if some BLEDevice becomes available shortly after async_setup_entry is called? Then it will only become available once HA restarts again. \\r\\n\\r\\nYou can also register a callback with HA in your async_setup_entry that will update the ble_device for your dice. This is useful if your device becomes available through a different adapter or bluetooth proxy:\\r\\n initially I used `assert not None` to fix type check failure - `async_ble_device_from_address` returns BLEDevice | None, while `BleakClient` first arg is BLEDevice|str. But yes I agree that in case `ble_device` is None then AssertionError will be raised and HA will skip connection retry. I\\'ve put that code snipped under try-catch too to make sure I wrap an exception with `ConfigEntryNotReady` if any If you ever get a type check failure you can also use TYPE_CHECKING constant which will only execute the assertion for type checkers:\\r\\n\\r\\n\\r\\nBut in this case I think the best way to solve it is indeed to use `ConfigEntryNotReady`, then HA will automatically retry it later. I would still add the `async_register_callback()` though to always have access to the latest BLEDevice does not `async_ble_device_from_address` return the latest ble_device ? I supposed it does. Theoretically I can register a callback to receive the last ble_device too after a call to `async_ble_device_from_address` but I\\'m not sure I need it anywhere now. I try to connect once when the integration loads, then if it fails I just raise `ConfigEntryNotReady` leverage HA reconnect. In case of receiving new `ble_device` while integration is alive I will just lose it after initiating integration reload since as I understand all vars are lost between reloads.\\r\\nPlease correct me if I\\'m wrong Do you only connect once when the integration loads and not anymore after that? In that case I don\\'t think you need the latest BLEDevice, but if the user can initiate a connection themselves then you should use the latest BLEDevice for that as it contains information on what adapter it is available on Correct, I connect once only when the integration loads I would personally put these keys in const.py not sure it is needed since they are not referenced anywhere else Try to add types for the arguments and return type. Same for device_info, device and entity_description in your init methods Everywhere you set class variables I would include the type in the class body\\r\\n DiceColorSensor, BatteryLevelSensor and DiceNumberSensor all have a `dice` class variable. Why don\\'t you put it in BaseSensor? Then you can also remove the __init__ for each of these right?\\r\\n\\r\\nAnd you can include the descriptions like below. Also small point but you write `async_add_entities(entries)` but you are really adding entities instead of entries, but that won\\'t be a problem if you do it like this.\\r\\n good catch, really better to adjust a base constructor to be used for all child classes. Done I would suggest just writing names out fully when they are not too long. Makes it much easier to understand what the function does when quickly reading through it. Same goes for a couple of other cases like using \\'desc\\' for \\'description\\', or \\'devinfo\\' for \\'device_info\\' which you already addressed. Difference in length is not too much but something like device_info or _handle_number_update is much clearer as opposed to devinfo or _handle_upd\\r\\n Why do you use a separate function `create_device_info` if that function is only really used once? Also, I think you can remove sw_version if it will never be known, and if it will change later you can set it to `None` instead of `\"unknown\"`\\r\\n\\r\\nActually I don\\'t think you even need to save the DeviceInfo in hass.data right? If possible I would suggest just moving it to the constructor of `BaseSensor`\\r\\n Same for the other assertions in the config_flow\\r\\n\\r\\n I don\\'t think it is a good idea. Doing this way we don\\'t learn from the checker but just make type checking pass while the checker watches but ignore its recommendations when it does not. Instead with assertion like that we declare explicitly that `None` is not expected and can fail early Related to the other suggestion about DeviceInfo, I would include it here in the BaseSensor and then pass the ConfigEntry to the constructor\\r\\n\\r\\n moved DeviceInfo var declaration to `sensors`. Passing DeviceInfo to sensor classes instead of ConfigEntry since only DeviceInfo is needed there',\n",
       " 'The on/off handling is already handled by the climate entity:\\r\\n\\r\\n<#L224-L228>\\r\\n\\r\\nAnd thus should not be added as a switch.',\n",
       " \"Don't use f-strings in log warnings, do like this instead\\r\\n This should be protected\\r\\n This too should be protected\\r\\n\",\n",
       " 'I think all these extra attributes need to be added as sensor entities instead of attributes.\\r\\nI don\\'t think this is allowed, but I will ask for a second opinion.\\r\\n\\r\\nThe benefit of sensors would be you get a history, users can enable/disable the ones they want and it is better for the state_machine/database. Agreed! I usually leave the unique id in the constructor of the platform entities. Each entity requires a unique id, so I don\\'t see an advantage in doing this. Please call it entity.py This should happen in sensor.py This will hard code names. We should use translation keys. Even tho every sensor would only need 2 fields (or 3 if you add the value function as well), I recommend looking at entity descriptions for this. Can you explain how media player entities are created at the moment? I understood that we create one per zone, is that correct? Yes, one per zone. After the change we will have 11 per zone. The zone attribute is that you are able to see which sensor entity belongs to which media player (main) entity. But you can already see to which receiver it belongs, so how much added value do these extra state attributes add?\\n\\nFyi, we\\'re more hesitant to add new extra attributes, because they usually can be extra sensors or are unneeded, but still take a lot of space in the database. Tbh., I would have problems to see the relationship between the media player entity and the sensor entities without the `Zone` attribute.\\r\\nI can assume that there is a relationship based on the suffixes of the entity names (no suffix, `_2`, `_3`), but this relationship is gone when I start renaming the entities. That\\'s why I added this property.\\r\\n\\r\\nHowever, I checked the properties and all the sensors belong to properties which are device settings and not zonal settings. Thus, we don\\'t need to create them multiple time and will have 10 sensor entities + one media player entity per zone only.  Is every media player its own device?\\n\\nDon\\'t I then have a device called \"living room\" and \"bedroom\"? Nope, a device represents a physical receiver which can have up to 3 zones. Each zone is represented by a media player.\\r\\nIt is easy to figure out a relationship between a device and its entities, but it is hard to figure out relationships between different entities of the same device. As I said before, you could assume a relationship depending on the names, but this lasts only until you start renaming entities.\\r\\nAnyway, the relationship between entities is a theoretical discussion now, because there is only one sensor entity per device left. I am more talking about the relationship between devices and the sensor entities. If the device is called \"Bedroom\" and you attach these entities, it would prepend the devicename, avoiding the `_1` and `_2`. It would look like `sensor.bedroom_something`. This would also rename when you rename the device, it will ask you if you also want to rename the entities attached to it.\\r\\n\\r\\nBut looking at the sensor setup code, you only setup the sensors for one entry and not per zone. > But looking at the sensor setup code, you only setup the sensors for one entry and not per zone.\\r\\n\\r\\nYes, that\\'s what I said in my second message and did with \\r\\n\\r\\n> However, I checked the properties and all the sensors belong to properties which are device settings and not zonal settings. Thus, we don\\'t need to create them multiple time and will have 10 sensor entities + one media player entity per zone only.\\r\\n',\n",
       " 'Is there a reason for this not following the pattern of the previous items (if \"XX\" in family)? No. Fixed. Done Done',\n",
       " 'Maybe this was better to leave as a sync function as the `_load_config` is doing IO. Replaced with `await hass.async_add_executor_job` I think better just to revert it to a sync function and let the notify component run it in an executor job for you. There was no reason to change this in the first place afaict. Other than that all looks good. \\r\\nOr similar Maybe a comment here just explaining that you\\'re using `async_load_platfom` because notify doesn\\'t support config entries. I decided to not do this because the other notify platforms don\\'t have this. Is it possible that the yaml import could be picking up these values and trying to store them with the config entry? Do you maybe need to make sure to strip them out before starting the import flow? The import config flow both validates and only includes relevant values automatically. Nothing extra is included.  I looked at a number of other notify platforms and many of them pass the config as the config parameter as opposed to the discovery parameter (some pass both) but I couldn\\'t find any passing empty dict as the config. Your changes below to `get_service` switch from the config to the discovery info.  Are you sure this is correct? (I\\'m not sure myself but `async_load_platform` asserts that the config is not none and AFAICT this is config as opposed to something that has been discovered) I\\'m not terribly familiar with the architecture of HA, but I have seen from pulling this up in the debugger that passing in the data through the config entry doesn\\'t seem to work. I got this idea from the discord component (#L42) and it seems to work correctly. Okay I debugged it again and remember now. The config is only presented when configured using YAML. Discovery info is presented during config entry setup. I changed it to also pass the hass config to the load_platform call so that the notify component is loaded correctly. This seems to be what other components are doing as well. Sorry missed that this should now be 2024.5.0 Done This should do the job\\r\\n Replaced with `await hass.async_add_executor_job` Please prefix functions that are safe to run in the event loop with `async_`\\r\\n\\r\\n Done Done Thank you for your contribution thus far! ðŸŽ– Since this is a significant contribution, we would appreciate you\\'d added yourself to the list of code owners for this integration. â¤ï¸ \\r\\n\\r\\nPlease, add your GitHub username to the `manifest.json` of this integration.\\r\\n\\r\\nFor more information about \"code owners\", see: [Architecture Decision Record 0008: Code owners](\\r\\n Done \\r\\n#writing-tests-for-integrations\\r\\n\\r\\nPlease don\\'t patch the integration itself in tests (there are a lot of bad examples of the tests already doing it and we don\\'t want to add more). We should let the issue get created and verify it exists in the registry instead. Done #r1584794986\\r\\n\\r\\nWe generally make exceptions to this rule for `async_setup_entry` and `async_setup`\\r\\n Done Please reverse the condition and continue when it does not match to reduce code indentation. Please mark this as a callback and prefix it with `async_`\\r\\n\\r\\n#the-callback-function Please convert multi-line ternaries into if blocks or rework so its not multi-line',\n",
       " \"This doesn't show that the thread id is passed to the API.\\r\\nThe test already uses the fixture `mock_external_calls` indirectly via the `webhook_platform` fixture. I suggest to modify the `mock_external_calls` fixture to yield the patches instead of yielding nothing, then you can test here that `telegram.Bot.send_message` was called once with the correct data.\\r\\n Hi @emontnemery , Thanks for the heads up.\\r\\nI added `message_thread_id` to event log (since it might actually be useful in automation or for debug) and added the corresponding test in tests.\",\n",
       " 'port should never be `None`, since we take it from the configuration entry, where it is a mandatory paramater\\r\\n this should be handled in the config flow, so that a configuration entry always has a valid port in its data no need to define `data_schema` , just use the `vol.Schema` in the `async_show_form` as it was before place here the logic about the default ports from above\\r\\n I think we should also remove `self._port = ssdp_location.port` from `async_step_ssdp` , extend the schema in `_show_setup_form_confirm` with the ssl option and also add the logic about default ports in `async_step_confirm`\\r\\nWith this we were also able to provide ssl support for discovered Fritz!Box we should also test that the logic about default ports, based on ssl option is working as expected and that the user can overwrite the port in advanced mode. this could \"easily\" be done with the `@pytest.mark.parametrize` annotation.\\r\\nIf you need support with the tests, don\\'t hesitate to ask ðŸ˜‰ ',\n",
       " \"Is `wifiguest` always correct?\\r\\nShould we set some flag so we know which device trackers are guests? There is no way to configure this value on the Freebox OS.\\r\\nI got `wifiguest` value in the result of the following API request: `GET /api/v4/lan/browser/interfaces/` ([source](#))\\r\\n\\r\\nGood point for the flag. But I don't know the best design practices for defining this flag in a device tracker. Just implement an `extra_state_attributes` property in the device tracker entity.\\r\\nThe `unifi` integration actually has an `is_guest` flag, I'd suggest to use the same here:\\r\\n\\r\\n#L42-L64\\r\\n\\r\\n#L349-L362\",\n",
       " \"\\n Can be omitted  Done For some reason they are back Fixed again, thanks \\nYou probably did this because the config entry unique id can technically be None. Please assign it to a variable and assert that variable Done Since you use a coordinator, that means the BaseAprilaireEntity is inheriting a CoordinatorEntity -> you should also call `super().available` Oh I see you do now, but can this statement be simplified? @joostlek I have simplified what I can. Hopefully it is a bit clearer Please avoid using inline ternaries if they span more than 1 line Done Please use sentence case instead of title case Done these status sensors look to be returning a default set of names. You can make these an enum sensor. The added value of this is that you have to pass in a list of possible values (via `options`) and when users want to automate with it for example, they can see what possible values the entity returns.\\r\\n\\r\\nThis does require that the values returned by the sensor are in `snake_case` and then you can add state translations in the strings.json.  Good idea, done What do we do here? @joostlek There's not really a better way of writing this I don't think. It is getting all of the possible sensor types and including them if either\\r\\n\\r\\n1. `status_key` or `status_sensor_exists_values` is `None`, indicating that the sensor should always be added\\r\\n2. The coordinator data for the `status_key` is one of the allowed values in `status_sensor_exists_values`\\r\\n\\r\\nThe reason for the slightly clunky logic with the `status_sensor_exists_values` is that the thermostat returns a value for the status for which multiple may correspond to the sensor being available. For instance, the `Indoor temperature controlling sensor` should show in the UI if the `INDOOR_TEMPERATURE_CONTROLLING_SENSOR_STATUS` value is either 0 (normal) or 1/2 (installed but in an error state).  What does the Aprilaire device return? In what unit? Is this dynamic?\\r\\n\\r\\nLooking at the util.py the device always returns celcius. Can you maybe give an example why the special rounding is needed? The device does always return celsius. The problem is when converting to Fahrenheit, the device itself uses away-from-zero midpoint rounding, whereas Python uses banker's rounding. This leads to inconsistent rounding in the case of values when the user is displaying values in Fahrenheit in HA.\\r\\n\\r\\nConsider 22.5C which is 72.5F. With away-from-zero rounding, the device displays this as 73F. However with banker's rounding, HA would show this as 72F.\\r\\n\\r\\nThe solution as implemented is to have the sensor always report that it has the same native unit of measurement as it is configured to display in, and then handle the correct rounding when returning the native value. This actually reminds me that I need to do the same for the climate entity. This fix was made in the HACS repo after I started getting this merged into core, so I never made the change on the core side. Please let me know if you have any other questions about this\",\n",
       " \"\\r\\n\\r\\nI'm not sure if lock makes sense here Ideally this becomes a separate test or parameterized as we want to avoid branching in tests #r1534644418 #r1534644418 I realize this is copied from lock, but `add_default_code` is a really confusing name of this method IMHO. Can we try to come up with something which better describes what it does? Maybe `code_or_default_code`? The doc string is lying, maybe\\r\\n Can this be simplified?\\r\\n Why not initialize to `None`? Why don't we default to `None`? Let's shorten the variable names a bit to avoid some of the line breaks:\\r\\n Why is this changed? These integrations doesn't require a code for their methods but was by not implementing `code_arm_required` actually setting it to `True`.\\r\\nWe are with this PR introducing validation for code so without setting this property to `False` these integrations would require a code input from the user.\\r\\nSee blog post link in the PR description.\",\n",
       " 'I\\'m wondering if we want to let the potential exception here (and have a potentially \"ugly\" error in the logs), vs catching it and wrapping it slightly with \"Oops, couldn\\'t get this image to send it\" (and still including the stack trace via `_LOGGER.exception` As in the original: `asyncio.wait` on an empty iterable is a safe no-op\\r\\n Can iterate directly over what we grab from `data`: no need for interim tasks lists (please feel free to improve on my formatting though ðŸ˜†)\\r\\n Minor: I love `pathlib` and I fully support its use, but I\\'d universally suggest doing `from pathlib import Path` to avoid using `pathlib.` suffixes in code. Some sans/reduced-IO ideas:\\r\\n- [Good] Use `AsyncSpooledTemporaryFile` instead; just like [SpooledTemporaryFile](#tempfile.SpooledTemporaryFile), all the data is spooled in-memory instead of using the disk, which can be a precious resource on some low-resource systems.\\r\\n- [Better] We don\\'t even really need the idea of a temporary file; we just need something to iteratively read bytes from. I think that modifying `_send_image` to accept either an image `Path` *or* `resp.read()` directly would easily cut out the need for temp files at all Please feel free to modify `_send_image` to accept a `pathlib.Path` rather than a str: I think it\\'d be better that way anyway ðŸ™‚ Can\\'t verify ssl for `http` :^)\\r\\n',\n",
       " \"ðŸ§µAcking that I've seen this PR as well as  !\\r\\nLmk which would be more helpful to take a look at first and I'm happy to do so. And feel free to reach out to me on matrix as well I think unfortunately, this won't be able to get in because of the dependency conflict with `matrix-nio` requiring `cachetools<5.0.0`. Since theres this conflict, I might let this PR sit until sometime in the future whenever this dependency gets upgraded in the `matrix-nio` library.  is ready for review however. @alexyao2015 Gotcha; please feel free to file an issue on `matrix-nio` itself/tag me, as I also maintain `matrix-nio` and we can probably get that done.\\r\\nWill start looking at #112539  in the meantime! @alexyao2015  has been opened to bump the cachetools requirement for 0.25.0\",\n",
       " \"The config flow requires full test coverage ([dev docs](#testing-your-config-flow)) Do we need to close here? I saw your are passing a aiohttp session in the coordinator to the client  Checkout e.g. the `holiday` integration how to use the `SelectSelector`, this way we could make the options translatable No need to create a new const, we have `homeassistant.const.CONF_COUNTRY` done. I don't see that `SCAN_INTERVAL` is used anywhere else, so keep the definition in this module instead of const done. `.info` is reserved for core, please use `.debug`  done. Please wrap multiline lambdas into parentheses i have put it on one line, ok ? Is there any other data provided by the API that makes it necessary to add the service type here? Is a attribution needed? First of all, thanks for all your suggestions, i am pretty overwhelmed on how this whole project runs ! - ok, its my first approach on submitting something to such a ahuge project !\\r\\n\\r\\nwhat does attribution generally mean ? do i need to set it when the API provider requires me to ? i basically took the easyenergy integration as base *sigh* It's no problem ðŸ˜Š we are there to help! And no need to be overwhelmed, you can address the points step by step if you want to.\\n\\nNormally the API provider has some terms of use. And some have a clause that in order to use the API you need to credit them, in some cases even writing what you should use as an attribution. But when there is no such clause, it is not needed.  Exactly what @autinerd said. The problem with the attribution is that it's not translatable, so it would be in English even though the rest of the UI is in your chosen language. Thanks for your answers, on the page they say that one can use the API for free with fair-use (max. 100 queries a day). Thats why i only query every hour. So i think i can remove the attribution.\\r\\n\\r\\nBut, is there is a way to query the api once on integration start and then every day at 14:00 + some random delay as the data only changes at 14:00 ? and how would this be implemented ?\\r\\n\\r\\nAnother question regarding entity-id's: mine look this: \\r\\n\\r\\n`sensor.energy_market_price_current_hour`\\r\\n\\r\\nwhereas easyenergy's integration entity is: \\r\\n\\r\\n`sensor.easyenergy_today_energy_usage_current_hour`\\r\\n\\r\\nShouldn't they be unique (to have all energy providers providing the same entity-ids, but then you cannot have more than one energy provider) ? \\r\\n\\r\\nOr should i add `awattar_` to the entity-id to distinguish them so that every integration providing energy data has different - and unique entity-id's ?\\r\\n\\r\\nI think the other points (except testing) i already solved thanks to your suggestions :) Why not set as default in the dataclass above? Is there a reason why you do this? sorry, was old code - i removed it completely, can you please take a look at the code and check if it is ok now, i also made some other changes according to all your findings, should be ok now :) \\r\\n\\r\\nNot needed. For this integration a Schema config flow would be ideal. Check out `webmin` or `systemmonitor` for examples. You could use `CONF_COUNTRY_CODE` (in `homeassistant.const`) and use the country codes like `picnic` does. \\r\\n\\r\\nCan be removed as it is not used. thanks! \\r\\n\\r\\nCan be removed as you don't use any parameters besides coordinator and description thanks!\",\n",
       " \"This could also be a property as it's only called by `entity.py` without a parameter. Which would make more sense to align with the rest. This may change back in a future PR, but for now its a property. Is this really a validation error or simply the service returning with an error.\\r\\nWe should separate a validation problem ( `ServiceValidationError`) or other issues such as connectivity etc. (`HomeAssistantError`) Seems to be more cases also below I recall being told or reading that service failures were `ServiceValidationError` not `HomeAssistantError`, but I'm probably wrong. I have changed them all over. #exception-handling-during-service-calls \\r\\nAlready in the base entity? Removed Use pytest parameterize instead DOne Why are we removing these tests? This PR removed the first refresh code from the coordinator so this test is no longer valid. I think this could be good to have as a decorator instead on the respective methods that's using it (in a follow-up PR) On line 115 (out of reach for this review) in a follow-up move from `hass.data` to `entry.runtime_data` Don't both log (above debug level) and raise an exception. It's enough to pass the message to the exception instance. The message will be logged by the exception handler.\\r\\n\\r\\nIf you want more information than the message for debugging, log that at debug level. Addressed in  Please move the log down out of the try... except block.\",\n",
       " 'Can move the CoordinatorEntity to the base class moved Maybe disable this one by default entity_registry_enabled_default=False added for all enabled it now per default again, why would like to have it disabled per default?\\r\\ncause enable every sensor separately is tedious job,\\r\\n(didn\\'t see that on testing before cause i didn\\'t do factory reset) Typically entities which are not used so much should be set as disabled and the users who wish can enable them. \\nI didn\\'t say for all, just for this one as it\\'s quite uncommon `rssi` provides any value.\\n\\nThere is also possible to mass-enable entities so no, it\\'s not a very tedious task.  nice, wasn\\'t aware you can set all at once\\r\\nmakes sense, most users don\\'t care about rssi, disabled it now per default again\\r\\n What\\'s the state of this sensor? its the raw value of the optical dirt sensor, its rough around >4000 when dustbin is empty and gets <4000 or less when dustbin is full 4000 what?\\r\\n\\r\\nShould we disable this by default? It doesn\\'t sound like a entity that is useful for the majority of people its a raw number in range between 0-4096\\r\\ndisabled it now per default\\r\\n \\n Maybe consider just using \"runs\" since the entity name already contains \"cleaning\" changed to runs Would the state class Total make sense? jop, changed it for all total_ sensors \\n Unneeded removed Stale docstring  changed to\\r\\n\"\"\"Initialize the RomySensor.\"\"\"\\r\\nand\\r\\n\"\"\"Initialize the RomyBinarySensor.\"\"\"\\r\\n\\r\\nwhats missing or what do you prefer? I just noticed that it isnt a StatusSensor, so that was my issue mostly',\n",
       " \"Should we raise here an exception to trigger ip ban? Please limit docstrings to max 72 characters per line in accordance with PEP8. Why do we set the default to import time + offset? Why do we never set this attribute during run? Thanks for the catch. I use now the init function  What other types than None and the generic type can data be? None and StoreData (TypedDict) are the only types. I copied this check from `auth_store.py` Ok. Maybe we don't need the check for dict then? This can be an async callback. Can the session instantiation raise or is it just the line above that can raise? If the line can't raise, please move it down out of the try... except block. Can any of the method calls to create and set the cookie raise an exception? encrypt will raise a TypeError if `cookie_data` is not `bytes`, but the encoder is returning a str, which will be encoded. So the TypeError is not raised.\\n\\nThe encoder itself could raise `JSON_ENCODE_EXCEPTIONS` so maybe we could catch these. Normally these errors shouldn't be raised as we control the data, which is encoded.\\nWhat should happen if an Error is raised?  If we control the data it's ok I think. It's important that we don't leave any room for an attack that can crash the server. Maybe use `__slots__` for this class? I think we should add a comment here why we filter away all existing sessions for this refresh token. It means that there can only be one session per refresh token, right? This seems important. I'd add what the actions are in the body of the docstring.\\r\\n\\r\\n1. Check ip address.\\r\\n2. If ip address is local let the request through, otherwise 3.\\r\\n3. Show static page if that's enabled, otherwise 4.\\r\\n4. Close connection. Should we show the static page also for invalid ip addresses? Why do we update the secure key in memory stored `cookie_params` here? It doesn't seem used afterwards. We update it again before setting the the cookie in `save_session` and the parent `save_cookie` doesn't seem used since we override `save_session`.\\r\\n\\r\\nIs it just if the parent class would use `save_cookie` in more places in the future? I'd add why we implement our own child class in the docstring body. My conclusion:\\r\\n\\r\\n1. We want an lru cache for decrypting the cookie.\\r\\n2. We want to use `is_secure` in the cookie name and params. Maybe add a comment why cache control is important?\",\n",
       " \"You can avoid the mixin when using `kw_only=True`\\r\\n \\r\\n Isn't used in file\\r\\n\\r\\n Consider using the binary sensor device class Battery charging\",\n",
       " \"Any tips how to get the tests cover these lines are appreciated? This PR is changing our entity model. Before we can review this PR there needs to be approval in a discussion in our architecture repository.\\r\\n\\r\\n\\r\\n\\r\\n#changing-the-entity-model If I remove this part from the PR, only implementing the per-device speed setting, any chance this PR is going to move forward independently of that architecture discussion? Setting a default speed is ok. Please open a new PR in that case that doesn't touch any core files so that the core team isn't notified.\",\n",
       " 'May be add a test to ensure code test coverage. Was a mistake in lock state which made this but it\\'s now also tested properly ðŸ‘  This is technically correct as open means unlocked, but it would be easier for the user in the frontend if this would be\"{entity_name} is open\". ',\n",
       " \"<strike>weather</weather>  Fixed! Took some inspiration from the weather integration and forgot to remove all traces :) should this timedelta perhaps be configurable We thought about it, but wanted to keep the integration as simple as possible for the first PR. But this is definitely something we want to implement in future versions! We don't allow configurable polling intervals in the UI. This can be archived with disabling the automatic polling and using a automation for it: #defining-a-custom-polling-interval just for styling\\r\\n why do we need the executor job? Can we maybe move the initialization of the `ApiClient` to the coordinator? \\r\\nis the default \\r\\nappears it's not used currently why the executor job? catching broad `Exceptions` is not allowed outside of the config flow what's the benefit of the extra exception here? can't we just move/simply all of this, if we move it directly to the coordinator? @l-holter are you fine with being a code owner? why that extra file? Apparently it's only used in the config flow? you don't appear to use those anywhere else, so I'd just use them directly no reauth in this PR\\r\\n \\r\\nno references doesn't have an options flow\\r\\n I _believe_ that this should be a service, also need to set it in the manifest then\\r\\n please finish the test, to show we can recover from errors idem idem, I think we could just use a parametrized test for all 3 of those we don't usually test internals like like coordinator. Rather write tests showing the side effects of those errors (e.g. sensor going unavailable)\",\n",
       " 'Please don\\'t add constants to the common constants. We only do that after we see that they have multiple users and are actually common. Understood, I will move it into the component directly, sorry about that This appears to work even though US originally defaulted to Maytag.  \\r\\nI\\'m not sure that it will work for everyone, but in the \"worst case\" the user would need to delete and re-install the integration. We should also test `init_integration` without `CONF_BRAND:` verifying \"update\" works.  Good call, I\\'ve added `test_setup_brand_fallback` in `test_init.py` to test that setup without a brand uses Whirlpool The translation strings in `strings.json` haven\\'t been updated. Please do that. That will also show how we\\'re going to explain this to the user, which is important. I\\'ve added a line in `string.json` for the brand. Whirlpool makes the brand very confusing, as far as I can tell it only affects the output of the shared appliances query, so the string I added was `\"brand\": \"Brand of appliances\"`. I\\'m not sure what happens if there are users with shared appliances of multiple brands, but I think we\\'ll have to cross that bridge when we come to it. Will users know which one to pick from this item name? Should we add a data description as well with a bit longer description? Added a description that gives more information about which brand to choose If the brand is incorrect for a user, will there be an authentication failure and a re-auth flow started giving the user the chance to correct the brand? Yes - authentication fails if the user name / password is not the correct \"brand\" for their account.  I would make sense to add brand selection to the reauth flow - pre-populated with the current value. @mkmer  Right now the reauth schema just has the password, would we need to add the brand to the reauth schema in order for it to prompt the user to add/update the brand value? Yes, you would need to add it as an option to reauth flow (mostly just copy from the base auth flow schema).  I feel like it\\'s one of the better paths for upgrade failures to recover without deleting the integration - if the brand is wrong, they will get a user/password failure. I\\'ve added this and also expanded the strings in strings.json a bit so make those more descriptive. @MartinHjelmare  I\\'ve added a description to the config steps (both init and reauth) to give more info on what to choose for the brand. Let me know if that looks okay or if I should do something differently there We have the `data_description` item to describe data items in config flow step forms.\\r\\n\\r\\nExample:\\r\\n#L14-L16 Thanks for pointing that out, I missed that my first time through the docs. I\\'ve switched the brand info to the data description now',\n",
       " \"Why do you need the `device_id `in a system entity? Maybe I'm overseeing something. This sensor is added to the HA device with this device_id. This is the most user-friendly way to handle a system with one single device. The vast majority of heatpump systems has this configuration. In a later PR we will create a separate HA device on the system level if the system contains two or more heatpump devices.  If you have more than one system, will this be correct? I thought you should find the correct system based on `system_id`? Good catch. I will correct it. Can we use entity translations? Yes, we can, but we don't use entity translations in this integration because all other entities are named from data in API or by device_class. But it is reasonable to enable translation of this entity name so it behaves similarly to those named by device_class.  \\n OK It would be nice if this was a dict so we didn't have to look the system up every time.\\n\\nThis could then be its separate property for easy access I put the dict comprehension here for now. It could be moved to the DataUpdateCoordinator, but this is currently the only place we access one specific system in the integration. I would prefer to keep it this way for now. The conversion of Systems to a dict would have implications in many places in the integration and I think it is better to do that in a separate PR. Agreed. But since you only use this in one place now (which I didn't know) I think I like the for loop more as that would be more efficient at times Reverting! Why doesn't this inherit the class above and overwrite the relevant properties? Done! Why the noqa?\",\n",
       " 'Please move this to `icons.json`:\\r\\n\\r\\n',\n",
       " \"What about an `and` instead of the nested `if` ? It may improve cognitive complexity by removing a level of nesting.\\r\\nSame thing below. Thank you for your suggestion!. I'll update the code accordingly to reflect this readability improvement. This should be done in the `__init__` function? See #L42. Also, I don't think the `native_max_value` inherited property should be replaced, shouldn't you use `self._attr_native_max_value` and `self._attr_native_min_value` instead ? Should we call this `min_value_state` or `default_min_value_state` or something similar? @Tronix117 what do you think?\\r\\nLet's try to make this as descriptive as possible. By order of priority (first is higher), there is : \\r\\n\\r\\n1. `_attr_native_min_value`\\r\\n2. `<native_min_value_from_state>`\\r\\n3. `native_min_value`\\r\\n4. `DEFAULT_MIN_VALUE`\\r\\n\\r\\nIndeed, we should drop the `native_` prefix, it does not make sense here.\\r\\nI don't think `default` should be part of the name, we are levels ahead of default in  the hierarchical order.\\r\\n\\r\\nThe `_key` suffixe is used in some other files, but if I were to do it I may have wanted to be consistant with Overkiz naming, using a `_state_name` suffix.\\r\\n\\r\\nHowever pyoverkiz constants are simply named `state` so I guess it's better to follow your suggestion `min_value_state` or more verbose `min_value_state_name`.\",\n",
       " \"Maybe we can assert the whole response with a snapshot so it's easier to see what this service would actually output? Good call! I have made that change. Is there any use for this for an end-user or can it be removed (I see no use for it)? It is used for\\r\\nload_multi_map\\r\\nname_multi_map\\r\\nrecover_multi_map\\r\\n\\r\\nwhich are used by some end users. I could go either way on this. Let's keep it then ðŸ‘  Somewhere it says there can only be returned the active map.\\r\\nSo should this really be a list or not just return the correct dict for the current map? It caches all of the maps that is has seen - and it should see them all on startup. I suppose this is empty as it's not the current active map? So this was actually a side effect of the map flag not being updated in the coordinator. It gets updated on status change - but a) that doesn't happen in tests as status is static and b) in the real system that also wouldn't always happen before setting the room info. so I manually set the current map now.\",\n",
       " \"you can't change internals (at least not in this PR) `services.py` is reserved for HA services. This looks like it is the downstream lib \\r\\nalso need to put it in the manifest I'm not adding any new service (not for now at least).\\r\\nI have a file that I called `service.py` where I'm putting all related to my PlexampService to have it somewhere while I work on this and that I will eventually move out.\\r\\nI've been looking at what other Media Player like integrations are as integration_type and almost all of them are 'hub'. If I don't provide any service, should I still list it as 'service'?\\r\\n\\r\\nI really appreciate your time and doing the code review. I still have it on Draft and I really wanted to know if I was very off with what I was doing, your review has given me some reassurance! \\r\\nnot needed lots of duplicate code here, I think we can simplify that I'd suggest moving the sonos stuff out, for now, to make this PR smaller this looks like it belongs to the downstream libary and not here you'll need a downstream lib in PyPi where you put things like this\",\n",
       " \"I would suggest to extract the login etc. to a helper and reuse in `cover`. I don't think this will help much, it wouldn't really reduce on lines since we have to pass in email, password, etc. into the helper again anyways. Can be removed once you create device info here.\\r\\n Can be set outside of the constructor  I'm assuming this is also present in cover.py. consider creating a base entity where all similar calls are stored to reduce code duplication This looks a bit ugly tbf. Isn't the client already present in the coordinator? I know, but Linear in itself is very ugly to begin with. Not even their own mobile app is reliable ðŸ˜…\\r\\nThe client uses WebSockets, but, it's extremely unreliable, and the only real way to get working communication without somehow not receiving messages anymore, is to pretty much connect only when we need to retrieve data, then disconnect. I haven't really found a good way to fetch data other than this, hence this ugly mess ðŸ¥² What would you think about moving this to the coordinator anyway? In what other places do you create this? Should I just move `linear = Linear()` to the coordinator and then access it from `cover` and `light`? One question i still have, do we need to login every time?\\n\\nYou could make this a property in the coordinator so every time you fetch coÃ¶rdinator.client you get the logged in cliÃ«nt Yes, sorry. Every time you connect, you have to send the log-in request. If you stay connected after sending a request or fetching data, it will completely stop responding to requests, which is why I went with this method. Is there something I need to do here or can this be something fixed in the future? Beta has been cut, so let's take the time to make it nice if you don't mind :) Please don't touch internals This is practically testing the same Consider creating a broader patch, checkout analytics_insights or Epion  ~~Take a look at what I did with the patches, is that enough?~~\\r\\n\\r\\nEdit: Just realized this makes the tests fail, reverting Let's do this change in a separate PR \\nI think unneeded because it's used in an f string Oh and you don't need this as this means the state is updated every 60 seconds, but since the state is updated through the coordinator, that doesn't make a lot of sense. This is the default, why do we set it? Truncating will cause annoying off-by-one errors, I suggest to round instead, both here and in `async_turn_on`\\r\\n \\r\\n We can use a translation key for this\",\n",
       " 'Might be better to add `eager_start` to the existing function\\r\\n The tests that call async methods should really be coroutine functions so that the context is correct.',\n",
       " 'This attribute is always overwritten @ line 74 \\r\\n\\r\\n',\n",
       " \";) You're already snapshotting the attributes in the snapshot test down below. So this test is obsolete imo.\",\n",
       " 'Same comment as on the previous PR #discussion_r1404558026 Sure, I\\'ll have a look at this I moved the uptime calculation in the DataUpdateCoordinator as requested, let me know if this looks better.\\r\\nThanks ! It appears translations was not generated given the strange name? You\\'re right, and the tests weren\\'t running on the uptime sensor.\\r\\nI updated the snapshot, reference uptime and also froze time to fix the time reference used in the snapshot. It would be better to use `_handle_coordinator_update()` also here so you can remove `native_value` completely as it\\'s defined already in `SensorEntity` Thanks for the suggestion, I wanted to minimize change to the existing sensors but it makes sense to be more consistent with the uptime sensor.\\r\\nI\\'ll test the change and submit back if this works. Done, I have moved the code to `_handle_coordinator_update()` and removed the `native_value() `override Same as previous comment Done \\r\\nShould be able to remove this completely _handle_coordinator_update is  not called by the DataUpdateCoordinator during initialization of the sensor, so I have to add this initialization of the value for _attr_native_value.\\r\\nIf I don\\'t the sensor remains null until the second API update one minute later. Yes. But in the base class you could have\\r\\n`self._attr_native_value = self.coordinator.data[self.entity_description.type]`\\r\\n\\r\\nSo instead of calling `get_uptime()` here you can do it in the coordinator to store the data properly in the dict and also it would be better to control the refresh rate of this in the coordinator than in the entity update. Ok got it thanks! \\r\\nI\\'ll update this. Done, most of the code specific to the uptime sensor has been moved to the `DataUpdateCoordinator` Why would this be needed? The coordinator only updates once a minute. The glances API provides a string representing a timespan (like  \"uptime\": \"3 days, 10:25:20\") but does not provide the absolute time it refers to. There is a sum of delays which varies each time the API is called (internal Glances poll loop, duration of the Api call, time inside Home assistant before converting back to an absolute time..) which means that the resulting datetime computed in the HA sensor varies from a few seconds to a few minutes depending on the configuration, for each call of the API.\\r\\nIt\\'s not a big deal for an uptime sensor as it is typically measured in days or weeks rather than seconds or minutes.\\r\\nBut without this check to eliminate small changes, the sensor value changes every minute which makes the history UI unreadable and spams the database uselessly. I have moved the update frequency code to the `DataUpdateCoordinator` This does not give an uptime. It gives you the time it started.\\r\\nShould the sensor be named differently? This seems to be the standard in home assistant : uptime sensors return a datetime which is the moment of startup. \\r\\nSee for example the uptime integration : \\r\\n#L34\\r\\nA few other examples:\\r\\n#L111\\r\\n#L143\\r\\n\\r\\nIn the UI, the absolute datetime is displayed as a relative time (like 2 days 10 hours..) by default, so I think it makes sense.\\r\\n How about just checking here if it should refresh. Something like:\\r\\n The test is a bit more complex, because we don\\'t just wait for a certain time to refresh. We need to check if the uptime itself has changed significantly, and update it only of it has moved more than a certain amount.\\r\\nHence the comparison to the previous uptime value, not to the previous refresh time.\\r\\n\\r\\nWhat we want to avoid is a succession of changes to uptime like this (what i called flapping) - those are actual values for a server that was not restarted:\\r\\n uptime=2024-03-10 21:**18**:28.**588024**+00:00\\r\\n uptime=2024-03-10 21:**19**:28.**397835**+00:00\\r\\n uptime=2024-03-10 21:**20**:28.**381627**+00:00\\r\\n uptime=2024-03-10 21:**18**:28.**408223**+00:00\\r\\n uptime=2024-03-10 21:**19**:28.**393393**+00:00\\r\\n uptime=2024-03-10 21:**20**:28.**391400**+00:00\\r\\n uptime=2024-03-10 21:**18**:28.**410554**+00:00\\r\\n uptime=2024-03-10 21:**19**:28.**382378**+00:00\\r\\n \\r\\nJust overwrite the value? Two reasons to have uptime in a nested dict : \\r\\n1- Having the computed value in a nested dict like the other sensors simplifies the code. \\r\\nWith the nested dict, no need to make a special case for uptime anymore.\\r\\n2- Keeping the original value (a relative  value stored as a `string`) and the computed value (an absolute `datetime`) distinct makes the code repeatable, no need to check for the type or risk of applying a transformation to the wrong value Good point Set the icon in `icons.json` instead Good point \\r\\nWe should move time instead of using coordinator internals.\\r\\n\\r\\nSearch for `freezer.tick` to see examples.',\n",
       " \"Instead of putting this here, you can extend the ValloxButtonEntityDescription with a press_fn and put the function in there. Check Flexit_bacnet (I think the number entities) for an example I was thinking `ValloxButtonEntityDescription` will be stored somewhere, so it would be bad to extend it with non serializable data. Will take a look. Nope. Some integrations contain 10s entities. To avoid creating 50 separate classes, we have this entity description that we can inject from which it takes data. This way we can keep all the logic of that sensor concentrated in one place. I do not think this integration would ever have more than one DateEntity. Filter change date is the only only one that unit exposes. But then we shouldn't use the entity description. Although this works, this isn't the optimal way of using either method I see DateEntity class has entity_description: DateEntityDescription parameter. No idea what it is used for. Well the idea behind an entity description is a way to quickly create new entities. For example when you look at a `device_class` property:\\r\\n\\r\\n\\r\\n\\r\\nSo instead of having 50 classes with each their own variation, we have an entity description, a class we can inject and then the trick is to encapsulate all the variation in that entity description. Your `SensorEntity` (as example) would then be a generic class that gets the right values from the entity descriptions to still express that variance. Since you can manually update the date, wouldn't it make more sense to use a DateEntity? That would make it more useful for example for people who changed the filters last week. Can you also retrieve the last filter change date? Hmm, I received request for a button, but that makes sense. Will change then. True, a DateEntity would be a bit more flexible. ðŸ¤” I liked the simplicity of the button though. OTOH, if one presses it by mistake or forgets to press it after actually switching, it could be useful with a date input. I mean, you can replicate the simplicity of a button by using an automation :) Please just repeat the translation key instead of referencing it. Stale docstring Stale Stale  Stale\",\n",
       " '',\n",
       " \"_ attr_device_class can for some reason not be defined like this.\\r\\n\\r\\nRunning the following after startup:\\r\\n\\r\\nReturns\\r\\n\\r\\nThe previous method worked as expected.:\\r\\n\\r\\n That's interesting, I have implemented it like this in a lot of integrations Is it because the order is inverted here? class BangOlufsenEntity(Entity, BangOlufsenBase): Oh that's something I should look into Ah, apparently we set `self._attr_device_class = None` in the constructor Should imports still be this order? This one doesn't matter as the `BangOlufsenBase` doesn't override anything from the Entity Wouldn't this be better to have in the BangOlufsenEntity class? I usually only put this in the platform it applies to, so whenever someone is going to add sensors or something like that, they don't have to refactor that\",\n",
       " \"\\r\\n\\r\\nDoesn't this assume the entity is using `_attr` shorthand? Yes. It was just a quick and dirty to have a discussion around but I didn't come back to it yet. It's not in a state that it would be any good. \",\n",
       " 'We should be able to think of a better sentence that includes the name. We wouldn\\'t want the name to be first in the sentence though, as a long name might hide what is to be repaired.  Maybe something like: `The integration <for> {name} needs to be reauthenticated`\\r\\n\\r\\nNot sure about the \"for\", it depends how other integrations use the name/title I\\'ve pinged UX for help :)  I was personally thinking maybe something like\\r\\n\\r\\n> Authentication expired for {name}\\r\\n\\r\\nBut it depends on the guidelines for repairs which I don\\'t currently recall. Do we describe the issue or the fix the user needs to do ? \\r\\n',\n",
       " 'If there is only one light, we should not return \"\", it should be its own translation key Done. It is required to set the supported color modes (\\r\\n\\r\\n Done. Done.',\n",
       " \"\\r\\n\\r\\nYou can avoid creating a list here Done. (Though, the previous approach was consistent with existing code in this integration.) Please use icon translations: #icons How does that work, now where I use two different translation keys based on whether it's the only pump or one of multiple? Do I have to duplicate the icon translation for each translation key?\\r\\n\\r\\n(FWIW, I just did this consistent with the existing code in this integration which already uses the icon property in `binary_sensor.py` and `climate.py`.) > How does that work, now where I use two different translation keys based on whether it's the only pump or one of multiple? Do I have to duplicate the icon translation for each translation key?\\r\\n\\r\\nYes, you need to duplicate the icon translation for each translation key.\\r\\n\\r\\n> (FWIW, I just did this consistent with the existing code in this integration which already uses the icon property in binary_sensor.py and climate.py.)\\r\\n\\r\\nIt's true, we haven't migrated every integration yet. The icon translations are quite new (introduced with 2024.2), so feel free to create a PR for it. Edit: Ok, there was a PR for this, that has been merged.  Done. I got rid of the duplication, not sure if there is a model with only one pump anyway.\",\n",
       " 'Can you add a test that uses this fixture?  I guess this not necessary then? :thinking:  Oof, yeah. Removed it The whole wind feature seems a bit weird to me :sweat_smile: . \\r\\n\\r\\nI wonder if making them preset modes is a good idea. From what I understand, the Natural Wind mode is meant to emulate natural wind (presumably vary a bit?) but based on the current setting otherwise. It is like a \"feature on top\" of the regular setting.\\r\\n\\r\\nMaybe better to just leave it out completely for now? Or make it a boolean configuration entity so it can get toggled manually? :thinking:  I thought about it for a while and it fits HA presets - I see it reversed, I think its super strange they made this a separate feature. If this mode is enabled, the device handles the speed, just like with a preset.\\r\\n\\r\\nI\\'m open to more ideas but making it a configuration entities doesn\\'t make sense to me as its in fact an additional mode, impacting the primary functions of the device.\\r\\n\\r\\nMaybe a separate input select entity but that decouples it entirely which is imo not so nice UX > I thought about it for a while and it fits HA presets - I see it reversed, I think its super strange they made this a separate feature. \\r\\n\\r\\nThey made it separate because it is based on the speed setting, see:\\r\\n\\r\\n> 4.4.5.2.1. SleepWind Value\\r\\nThe fan speed, based on current settings, SHALL gradually slow down to a final minimum speed.\\r\\nFor this process, the sequence, speeds and duration are MS.\\r\\n\\r\\n\"based on current settings\", that said, the same is missing from natural wind, but I would expect that the natural wind feature too is based on the current setting. It says it is \"manufacturer specific\", so I guess technically it could be both? :thinking: \\r\\n\\r\\n> Maybe a separate input select entity but that decouples it entirely which is imo not so nice UX\\r\\n\\r\\nI guess both could be enabled at the same time (in theory) so input select is also not ideal. But IMHO, it would be better so it can be selected separtely to the presets.\\r\\n\\r\\n Both can be enabled at the same time ? That is even more strange.\\r\\nSo, what you are proposing is a \"multi select\" input select entity then or 2 switch entities ?\\r\\n\\r\\nThat also feels like a weird hack to me and completely detached UX-wise for the user because we do not logically group the entities together for the user. But yeah, if wind mode is a special feature on top of fan modes and speeds we should make separate controls. I\\'ll quickly discuss this with a vendor first. > Both can be enabled at the same time ? That is even more strange.\\r\\n\\r\\nIt seems device dependent, but it could be possible it seems :see_no_evil: But no idea what is out there, and if that would ever be used together, so... :man_shrugging:  \\r\\n\\r\\nI think I\\'d go for two separate switch entities still, but I honestly don\\'t have any strong feelings here. A separate input box is fine by me too.\\r\\n Like discussed just now in PM - Vendors will also treat the wind modes as presets - the fact that it is separate is just some inheritance from the zigbee clusters and in practice no device will support both sleep modes at the same time. If they ever will, we will have some refactoring to do but let\\'s just start here and wait what happens in practice.  Yeah agreed, it seems this is mostly treated as preset. Also, the fan speed can still be selected, even when natural or sleep wind mode is chosen, so it will still be possible to change the speed.\\r\\n\\r\\nAnd ontop of all this: If there is a good reason, we can still refactor/change this. I didn\\'t really see 255 in the spec, is that something you encountered in testing? If so, maybe worth a comment here what\\'s up with this value exactly. Yeah, I get back 255 if the speed is controlled by auto mode added a comment Why did we exclude this file from coverage?',\n",
       " \"We should create repair issues instead to point users to the fact that they need to remove the YAML. Please checkout integrations like `lutron` and `suez_water` for this. Done I think this function would work better inlined in the user step Done Only have stuff in the try block that can raise Done This step is missing a check for uniqueness. Can we fetch some kind of value from 17track that could act as unique identifier? Otherwise we should use `async_abort_entries_match` to compare the new user input with existing entities.\\r\\n\\r\\nCan users change their username in the 17track app? Done. I used `account_id` from the 17Track API \\r\\nI'd argue that this is a service instead of a hub We should keep this import in the `sensor.py` I'm not sure what you mean?\\r\\nIf I move this to `sensor.py` I get the following error:\\r\\n`[ERROR] [CONFIG_SCHEMA] Integrations which implement 'async_setup' or 'setup' must define either 'CONFIG_SCHEMA', 'PLATFORM_SCHEMA' or 'PLATFORM_SCHEMA_BASE'` Currently the integration is setup in sensor.py (with I think either (async)setup(platform)) removed setup from `sensor.py` Currently this is never set or imported afaict see Line 314:\\r\\n`self.async_update = Throttle(self._scan_interval)(self._async_update)` yes, but I am talking about how this data got into `config_entry.options` you're right. I'll just use the default Use default constants\\r\\n\\r\\n\\r\\n I would omit the integration name in the entry name, it adds no real information.\\r\\n\\r\\n Is it possible to combine `USER_SCHEMA` and `OPTIONS_SCHEMA` here to avoid code duplication? Done Can be removed removed This error doesn't add anything as the error message already reflects this Issues should be guiding the user more to what they did wrong. Did the connection fail? Are their credentials incorrect? Please check integrations like `lutron`, `suez_water` or `streamlabswater` for examples \\n\",\n",
       " 'Use [translation_keys](#entities) how do you suggest use a translation_keys \\r\\n\\r\\nand this goes to `strings.json`\\r\\n\\r\\n\\r\\n\\r\\nBut it would not be used if you overwrite `name`. Just noticed that you can have placeholders in the translation as well. Would a naming like \"{sensor.name} motion sensor\" make sense? no, actually the user can edit the name from our app, not needed to add the type of device in name I thought that you\\'re supposed add each entity as a device, set name to none, and use has_entity_name = True.\\r\\n\\r\\nThen the type will automatically be populated. See [entity naming section here]( use list comprehension\\r\\n Your solution is better :) If name comes from the sensor, can you omit the `entity_description.name`? Please use has_entiy_name for new platforms #has_entity_name-true-mandatory-for-new-integrations Yeah, that\\'s what I figured. has_entiy_name is inside MicroBeesEntity alrady The way I understand it, you create a device for the physical sensor.  The main thing the sensor measures has an entity with a name of none.  Any other entities related to the sensor are separate entities with names, i.e. low battery, tamper, etc.  You then attach all your entities to the device.\\r\\n\\r\\n[see here:](\\r\\n\\r\\n microBees has several Bee(device) prototypes, every prototype (or device class) have sensors and actuators. For example a light (LightBee) has 2 sensor (absorption sensor and switch status sensor) and 1 actuator.\\r\\nThe name of the sensor can be changed from the user but usually is \"absorption sensor of the bee 12345\". We have devices offers sensor only too without actuators.\\r\\nWe could add SensorEntity also to light and some kind of switch, but we\\'ve seen in the integrations we\\'ve studied before submit ours, so we separated the platforms. Make sure you are looking at newer integrations, the scheme has changed.\\r\\n\\r\\nIn the case you are describing (@bdraco correct me if I\\'m wrong), you would create a light entity.  It would have an entity name of None. It would also have a device property filled in according to this:\\r\\n[device properties](#device-properties)\\r\\n\\r\\nYour identifier would probably be the serial number.   It\\'s name would be the name and name and name_by_user properties.\\r\\n\\r\\nyou would add the switch status sensor binary sensor entity.  It would have a name like \"Switch Status\" as a name, and it would return the device object you created when you created the light entity as the device property.  \\r\\n  @rlippmann we haven\\'t seen any Integration act like this. can you please suggest some sample? it\\'s a new practice but I think is still valid the old one we have followed. Is this PR legit and ready to be merged? Look at any here:\\r\\n\\r\\n[February 2024 new integrations](#new-integrations)\\r\\n\\r\\nThey sometimes use self._attr_device_info, but it\\'s the same thing. Hello @rlippmann , as you can see  and  (for example) we do the same exactly thing. we do in the entity.  1) I have no authority to approve or deny a pull request.  I am merely giving you suggestions on how you would go about getting it approve\\r\\n2) both those instances cited have self._attr_device_info attributes. @rlippmann we have too. please check MicroBeesEntity. Can this change at runtime ? If not it would be better to set it as `_attr_name`\\r\\n\\r\\n#L686 Yes, users can change bee and sensor name from our mobile and web Apps Since there\\'s a unique id, changing the name during the entity lifetime won\\'t have any visible effects to the user. It will only change the state attribute friendly name. The entity id and name shown to the user will remain.\\r\\n\\r\\nWe should move this to `_attr_name` in the init method or just remove it since there\\'s a device class set and we have default names with translations then.',\n",
       " 'Although only tests, these lines are very long. So maybe break up the strings into max 88 characters per line. We should probably follow the max line width of 88 chars here. Should also be fixed in some other places. The extra check (and not always writing `_on_value` / `_off_value`) is done to make sure the type is a `bool`, right?\\r\\nIs there really any difference though (or is this done bc of some other reason)? zigpy should always use the correct \"Zigbee type\" at least.\\r\\n no these are to use custom on and off values... meaning we have to write something non 0 or non 1 to the device to make it on or off. there is a test for this.  Yes, but why do we need the third condition for that? `_on_value` and `_off_value` are 1 and 0 by default. We can just always write `_on_value` (or `_off_value`).\\nI would think this logic could be simplified.\\n\\n(Might be missing something though, I\\'ll have another look at this later again..) Adjusted The `__` (double underscore) in `zcl_enum__metadata ` seems to be a typo.\\r\\n I\\'d put this in one line here:\\r\\n Technically, the line is also a bit long. Maybe put the comment above and make it slightly more clear?\\r\\n Should this message be a warning maybe? Like, this shouldn\\'t really happen with any zha-quirks release.\\r\\nSo, having a warning would make it clear why a custom entity isn\\'t created for people developing a custom quirk. Referring to the above comment with changing a log to a warning, this one should likely be changed too. Referring to the above comment with changing a log to a warning, this one should likely be changed too. Some of the entity classes set the category for HA (e.g. `ZHASwitchConfigurationEntity`, others like `ZHAAttributeButton` do not).\\r\\nI\\'m not seeing anywhere where `_attr_entity_category` is set to the `entity_type` of zigpy `EntityMetadata`. Should that be done in the base ZHA entity class? not in the base intentionally. the type is only used in the matching logic here atm and most classes set the category appropriately. This needs to be addressed subsequently when it is safe to set it in the base.  will try setting this in the base entity. I don\\'t think it will hurt anything but in the cases where the match is to a specific class that overrides it this could be confusing. once this is in we can migrate a lot of these classes to quirks definitions and remove them from HA. This will make this much easier to clean up/ Should this also set `_attr_entity_category` to the `entity_type` of zigpy `EntityMetadata`?\\r\\nDo note that some classes like `ZHASwitchConfigurationEntity` would overwrite that category again. Might be nice to also add test coverage for this line. test would be contrived. the only platform that would combine them atm is update and there is no way to express update entities from quirks yet.  The `update` method returns `None` so I think this would actually fail. You may be able to replace both cases with this (and remove `_maybe_combine_kwargs` entirely?)?\\r\\n\\r\\n The following three tests all share quite a bit of code.\\r\\nMaybe `parametrize` could be used here (easily/in a nice way)? If not, eh.. probably doesn\\'t matter. They are testing (slightly) different things after all, not the same. This line is also a bit long. The translation key must be set with a string from the integration since it must map to a string in the strings.json file. We don\\'t allow setting it directly with data from a 3rd party library. Units are preferred to use the Home Assistant constants as far as possible. We are using clones of the HA units in the lib We still prefer using the Home Assistant constants when possible. Side note: Where is the `options` property set for the enum sensors with device class enum?\\r\\n\\r\\n#available-device-classes Options are computed from the enum values and that has not been changed by this PR Where is the options set? This will create extra state attributes that we don\\'t see the name of. We want to review all extra attributes before they are added. There must at minimum be a map in the integration for these. This is the ZCL attribute for the sensor and has nothing to do with HA state extra attributes.',\n",
       " \"I suppose we could move this up to `get_description` and then use it also in `find_matching_platform` The `name` could also go into `get_description` Definitely possible, but we chose to do it way in previous platforms (sensor, binary_sensor, switch) following advice from the reviewer. The EntityDescription classes are immutable and that makes it more complex to change or add attributes. We pick up static data from get_description and then add other more dynamic attributes by setting \\\\_attr\\\\_*  this way. We should not add entities without an entity description. Can this even happen? Yes, it can happen. In fact it is common in sensor platform. The API delivers some 60 device points for e.g a Nibe F730. It is not uncommon that we can't identify the optimal device description from the meta-data. Then we create the entity without description. The name is most likely enough for the nerd-user to understand what the data is representing. But the names are not stable enough so we have chosen not to use names for selecting platform or device_class.\\r\\nIf a device_point has the attributes maxValue and minValue set and writable is true it is best represented in HA by a number entity even if we cannot assign an optimal device_class or icon. Why isn't it sufficient with the first one as they both result in the same entity description? The world is not perfect...\\r\\nOr the upstream implementation of the API is not perfect.\\r\\nThe myUplink  cloud service is an attempt from the Nibe group to consolidate the service for all their brands (Nibe, CTC, Contura, Ceteterm and 10 more). Most of these heatpumps report DM as unit_of_meaurement for degree-minutes data while Nibe F-series products leave this field empty. But all F-series appliances feed this data point from the same parameter_id. That is why we need an override table, also used in other platforms in this integration.\",\n",
       " \"I think we can use icon translations instead? Indeed, we could (and likely should) do just that. I suppose we cannot provide these programmatically, but they need to be defined in the JSON file. Right. They allow a default icon and one based on the current state\\r\\n\\r\\nExample:  Created some entries for testing, alas, the manual icon definition overrides the `translation_key` so we need to rethink how to expose custom icons in cases where no icon translation is (yet) available.\\r\\n\\r\\nMaybe we can programmatically check for the existence of a translation icon in our own `icon` property implementation, and use that to decide whether to return the custom icon definition or `None` (for translated icons)? That sounds rather hacky, though, so I hope there is a better solution available... Doesn't having to hardcode the icons in the icons.json lose some of the flexibility we're trying to introduce with the features? Yes, I think we don't want to do that until we find a workable solution for this. I tried to look into how we could check for the existence of translation, but couldn't find a quick solution. #103294 is the relevant PR, adding just here to have it written down somewhere.\\r\\n\\r\\nGiven it is just UI candy, we can do without it for the time being. As we now have static identifiers for features, I think this is now resolved & just requires us to add icon translations for the features we want. We can strip the new platform out before merging and put it in a second PR Yes, this PR is just for development use, the final one will be split up, and the new platforms moved into separate PRs. We can strip the new platform out before merging and put it in a second PR Its a bit strange for the library to know about HomeAssistant.\\r\\n\\r\\nI think we should rename this `legacy_compat` instead So this is a counterpart for  - basically, we need some way to inform homeassistant on its own special handling for some features. An alternative would be to store this information inside the integration, but I was thinking that it would be better to keep this local.\\r\\n\\r\\nWe could inverse it by 1) adding static ids inside python-kasa and 2) using those ids to map for wanted parameters. Do you think that would be a better approach? We definitely shouldn't be teaching the library about Home Assistant.  We should store this information in the integration.\\r\\n\\r\\nI think its fine to add information to `python-kasa` to make it easier to map in Home Assistant, but its separation of concerns problem for the library to start learning about HA Yeah, I tend to agree on that, back to the design board then. I think we could map _some_ information directly using the unit information the library provides, for some other we may need to have a static map inside homeassistant. For the static ones, we need probably set static identifiers instead generating ones from pretty names to avoid breaking this in the future.  requires static identifiers for features, so we can move the mapping inside the integration. done. Changed in be3b586ce8d7 I think there could be an issue here for the existing child devices.  What I seemed to encounter when working on the ks240 PR is that if a device registry entry already has the `connections` set then when you remove the `connections` from the entity creation they are still present in the device registry.  At least that's what I thought was happening. I think this is where we can check if `feat.category` is Debug and set `_attr_entity_registry_enabled_default` \\r\\nIf you look at #diff-3039452aefa70a1099b307cc1eea25b60996f064fa974f679a56c732e09919a8R76-R87 this has an option to also add the entity to the parent which I think works well for the ks240 and would also work well for the power strips (and be consistent with how it looks at the moment on the parent IIUC).  And then we only put all the extra sensor info on the children so they can drill in. Is this `children_coordinators` logic specific to `Iot` Strips?  I think so as the `Smart` parent handles the updates for it's children.  If that's so then this should probably check for `Iot.Strip` to be specific Also I can't work out why this doesn't also use the ` _entities_for_device_and_its_children` I think we should be naming all our entities with the TPLink prefix.  That seems to be the norm for other integrations and  it's consistent with the entity description names etc. Yeah, I kind of like shorter names as they are already namespaced by the package, but this probably needs to be changed to get it merged :-)\",\n",
       " '\\r\\n\\r\\nYou can avoid creating a list here Please use icon translations (#icons) Why do it this way? Are there more IDs? yes, i have more IDs \\r\\n\\r\\nThis way you could avoid create a second dict and maintaining the IDs twice. Maybe use `BUTTON_PRODUCT_IDS` as the const name instead',\n",
       " 'You should consider add tests actually they\\'re not mandatory and we\\'ve speed up to introduce all our platforms, we will write in future releases Invert the if and raise if the sendCommand failed. Then we can outdent.\\r\\n\\r\\nWhy you use `Timer` here? You could make use of `async_call_later`, which is a helper function. Same as above Move outside the `__init__` Move above the `__init__` for better readability There is no way to determine the current state? no, there\\'s not Ok, but we still need to set `_attr_is_closed` to an assumed state after we have executed the open or close command. Otherwise the state would always be unknown. It will be always unknown. Our device doesn\\'t know if cover is open or closed. > Ok, but we still need to set `_attr_is_closed` to an assumed state after we have executed the open or close command. Otherwise the state would always be unknown.\\r\\n\\r\\nwe cannot determine or assume the status because you can also use manual mode (without our device) to open or close and we have no way to have the actual status. You could take a look at the Comelit cover platform, which also cannot retrieve the current status. I\\'d rather have a status that doesn\\'t match the physical status of the device 100% (due to manual intervention on the device or something) than a constant \"unknown\" status which is not a good user experience in my eyes. Actually we don\\'t like the Comelit solution. We prefer customer can open and close in every case and stop. For example if I want to open just a little I can do it stopping whenever I want. Assuming the actual status avoid this and can cause inconsistent status in case of manual intervention or something else.\\r\\nIn our opinion this is the best user experience and freedom for the use of the device I talked to another core dev about this, and it\\'s fine to have the permanent \"unknown\" state, but you should probably note this in the documentation as I suspect there could be some issues coming if the entity is constantly \"unknown\" . So feel free to mark the PR as ready for review. Please use a generator expression instead of filter + lambda. The library should create human readable abstractions for the product ids etc so that the library user doesn\\'t need to handle these magic numbers.\\r\\n\\r\\nOne way would be to create enums that name the numbers.',\n",
       " 'Please use identity checks to compare enums  \\n \\n Usually we do the lib bump in a separate PR if its not a breaking change  This is the only change between version 22.1.0 and version 22.0.0:\\r\\n\\r\\n\\r\\nBut I will prepare a PR to change the version. #111435',\n",
       " '',\n",
       " \"Why is this case added? If it's only needed for preview, it should be possible to handle it in `async_start_preview`, if it's a bug fix it should be moved to a separate PR. Yea, that's just the case for preview. I moved this to `async_start_preview`. See the new PR as I screwed up the rebase\",\n",
       " 'Would be faster to initialize the schema once\\r\\n',\n",
       " 'Can we create a private function for it and use it also in `label_devices` and `label_entities` Done!',\n",
       " \"Should this be handling multiple adapters instead of picking the default? Yes, I think we can always pass a list to the socket initialize method. Will test it I think we should try the default one first, than add the others so we can catch `OSError` on subsequent ones so we don't have a repeat of  I followed #discussioncomment-672957\\r\\nShould be safe.\\r\\n I think we should have a test that wraps `context.initialize` checks what is passed to it based on a few parameterized network configurations I added a test with 2 ip addresses, while the others use the default one.\\r\\nWe can always expand it, but I need some help ;-)\\r\\n I think you want to patch it with `wraps` #unittest.mock.Mock and than check what it sends\\r\\n\\r\\n> wraps: Item for the mock object to wrap. If wraps is not None then calling the Mock will pass the call through to the wrapped object (returning the real result). Attribute access on the mock will return a Mock object that wraps the corresponding attribute of the wrapped object (so attempting to access an attribute that doesnâ€™t exist will raise an [AttributeError](#AttributeError)). \\r\\n\\r\\nI think this is duplicate logging since it will get logged at #L33 if the network integration has debug logging Discussed on discord that it would be helpful for this information to appear in the shelly debug logs when enabled from the UI I added it only because users usually enable debug from the ui and this will be only for `shelly` component and `aioshelly` so to get the info easily, IMHO the debug on the shelly side is useful.\",\n",
       " \"This should go before the repair cases (we shouldn't have those repairs if this is what we want).\\r\\nAlso likely update the description of those repairs to make them more clear and easier to understand. Need also to update `_get_valid_units` below Name this more specific on what it's testing Should probably also change a source sensor to another UoM to test that behavior in this case after the asserts below\",\n",
       " 'We should preferably catch `ClientResponseError` first and raise `ConfigEntryAuthFailed` for status 401/403 as specified by the API. Raise `ConfigEntryNotReady` for other client errors.\\r\\n\\r\\nExample:\\r\\n#L168-L175',\n",
       " \"Why do we update the `vicare_programs` attribute but not the `_attr_preset_modes`?\\r\\nIf the programs can't change, we should probably set both in `__init__`, if they can change, we should change both here?\\r\\n\\r\\nAlso, can't the call to `getPrograms` raise `PyViCareNotSupportedFeatureError`? > Also, can't the call to getPrograms raise PyViCareNotSupportedFeatureError?\\r\\n\\r\\n`getPrograms` iterates over a fixed list of known programs, if no `PyViCareNotSupportedFeatureError` is raised, the program is considered as supported and added to result list.  I see no reason why this should change, so will move it to `init`.\",\n",
       " 'Can raise `KeyError` on `old = self.categories[scope][category_id]` Nice catch! Addressed in [a42423e]( Could we add a test that the same name can be used in two different categories if the scope is different?\\r\\nNot sure if we should add it here or in the helpers/test_category_registry tests Added to both, done in [d9c7c92]( actually ulid is faster. \\r\\n\\r\\n Done in [ccd62c1]( How can an entity be in different categories? Shouldn\\'t it only be able to be in the category for the scope that is the same as the entity domain?  Depends on the view/dashboard.\\r\\n\\r\\nFrom the entities dashboard, you could have a different categorization compared to your automations or zones dashboard. Yet, entities are on both, and both can have a different set of ~~folders~~ categories.\\r\\n\\r\\nThe original PR (#93498) was based on a `domain`, but we changed it to `scope` as it doesn\\'t have to be a domain-limited view (like, for example, an entities dashboard, helpers dashboard, or whatever else).\\r\\n\\r\\nAs this is a full frontend visualization thing, the scope can be managed by the frontend to match its display. Same question as above: this can just be a string ID to the category that belongs to the domain ?  A `entry.categories.get(scope)` should be faster as it only needs to lookup the `scope` key once in the dictionary.  Addressed in [deb45eb]( Same Addressed in [deb45eb]( It could also be the scope that is missing. The error message isn\\'t wrong, as the category entry for that category id wouldn\\'t exist in that case either, but it\\'s confusing if we also don\\'t mention that the scope is missing. Well, this is a safeguard (which should technically not happen). If the category exists, the scope would as well (as a category is nested in the scope).\\r\\n\\r\\nFrom the end-user, they can create categories, they can\\'t create scopes. So, from that perspective, I think the current messaging is better in that regard.\\r\\n\\r\\n Side note: we probably need a way to group the loads in the executor here There was a base class for registries added a while back that could be used here \"a while back\" \\r\\n\\r\\n![CleanShot 2024-03-14 at 20 51 34@2x](\\r\\n\\r\\nðŸ¤£  done in [ef197e3]( It felt longer.  ðŸ˜‰  The items besides categories should probably not change. Hmm seems like I forgot to update the translations before generating these ðŸ¤¦  fixed in [51f8417](',\n",
       " \"This seems wrong... What is Python runs in optimized mode and the asserts are not ran?\\r\\n\\r\\nThen we don't fetch this at all? PS: We can rewrite this without having a need to assert at all.\\r\\n\\r\\nAvoid the use of cast and assert whenever possible. How would you do it? Raise if `None`?\",\n",
       " 'There is no `host` in the `user_input` in the `async_step_credentials` function:\\r\\n\\r\\n Thx, wrong variable used :-( Should we increase the  config entry `minor_version` if we add a new field?  This will raise a `ValueError` if the user provides a host with `:` but no port number, e.g. `192.168.2.56:`. You want to guard against ? Current code if you put a \":\" in the host raise an error as well;  Done What about gen2+ battery powered devices? You mentioned that they also don\\'t work when configured via a range extender. Shelly is checking in order to support them. Seems it\\'s trivial.\\r\\n\\r\\nEDIT: Currently you get a Cannot Connect error so it\\'s fine. Will make clear in the documentation Fixed with latest aioshelly I think this will look better in one line:\\r\\n\\r\\n\\r\\n\\r\\n![obraz](\\r\\n We shouldn\\'t be using a custom parser for config flow inputs. The config flow uses `voluptuous` to validate user fields and fields should be visible to the user which will also make it easier to document them.\\r\\n\\r\\nExample (all other integrations with HOST/PORT are the same):\\r\\n#L14-L17\\r\\n#configuration-variables Was discussed with @bdraco and due to the fact that that less users will use this config was suggested to not expose the port field to the flow\\n Why are you returning the input `port` as an output? the caller already has the `port`? (we are also not returning the `host` here and they are used together\\r\\n Probably a leftover when port was parsed.\\n `data.get(CONF_PORT, DEFAULT_HTTP_PORT)` this repeats 3 times in this PR, can we make it a method that receives the `data` dict and return the port?\\r\\n\\r\\n`get_http_port` \\r\\nIt is no longer just host Fixed Please make sure to add a test to cover this Honestly I\\'m not sure this code path can ever be executed as \"gen1\" devices are not supported so they cannot be reauth with custom port.\\r\\n If it can\\'t be executed, what is it here for? `get_http_port` `get_http_port`\\r\\n\\r\\nNeed to add a test that verify that existing entry that doesn\\'t have the port in stored config entry is loaded correctly, otherwise someone might remove this get in the future thinking it is not needed. Sorry but I miss the point: we load a default for all config entry that doesn\\'t have a port.\\r\\n\\r\\n PR description mentions devices behind NAT (which is correct), and the error is `custom_port_not_supported`, the description should be similar.\\r\\n Done You should not patch the code you test itself, you should patch the upstream method. This patch removes 46 lines from being tested. Please patch `BlockDevice.create`\\r\\n\\r\\nA similar example for patching upstream in this test is the `\"homeassistant.components.shelly.config_flow.get_info\"` which patch the `get_info` from `aioshelly` so only the upstream code is not being tested here. Done Fixed',\n",
       " \"The frontend probably would want to list labels that are used by a specific type (ie automation) to render a filter list. Can be added in a future pr  Should we enforce hex format?  Will do ðŸ‘  Done in [9c7748b]( Why bool it? Yeah odd huh? Data can be any, thus it could be something that implements the equality dunder method, which doesn't have to return a boolean.\\n\\nLong story short: mypy wants it. Ha, interesting. And I think pylint wants us to have the variable on the left side of the comparison ðŸ™ƒ An alternative could be to type the event [like this]( but keeping `bool` is fine. The problem is, that async_listen will not accept that either.\\r\\n\\r\\nLet's assume this:\\r\\n\\r\\n![CleanShot 2024-02-18 at 10 31 51@2x](\\r\\n\\r\\nThis will result in:\\r\\n\\r\\n\\r\\n\\r\\nHow that is solved on some places, is by silencing the arg-type rule:\\r\\n\\r\\n![CleanShot 2024-02-18 at 10 33 44@2x](\\r\\n\\r\\nAs far as I understood, we can't turn `Event` into a generic just of yet.\\r\\n\\r\\nNot sure what we prefer here. Since I've found some occurances, I'll go for ignoring the arg-type rule ðŸ¤·  Done in [9c7748b]( This one might get expensive if we call it a lot since it has to do the linear search.  We can always add an index if that turns out to be the case It isn't used a lot.\\r\\nThis pattern is in most registries.\",\n",
       " 'Can you maybe sort it? Unused Does it maybe make sense for the integration to have a shared base entity and maybe a device?',\n",
       " \"Is there a reason to have this moved here? Yes, the setup from YAML was moved to integration level. \\r\\n\\r\\nYou're already doing `hass.data[DOMAIN][config_entry.entry_id] = None` in `async_setup_entry` \\r\\nif I saw it right thnx Hm, we normally don't want to collect names in config flows, but I'm also lacking a better idea since we are collecting multiple recipients.\\r\\n\\r\\nOtherwise this looks good to me, I've tested this and it works like a charm, great work, thanks ðŸ‘  The name seems a key feature to determine the notifier service name, I left it away at first, but then that will break the existing configurations. Okay, thank I think this is okay We must use the async API inside async context. `async_load_platform`. And a task must be created to not deadlock. Addressed in #110857 We shouldn't use platform details outside the platform. This needs to be refactored. Addressed in #110857 Don't remove the schema until we remove the import. Addressed in #110857 Why don't we do the import from the notify platform? Addressed in #110857 Setting up the smtp integration notify platform via configuration.yaml is deprecated. Addressed in #110857\",\n",
       " \"Since the reauth is quite big, can we extract it into a separate PR? These values are never set in the config entry data? Please make it a list  Please refresh before setting to Hass.data Please add this in a follow up PR Please move this to `entity.py` Already set in constructor Also set in constructor, but you need to overwrite the type using\\n\\n I'd suggest creating a base controller entity and base plant entity So wait, the controller has the same sensors as a plant? Please only call async_add_entities once Isn't this already something for the device name? What does this measure? What kind of measurement is this? Idem Idem Idem Please use constants for this\\n\\n\\n\\n Doesn't need translation key because device class translations  Can be removed, comes from device class  Light in mol/d? Please use icon translations  Can be removed Idem Can be removed  Idem Idem Idem Please leave this one for a followup, as I'm not 100% sure we like this kind of sensors. This way the PR can be merged faster What value does this add?\",\n",
       " \"This is already done in the mock config entry fixture.\\r\\n Make this a fixture. Make this parameter a fixture.\\r\\n\\r\\nExample:\\r\\n#L39-L56 We can set the platform fixture like this or in a fixture defined in this module that is auto used by all tests in this module.\\r\\n\\r\\n#L16 I'd use `hass.config_entries.async_setup` instead. Remove this check. It's up to the tests to override the platforms fixture when they use this fixture. Indent this line too. I think we should yield the mock config entry within the context manager so that the patch is in place for the whole test. It could have weird effects if the platforms differ during the lifetime of the integration. We use the `Platform` enum to populate platforms.\\r\\n\\r\\n#L31 I had problems to set the returned type. This variant removed the complaints but I must admit that I don't relally understand if it is correct. Can this raise exceptions?\\r\\n\\r\\n Yes, We do a response.raise_for_status() after every request in the lib. Normally there should not be any exceptions here. I can think of one, an error 409 - Conflict when the turn_on service is sent to a switch that is aleady on. This could happen even if we check the state here. Someone else could have toggled the switch in the myuplink app or on the web-site. The state in HA is updated just by polling every minute. \\r\\nCan this be acceptable for the time being?\\r\\n No. We need to catch the expected exception and raise `HomeAssistantError`. Preferably the library should raise library specific exceptions that we can use here. For now we can catch `aiohttp.ClientError`. This just makes it harder to read and understand the test.  See comment below I still don't see a reason. Fair enough, my thougths were already in updating the pending test_sensor.py where it is more relevant.\\nI will revert. If it's only used once we don't need a constant. I know, but in next iteration (new PR) I plan to use parameterize to test more sensors based on parameter_id (unit_of_measurement) and override categories. Please change it then in that case. We should not add code prematurely. Hope this is OK for now. We will sort out the exceptions in the lib within short. Yes. Please add a test for the fail case by setting a side effect on the client mock method. Please add a parameter for the service name so we can test both turn on and turn off. Use `pytest.mark.parametrize`.\\r\\n\\r\\nHere's an example with two parameters.\\r\\n\\r\\n#L177-L185 The two tests `test_switch_on` and `test_switch_off` can also use `pytest.mark.parametrize` as below.\",\n",
       " 'Why is `extra_slot_names` not derived from `extra_slot_schema` ?  Can this be done in all cases? It seems you can nest arbitrarily code into the schemas, so I didn\\'t see a way of always being able to extract the keys. I decided to make the extra slots required, which meant I could just use a str -> Schema dict. Yeah if it doesn\\'t work just crash and we can deal with it then Consider making it a `cached_property`.\\r\\n\\r\\n Done. Instead of making a copy, why not define `attr` before checking the extra attributes?  Done. This service made me wonder â€¦ how will we respond if the specified entity does not support the set volume service?  Hmmm...we may want to consider an \"unsupported feature\" error message. We already raise that error from service helper Just would need to translate it for voice why coerce to int ?  I copied the schema from the cover\\'s set position service call. I suppose it doesn\\'t matter since it\\'ll be coerced there anyways. Why don\\'t we just accept 0..100 and divide it by 100 before passing it to the service? I don\\'t think that we should let our service design decisions leak into the intent?\\r\\n\\r\\n That will also make it easier if ever AI needs to generate intent calls.  I\\'m happy to do that  :+1:  This is typed as a `vol.Schema` but you pass a dictionary everywhere.  I don\\'t think you need this. Just iterate `extra_slot_schema`, single source of truth.',\n",
       " 'The result is generally meant for data. Since we have no data, we don\\'t need to add \"success\" as it\\'s already a result message, which indicates success.\\r\\n\\r\\n You can pass this to `async_listen` as an event filter. Although this is already a callback, so not sure if necessary ðŸ¤·  We made these callbacks yesterday.\\r\\n\\r\\n#L13-L15',\n",
       " '\\r\\n\\r\\n \\r\\n\\r\\n\\r\\n You can probably combine them without the mixin after switching to `kw_only=True`',\n",
       " 'Bit in doubt on how hard to break with the current behavior. If current users don\\'t update their config, this new config will default to `None` and they don\\'t get time based integration, changes are minimal. \\r\\n\\r\\nWe could also decide to pick the default of 60s here. Leaving less legacy. But that would trigger sudden state changes of this sensor even if the source doesn\\'t change (which is also the point of this PR).  We should always avoid breaking changes I can leave it as is, then current users will get a `None` value for `max_dt` and not get time based integration.  I would advise the use of a more sensible max: 1hour ? 1 day ? For most users 1 hour or 1 day is probably more than a sufficient max. However, \\r\\n- I can imagine users with slow updating source sensors wanting the flexibility of waiting on a state change for longer periods, e.g. days, weeks, months. \\r\\n- Setting this value very high is effectively disabling time based integration triggers. Which is can be useful with the number selector in the webinterface not accepting `None`. See also my other comment about this. As per my comment on the main thread, I suggest the use of zero to disable max_dt Good suggestion! Done. I did not convert it to None in the config flow, but it the constructor of the sensor. Will see how it can be done in the config flow.  What did you mean with \"You can use zero as a special value that is converted to None in the config_flow\"? I guess my current approach overriding it in the constructor of the sensor is not what you meant? \\r\\n\\r\\nHow would I convert 0 to None in the `config_flow`? If found the method `async_config_flow_finished` and that could be used like this in the `ConfigFlowHandler`?  \\r\\n\\r\\nThis works, but this method is almost never used in the repo, so in doubt whether I\\'m doing the right thing.  Did the conversion of `0` to `None` in the `async_setup_entry`, looks like the right place. availability should be set when the sensor is added and should follow the source, why remove ? This has been moved to line 446 and it is (like with the current implementation) set after it passes some validations checks on the source. it\\'s in `_integrate_on_state_change` but this method is not called by `async_added_to_hass` Correct. But in the old situation it was part of the method\\r\\n\\r\\nwhich was defined in the scope of the method `async_added_to_hass`. But it was only executed as part of state changes. you are right, should probably fix this is another PR ðŸ˜“  Good to know! Availability was and is now set only if the source sends an update. We can address this method afterwards. There is also a legacy comment in the `async_added_to_hass`. I expect this PR makes it easier to address because of the extraction of the calculation logic. We should not create a breaking change This might be an issue, as the state might be written twice ( _derive_and_set_attributes_from_state plus this function) I\\'ve removed the write state call from `_derive_and_set_attributes_from_state`. Then now it will only be called once: on unavailability of the source or successful integration.\\r\\n\\r\\nNote however that this call was also made twice during the state change `calc_integration` method.  Should we skip calling this if the state is `0`? I use riemann a lot for sensors that spend a lot of time at 0, and it would be nice to have high frequency updates when the sensor is nonzero, but seems just wasted cycles to keep calling this when it is not accumulating.  Sounds like a nice optimization! Will give it a try. Don\\'t over optimize... this integration is doing simple math, it takes no time. \\r\\n\\r\\nGo for it, but don\\'t overcomplicate the code ;) While the individual operations are probably minor simple math, I wasn\\'t sure if having dozens of riemann\\'s doing updates frequently forever would put extra load on the system or reduce power optimization if it has to keep waking up all the time to service and reschedule timers. \\r\\n\\r\\nBut I\\'m not a core expert, so feel free to ignore the suggestion if it doesn\\'t make sense. \\r\\n\\r\\nJust thinking about my own use case, I have 20 sprinkler zones which are off/`0` 99% of the time, but use riemann to accumulate water consumption when they are on. It would be cool if they could update consumption in relatively quick realtime when they are on (once/minute?), but didn\\'t want to have them all calling callback timers infinitely forever.  You should not worry about it :) specially because max_dt will work seconds (not milliseconds) Yes keep it simple. Now I use helper template sensors with time triggers to force updates. This will be more efficient I guess.\\nThanks for fixing this ðŸ™ On second thought this cannot be skipped when the source is 0. We still want to update `_last_integration_time` and `_last_integration_trigger` even if the source is constant 0. This doesn\\'t affect the integral, but it will affect future calculations if your source starts increasing again after a period of constant 0. \\r\\n\\r\\nDid apply the following other minor optimizations:\\r\\n- Using the new state for scheduling a trigger and not accessing the source sensor from hass. Because if the timer didn\\'t cancel, the state wasn\\'t changed, so the earlier obtained new_state from the `EventStateChangedData` can be used. This is more clean and in line with the source being constant assumption.\\r\\n- Only schedule a trigger if the new_state is numeric.  Why do we have this nonsensical max value, does it not work if it\\'s omitted? The statistics sensor already has a [max_age configuration parameter](#max_age) which means something completely different (discard old samples) compared to what it means here (fall back to sampling if the source sensor does not update for some time)\\r\\n\\r\\nCan we try to give a better name for this parameter? Maybe something with sample or enforce period in the name, since that\\'s what it\\'s about? Please try to rephrase to better explain what the option does. This is impossible because the config schema blocks it. Please remove it.',\n",
       " 'The best practice is to raise a `HomeAssistantError` when a service call fails. Catch and re-raise? You will need to add translations for the raised error as well...\\r\\n#exceptions I see you were caught by the \"do it like the other service\" - we need to update the #L132-L136 as well - I\\'ll put that on the \"list\" :)\\r\\nThis is more like how to do it: #L106-L111, except add translation to the new one.  I\\'ll also put \"general translation\" on the list for the rest of the raised errors. Okay, I will look into updating all services as well. I\\'ve already made the updates to the other services.  You just need to fix up this one. Thanks, saw that already. Will finalize it tonight, didn\\'t have time to fix CI yet.',\n",
       " \"Failing tests:\\nWhen this point is reached from test_config_flow self.config_entry_reauth is None. It is correctly populated when running Hass.  Failing test:\\r\\nresult2 === result1 during test run. I.e. async_configure() is not jumping to next step.\\r\\nSame thing is happening in test_full_flow() above but it is passed unnoticed as we dont pick up the return value from async_configure() in that case. It's enough to add a MockConfigEntry to hass.\\r\\n\\r\\nExample:\\r\\n\\r\\n#L460-L531 Passing the existing config entry data is correct. Don't do that like the example I posted. :smile:  Confirming the step will pass an empty dict.\\r\\n We have a helper now to do this:\\r\\n\\r\\n#L2030-L2041 Everything works fine when running hass, the entry is updated, the integration is reloaded and the flow is terminated. \\r\\nHowever, when running test_config_flow I can see that self.config_entry_reauth is None here. Therefore the abort-helper is never run and the coverage lacks this one single return statement. The current reauth test will fail when the WRITESYSTEM scope is in place in the mocked entry. I was too tired to learn how to make an elegant fixture for that entry so i just duplicated a lot of code.\\r\\n\\r\\nThe snapshot is fixed. Modify the first mock config entry in the test instead with `hass.config_entries.async_update_entry`, before starting the reauth flow. We don't seem to have rebased correctly on latest dev branch. I don't understand what has happened. This still needs to be addressed. I dont see the problem from here. And I dont know how to address it. Please advice. The only thing that should change in this module is the `mock_config_entry` fixture, right? Maybe just copy those changes, then paste the module contents from dev branch on top and then paste back the changes for the `mock_config_entry`? Ie we revert this module to dev branch state and then just re-apply the changes to `mock_config_entry`. I followed your suggestion and the result is exactly the same as in this PR We don't need this. Just add a mock config entry. Update it with the old scope in the data. Then start the reauth flow. We're missing the required fixtures here. Check the test above. We should use the same fixtures. Add the mock config entry to hass before returning the entry from the fixture.\\r\\n\\r\\n Bump. The updated config entry data should be asserted. We don't need to check current flows. We already have a handle to the flow via the result flow id.\\r\\n\\r\\nPlease assert the step id of each result. It's much easier for everyone including yourself to see where the flow is at. This is incorrect. Please see the example I posted above for how to continue the flow in the auth step. Block till done before asserting the config entry since updating the config entry will happen in a scheduled task. Adding the config entry to hass should be done before updating the config entry. Add it already in the fixture for the mock config entry We don't need to set up the config entry.\\r\\n This should not be here in this PR. Same here.\",\n",
       " 'Please check also the event data',\n",
       " \"This is not a great folder name, can we instead use the domain name as folder name?\\r\\nAlso, if the use case you really want is gitlab, consider adding a specific importer for gitlab. :+1: Updated to use the URL host + rebased.\\r\\n\\r\\nMy specific use case is not GitLab, personally I'd like to use sr.ht. I also know of some people who might be interested in using Codeberg. Therefore, I think adding specific importers for each and every source forge might become a bit cumbersome, esp. in cases where people would like to use their personal homepage or blog. Yes, sure, the generic downloader added in this PR is fine ðŸ‘ \\r\\nIt's just that the specific downloaders can be a little bit smarter. It's important that the generic downloader is tried last. Can we make it less likely that the order is accidentally changed? Maybe move the functions to a global and assert in a test that `fetch_blueprint_from_generic_url` is the last element of the tuple? I agree, makes sense :+1: \\r\\n\\r\\nI've given it a shot, not a python expert, lmk if this is an appropriate way to solve this. The error handling is not great, but it's obviously copied from the other importers.\\r\\n\\r\\nIn a separate PR, I think we should replace the assert with raising a HomeAssistantError if `data` is not a dict? Do you want this separate PR to be done before this one gets merged, or should I do it afterwards? I'd suggest to do that PR first, add a link to it in this PR please. Let's improve the error handling after this PR is merged then.\",\n",
       " '`problem` is not a valid state for Home Assistant covers, have you tested this change, and it works the way you expect it to? I\\'m aware of that. As you have also noticed in other comment the same is for jammed state (which is closest conceptually to safety stop as it means engine has stopped because gate/shutter driver discovered obstacle).\\r\\n\\r\\nIt\\'s a pity that neither STATE_JAMMED nor STATE_PROBLEM is in any way observed by HA covers. On the other hand, existence of this state here has no negative impact on integration. \\r\\n\\r\\nWhat if we leave it here as is and let me figure out if I can make the base cover somehow observe problem/jammed state. This will be a bit more challenging to me as I need to look how such states are handled/implemented in other components. I could then submit such change as a separate PR so other integrations could benefit from it? I see. The end result is that the cover will in states problem and jammed get the \"open\" state, right? Also, this change should be moved to a separate PR. Reverted, will submit separate PR `jammed` is not a valid state for Home Assistant covers, have you tested this change, and it works the way you expect it to? Reverted, no longer relevant. Why is this changed? Is it just to make the code more readable? Yes it was meant to improve readability. I was constantly confused whether it has position and stop features. What does this comment mean? Yes, it means that cover features in blebox_uniapi>=2.3.0 have dedicated `async_open_tilt` & `async_close_tilt` methods that are better suited for closing tilts. I could update straight to 2.3.0 but it would introduce much larger backlog of changes to process and I wanted to maintain smaller PR for this.\\r\\n\\r\\nWe\\'ve fell a little behind with following `blebox_uniapi` updates. I\\'m working on picking up where my predecessors left and it is a bit tricky to coordinate all the changes around multiple features being worked on / fixed so my idea was to make the change so that I can remove this `if hasattr()` once bumping to newer blebox_uniapi version in subsequent PR.   After some thinking I decided to remove this branching logic. Hopefully, once #118836 is merged I will have time to submit a \"Code quality improvement\" PR that introduces new dedicated method call for tilt open/close actions.',\n",
       " 'Let\\'s rename this to `COLLAPSED` What I\\'m doing here (I think) is for every test that uses blueprint_2, I\\'m creating an additional variant that uses the same blueprint, except that the inputs are put into sections. \\r\\n\\r\\nThis shouldn\\'t functionally affect the test, so the test code should still pass equally whether the inputs are in sections or not.  OK, but for the final version of the PR, please add a new `blueprint_3` or `blueprint_2_sectioned` instead of branching in the fixture. If I make an entirely new fixture, is it still possible to reuse the existing tests that currently consume blueprint_2? That\\'s why I used the param so I can leverage and don\\'t have to duplicate the tests.\\n\\nI\\'m not so familiar with pytest so the concept of how to run a test with multiple different fixtures I haven\\'t grasped yet. I believe what is happening here is the inputs used to come from the yaml loader, so they were the special class `NodeDictClass`, but now the inputs are put together as a dictionary manually in the `inputs` function, as it has to merge them together from several sections, so that\\'s why the snapshot need to be updated.  The requests was to do the flattening in frontend, now the flattening happens in core instead if I understand it correctly. Will this have any side effect on existing blueprinted automations? I reread the comment thread but I never saw a request to \"do the flattering in frontend\", or at least I missed that if it was implied.\\n\\nI\\'m not quite sure what that would really mean anyway, don\\'t I need to have a single list of inputs for core to iterate them for replacement?\\n\\nI\\'m also not sure what the concern is here for backward compatibility, for BPs without sections (all of them today), isn\\'t this block of code just basically a no-op? Flattening in frontend is what @bramkragten meant here: #issuecomment-2018148737 unless I misunderstand.\\r\\nHowever, the solution you\\'ve come with seems fine too, I just want another pair of eyes on it. Never mind, I misunderstood what\\'s happening here. Please add a comment here, or above, explaining that the correct schema is picked by the presence of an `input` dictionary. I think this needs a custom validator which fails if the input keys are not unique. Added validator. ',\n",
       " \"I changed this, because multiple there was multiple identical values, it was not kiss enough Would you be willing to make other contributions / help maintain this integration in the future? \\r\\n\\r\\nSee  I will, I got some IO devices at home (and I guess for a very long time), and I will want to improve their integration. Great! Are you on Discord by any chance? We have a Discord channel with more devs (very inactive at the moment). Same pseudo ;) Dependency bumps should be done in a separate PR (including a link to the diff between both releases). Would be good to split this from this PR. \\r\\n\\r\\nNot sure what you tried to say here? I think this comment should be simply removed It should but the work is not finished yet on this because for your device @nyroDev there is a way to convert it to cooling and it's not handled by this PR, I may do another one for that but I lack someone with a working heat+cool device like yours You should use `OverkizCommad.SET_HEATING_COOLING_AUTO_SWITCH` you should use `OverkizState.CORE_HEATING_COOLING_AUTO_SWITCH` you should use `OverkizState.CORE_HEATING_COOLING_AUTO_SWITCH` You should use `OverkizCommad.SET_HEATING_COOLING_AUTO_SWITCH` Reading these 2 lines, I think the classname (and thus all code insisde) should be inversed in order to have a match between the controllable name and the class. Not too sure about that since it's the combination of the two factors for this specific device, maybe @iMicknl can give us his opinion on that\\r\\n\\r\\nedit: I think you're right, I'll keep the `AtlanticPassAPCHeatingZone` since its integration is incomplete, however, I'll change the `AtlanticPassAPCHeatingAndCoolingControlledZone` to `AtlanticPassAPCZoneControlZone`, it makes more sense Should we use `PRESET_COMFORT` instead? Manual is not the same as Comfort, which is another preset, but the device API don't allow the switch to it. I'la allow to virtually select preset comfort or eco on another PR by using eco or comfort temperatures (different than manual temperature).\\n\\nSchedule can be either comfort or eco, depending on the time of the day (internal_schedule of the device). Could you do this change in a separate PR? @Tronix117 would be good to include both lines. Would be great if you can add this to a constant. See `somfy_thermostat.py`. This makes it a bit more clear where this number is coming from. Can you elaborate on this? Don't you want to set them separately based on the current mode? I wanted to improve that in a future PR, there is some issues by setting the temperature to the current mode. For exemple when you're in Auto mode, Home Assistant don't let you set two temperatures but only one, so there needs to be some arbitrary decision there. \\r\\nSame thing applies when it's in Schedule mode (there is comfort & eco to set with heating and cooling).\\r\\nIn fact there is 10 temps possible to set on those device, but on Home Assistant the widget only support for one.\\r\\n\\r\\nAnyway, usualy you want your automations to control your climate, so it should be ok for > 90% use cases, your automation can set temperature as well change mode. I am not an expert on climate devices and the implementations, but HA also offers `target_temp_high` and `target_temp_low` for devices in `heat_cool` mode. Here you can set 2 values.\\r\\n\\r\\n#service-climateset_temperature I thought about using that for individual thermostats, when main control device is on AUTO mode.\\r\\nHowever, I loose the possibility to indicate if individual thermostats are heating or cooling, so I'm not sure if it's better in term of benefits.\\r\\nPlus, those devices are still quite buggy, so Auto mode is not recommended. `_attr_hvac_modes` is now a mutable field with this change. That means it should be set in the constructor. Otherwise this will cause a bug where someone has 1 without auto hvac and 1 with, and then they share(!) the same list, which is a bug which is a pita thanks for this syntax\",\n",
       " \"Should these be sensors or number entities instead of just adding the as attributes here? Yeah, these should probably be numbers. Will remove them from attributes. I don't know the product but is this pre-heating and not just heating? This is a really good question. The device has a heating unit inside that heats the air. Is it heating the air inside the hvac unit or is it pre-heating the air before it is blown into my bedroom? I don't know ;) `preheating` would be that it needs to heat an element/air/something inside before it starts operating and heating the room at which point it would then switch to `heating`. Heating would be that it's actually heating to heat the room.\\r\\n\\r\\nSo in your case it seems `heating` would be the right pick as it's heating an element while circulating the heated air into the room and not `preheating` an element when their would be no air circulation. I agree. Let's change it to `heating`\",\n",
       " \"We call `dataclasses.asdict` on ourselves, why don't we do that on the `ice_servers` list? How come we don't omit null values from `IceServer` items?\\r\\n\\r\\nAlso, Instead of the custom `dict_factory`, would it be more maintainable and easier to understand if the three items we intend to serialize were just spelled out? This needs to be added to manifest.json if we really need to use it The PR claims to add support for two way *audio*, why do we have a `video_direction`? Do we need this now, or should it be added in the future if needed? Move this to a decorator to be used here and in  `ws_camera_web_rtc_close` to avoid the duplication mypy does not agree with the changes\",\n",
       " 'What\\'s the difference between `hrain_piezomm` and `hourlyrainmm`? Why do we need both? the different sensors report there rain values this way - so you have to account for both ways  Does it mean depending on which rain sensor is connected one, the other, or both will report the hourly rain rate? Sensors report different based on sensor - I donâ€™t know what happens if both are connected. The display unit might have a preference and likely only display one value- but both values might still be sent with the data request/push.  OK, I see.\\r\\n\\r\\nThe title of this PR is \"Add ecowitt sensors for hourly rain rates in mm and in\", but that\\'s not what the PR does.\\r\\nCan you try to better explain what the PR actually does and also confirm you\\'ve verified that your changes work? The rain bucket sensor reports an hourly rate just like the piezo sensor - so its value needs to be handled the same as the piezo rain sensor. If itâ€™s not it reports an error - Iâ€™ve been using this code for months so I know it works. Thanks for confirming the changes are tested ðŸ‘ \\r\\n\\r\\nHowever, can you please clarify what the PR does. The title is \"Add ecowitt sensors for hourly rain rates in mm and in\" but it doesn\\'t really do that, the PR changes the state class of two of the sensors? Iâ€™ll also add someone else changed my original title â€œUpdate sensor.py for Hourly Rain Rates mm and inâ€ to â€œAdd ecowitt sensors for hourly rain rates in mm and inâ€ So feel free to make the title to something you prefer.  Iâ€™m adding the tipping bucket but Itâ€™s only one sensor - but the sensor can report in inches or millimeters based on a setting so you need to account for both. The way the current code handles the sensor is increasing total - however the value is reset hourly - when the value is reset ha writes a message to the log thatâ€™s itâ€™s not an increasing total. \"Update sensor.py for Hourly Rain Rates mm and in\" is not a good explanation\\r\\n\\r\\nPlease update the PR title to match the implementation and fill in the \"Proposed change\" section to explain why the change is needed. I can\\'t do it for you because I\\'m not familiar with the ecowitt integration.\\r\\n\\r\\nFor title I\\'d suggest to change to \"Correct state class of ecowitt hourly rain rate sensors\"\\r\\n\\r\\nThere\\'s an explanation here about why the hourly sensors should be state class measurement: #issuecomment-1609943505, maybe link to that and explain the non piezo sensors were forgotten in that PR if that\\'s the case?\\r\\n\\r\\nOnce that\\'s done, the PR can be merged ðŸ‘  Updated - let me know if something else is needed.',\n",
       " \"Done! We don't need a local variable if there's only one class. Done!\",\n",
       " \"This requires #110294 and an availability check on `vehicle.is_remote_climate_stop_enabled`.  @rikroe added now, not sure how I can define possible states here, any hint, please? Thanks `options=[...]` thanks @joostlek , updated now, hope it is ok ! Please use icon translations What are the possible states of this sensor? The possible values are available in [this enum](#L11-L18). If we can convert these enum values to lowercase values for the sensor, this can be an enum sensor with according translations If the state is unknown, the snesor should return `None` since HA will register that as `Unknown` ok, thanks, pushed now, hope it makes sense Maybe loop through `bimmer_connected.vehicle.climate.ClimateActivityState?  instead so we don't have to specify a separate enum?\\r\\n\\r\\n`[s.lower() for s in ClimateActivityState if s != ClimateActivityState.UNKNOWN]`\\r\\n\\r\\nOr is this something we shouldn't do in HA? We shouldn't do this in HA. If that enum changes in a dependency bump, the integration is missing a translation key, so we have this kind of guideline to have these lists in the integration itself i have no idea what is the right way, just pushed your suggestion, thanks ok, will revert then, sorry, thanks @joostlek  @joostlek @rikroe reverted, rebased and pushed now. thanks Ah sorry I seem to have created more confusion.\\r\\n\\r\\nI see the issue with a dependency bump, but what would happen if a new enum state is added without changing the code here?\\r\\n\\r\\nWould there be a hard error vs a missing translation? Of so, I would rather have the missing translation than breaking the whole sensor.  I am willing to argue with others that if you use a snapshot test to snapshot the whole state/entity registry entry (which includes options) we can just use the enum, because if you then test the content of the options field, but we can maybe do that in a folowup to get this sensor in first :) Sounds reasonable! Sensors are already in the snapshot test with options. \\r\\n\\r\\n@brave0d you'll have to update the pytest snapshot by running ` pytest --snapshot-update tests/components/bmw_connected_drive/test_sensor.py` and then checking in the changed `test_sensor.ambr`.\\r\\n\\r\\nIt only didn't run (and therefore didn't fail) because this seems to be your first PR to HA (and therefore the CI run needs to be approved every time). I think we agreed on this code, if the updated snapshots are pushed, I'll kick off the CI tomorrow on my way to the office and fix any thing that fails (to avoid getting back again and waiting another x day/week to get this merged) @rikroe yes, it's my first PR and I am not sure what i am doing wrong - trying to update snapshots and getting the following errors ðŸ¤¦ :\\r\\n\\r\\n In case you haven't set up the full dev environment, you would need to do that (see \\r\\n\\r\\nI personally don't use the Dev Containers, but just a Python 3.12 venv and then inside the venv run `script/setupÂ´ and `pip install -r requirements_test.txt bimmer-connected`. Then pytest should run. @brave0d just created a PR against your branch ( that has the snapshot changes in. Just merge it and then @joostlek can contine here.\\r\\n\\r\\nAlso had to add a second variable to the lambda function (which I missed before). I would check `x` against `ClimateActivityState.UNKNOWN` as well. @rikroe is it ok or should we have here:\\r\\n\\r\\n\\r\\n\\r\\nthanks This is perfect, you shouldn't need the `. value` thanks, fix pushed, I got confused a bit there\",\n",
       " 'I don\\'t think you need to cast You\\'re right, removed it. I would expect it would look like this\\n\\n\\n This seems to be coming up only when iterating over config entries as done e.g. in the [`airly` tests](#L32).\\r\\n\\r\\nI don\\'t think it makes a difference. Why remove the rest? Might as well include it now and use suggested_display_precision in the entity descriptions Set the display precision, but now had to add the full length converted value, as HA will print the full float as string state value. @MartinHjelmare Usually we discourage developers to do this because \"what if the library changes?\", but in this case the options are fixated in the snapshots, so whenever the enum changes and the library is bumped (without regenerating the snapshots) tests would fail. So the only thing left is that the reviewer should know that a string should be added to the strings.\\r\\n\\r\\n#diff-3cb4a00db27894cb9e17559dd978b695621d9a673c6899905f94f839e97910ebR22-R35 I still don\\'t think it\\'s a good idea to take that approach. The same reasoning still applies. The integration should blow up if an option is missing in the translations. But that can also happen if someone just adds a value to \"a random list in const.py\" without adding the transition key? It both comes down to the alertness of the reviewer on this. (And imo, with these snapshots it\\'s even more clear what this change is and that a key should be added) > The integration should blow up if an option is missing in the translations.\\r\\n\\r\\nI implemented a separate test only for the translations to make it clear after a library update if translations are missing (see latest commit).\\r\\nThen users would not get error messages it is already part of the testing pipeline.\\r\\n\\r\\nIf a translation key is missing (or malformed), pytest assertion would throw an error similar to this:\\r\\n\\r\\n\\r\\n Oh you added a full test for it, my point was more saying that having a way to fixate the options list somewhere would suffice instead of duplicating all enums. Wondering what I can do for this to go through?\\r\\nJust pinning the enum sensors? I have reverted (i.e. pinned) the Enum values so this PR can be (hopefully) merged.\\r\\n\\r\\nI might create another draft PR with a corresponding architecture discussion as I think that Enum values from a library should be allowed, provided there are tests if all translations are available. We can remove this test Done. Please use the snapshot_platform helper. It will also give a right name to the platform, so if you change something (add a sensor, or rename one), it doesn\\'t completely mess up the git diff (as this is a list, and the snapshot_platform helper makes it more like a dict.\\r\\n\\r\\nMaybe it\\'s a good idea to migrate to the helper in a preliminary PR Thanks, that makes sense!\\r\\n\\r\\nAdded it here as well as in  and \\r\\nDepending on what gets merged when, will rebase/fix merge conflicts as they come up. Which one is missing? Not sure if I follow. The only Enum not in this list is `ChargingState.UNKNOWN` as this is not a valid state and (from previous comments) should be `None`. But now we fixate the options in the snapshot, so we can do `[x.lower() for x in ChargingState where ChargingState is not CharginState.UNKNOWN]` I\\'m sorry, I thought the discussion about this with @MartinHjelmare (#discussion_r1571806397) was the reason this PR was stuck.\\r\\n\\r\\nThats why I reverted this in  Yes that was the original point of the PR, but I still believe this is a non-issue because we got it covered. I spoke Frenck today and he was like \"why not\" idem Same as `ChargingState`. typo? Thanks, fixed Having 2 the same states doesn\\'t make a lot of sense imo Yeah - the issue is we don\\'t really know which of these enums could occur, they are collected over multiple years.\\r\\nTherefore I decided in this case to combine both, but I can also have different translations if you feel this is needed. The thing I am worried about is that with this change when you edit an automation and select a possible state, you see \"Fully charged\" twice and never know which one is triggered when. So imagine created an automation for Fully charged 1, and then the car actually displays 2, that\\'s strange. +1, I agree on this.\\r\\n\\r\\nI\\'ll translate it for now and then have to think later how to deal with this ever growing list.',\n",
       " \"Done Done Done Done Why do we test this? Didn't we test this already in the previous test? Copy paste error. Will remove.\",\n",
       " \"Is it not possible to clean up old devices automatically when setting up the config entry? That would be possible. However I'm not sure if this is desired from a user-perspective, as by doing so the old entity data would be deleted as well (assuming I understand it correctly)?\\r\\n\\r\\nI've kept in line with two other integrations I use, namly fritzbox (which has this functionality) and deconz (which provides a seperate service for cleaning up). What would be the reason for keeping a stale device? Thought about it for a while and couldn't think of it any really valid reason. Adjusted the code to remove old vehicles automatically. Please instead update the device entries and remove the config entry id from them. If there are no other config entries remaining the device entry will be removed automatically. That's safer than removing the device entry directly as it's (theoretically) possible for multiple config entries (from any integration) to be connected to the same device entry.\\r\\n\\r\\nExample:\\r\\n#L191-L193 Thanks - copied from the wrong integration :)\",\n",
       " \"minor_version is 1 by default \\r\\n`_LOGGER.exception` already logs the stacktrace Don't set `minor_version` here, pass it to `async_update_entry` The comment is misleadingly placed IMHO\\r\\n We need to guard against the user attempting to downgrade from a future version:\\r\\n This is not correct\",\n",
       " 'Please remove empty entries. \\r\\nThis is the preferred sequence, so that `hass.data` is only filled with the object when the first refresh was actually successful. Please move the names to `strings.json`, so that they can be translated. I would like to have this as a snapshot test, which would make this a lot smaller. See the `webmin` integration for a simple example of the test code. Parts of this which are reused in every test can be outsourced in a function as well. (Most integrations call it `init_integration` or `async_init_integration`)',\n",
       " 'Please add a constant in the library for `\"NOT_APPLICABLE\"` Why do we need to check the planner restricted reason? The restricted reason could also be `WEEK_SCHEDULE`, if the Mowers state is restricted. So we need this information differentiate. Ok, so the switch in on-state means the mower will park itself and wait for the toggle to off to start mowing again?\\r\\n\\r\\nWouldn\\'t it be better to implement a service for such a feature? Together with a binary_sensor to show the state: parked/mowing?\\r\\n\\r\\nI can see the reason for using a switch but I wonder is this following the Dev rules? > Ok, so the switch in on-state means the mower will park itself and wait for the toggle to off to start mowing again?\\r\\n\\r\\nYes\\r\\n> Wouldn\\'t it be better to implement a service for such a feature? Together with a binary_sensor to show the state: parked/mowing?\\r\\n\\r\\nA button and a binary sensor would be an alternative, yes. But I think this gives the best user experience.\\r\\n\\r\\n> I can see the reason for using a switch but I wonder is this following the Dev rules?\\r\\nNot sure... ~~After checking the HA Developer Docs, I think a Select would be a better fit to what you want to achieve: ~~\\r\\n\\r\\n~~The Switch platform is meant for turning something on or off. That\\'s not what your switch is doing.~~\\r\\n\\r\\n~~Selecting between the options `mowing the lawn` and `parked until further notice` makes more sense.~~ Wait, there is this which is the perfect fit :smile: \\r\\n\\r\\nWait 2, that\\'s already in use I see, sorry.\\r\\nAnd there is not a card available that allows you to select the lawn-mower function.\\r\\nWith this in mind, I (again) suggest using a Select.\\r\\nWith a select you can use an Entities-card to show the Options, like this:\\r\\n![image](\\r\\n In the select you can connect the action to execute to a selectable option.\\r\\n See for reference \"my\" work:  What would the options be for a select entity in this case? Could we detect which option would be in use from the state of the mower device? Can we extend the select entity with more options and still detect what option is in use? The options could be: `start_mowing`, `pauze` and `dock`, implementing access to the three \"set\"-functions in `lawnmover.py`. The property `activity` reports the active state (= current_option). Why would we do that? They are already available in the lawn mover entity. I\\'m thinking @Thomas55555 wants to provide easy access to the lawn_mower set-functions/services?\\r\\nI\\'m thinking there is no lawn_mower card that gives the user access to the set-functions? Or is there? Does the Entities-card provide what Thomas wants to achieve? My interpretation of this PR is to give access to the setting to enable and disable the schedule as described in the architecture discussion:\\r\\n#discussioncomment-5873265 Ah OK, that is the background of this PR, thanks for providing the info :)\\r\\n\\r\\n\"should be represented by a separate switch entity per schedule\": if there can be more schedules than one, a select with an added off-option would be more suitable?\\r\\n\\r\\nLooking at the code again, I would suggest switching the on/off implementations: turn_on should enable the schedule, turn_off should result to parking.\\r\\n\\r\\nAnother thought, will this really achieve what is requested/intended? Does a schedule not include parking-time?\\r\\n\\r\\n I see that there is also a `park_until_next_schedule` option in the backend, so yes, the `park_until_further_notice` option does disable the active schedule. Summarizing: if there is a single calendar with a single schedule, then the switch is the correct implementation.\\r\\nMy feedback for this is: switch the turn_on/_off options: turn_on should enable the schedule (and the name should be something like: `Activate schedule` or `Enable schedule`).\\r\\n\\r\\nIf there can exist more than one schedule then I would suggest implementing a Select.\\r\\n Why is a select better than a switch per schedule? When there are more than one switch the user can enable more than one Switch. That\\'s not possible with a Select.\\r\\nSee the Plugwise climate thermostat_schedule select for reference:\\r\\n![image](\\r\\n Looking at the backend code, and at a relevant Husqvarna webpage, my impression is that there is only one Schedule so implementing a single Switch would be OK. Yes, if there is more than one schedule and only one schedule can be active at the same time, a select entity is better than a switch. @Thomas55555 Does the lawnmower App provide a single schedule/calendar? There are multiple schedules possible in the app. But you cannot select to use just a specific schedule. Either you use all of them or not.\\r\\nThe sentence above is valid for **all** mowers.\\r\\nThere are **some** mowers, which support workareas. There you can have separate schedules for each work area. But you can\\'t turn them of, or select a schedule. So in my opinion the switch is the best option. With multiple schedules you mean for instance different schedules for different days? Or weeks or months? In winter you mow less than in summer, is that what you mean? In principle that is still one schedule, you use the term calendar I think.\\r\\n\\r\\nWith such a single calendar, a single switch is OK for me as well.\\r\\nBut please make the function as I wrote above: switch the functions of turn_on/_off and change the name so that it\\'s clear that the schedule is active when the switch is on. > With multiple schedules you mean for instance different schedules for different days? Or weeks or months? In winter you mow less than in summer, is that what you mean?\\r\\n\\r\\nI mean, multiple schedules can be:\\r\\nSchedule 1: monday 9:00 - 11:00\\r\\nSchedule 2: thursday 7:00 - 10:00 OK, in my mind these are schedule-entries, not schedules. A schedule is something that is fixed and repeats after a certain time-period. Like a weekschedule for a thermostat. I\\'m from the thermostat-world :)\\r\\n\\r\\nNow I wonder, are you planning to create switches for these two schedules? Or is that not possible?\\r\\n It\\'s possible. But the better way is to create an calendar entity I think. There it would also be possible to change, delete and create the schedule-entries.\\r\\nI\\'ve already did that in the custom component:\\r\\n Ok, it\\'s possible, that sound complicated.\\r\\n\\r\\nAnyway, if there\\'s a (single) calendar, better to create a single switch that allows the user to block the execution of upcoming calendar-tasks. > Ok, it\\'s possible, that sound complicated.\\r\\n> \\r\\n> Anyway, if there\\'s a (single) calendar, better to create a single switch that allows the user to block the execution of upcoming calendar-tasks.\\r\\n\\r\\nI thought about how to implement that... The problem is, if we do that, we have to save the deactivated schedule in the config entry, because it\\'s not possible to disable the schedule over the API. We just can delete schedules in the API, not disable them.\\r\\n\\r\\nedit: And to enable the schedule, we have to take the values out of the config entry, and write them to the API. Bit then we are not consistent to the App.',\n",
       " 'The reason this is not covered by the tests is that `data_without_xml` does not return `None` if the data is not valid XML, instead it returns the data as is:\\r\\n#L72-L90 Is this really correct, it\\'s causing the tests to fail, right?\\r\\n\\r\\nI think it\\'s better to modify `data_without_xml` to let the `ExpatError` bubble up and catch it in this function as well as in `RestSensor` and deal with it there. Seems to be failing on `test_setup_minimum_payload_template` which is an existing test - but that\\'s beside the point, let me try my hand at implementing your idea. I will ping back once I\\'m done. Ok, looks fine now, submitting Instead of changing the test, parametrize it:\\r\\n Thanks for the hint, done I think it\\'s a bit of an antipattern to catch, log and raise.\\r\\nMaybe OK here though since this function is only called from the `rest` integration, up to you to keep it as it is if you prefer. I misinterpreted your recommendation to \"bubble\" - you seem to have meant that I need to remove exception handling from the shared method altogether and catch it in the functions that are using it. Yeah, that\\'s what I meant',\n",
       " \"Raise a `HomeAssistantError` here since it should fail loudly to the caller.  I realize you followed what the existing code is doing (which isn't following current standards). The existing function uses the variable `entity_id` but passes the actual entity. I think this should `image.entity_id` to be more correct here. (I realize this is following what the existing service is doing, but I believe its not correct) The examples need to be updated for the new variables because it was corrected to have the entity id instead of the entity or something else? Yes `entity_id` is a string not an object This tests needs to be updated to expect the exception How about adding a test that exercises the entity template variables? Sorry, can you elaborate? I am not 100% sure what you mean by that Add a test case that in the template references the variables that are used in the examples. Like add a test that uses a filename of `/tmp/snapshot_{{ entity_id.name }}.jpg` This is not needed\\r\\n You've changed the behavior compared to the camera snapshot service; that service passes the camera entity instead of its entity id. I first thought it was a bug, but the behavior is [documented]( although not clearly: `Variable is entity_id, e.g., /tmp/snapshot_{{ entity_id.name }}.`\\r\\n\\r\\nI think the behavior in this implementation is the wanted behavior, but I want to double check before we merge this PR.\\r\\n Thinking about this some more, we don't want to copy the explicit templating of the filename to the image service because it became very difficult to use after we added the implicit templating of all service data. There's a 4 year old bug report on the `camera.record` service:  caused by that\\r\\n\\r\\nThe workaround is to do this, which is difficult to understand IMO:\\r\\n\\r\\n\\r\\nHence, I suggest to remove the explicit templating of the filename from this PR. to make sure I understand what you mean, we essentially shouldn't allow entity_id to be used in the filename so the call to async_render would not be used? From my previous suggestion here it was that I though the camera implementation is bogus and weird.  Firstly, the `entity` is named `entity_id`. Secondly, its very odd to actually pass the `entity` here as a template in the first place.  I definitely think this should be `entity_id` and it should be the entity id, if anything.\\r\\n\\r\\nNot having templating at all is also totally fine with me too, and it's is not really needed. Users can handle this themselves in a script so i don't even know why its needed in the first place. I like the proposal to drop. You're summary is good @allenporter, there's some additional context here:  It's not great that this service handler is now fully duplicated between camera and image I figure implementations could change in the future if some feature is added to one service but not the other. If that's unlikely then is there a good place in the code to consolidate this implementation so both services can use it?  Let's keep them separated ðŸ‘  Please break long strings around max 88 characters per line. What catches `TimeoutError`? Only `HomeAssistantError` is allowed to leak out from the service handler. Shouldn't this be `ServiceValidationError`?\\r\\n\\r\\n Didn't we remove the `entity_id` variable?\",\n",
       " 'Translations keys may not contain capital letters.',\n",
       " \"This is incorrect Removed Thanks, I just copied from `strings.json`. I'll remove that. Whoops! Thanks.\",\n",
       " \"I think we should follow this pattern instead for setting up the prerequisites, before setting up the integration.\\r\\n\\r\\n#L59-L71 I have very limited experience with tests so this has been a challenge. However, I think it is done as you want it now.\\r\\n\\r\\nI have also copied test_init.py from automower and it works fine within this framwork. But I guess that module should be in a separate PR. Is it important to have this mock token in jwt format? Maybe just set a fake value in the mock config entry data? Nope, took all jwt stuff away. I don't see the serial number in the mock config entry data. Where is the serial number redacted? Good catch!\\r\\nThe serialNumber(s) are unredacted.\\r\\nThe redact has disappeared somehow. I must have mixed up version of diagnostics.py.\\r\\nI'll be back. Fixed.  This line can be moved up out of the loop. Done Thanks, this was leftovers from my trial and error exercises. Normally this should be a separate PR. But since it's small and just tests it's ok this time.\",\n",
       " '',\n",
       " 'I\\'d rather make an entity sensor subclass for enum sensors with its own property for `native_value` and an attribute for `options`, so we get rid of those two checks (the check here and the check in `get_description`). Then it\\'s only one check for the enum device class when iterating the data points, before creating the entity. Looks like we can move this to the module level, ie outdent one level. If the device point enum values are static after entity creation, we could consider storing the dict that maps value to text in an attribute on the entity, so we don\\'t need to create that every state update. It is reasonable to believe that enum_values are static between HA restarts. But there is really no way to know for sure. The MyUplink help desk explicitly says that they do not provide any support for the public API. They just point me at the Swagger site.\\r\\nBut that said, I think it is reasonable to do as you suggest. We could store the entity class to use in a variable and move the entity instantiation out of the if/else block. Good idea! Changing... S series an F series have overlapping number series (at least with the old f series numbering) so this might not be enough. I kind of doubt that myuplink upgraded F series have adapted the numbering of the S series.\\r\\n\\r\\nIve not looked at the numbering for S series on myuplink uet  but it would sort of make more sense if matched modbus numbers, but maybe it doesnt? We are prepared for overlapping numbers. The numbers in the descriptor keys can be qualified with category name if needed. However I suspect that this can be a source of more work until everything calmes down...\\r\\nI would really like to know how S-series presents itself in the myuplink API to try to find the most efficient solution.\\r\\nThe new firmware for my F730 was released about two weeks ago and i upgraded and migrated last week and quite a lot of sensors are missing in the public API. I noted that Nibe/myUplink have made some significant upgrades to the capabilities in the ios-app and on the web for F730 the last few days. So far as S series and F series never have same number for anything. So i think it should always be qualified.\\r\\n\\r\\nIf want to see the mostly complete databases, they are here \\r\\n\\r\\nWe can probably ask some S series guys using the modbus setup test the myuplink integration of you dont have any such testers. Once the new release is public i suspect they will test it. @elupus when you mention S serie, i have a NIBE VVM S320 E EM 3x400V DK - what do you want me to test?\\r\\nWithout fully understand you point, i think it\\'s fine to have these parameter_id config, and fallback to parameter_unit. @pajzo what does your parameter 43108 represent Or 49994? Or some other parameter for \\'priority\\' you have > @pajzo what does your parameter 43108 represent\\r\\n\\r\\nIt is \"Current fan mode\" in the F730, = [0, 1, 2, 3, 4] It is assigned % as unit which is incorrect.\\r\\n\\r\\n49994 is labelled Priority and can be Off, Hot water, Heating, Pool and so on.\\r\\n\\r\\nFrom the metadata in each device-point I think we can make an educated guess what entity platform that is suitable. E.g. a parameter that can be zero or one and is writable should be represented by a switch. If it is read-only, a binary sensor would be appropriate.\\r\\n Im asking for S series report from @pajzo . As i said their number series are very likely overlapping and with completely different meaning for same number. Yes, I fully understand that there are overlapping number series. \\r\\nPlease regard the current code more of a proof-of-concept than the ultimate solution. If we change the \"49994\" key to \"NIBEF F730 CU 3x400V-49994\" it will be correct for F730 and the sensor will show a number value with default icon for all other devices with a \"49994\". \\r\\nI am currently working on a better method to interpret the point metadata and assign proper platform, device_class and other properties. Hopefully this will be reasonably correct. The ambition should be that the need for \"manual\" overrides is not too big.\\r\\nThe overall aim with the intergration is to make use of the metadata and do the best we can with it. The alternative is to maintain a huge database from all manufacturers connected to myUplink and all their models and that seems rather unattractive to me. Here is a output for my S320 - seems like the parameter_id\\'s is unique.\\r\\n\\r\\n Could we calculate the prefix by only using the `device_point.category`? Eg by looking for a separator in the string or taking a certain number of characters from the beginning etc?\\r\\n\\r\\nI\\'d like to avoid having a tuple of known prefixes to match against and needing to maintain that tuple. This is a difficult one...\\r\\nThere is no simple way to categorize the models. The product,name appears on different levels in the object hierarchy and the device_point.category is not an exact match to the product.name.\\r\\nMy interpretation of the data model in the API:\\r\\n\\r\\n1. An account can containg many systems.\\r\\n2. A system is a heat-pump appliance.\\r\\n3. A system can contain one or more devices\\r\\n4. A device contains many device-point.\\r\\n5. There is no official documentation from the manufacturer on the actual data that each model reports.\\r\\n\\r\\nExample from my F730:\\r\\nOne system with one device with some 45 device points.\\r\\nproduct.name in system object: \"F730 CU 3x400V\"\\r\\na single device with product.name: \"F730 CU 3x400V\"\\r\\ncategory in all device_points: \"NIBEF F730 CU 3x400V\"\\r\\n\\r\\nExample from @pajzo:\\r\\nproduct.name: unknown to me\\r\\ncategory in device_points: Mostly \"NIBE VVM S320 E EM 3x400V DK\" but mixed with \"Varmepumpe 1\"\\r\\n\\r\\nI am out of ideas (for a short moment - I hope). I am a bit sorry that the search for a perfect solution is blocking other areas of improvements. It is possible to create generic binary_sensors, generic switches and other suitable entities. It is when it comes to fine-tuning device_classes, icons, display precision etc that we are stuck.\\r\\n\\r\\nThe current solution will work for Fxxx -series appliances. All other models will show up with generic sensors as in the original release.\\r\\nI suggest that we merge this version. We can then revisit the challenge of classifying appliance models when we have collected more diagnostic data. I agree with you @astrandb, i think it\\'s fine to map based on parameter_id, and fallback on paramter_unit. Then we over time can improve by adding more and more parameter_id mappings. We now have confirmation thay S series have a different numbering scheme which may overlap. So we must discern them.\\r\\n\\r\\nWe also now see that S series prefix by \"NIBE\" and F series by \"NIBEF\". That is enough.\\r\\n\\r\\nJust use partition on the category and grab first words. Use a double level dict. For lookup.\\r\\n\\r\\nAlso avoid putting unit lookups and paramater id lookups in same dict.\\r\\n\\r\\n\\r\\n Thank you @elupus for you constructive ideas. They are implemented now. Please wait with adding this until it\\'s populated. OK What does this check mean? Normally the API will not include device_point that are permanently unavailable. The API will return -32768 if data is temporarily unavailable. I.e. \"Unknown\" with HA terminolgy. It happens on two data_points in my F730. I think it is better to show \"Unknown\" than showing -32768.',\n",
       " 'this gives a key error, has to be updated to `i[\"itemId\"]` same here `i[\"itemId\"]` Please limit docstring lines to max 72 characters per line in accordance with PEP8. Please end sentences with a period. @MartinHjelmare Follow up PR: ',\n",
       " \"This is not required as the library will always return `other`.\\r\\n Ok, this is something that I inherited from the previous PR and didn't check :) Why do we need to add this fixture in this PR? AFAIK there's not a dependency on the groups data for the intercoms.  I agree it's a good things to add but it should go in a separate PR.\\r\\n `update_groups` is called inside `_update_data` that is called according to #L65C18-L66C1 All the other devices have `location_id: null`, this is why that API wasn't called before the Intercom integration. Got it thanks.  Agree we should leave it in. Same as above, I don't think this needs to be this PR. Agreed this should stay as per #discussion_r1481642758 This seems to be included from the baseline PR but doesn't do anything?  Can you add a fixture for `intercom_history.json`, rename `doorbot.json` to `doorbot_history.json` and then modify the request_mock to load the appropriate fixture.  Then add a test to test_sensor to make sure that in this PR the intercom history is not called and we can then update the test when we release the history capability to the library (or we may end up updating the library first in which case we modify the test accordingly)\\r\\n Can this go in `conftest`\\r\\n As I check if that URL is called once, I find it easier to have the Matcher in place (the one I keep in the `mock` variable) and assert on it.\\r\\nPutting it among the other mocks means I need to look at the history, and I'm not sure that's worth it. Also, the open_door is called here and only here.\\r\\nMaybe if more tests will need to use the same URL in the future a refactor could be necessary.\\r\\nThere are a lot of mocks put inside the tests. I don't know if this is an anti-pattern that needs to be completely removed. Can you leave it in both so that anyone in the future adding tests does not miss the fact that this is not mocked centrally? Done This is not required as the library will always return `other`.\\r\\n This is not required as the library will always return `other`.\\r\\n We shouldn't need to call `setup_platform` twice and tick for 120.  Try this:\\r\\n\",\n",
       " 'Happy to get feedback on that point : that\\'s the only way I found to have an entity id I can use in automations that\\'s always the same (`calendar.switchgrid_events`) no matter what language the end user selects. Just let the name be what it is, people can also change it, breaking it again ok ðŸ‘Œ  Why did you want a stable entity ID to begin with @licarth ? You dont have any YAML, can be removed ok This isn\\'t fixed Why do we refresh twice? So, without this I was not seeing the calendar updating on HA restart. But this is because I was initializing the _events prop to an empty array in the calendar platform.\\r\\n\\r\\nFixed that, and removed the `async_refresh()`. Please don\\'t initialise lists at class level You could create a device for switchgrid service. Then you can name the calendar \"events\" Why do you need this? I don\\'t ! Removed. We should test if we can fetch data and abort properly @joostlek You mean check whether the coordinator is able to successfully fetch its data, and if not, then abort the process of installing the integration?\\r\\n\\r\\nI\\'m not sure how to access that information from there. Should I instantiate the coordinator here?\\r\\n\\r\\nSorry, I\\'m new to python and the internals of HomeAssistant, too. Can we please rename this to something better? It\\'s a client no? Yup, will rename this to `SwitchgridClient` and update the dependency. Remove empty fields Please don\\'t use the coordinator in the config flow. Just use the library and have a check if we are able to receive data. The unique id only needs to be unique among all switchgrid calendars, there\\'s no need to prefix with switchgrid\\r\\n The config_entry parameter does not seem to be used\\r\\n I\\'m not sure *eventual* is the word you\\'re looking for here? Move this to coordinator.py What calls this method?',\n",
       " \"This is the default already.\\r\\n OK What is this update entity updating? If it's the firmware, please remove this line and add the device class FIRMWARE. (This can be done outside of the constructor) Firmware device class is in the entity description. We can just remove this line, I think.\\r\\n Oh haven't spotted that, good catch  Removing...\",\n",
       " \"For every non-time sensor this code would need to check on timestamps as well. Sensors with device classes that are numeric will be treated in this part of the code:\\r\\n#L230-L237\\r\\n\\r\\nSensors that do not have a device class or that have the ENUM device class will be treated in this part of the code:\\r\\n#L238-L240\\r\\n\\r\\nTherefore, only the sensors with the TIMESTAMP and DATE device classes are left to be treated by continuing the code:\\r\\n#L241-L262\\r\\n\\r\\nSo I understand that non-time sensors will not pass this code.\\r\\n\\r\\nIf I'm wrong, please let me know... The same check is also at L248. In this line (L242) I need to check if the value cannot be converted with `parse_datetime` to apply the conversion with `fromtimestamp` and provide a new converted variable `new_value`.\\r\\n\\r\\nOn line 248 I convert the variable `new_value` (from the payload or from the conversion of `fromtimestamp`).\\r\\n\\r\\nSo in each of these lines I analyze different things.\\r\\n\\r\\nDo you have a suggestion to improve this? Followed the suggestion made below with \\r\\n\\r\\n#L241-L262 Float conversion can fail here. Added conversion error handling. This does not make sense. If a `ValueError` occurs, we log and return. Lets not nest not blocks. Maybe add some failing cases with `0` or a negative number/float?\",\n",
       " 'Hassfest generated this, even when a similar manifest.json for symfonisk has this set to true :thinking:  Seems to work anyways Nvm, I was reading a wrong entry.',\n",
       " 'Please extract the device specific interface code and data parsing to a standalone library published on PyPI.\\r\\n\\r\\n#4-communication-with-devicesservices',\n",
       " 'spelling: state_attr thanks, fixed it. `onkyo` media player has a `dynamic_range` attribute, can we use the same attribute name here? Yes, thanks for the suggestion, sorry for the late response, I was on vacation. Can we also add translations for this state attribute? example:\\r\\n#L44-L47 @joostlek how to do this if `_attr_name = None` and there is no translation key for the media_player entity (since it is the only single entity of the integration)? just come up with a translation key, \"media_player\", or \"kodi\" would for example work But the translation key takes presidents over the _attr_name. Or can I just not include the name in strings.json? > the translation key takes presidents over the _attr_name\\r\\n\\r\\nNo, it doesn\\'t I added the translation and tested it. OK, that\\'s great. Were the tests successful? Yes it was translated correctly.',\n",
       " 'If it\\'s only about config entries we shouldn\\'t extend the base class. What about?\\r\\n Please limit docstring lines to 72 characters per line. The first line is a header and must be a single sentence. Please break long strings around max 88 characters per line. Maybe use a walrus for this dict lookup since we use it both here, above and below. Please break the string. I think we need to handle ignore/unignore flows with source `SOURCE_IGNORE` and `SOURCE_UNIGNORE` too.\\r\\n\\r\\nThe best thing would be to not try to discover more flows at all when an integration only supports a single config entry. At minimum we still need to allow the user to ignore discovered flows. Fixed by  We should probably return an abort result with reason \"already configured\" here instead. I don\\'t think anything that calls this api handles `HomeAssistantError` at the moment. Yes, its going to blow up in a few places for sure if it raises here Fixed by ',\n",
       " \"I think this could be done with `_abort_if_unique_id_configured` just like you did in `async_step_bluetooth`.\\n You're right not sure why I did it this way Maybe it's better to use `homeassistant.helpers.device_registry.format_mac` to enforce a common format for the mac address? Disregard, I didn't realize `mac_code` is just 4 characters and not the complete mac address. I think you can simplify this by using `bluetooth.async_ble_device_from_address`. Disregard, I didn't notice you where selecting the device by name and not by mac address. These icons should be defined in `icons.json`. Will add them there thanks! This probably does not matter, but this could also be done when the config entry is setup and the bluetooth device is first discovered. That way you wouldn't have to search the device again using `async_ble_device_from_address`. The `MotionDevice` instance could then be stored in `hass.data`. Initially I didn't know how to pass data from config flow to an entity, but I could have indeed used this. However, right now I use `hass.data` to save the cover entity, which is then used by the other platforms to register callbacks. `hass.data[DOMAIN][entry.entry_id] = blind` Sure, I think it's fine either way. If you should change your mind about using `hass.data` you could of course always assign a dictionary to store multiple different objects. These methods seem to be unused and the callbacks are never set. These callback methods are used for the three platforms (button, sensor and select) which I'll make a PR for immediately after this has been merged. I could remove them but I prefer to just leave them in for now. Okay, I guess it's fine then. Just prepare for someone else to maybe mention this again in another review since many people here don't seem to like unused stuff that will be used once the other platforms are submitted (having the same problem in my own PR #109291 right now ðŸ˜„). I don't think this should be a `info` level log message. The same goes for any other messages that are logged each time default behaviour is executed. I agree, I'll change most of the control messages to `debug` This should not be specified for core integrations. Thanks, I'll remove them! Most core integrations I see do have keys `documentation` and `iot_class`. I did remove `ssdp`, `zeroconf`, `homekit` and `issue_tracker`. Oh sorry, I only meant to comment the `issue_tracker` key. `documentation` and `iot_class` should stay there of course. `homekit` could be removed since it's empty anyway. ðŸ‘  please use debug logs instead Should I replace all info by debug, or what would you leave at info? debug. `info` is normally reserved for HA itself \\r\\nis the default better to use instance attributes here\\r\\n might be `ABORT` here, or how could you recover if you didn't find devices idem idem in case of non-terminal states, please finish the flow successfully afterwards, to show we can recover from errors\",\n",
       " 'Stale docstring Stale docstring Would this be a better name? Of course, that would imply the logic is also reversed such that on mean sleeping and off means awake. Maybe that\\'s confusing?\\r\\n I will update to Sleep switch Stale docstring Improve this docstring so it explains what it means, for example \"Return true if the camera is awake\" Instead of this, add a translation of the name to `strings.json`',\n",
       " \"Looks like we can just set this during init? No, because the preset mode can change.\\n\\nThis PR is to move these out of init so they are dynamic to the preset. Maybe add a comment here and for supported features to avoid future review comments Comments added Read it wrong clearly so good to add a comment to it.\\r\\nI think in general it would have looked cleaner if you would use `_handle_coordinator_update()` to update the attributes instead of all these ifs within the properties but I guess it's a matter of taste TIL `_handle_coordinator_update` is a thing. Ill try use that where appropriate in the future @gjohansson-ST I have ended up refactoring to use `_handle_coordinator_update` as you suggested, and have started using this elsewhere. Much nicer way of handling things sometimes. Same here? No, this can't be in init either. This should be `ServiceValidationError` FIxed.  `_attr_preset_modes` and `_attr_supported_features` shouldn't be set anymore because you are overriding the shorthand attributes by defining `preset_mode` and `supported_features`.  It needs to be one or the other\\r\\n\\r\\nIts a bit faster to use `_attr_preset_modes` and `_attr_supported_features` and update them when they change because they are `@cached_property` Ill refactor to use `_handle_coordinator_update ` @bdraco I have refactored to use `_handle_coordinator_update` rather than `preset_mode` and `supported_features`. In a future PR I will also refactor many of the other properties to use the same function. \\r\\n\\r\\nBecause we have both sync and async code in this codebase, anything that is safe to run in the event loop is usually prefixed with `async_` or `_async_` Can this change at runtime? Should it be in the new functions? No, the preset modes avaliable should never change. In a follow-up PR I think adding translations would be nice ðŸ‘  Agreed, I also want to use `_handle_coordinator_update` for more platforms and values\",\n",
       " \"Don't we need to check if the HAVC modes are actually supported here? It seems like `self.support_hvac` is populated conditionally?\",\n",
       " 'We have an `async_turn_on`/`off` implementation in `Airtouch5Zone` below, but not in `Airtouch5AC` here.\\r\\nIs there a default implementation we inherit, or do we need to add one? This adds `turn_off` by default as you support hvacmode off and then tests to add `turn_on` if any other hvacmode is added.\\r\\n\\r\\nBelow we add both directly as on/off methods are implemented. I see now there is a base implementation in ClimateEntity\\r\\n#L742\\r\\n\\r\\nSeems good ðŸ‘ ',\n",
       " \"Not sure how often these are called but if it's often it would be better to make them constants to avoid doing the dict lookup in the event map for each one  It is called a lot, unfortunately, this is the _only_ place it can be replaced with constants. The other places, the event types are not known like this. This is the end of the line when it is generating the individual names. Media sources do require some level of user interaction though, so it is not like something that is running in the background causing performance issues. \",\n",
       " 'imo it\\'d be cleaner if we used the properties here instead of the attributes, because then we only need one \"function\" I\\'m not sure I understand. Specifically the part about one \"function\". I agree with @zweckj, you might as well transform the functions to properties.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nPlease checkout other integrations which use this (there are many, don\\'t have an example right now (I think flexit_bacnet uses it this way)) why are you suppressing the KeyErrors? So that an invalid mode doesn\\'t cause and exception (although, looking at the Entity code it looks like the mode is already checked before setting it so it might be worth just letting this raise an exception). only have code in the try that can fail\\r\\n remove empty keys please continue the tests to show we can recover from a failure I don\\'t see how we could continue here. The error is that the user doesn\\'t have any devices that match this intgration. As far as I understand FlowResultType.ABORT is a terminal state. oh right. My bad maybe put that in a method to avoid duplicate code Can you elaborate ? According to #defining-your-config-flow it seems important if the schema ever changes. 1 is just the default of a `ConfigFlow`, so no need to set it again are you planning to reuse that method in an options for or something? Otherwise I\\'d just put it inline. regarding your question this is what I meant:\\r\\n\\r\\nby using the built in properties, you don\\'t need to define a method that you then call to assign to an attribute, but can just put the code inside the property definition I tried doing that but it raised an exception from here : [raise TypeError(f\"Can\\'t override {attr_name} in subclass\")](#L386) so it seems you can\\'t use property decorated methods for those attributes (IIRC I also tried def _attr_... which didn\\'t work either). Actually, after looking at it closer it seems that this exception is only raised if _attr_... is a property decorated method, I could override the methods defined in ClimateEntity but I think I prefer keeping it this way because this way we use the way ClimateEntity handles those properties (specifically ClimateEntity decorates these properties with cached_property. I really think it would make your code a lot cleaner (compare it to ecobee\\'s climate implementation  Not sure about the `@cached_property` but maybe you can just redecorate yours the same way. This should all be moved to `async_setup_entry` in `__init__.py` \\r\\nthere\\'s a const for that Unique_ids are unique for domain and platform, so setting it to the serial number is just fine I think I know why you use bidict, but please just do it manually to avoid introducing a new dependency in the integration. If you still want to add it in the future, please try to add it in a follow up PR so there can be a separate discussion about this (As this is a use case more integrations have, so it makes sense to maybe apply to all places) Can these be moved to the library? I\\'ll check with the owner of that repo Unused Can someone change the username?',\n",
       " 'remove the commented out code would `HeatingProgram` maybe be a better name? I used that before but there are also programs for cooling (not used till now). Then that comment below is not accurate as it says heating programs.\\r\\nEither fix the comment or I suggest to actually rename it like suggested In ViCare context there exists a heating program (which can be heating and cooling) and a ventilation program ([not yet exposed in the library]( So to avoid confusions with ventilation in the future, I will rename it back to heating program. I know you\\'re not using it in this PR, but since you added it as enum now, do we need those? Can\\'t you use `Program(\"PRESET_...\")` and `Program.COMFORT.value` to do the conversions? Good idea, not sure how that would look like though.  you can discard this, was just an idea, not even sure if it\\'s valid. `HA_TO_VICARE_PRESET_HEATING = {v: k for k, v in VICARE_TO_HA_PRESET_HEATING.items()}` Check program You\\'re duplicating the names here so how is the user going to know what is what?\\r\\nMaybe add \"heating\" in the middle to diff from the ones above (or something else, maybe they have a good name in the app)? Devices support either one of them. Gas heatings have a *comfort* program where this in typically named *comfort_heating* on heat pumps as they have also a *comfort_cooling* program (see \\r\\n\\r\\nI thought it makes no sense to have the *heating* in the name as of today as we have no support for the `cooling` programs. I think we should mimic the native app/control so if it\\'s \"Comfort heating\" I think we should say so.\\r\\nAlso later we don\\'t want to change this if we implement the `cooling`s programs.\\r\\n\\r\\nLastly if none of above use a link to the previous translation to not duplicate for the translators\\r\\n(example: `\"[%key:component::vicare::something::comfort_temperature::name%]\"`) Just checked my system again, there is just the ability to use \"comfort\" and nothing about \"heating\"/\"cooling\" at all.\\r\\nSo I will add a link tho the existing translation.',\n",
       " \"this could be a function Done, logic is now implemented in the library. where do you use those? Those probably belong to `strings.json` Those are the names for the entities that I had to remove for now since I am only allowed to add a single platform in this PR. I will remove them. Removed for now since these are not used by the climate platform. and those to `icons.json` Removed for now since these are not used by the climate platform. I think we're not supposed to do calculations in our entites, but only in the lib Done, calculation is now implemented in the library. those are currently empty then, aren't they? Yep you're right, will remove. I normally like to be a bit more expressive and have this in separate lines, especially since in the platforms that will be added in the future some entities are only created based on a flag set in the options flow, but I guess I'll simplify this in the way you suggested. what exactly are you doing this for? The thermostats can only be set to temperatures that are increments of 0.5, so we round the temperature to the nearest half and also check that it is inside the temperature limits set by the thermostat. I guess this could also be extracted into the library. personal preference: set it thorugh `_attr_device_info` as it's static True, I only found out about that attribute today, will use that. \\r\\n\\r\\nis the default \\r\\nnot used, but is there a way to validate the user entered configuration is even valid? The only thing that could be validated is the mac address. I could do some regex or maybe use an already implemented validation helper method if it exists to do that. I can not validate macs based on if the device actually exists though, since most often the bluetooth radio of the thermostat is turned off when the user creates the config entry and therefore the entry takes 1-2 retries until a connection is established. It would great to get a ðŸ‘  from dbuezas here before merging this  Sure, I wrote him a DM and asked if he wanted to be listed before, told him to react here now. I'm ok with being a co-code ownerðŸ‘\\r\\nAwesome work @EuleMitKeule  If these are both enums than identity checks are preferred If these are both enums than identity checks are preferred If this is an enum on both sides, please use identity checks\",\n",
       " \"the entities are of domain todo, how can i ensure, they also belong to bring integration? You should put this section under `async_setup_entry`, to have the context of your todo list, instead of using `async_setup`. Also, the service will need the api object created in the `async_setup_entry` to call the api endpoint. registered it as entity service but the method is never called. Can't figure out why Should we check here whether an item_name for the notification type is required before sending it to the bring api? `ValueError` is very broad, are we sure it's only thrown when the item is missing? Maybe it would be better to check this ourselves? pretty sure, i wrote the notify method of the bring-api library.  also rewrote the error message to be more consistent with other error messages. How is this possible considering the schema requires the user to pick one of the 4 notification types? you are right, the schema validator already catches this so this is superflous, will remove it\",\n",
       " \"Please sort them went ahead and did so but is this a standard? If so, shouldn't we have something in pre-commit that enforces that? Please sort them\",\n",
       " 'Stale comment.',\n",
       " 'Can we type this?',\n",
       " \"Maybe include which node wasn't found?\\r\\n\\r\\nWe also shouldn't raise an exception from the library here, as those are not meant to be raised outside of the library. suggestion for an exception to raise ?  Yeah, I was just checking and a bit below i the helper we actually raise ValueError if the device can not be found so maybe raise ValueError here as well to be consistent ? (helpers.py, line 75) If we want to catch the exception I'd raise a more specific error. I assume we want to catch the exception in the error handler decorator and send an error message to the frontend.\\r\\n\\r\\nThe raised errors in the helpers are not expected but more developer bugs if they would happen. can you check what I did - I'm now raising ValueError with a specific error message and catch that in the decorator Yeah, that's according to plan, but I'd create a custom exception per above. yeah sorry, forgot to hit push. its now there I think we should make another decorator like `async_get_matter_adapter` that gets the node. done Please add a test for missing node for each of these websocket commands (even if we move the code to a decorator). I'd not catch ValueError. That would mean that the frontend tried to work on a Home Assistant device that doesn't exist. That would be a bug. ah yeah, makes sense :-) adjusted it Side note: I think we also need to handle not loaded config entry. We don't need to fix that now though. It's an existing problem.\\r\\n\\r\\nHere's what we do for Z-Wave:\\r\\n#L268-L286 OK, added that as well but was not sure how to test it as I cant even create a fake device with an invalid config entry id sorry, only now see your comment that it didn't need to be fixed right away (its getting late haha) - well its now added, except for a specific test To test a missing config entry, we can create a device from another mock config entry and try to use that device as input.\\r\\n\\r\\nTo test a not loaded config entry, we can just unload the config entry and try the command again.\\r\\n\\r\\nIf it's late, I suggest we remove the config entry error handling for now and add that later with tests. We also need to make sure that the config entry is loaded, to make it not raise an exception later when trying to get the matter adapter from `hass.data`. I have removed it for now so we unblock this PR (as frontend is waiting on this one) - We'll do a follow-up PR with this addition after having clear what needs to be done.\",\n",
       " \"I think we could use a better name for the event types. They look pretty sane to me? This will exclude the useless buttons.\\n Tests would be nice, but that's for a separate PR. I've tried adding tests, but its a pita to mock the full library Don't we need a corresponding unsubscribe if the entity is removed?\",\n",
       " \"Please use snake case for translations keys \\r\\n\\r\\nYou use a coordintor, this doesn't apply for the coordinator By the looks of it, this doesn't have to update the state, this will only update the entities, but there is no new state (iirc).\\r\\n\\r\\nwhat about just (request an) update the coordinator? I think I did what you suggested but I'm really not sure I understood your feedback properly.\\r\\n\\r\\nAlso, It takes a few seconds after the request to the station to complete before the state is reflected in the API, which means that when a user turns the switch off, they will see it off for a second, then it jumps back to on until it finally goes to off once the device has fully turned it off.\\r\\nDo you know if this behaviour can be improved? Flexit_bacnet has an improved version for the snapshot tests, it also check if the state is not none Done. Why is this added hmm, I can't remember why this would be added here and in sensor.py. I removed it.\",\n",
       " 'Do we have a mapping for these states? Having a code for state is not really user friendly.\\r\\nI found a mapping for the tesla wall connector integration. I\\'m not sure if it\\'s the same mapping using the fleet api.  I went looking for these states and couldn\\'t find them, so thank you for pointing me to that PR as I\\'ll implement those values.\\n\\nI believe the fault states will still be unknown? Do you have a wall connector? I can test your PR with my wall connector to see what I have for fault state. May be there is different type of errors so that\\'s why it\\'s an enum ðŸ¤·\\u200dâ™‚ï¸ Yes I have a wall connector.\\n\\nI set it as an Enum because I know it will have a set of numerical codes that probably relate to the errors in the manual, but I have no reference about what\\'s what and am not sure I could force those errors.\\n\\nThis is why I disabled these entities by default, since they will be useless for most users.\\n\\nExcept now that you have states I\\'ll probably enable the first one. I just tested with my wall connector. State codes are not the same between fleet api and local api... I could figured what\\'s fault state because it changed with the vehicle is charging.\\r\\n\\r\\n**Vehicle unplugged:**\\r\\nTeslemetry state = **2**\\r\\nTeslemetry fault state = **2**\\r\\nWall connector state = **1**\\r\\n\\r\\n**Vehicle plugged:**\\r\\nTeslemetry state = **4**\\r\\nTeslemetry fault state = **2**\\r\\nWall connector state = **9**\\r\\n\\r\\n**Vehicle charging :**\\r\\nTeslemetry state = **1**\\r\\nTeslemetry fault state = **8**\\r\\nWall connector state = **11**\\r\\n\\r\\nI\\'m thinking out loud. Can we have \"state code\" and \"fault state code\" an entity name instead of \"state\" and \"fault state\" so we can add these sensor with readable state when we will have it? Ive added \"code\" to the translations Only call `add_entities` once Done, using itertools.chain to join them up. Consider to make some disabled by default? That\\'s a lot of sensors... This isn\\'t even the full list of sensors I\\'m going to be adding.\\n\\nI\\'ll see which ones are logical to disable. I think here with so many it might be good to be a bit conservative and make a good note on the doc instead that many sensors comes disabled or something to encourage the user to look at which makes sense to them. I have disabled a bunch now, I\\'ll update the documentation accordingly. Just to be sure but the `product` can not contain both `vin` and `energy_site_id`? That is correct. It can\\'t be a vehicle and an energy site. Looks like there is room to make a base class here to not have to repeat `__init__`? Won\\'t that mess up the types since they accept different data objects?\\n\\nI will give it a go though as I actually have three coordinators in total. @gjohansson-ST added a base class. Ahh I just realised this is redundant and I will need to revert it back in a future PR, but its fine to stay as is for now.\\r\\n\\r\\n',\n",
       " \"It's not working without that. Other integrations have it, too.\\r\\n\\r\\n#L27 I think you're right, I forgot this was an oauth. one \\r\\n\\r\\nKeep in mind, an unique id is unique for both domain and platform, so it might as well just be\\r\\n \\r\\n\\r\\nTo also include the coordinator entity available state Commented code\\r\\n\\r\\nYou could do a\\r\\n\\r\\nTo refresh the state after a command I've missed to delete that line, from a test. Actually it works pretty good, to just send the command and wait for the websocket to send an update. I saw a lot of integration refreshing the coordinator after sending a command. What's the preferred way in HomeAssistant? _It depends._\\r\\n\\r\\nI think it depends on the integration, since your integration is a push integration, just waiting for a push makes sense. (Unless that push takes 5 minutes or something like that).\\r\\n\\r\\nIf you think it can just work on push and that gives a good user experience, go for it! The push feedback come really fast. I leave it like that. Not sure why this is needed, maybe you can use something like I did in Withings:\\r\\n#L46-L55 done We should patch the library instead of this method Maybe take a look at Withings tests Changed it. Oh you already do that, but why do we have the whole `config_entry_oauth2_flow.async_register_implementation(` then? `Autouse` solved the problem I think this is tested implicitly by the other tests I don't really see the value of putting in a real JWT instead of just a random string as the content of the JWT is of no use for us It's used here to create the config entry. So encoding is tested here. But I can also patch it.\\r\\n#L24-L36 oooh, in that case it's okay, I thought we never used it I am missing the test to test if a duplicate entry already exists Added. \\r\\n\\r\\n#L510-L513\",\n",
       " \"Some code from mixins is no also used in discovery.py.\\r\\nThis is moved to `device.py` to avoid complications with dependencies. This is a bit weird since most of what's in this file has nothing to do with devices. How about moving the schemas to a new module `schemas.py`? Well all shared stuff is within the device context. But I can rename the module if that suits better in you opinion. This schema does not allow extra values, and is used to validate a device based discovery JSON.\\r\\nNote that for the component only the presence of the `platform` option is validated. moved to ~`device.py`~ `const.py` This function replaces all abbreviations. and validates the origin info. Validation of origin info was moved out. When an empty payload is received, this will renerate a config to cleanup all ~siblings~ children of the device., When you write siblings, do you mean children? right, The discovery id's of the device is has been extended with the unique component key, This way it is easy to find and discovered device components. We parse the device JSON (or generate the cleanup instructions) and validate against the device schema. This will allow to override some shared options at component level. Since we allow extra options, it should not be an issue in case an option is not in the component schema. Why would we want to override a shared option? Can you give some example? E.g. a `state_topic` might get it's value from a different topic, In that case, if it is set within the component context  it should override the share context. It was changed this way to address comment:\\r\\n\\r\\nIt was the shared context that had priority, later I changed this based on:\\r\\n#issuecomment-1915172290\\r\\n @emontnemery There are two circumstances.\\r\\n1. You may have one device that sets a common state_topic / command_topic, and a different device that sets a per-entity state_topic / command_topic - this supports both (no overriding going on).\\r\\n2. You could have a device that sets a state or command topic for the device, but then for specific entities (maybe virtual entities, or who knows), it sets a different state / command topic for that entity, but not the rest of the device.\\r\\n\\r\\nThe former is likely more common.  But the code as written supports both.  ONLY having per-device options would mean a lot of repetition if there are many entities.  ONLY having device entities would make this impossible to use for things that do want different topics per entity.\\r\\nSince we want to support both, having the more specific (entity-based) option override the less specific (device-based) option just makes sense - provides a concrete way to avoid ambiguity. We parse the device discovery and forward the discovery for each component. At component level further schema validation is performed. In case of a single component we just add it to the list of components to process. The component key is used as a `node_id` or if `node_id` was in the discovery as a `sub_node_id`.\\r\\nThe component is retreived from the `platform` option in de component config. This way the `discovery_id` of the `components` of a `device` always contains the discovery_id of the device. shared `device` config is required, and always overrides any component `device` config. shared `origin` info overrides the component origin info (if set). We could choose to make origin info required for the new schema. The `origin` option has been made required for `device` based discovery. For shared options the component config can override the shared config. Returns `{}` in case the `origin` info schema fails. This part is not handled in mixins or the component code, hence it is handled here. I don't understand what you mean, we call `_replace_all_abbreviations` and if that fails we return an empty dictionary. What does that have to do with the origin schema? The origin info is validated against a schema, if that fails, _replace_all_abbreviations fails, and an empty config is returned The same code is is used for the single component discovery, hence we validate the origin schema first, because it is not handled at component level. I have moved the validation of origin info to `_valid_origin_info`, this is only for the current discovery schema (per component).\\r\\nThe `DEVICE_DISCOVERY_SCHEMA` now handles the validation or origin info. It would be nice to do the schema break out in a separate PR. It would really help with testing this so I can focus on making sure I'm profiling the changed code vs the existing code as I spent a bit more time digging around in the profile only to realize it was moved code and not new code.\",\n",
       " 'This change doesn\\'t relate to this PR. I\\'d recommend a separate PR that (a) bumps `simplisafe-python` and (b) makes this change. Then, rebase this PR on top of that one (once it\\'s merged into `dev`). I\\'m having trouble rebasing.  I sync\\'d my core:dev with yours, pulled my dev, \\r\\n\\r\\n\\r\\n\\r\\nand I get a bunch of conflicts I did not expect.  I seem to be getting conflicts with previous commits on my simplisafe-outdoor-camera-support branch.\\r\\n\\r\\n\\r\\n\\r\\ncamera.py for example, is not even in dev.  I am not sure what is happening.  Can you suggest anything?\\r\\n Run a `git status` and this stage and share your output. You need to see what changes Git struggles to reconcile in those two files, update accordingly, and then continue the rebase. \\r\\n\\r\\nWhat state am I in now?\\r\\n When that occurs, that means that the current commit matches your working stateâ€”in that case, I would just `git rebase --skip`. Did you end up making a separate PR with the version bump and this websocket event name change? Yes Is this necessary? Can we just `return content`? Because if I just \"return content\" mypy says:  error: Returning Any from function declared to return \"bytes | None\"  [no-any-return] And in simplisafe-python (_api) the function is declared:\\n  async def async_media(self, url: str) -> bytes | None:\\n\\nSo I don\\'t understand why mypy is freaking out. This can be simplified via a comprehension:\\r\\n\\r\\n Where does this get called? Does HA call this at some point?  I believe I found this sort of thing in other components, so I adopted it here too.  If HA does not call it, then I\\'ll remove it ... because I certainly don\\'t call it. Is this ever reset? Are we always returning a cached image once it\\'s been set? It gets set to None in async_update_from_websocket_event() when a new motion event arrives. This seems odd. Why not just construct the entire URL when you need it? This is what the urls look like from SS.  I do not know the desired width (from a user\\'s automation) until now.   Loop through these service registration calls (since they\\'re almost the same). Only DOMAIN is common.  The other 3 (of 4) are unique.  Seems to me the loop would be complicated. Should this really be an error? The user can\\'t do anything to correct it. Ok, removed error printing Why are we disabling `mypy` here? Because if I don\\'t I get: error: Incompatible types in assignment (expression has type \"Any | None\", variable has type \"Template\")  [assignment] Why are we disabling `mypy` here? Because I get: error: Incompatible types in assignment (expression has type \"Any | None\", variable has type \"Template\")  [assignment] All these nested functions are challenging to follow. What about just including them in the entity? Because they need the reference to self, and wouldn\\'t get it when called from HA as services?  I copied this pattern from other components, thinking this is the way to do it.',\n",
       " \"Please move this to the top of the class Can these change at run time?\\r\\n\\r\\nIf not let's use the shorthand `_attr` here so we don't have to calculate these every time state is written #color-modes\\r\\n\\r\\nPlease double check to make sure all color modes match the description in the table Ah, I see brightness is suposed to be standalone, and you should only return values in supported_color_modes. \\r\\nWould this be ok, is is there something else that needs to be fixed?\\r\\n\\r\\n It would be cleaner if we could determine the color mode from the device data itself without having to check `self._attr_supported_color_modes` It doesn't look like WHITE should be set here\\r\\n#color-modes\\r\\n\\r\\n> If this mode is supported, the light must also support at least one of ColorMode.HS, ColorMode.RGB, ColorMode.RGBW, ColorMode.RGBWW or ColorMode.XY. Hmm thats odd, Is there someone I could ask about that? it seems to be working just fine when I try it, and I don't know why it wouldn't be able to support ColorMode.white and ColorMode.COLOR_TEMP (See the W icon next to the color picker)\\r\\n\\r\\nEnabling white mode (warm dim) is a large part of the lutron lightstrips, so I would be curious to make sure there is a reason it's not supported, or just forgot to be added to the documentation in the list.\\r\\n\\r\\n![image](\\r\\n I'm not 100% sure why color_temp doesn't qualify so I added a request for a second opinion in case someone else knows Also some times it takes a few weeks/months to get a second opinion.  So we could always merge it without white support for now and you could add it in a future PR so we are only waiting for the second opinion on that PR  Please make this a const dict lookup by light type `supports_warm_cool` and `supports_warm_dim` never change. Please set them in the constructor Please type arguments Please type arguments Please type arguments Are these available as constants from the pylutron-caseta lib? unfortunately not \\r\\n\\r\\nlinter will complain about this suggestion Please make this a constant instead of binding it to the class since we don't need to override it in children Please move this after `__init__`.  We want `__init__` to be the first thing in the class \\r\\n\\r\\nthan make a constant set above\\r\\n\\r\\n\\r\\nWARM_DEVICE_TYPES = {DEVICE_TYPE_WHITE_TUNE, DEVICE_TYPE_SPECTRUM_TUNE} \\r\\n\\r\\nPlease prefix functions that are save to run in the event loop with `_async` or `async_` since we have both sync and async code in this codebase You can import Lutron's color mode as \\r\\n\\r\\n`from pylutron_caseta.color_value import ColorMode as LutronColorMode`\",\n",
       " \"Please create a separate list for the entity descriptions unused we don't use this in this integration afaik Please extend SensorEntityDescription and add a value_fn property for the value. Do a global search for `value_fn` for examples Sentence case What are you doing here Create the dynamic list of sensors to be added in the line after can be moved to the entity descriptions done done unused Can be removed can be removed What are you even testing? I'm testing that the entity is created correctly. As it does not have any direct logic but relies on the coordinator get_status with the communication with the projector I do not need to test anything else.\\r\\n Yes you do, you're adding two entities, at least test the state Can be removed as is default  Aren't these constants? The constant are in the jvcprojector library, if I put them I get an error, so I had to put the string. They are imposed by JVC so is ok to have litteral as they will never change\\r\\n Then why are they constants in the first place? What are you testing here? We could do better Please remove Unneeded  Unneeded  This code is now doing the exact same thing as above, except for the last line Off is actually not a valid state (only Standby). I would remove this to avoid confusion with users writing automations. You're right; I cross checked the documentation and it is not returned Can we have better icons for it?\\r\\nuse the outline variant for cooling/warming is wrong in my opinion as the user needs to know that the outline variant means cooling/warming As the input is changeable, this should not be a sensor but a select entity.\\r\\nPlease remove it from this PR and create a follow-up, where you add it as a select entity\",\n",
       " 'Will you also be able to update in the future? Maybe, but I don\\'t think so. Not for now at least.\\r\\n\\r\\nThe mobile app offers OTA updates but the server to check for updates is not public, I would need to reverse engineer the mechanism.\\r\\n\\r\\nIs there a better way than binary sensor you would recommend? In that case this will do just fine :) This could be disabled by default imo I agree, updated. \\r\\nIt\\'s already imported as fixture True! I changed it in my sensor test too for consistency. This one should be the `update` platform Also when you can\\'t install updates remotely? Or know what version you have/can upgrade to? > Also when you can\\'t install updates remotely?\\r\\n\\r\\nYes I think so\\r\\n\\r\\n>Or know what version you have/can upgrade to?\\r\\n\\r\\nProbably not as we need to know upgradable version to have a proper state. I just assumed we knew if we know an upgrade is available (or perhaps \"fake one\") as I think it looks nicer for the users to get it in the updates available section i in `settings` rather than just as a `binary_sensor` even if it\\'s not possible to update it from there. Looks like we only know the current version and if it\\'s up to date\\r\\n\\r\\n#L119-L130\\r\\n Maybe right now but are we sure it can\\'t be returned from the api of the device? For now, I have no way to know what version a user can upgrade to. I also have no idea how to get the next version. Should I just leave this info out of the integration until I have more details?\\r\\n\\r\\nAll I can get from the device API is a bool that tells me if an update is available, but I\\'m not 100% certain this ever changes (there are not frequent updates so I can\\'t test currently). I think the app does all the logic for updates right now. Let\\'s leave it in then ðŸ‘  would be better to set a fixture in `conftest` to load the integration once.\\r\\nNot seeing why we need to load single platforms. For the snapshot test, you still want to have the tests separated per platform, but not have every platform snapshot every entity Sure, was only referring to setting up the integration. I know, but when I added Withings sensor snapshot tests I checked if they were the right platform when snapshotting, but I was told I should patch PLATFORMS instead I guess anyone\\'s preference... This is a test for a Â´sensor` so why it\\'s here and not in `test_sensor.py`? Sorry about this. This was leftover code. I tried to go too fast yesterday. \\r\\nRemoved. Personally I would like to see setting the side_effect before moving time Done. I also changed it in the equivalent test in test_sensor.py for consistency. Why does all these state snapshots disappear? That sensor got removed, but syrupy doesn\\'t actively remove removed snapshots (I think it\\'s configured this way in HA) Ah. It wasn\\'t removed but now I see it\\'s all duplicated as the name changed.',\n",
       " \"I think this too should be marked as diagnostic Done, also cqi1 (the 4G one). Please remove these comments, they look like review comments, not something which is useful in the code.\\r\\nAs an alternative, rephrase. Rephrased some, suggestions welcome if more changes are wanted.\\r\\n\\r\\nI don't think the comment should be removed, because it's a valuable TODO (which isn't marked as such because the HA linter config at least used to forbid TODO comments), and I don't think there's a better place than right there in the code where the thing to address is. Please remove this sensor for now if it's unclear if it works Even though not perfect, it does work as in shows diagnostic information. We have a similar one for 4G in `txpower` already.\",\n",
       " \"Why does one of these set `log_api_exception` to True and the other to False? I'm not sure what you mean; all instances of the `log_api_exception` parameter are set to `False` in this file. You're right, I have no idea what I meant ðŸ™ˆ  Why is this changed? Is it to ensure the Play/Pause buttons always show in the frontend? Yes, this gives us separate play/pause buttons rather than a single dynamic button (which won't actually work correctly because the Vizio API doesn't provide a playing/paused/idle status).\",\n",
       " 'What\\'s the default icon for climate/can you use icon translations? Yup indeed, just copied from other integrations that explicitly have the `_attr_icon`.\\r\\nI think that for climate should be removed from all integrations.\\r\\n This can be a constant outside of the class (I think that\\'s more efficient) removed preset support as not always configured \\nI think this was a valid constant We dont raise update failed in these cases iirc I guess maybe just log and return None  ok What\\'s a MAN Manual I mean, the enum is to keep the code consistent and readable, why not change it to MANUAL :) renamed So we only set HVAC to ON when it\\'s off, what if we set it to MAN? HVACMode doesn\\'t have a Manual mode ;-)\\r\\n Why the *10 Because the api expect \"178\" for 17.8Â°C\\r\\n You have the same /10 when we read ;-) Isn\\'t that a device specific thing? I\\'d rather see that resolved in the library  As far as I know we do the same for many other integrations, for example fritz.\\r\\nAFAIK, we usually don\\'t manipulated data returned by the API in the library.\\r\\n Moved to the library Please bump in separate PR  I did only because the bump is needed for clima to work; will separate.\\r\\n #108862 I see different values: O, U, L, A. For O you already have a constant, would it maybe be nice to have the rest as constant/enum as well? Ok will do later this evening once back home Done CLIMATE has a 2 item tuple: We don\\'t want side effects like logging in entity state properties. Please remove it or move it.',\n",
       " \"Didn't you remove a lot of `Active` prefixes recently? That PR is not merged ;) Let's try it again.\\r\\n\\r\\nYou removed all the `Active` prefixes recently. Hah that is absolutely 100% true. I totally forgotten about that and will pick that up ASAP ðŸ˜‡  Rebased!\",\n",
       " \"Why don't we just use `area_id` and copy the return value from that to a boolean? The comment in the previous PR was to make `area_id` function as a filter. My goal is to make the template in the PR description work. Would be happy to see possible improvements. Please explain further why that wouldn't work. Already discussed in previous PR. I don't see anything saying we can't make area_id a test or a filter. On the contrary, that's exactly what we're suggesting. If you don't agree please explain further. > Why don't we just use `area_id` and copy the return value from that to a boolean?\\r\\n\\r\\nFirst I only wanted to check entity IDs.\\r\\nYou mean like this:\\r\\n > I don't see anything saying we can't make area_id a test or a filter. On the contrary, that's exactly what we're suggesting. If you don't agree please explain further.\\r\\n\\r\\nI don't know how without overloading `area_id()`.\\r\\nI think it is a better approach to create `is_area_id(<area_id>)` instead.\\r\\nI updated the PR description for better understanding. What we suggested in #101171 was to allow using the existing `area_id` function also as a filter.\\r\\n\\r\\nHowever, it turns out that's already implemented: <#L2795>\\r\\n\\r\\nThe two suggested templates in the PR description can be realized with existing functionality:\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n Sorry, but this is wrong. Please read the previous PR discussion, especially #issuecomment-1742094759. I am annoyed to explain the whole situation exactly in a second PR.  @emontnemery Please have a look at the community [topic]( @klatka In the PR description you give two examples of how the `is_area_id` test is useful.\\r\\n\\r\\nIn my comment I showed that it's perfectly possible to implement the same templates using the existing `area_id` filter and function.\\r\\n\\r\\nInstead of being annoyed, can you please show some example of a template which is impossible, or at least much more cumbersome, to do with the `area_id` filter and function? Thanks, @klatka, now it's clear ðŸ‘ \\r\\n\\r\\nInstead of adding tests, maybe we should make area and device data directly accessible from the state object, then it would be possible to do something like this:\\r\\n\\r\\n @emontnemery  I'd love that approach and it would make 80% of my area-based automation a lot easier. Should we be concerned about performance making area and device data accessible? Performance should not be a problem if the area attribute is lazily looked up, i.e. it's not assigned until `state.area` is accessed. Could you give it a try? You can contact me on Discord if you want to discuss the approach.\",\n",
       " \"Maybe make TRIGGER_MODEL_A and TRIGGER_MODEL_B constants so you don't have to construct them over and over.\\r\\n\\r\\nIdeally we name them something a bit more descriptive Good idea. Changed.\",\n",
       " 'The previous implementation left an empty title for cameras that took their name from the device. This seems to be a better choice, but if there\\'s a better way to get the name I\\'ll change it. I still want to see this change in a separate PR with its own description, etc. #creating-the-perfect-pr as i mentioned before. Update test description Tests do not interact with hass.data and instead should by string name as is done in other parts of the tests in this file..\\r\\n\\r\\nIn this case i think the reason this approach is chosen is because there are different return values for the different cameras?\\r\\n\\r\\nInstead, patch once and have either the callable or side effect return the different values for each call.\\r\\n\\r\\nAlso a small comment might go a long way here, something like: \"One camera supports HLS and WebRTC, one cameras supports only WebRTC, and one camera fails.\" etc I think everything looks good to go here, but now i\\'m thinking about one more idea to further streamline this, but not positive it would work out: Could the scope of this function be to just filter out the not relevant cameras and leave the browse media source building all together how it was?  It could just get the eligible cameras in one pass then build the sources in a simple loop together with building the root. We could return the camera instead of `BrowseMediaSource`, and then iterate over the results to build the sources, but I\\'m not sure I see why it would be better? Its possibly a style preference, but my thinking is: in general, reducing # of verical lines of inline functions or reducing the scope as much as possible seems positive. Having the `BrowseMediaSource` building closer together together seems logical as well. One exception may be if there is shared logic on both parts but i think the existing stream type filtering looks more complex than it needs to be It\\'s a bit tricky because we also have to recalculate the content type (or return a tuple).\\r\\nArguably refactoring the creation of the `BrowseMediaSource` to a separate function would achieve a similar result (see my latest commit) Thanks, that looks good. What do you think about gutting all the existing vertical whitespace? It seems like it makes this harder to follow given it has so many branches and is in an inline function. Collapsing vertically will also help make this simpler to grok quickly. Does it work for this to be a single statement? (Given this is 3 levels of nested ifs in an inline function)\\r\\n\\r\\n I took advantage of the ability to return early in a successful case to refactor a bit differently. Let me know what you think. This seems like it can either be 1 or 2 lines rather than 3 Maybe just drop this while we\\'re here\\r\\n\\r\\n',\n",
       " 'stale doc string \\r\\n\\r\\nUnless I\\'m missing something, this looks like a useless `any` expression Ahh. its a generator....  Instead of just return maybe we should kick in the reauth flow? That seems like a job for the frontend? Makes sense. Probably we should not show the option to reconfigure if an active \"reauth\" exists I think you can combine these Made the split to make the comment to kick in the \"reauth\" flow but if we should just return here then yes we combine them. Should the existing checks in `async_start_reauth` and `_async_init_reauth` also be updated to check both reconfigure and reauth? I think this is changed because you use black instead of ruff to format code in vscode. Please revert this change. I think this is changed because you use black instead of ruff to format code in vscode. Please revert this change. Ugh, this really should not be in `homeassistant/helpers/data_entry_flow.py` but in some config-entry specific sub class. This refactoring should probably happen in a separate PR.\\r\\n\\r\\nWould it be possible to add it here: <#L137-L164> Ideally, this should be removed. This is not OK, because all tests executing after this test will now have an \"assist_pipeline\" flow. assist_pipeline has a `config_flow_fixture` fixture already which adds a fake flow and then cleans up.\\r\\n mock_config_flow is the correct way to mock a flow, why is this changed? I don\\'t think this is OK, because there\\'s a single instance of the `ConfigManagerFlowIndexView` class handling all requests. This is not OK, because there\\'s a single instance of the `ConfigManagerFlowIndexView` class handling all requests. We should instead split up `FlowManagerIndexView.post` in an outer function, which is decorated with `@RequestDataValidator`, and an inner function, `FlowManagerIndexView._post_impl` or something like that, which child classes which have their own `@RequestDataValidator` can call. Is this change needed? Is this change needed?',\n",
       " \"\\r\\n\\r\\nI think you can write state directly here but thats probably not needed since it will happen at the end of the update anyways We can make use of `@pytest.mark.parametrize` here as these tests are nearly identical Ok that's parametrized now.\",\n",
       " \"Please don't modify these I modified the recipes and made a new commit Does this use Oauth? Actually yes, but token is long life so don't need to refresh Wouldn't it be nicer if we could use the Oauth flow instead of storing the credentials of users? Actually don't store credentials of user  but user Oauth cliend_id and secret and after this the token generated. Alternatively we have to use a unique client_id and secret for all the users and this is not good for us because we have limits on monthly call by client_id We have an Oauth flow, checkout integrations like google, withings, spotify etc. People fill in their own client id and secret and will be redirected to the service to login. After that they will be redirected back to HA.\\r\\n\\r\\nThe current approach would also work, but I think this approach would be a better user experience, and it would make HA a bit less dependent on the decisions in the company. (Maybe you will make new tokens short lifed, etc) Yes, we've seen the other integrations approach. OK, we will try to use that, is this a now decision or we can do in a second version of the integration? I asked around for a second opinion, maybe this approach is a good reason, but I want to be 100% sure what I am telling is true.\\r\\n\\r\\nIf we were to implement application_credentials, it should be in this PR It seems like this is an implicit flow. Do you also have a redirect flow available? It's not a implicit flow, is Password Credentials Grant type Hi @joostlek , we've choosed to leave Password Credentials Grant Type because is legacy. Now we use implicit, we've developed the flow as suggested from HA. The integration looks now ready to be reviewed Please don't change the package constraints in this PR. Thanks!\",\n",
       " \"I don't think we need this Let me reiterate. We should use this function to replace the `setup` function and use this step to import the YAML configuration as a config entry. If we can't import for some reason, we should raise an issue.\\n\\nFor an example, please check the Pull requests that have been merged at the PR tab and search for streamlabswater. This would be an example you can use to import configuration. (I'm on the bus right now so I can't quickly find it) Got it, thank you! The whole idea of `.setdefault` is to set it to `{}` only when it doesn't exist ;) Only put stuff in a try block that can raise What kind of error can occur? Removed, since this is was copy and paste from previous setup process You can just pass a list to the setup.\\n\\n\\n\\n Changed to `async_forward_entry_setup**s**` I think it's best to leave the has entity name and device info changes for a later PR so we can focus on the config flow in this PR Removed. I am leaning towards solving this in a follow up as well Removed. We only allow names to be set by helpers. We should set the name of the config entry to something the user can recognise if possible, otherwise just a default name Changed to: CONF_FRIENDLY_NAME Can both be removed Removed. \\n Changed. These are all required fields so you can just do \\n\\n Currently we are only checking if its a valid host. Can we maybe do a little check to see if we can actually find a device? If we can check if the device is supported?\\n\\nThe config flow is the best way to tell the user they f*cked up. So we should do our due fill to check if this is a valid device to connect to and abort if not.  Added connection check. General question: can we get any kind of identifier from the devices? Some kind of serial number or something along those lines? Do you mean the sensor or the alarm panel? I am probably adding a serial number in the future, but this will most likely be handled in the separate PR for device info Unused Removed Unused (afaict) You can use translation references. Checkout Sonarr for an example Currently you are not using this. I think we can add support for more instances with ease if there is no technical reason it's blocked There is no options flow\",\n",
       " 'Can we unset these?\\r\\n I have mixed feelings about this part. It\\'s very unclear what is happening when. I am leaning towards extracting this into a function, but that would require a lot of parameters. Or you would have to pass in the coordinator. \\r\\n\\r\\n(The biggest factor that makes this worse are the inline ternaries) Intent is to show phase features with the model. Maybe this makes it more clear:\\n I think it looks better, but I do think we should put it in a separate function  moved to seperate function Can part_number be None? In that case omit the `or \"Unknown\"`, this will just hide it in the UI (Like, \"Unknown\" doesn\\'t add value, so might as well just hide it) That section came from original code, only change is to show it in hardware version rather then model and change Envoy to Unknown.\\n\\n\\n\\n\\nSo it probably made sense in old setup and can be removed here. Unknown removed Can you maybe elaborate a bit more about why we do this? Is this a way to remove an assert (which we have too many of, I agree)?\\r\\n\\r\\nOr does this mean we only show unknown at devices which don\\'t support this? When can this be None?\\r\\n\\r\\n(this question also applies for the Consumption one)\\r\\n\\r\\n(if this is intended, I think inverting it would be better)\\r\\n\\r\\n Yes they can be none and will be none for Envoy without CT or non-metered versions. I\\'ll apply your reverted proposal and do the same for the one below to get rid of the assert\\n But if someone has no CT, shouldn\\'t we omit these entities from being added in the first place? This way they aren\\'t fed up with X amount of entities that are Unknown Yes that is the intent. If none is returned no entity is created. refactored it We should not access internals during tests.\\r\\n\\r\\nI am not up to date on the test state of the integration, but these ideally would be sensor tests as in \\r\\n1. We set up the integration with this as source data\\r\\n2. Observe the created states and check if they are what we expect\\r\\n3. profit I\\'ll change to use   state = hass.states.get(\"sensor.whatever\") May require more overhaul of current test. Currently the device is set up, but no entities, so no states. The flexit_bacnet example does this, but is setup different as enphase currently. I think `dataclasses.replace` could be used here instead\\r\\n\\r\\n#dataclasses.replace It has an additional item `on_phase` not present in dataclass its getting the data from. Would that work? sadly no. it looks like we are stuck with something complex You might be able to do `dataclasses.asdict` and unpack with `**`\\r\\n\\r\\nuntested... but maybe this will work,\\r\\n\\r\\n Doesn\\'t fly, complains about key and translation_key having double values as they are in the asdict list as well. To simplify this, adding the on_phase field to the base class (and not using it) would allow for the dataclasses.replace use. > adding the on_phase field to the base class (and not using it) would allow for the dataclasses.replace use.\\r\\n\\r\\nThat seems like a better idea to me. (typing it to `None` when not used)\\r\\n\\r\\n Done Please separate words with _ Done (need to get rid of this old habbit) Can we move this into the library?  It seems like HA shouldn\\'t need to know how to generate this Could combine these ifs since they do the same return  Done As above  Done',\n",
       " 'Should we return None if time=0? Any reason we don\\'t use device class translations? \\n @cdce8p I hope it is fine to ping you directly :)\\r\\n\\r\\nI have a type issue with mypy.\\r\\n\\r\\nWithout this code line I get the following error:\\r\\n`homeassistant/components/ecovacs/sensor.py:176: error: Definition of \"entity_description\" in base class \"EcovacsDescriptionEntity\" is incompatible with definition in base class \"SensorEntity\"  [misc]`\\r\\n\\r\\nBut I use generic in the base class:\\r\\n\\r\\n\\r\\nWhat do I miss? Try removing the `entity_description: _EntityDescriptionT` line from `EcovacsDescriptionEntity`.\\r\\n\\r\\nThe issue here is that you\\'re trying to make a variable generic which isn\\'t generic in the base class. `entity_description: ...` is basically a just hack to avoid having to make it generic in the first place and needing to update all integrations. It would be \"more\" correct and at some point we might even want to do that. I would wait for [PEP 696]( support though (at least).\\r\\n\\r\\nAs for your case, I would suggest to remove `_EntityDescriptionT` and continue to use the \"hack\" here. That should probably work. Thanks :) Each minute we get an update from the bot so not sure if we should use seconds as maybe the user gets confused as the values is not counting upwords... It would be a more accurate number but indeed updated less frequent. 1:30 would now be 90 seconds, and with the current code be 2:00. (Also depends on important those seconds are) What\\'s the value of this? Which type of cleaning it was:\\n- spotArea\\n- edge\\n- spot\\n\\n....\\nI myself I don\\'t use the sensor et all and we can also not add it for now and see if really some users are needing it âœ¨ _ENUM sensor_ âœ¨  I know that would be great but I don\\'t know all different types... Different models have different types and no public available documentation This is already typed as bool right?\\r\\n You are still referencing `self.entity_description.key` in the unique_id `EcovacsEntity` is a subclass of `Entity`, which has `entity_description` attribute Can I also use `\"[%key:common::config_flow::data::ip%]\"` even when it\\'s not used in a config flow? I think we don\\'t allow that, not 100% sure tho Isnt this the default already? This also sounds like something someone might automate up on, is it worth extracting to a separate sensor?',\n",
       " \"Please just add the Binary sensor to this list instead of splitting stuff @joostlek ok. I have to understand how to modify a file and add the change to the pull request. I continue to end up in a mess and have to cancel :(\\r\\n Just add the changes, don't try to revert JvcProjectorEntity already has this I thought it was requested for each instance I think this is a valid device class for this entity.  ok, in reality I saw the icon and property was ok even without the line, this is why I commented it We prefer the device class over something custom.  Hmm, I am leaning towards just removing this and adding the device class. This would make it `binary_sensor.jvc_somrthing_power` which is quite nice. name should only be set to None when its the main feature of the device. And I think remote is a more valid main feature than knowing if it has power. what do you think? @joostlek in reality I think the main feature is the Binary Sensor. The Remote is very dangerous, for example in my case I need to disable it as I do not want actions performed on a video projector remotely. Sending commands can screw up the setup and mess the configuration. The Power Status is needed before any communication to the porjector, needed in automations (i.e. open screen when on, dim lights when on, power on stereo when on etc...).\\r\\nSo I think is better to have the main feature the Binary Sensor and additional the Remote (and the sensor when I will add it :) ) Can be removed when using the device class Yes, I added it to have the correct icon as I removed the device class Do yourself a favor and add something recognizable to the unique_id for the future\\r\\n\\r\\n\\r\\nIf you ever add more entities you don't have to migrate the unique_id I was using the _power for the Sensor (the other part I will add after this). Ok I will change the other Can be removed Can you make that list a set and put it outside of the class? That's more efficient  coordinator is already set at `self.coordinator` so I can remove it? will check Yes Please revert @joostlek sorry do not understand what I have to do, what you mean with revert? there should be no change here. Please revert @joostlek sorry do not understand what I have to do, what you mean with revert? there should be no change here. There's an extra line. Sorry for the nitpicking but let's try to clean this PR as much as possible :) understood\\r\\n Can we also revert these changes. These change logic and have nothing to do with the binary sensor platform @joostlek I can remove it but is a debug info that reports the projector status, at pooling time. To identify if there is any issue with communication that can invalidate the Binary Sensor status (i.e. in the last firmware update it has been added a power new status, without debug it would have been impossible to detect and diagnose) You could remove this field and then the device is named as the config_entry title. So then renaming the device is even easier @joostlek ok. I have to understand how to modify a file and add the change to the pull request. I continue to end up in a mess and have to cancel :( Please order alphabetically \",\n",
       " 'Don\\'t add this as a sidebar, instead add it as a configuration panel.\\r\\n\\r\\n\\r\\nBackground in PR  Done We don\\'t need this and the issue\\r\\n Removed Let\\'s bump this, maybe to 2024.12.0?\\r\\n Changed The docstring does not seem to match the implementation? Changed Can the bump of pypck happen in a separate PR Yes, that\\'s possible. The newest changes are not necessary for this PR. This looks like a race, can\\'t we check if what we\\'re waiting for has happened instead? That\\'s indeed a relict from testing. I removed this. I guess it\\'s not necessary as it never occured during my tests. Instead of an options flow, I think this should be a reconfigure flow (add a flow starting with `async_step_reconfigure` to the config flow) Thanks for the hint. I changed it to a reconfigure_step. The integration already has tests, I think tests should be added for the websocket handlers. I added the tests. \"get hosts\" does not seem to match the implementation, the command returns a list of config entries? No, it sends a list of dictionaries with names and ids of the available hosts. I guess it\\'s correct as it is. Can\\'t you just use the existing command `config_entries/get` though? I just realized that the config_entry_id is passed from the integration-panel to the custom-panel via url-parameter. This means that I do not need the host-selector box in the first screenshot. I therefore removed the whole `websocket_get_hosts` method and handle the url-parameter in the lcn-frontend code ( Why is this changed? The CONFIG_DATA dict is used to test the reconfiguration_step. The original configuration for the config_entry is read from the fixtures. To test the reconfiguration, the CONFIG_DATA is used as modified data (port has changed). The deepcopy seems unnecessary, how about this:\\r\\n\\r\\n\\r\\nSame comment for the other places where deepcopy is used Changed and removed all deepcopies. Can we cover this case in tests too? I added a special case to the tests, so that at least the code gets covered. Why do we mock the HTTP server? When registering the new panel\\'s path, we need to call `hass.http.register_static_path` in `websockets.py`. But `hass.http` returns `None` for the mocked `hass` object. I tried out a few things but I did not find a better solution, then mocking `hass.http`. OK, please add this explanation as a comment Let this check happen in a decorator instead. The decorator will then call the decorated function passing the config entry; like this:\\r\\n\\r\\n',\n",
       " \"Maybe look into icon translations This will have to come in a separate PR I'd move these to a separate test You have a finally clause in your try except block. You could try patching it again to something different to verify you actually fetch data after an error like this. Done! \\n\",\n",
       " \"What does the `continue` do here? Can we start with calling super? Why do we copy here? Why do we modify the config entry options here when we have the config entry migration? We should just reload the config entry in this flow to have it migrate, I think. The migrations makes a copy of the sensors and add them as binary sensors so we have both.\\r\\nThe repair removes the sensor ones so we only have binary sensors left.\\r\\n\\r\\nCould make it more obvious in the repair flow by popping the sensors instead of constructing a new option dict? Ok.\\r\\n\\r\\nShould we remove the entity registry entries for the process sensors too? The corresponding entities will then be removed too. What does this test? It tests the generic `ConfirmRepairFlow()` #diff-56692cd2c2c999c37c62870717f33c9a21943867a6d0d69835c33b3efabd82d2R66 Why don't we let the integration create the issue? The integration doesn't have such issue so it can't make one. \\n\\nThat's to ensure the integration has the generic support for fixable issues in case such should be added down the line.\\nIt's added like this in all integrations adding the repair platform I believe.  Ok.\",\n",
       " 'This is protocol details that should be part of a 3rd party library.',\n",
       " 'If I assume correct, you will use this device fixture in probably more platforms. Can you maybe move this test to `test_init.py` as its not specific to binary sensors? With snapshot tests I want to recommend giving your entity and state snapshots a name. Because If you add more entities in the future, the list can get messed up (as order changes).\\r\\n\\r\\nIn this case you only have 1 entity to test, but for other platforms, please checkout tests like this:\\r\\n#L13-L29 Done it also for the binary sensor  This is an integration detail that we should not use in the tests. Try to patch the library instead to get access to the relevant resource, eg the event handling.',\n",
       " \"Do we need this ?  Since it's only used in tests, I'd say we should not add this. `async_get_floor_by_name` will already normalize the name. \\r\\n\\r\\n We normally use the opposite pattern where the device registry would be responsible for listening to `EVENT_FLOOR_REGISTRY_UPDATED` and remove the deleted floor id from devices. I think it's a good pattern because the responsibility is centralized, and I think we should do the same here as well as in the area registry. Instead of multiple separate indices, make `FloorRegistry.floors` a `UserDict`, then the additional index is the responsability of the `UserDict` instead of spread out over the `FloorRegistry`. We use that pattern in the entity and device registries, for example #L390-L396\\r\\nWe should use that pattern here and in the area registry too IMO. PR for area registry:  Make this a protected `staticmethod` of `FloorRegistry`  With the latest change, I've not moved it. I found it odd to use it in both FloorRegistry & FloorRegistryItems. Instead, I've left it where it is and marked it protected.\",\n",
       " \"Users can already rename the config entry or device. We shouldn't add name here. Use the config entry title for coordinator name if there's one coordinator per config entry. Users can disable the remote entity if they don't want it.\",\n",
       " 'Adding custom polling rates in the UI (also known as, scan interval) is no longer allowed.\\r\\n\\r\\nIf you wish to use a different interval, you can define your own, based on your own rules and schedule, using an automation that call the home assistant update entity service. This problem should not be solve by manual control.\\r\\n\\r\\nInstead, the integration should take into account the number of entries when polling automatically.',\n",
       " \"It's the default icon, so no translation is provided. It's the default icon, so no translation is provided. This should be the default temperature icon, will change that in a follow-up PR. \\r\\nWe can remove this in this PR Thanks\",\n",
       " \"We typically try to avoid multiline ternary lambdas, as they're hard to read. Can we move this into a small function? Done. \\r\\nPlease avoid multiline ternary operators That breaks the code coverage, I'm going to add tests and possibly a fixture just to meet this code formatting requirement. ðŸ˜¬ Yea, otherwise we shifting the multiline ternary into a function instead of a lambda ðŸ˜„ \",\n",
       " 'Add this in a separate PR. Not related Sensor entities should be in a sensor platform file `sensor.py` \\r\\nMight be best to add the sensor in different PR and remove it from this one Should also include `Platform.SENSOR` and separate sensor entities to the sensor platform Sensor should be in sensor platform. Something flaky goes on when setting up and paring the device the first time.\\r\\n1)  I paired and the setup \"hung\" at the pairing state.\\r\\n2) Reloaded the integration and it found entities but they were unavailable.\\r\\n3) Reloaded again and the entities became available.\\r\\n\\r\\nOn a second try with the esphome ble gateway already \"paired\" I still needed to do a reload to get the entities to become available when adding the integration. Can you provide logs?\\r\\n\\r\\nI found pairing the official application unreliable for the first pair as well I don\\'t think we want to \"fail\" the integration here.  We have already \"validated\" the connectivity in the config flow.  At this point, it\\'s just not in range and should continue to try.  Simply `raise  ConfigEntryNotReady()` to let HA retry automatically. We should `try:` to connect to the mower and catch `except: bleak.exc.BleakError)` : Error ESP_GATT_CONN_FAIL_ESTABLISH while connecting: Connection failed to establish.  \\r\\n `try:` around this section as well Bleak and/or aioesphomeapi.core.TimeoutAPIError should be caught here. Stale doc string? Should name this something like `HusqvarnaCoordinator` to help prevent confusion with the normal `coordinator` - like other integrations do. Based on other examples, this is usually = DOMAIN (not sure if it really matters) Each entity should have it\\'s own DeviceInfo to put in the device registry.  I think it needs to move the the entity setup for each. I dislike the use of snapshots here as you \"hide\" what you are actually testing \\r\\nPersonal ick Please don\\'t log on info level Why are you passing in a logger if you made one on line 24?\\r\\n\\r\\nIf you like, you can also create an integration level logger with `LOGGER = logging.getLogger(__package__)` in `const.py` Please move this to `entity.py` Why the context? I agree with @mkmer that it would be nice to create the DeviceInfo here instead We usually also incorporate the super().available in coordinator entities Why is this a parameter if it\\'s static? Why don\\'t we just pass in what we need and let the entity decide The lawn mower is the main feature of the device, so the name of the lawn mower should be set to `_attr_name = None`. This way, the name of this entity is decided by the name of the device, which is consistent Also, for unique_id, address should be purely unique I assume? Reminder that unique_id is unique per platform per integration, so there\\'s no need to prepend it with automower (if that\\'s what you were trying to avoid) can be combined This call appears to return a `bool`\\r\\n\\r\\n\\r\\n#L459',\n",
       " 'Can the services be [entity services](#entity-services) on the main entity instead?\\r\\n\\r\\nIF yes there is no need for `__get_coordinator`? ~~yes makes absolutely sense to add to calendar, but somehow I can call them in tests, but no code is executed, any idea? Also~~ Done, but should I add it to the calendar platform PR, or keep it as separate PR? Please use a [time selector](#time-selector) instead Does this service not the same as the calendar entity in  calendar platform is for display only, this is for setting only. As the app sets one schedule for mon-sun which applies to every week, editing one calendar entry, which then would edit all entries would be weird. Why do we need two services for one use case? because that is how it is in the app. You can enable/disable the schedule for a specific day, but independently set the schedule for each day. If I have it in one service you would always need to set the schedule if you want to en-/disable one day. and because I find it weird if you had a either put enabled, or all the other attributes, which then would be custom validation logic (afaik) which I find annoying from a UX perspective. I added the option to disable optionally to the schedule call, so you only need to make one call in that case.',\n",
       " 'Showing a serial number here is a bit too detailed. The most user friendly thing would be to show the name of the entity / device here? Lets extract a `now` variable at the top of this function and use in the 4 calls. The logic for this function i think should be to return the active or next upcoming event. Is this currently skipping an event if it already started and already ended? It seems sufficient to just skip if it ended, but allow it to be a return value even if it already started and is still active, which represents an `on` state. that\\'s excactly what I was already doing, I removed the unnecessary `and` from the `if` I think it may be possible for this to skip events in the range.\\r\\n\\r\\nSay you have a schedule of: \"Every Sunday between 07:00 - 07:30 (only)\" then this function is called with:\\r\\n- start: 2024-02-11 09:00\\r\\n- end: 2024-02-18 08:00\\r\\n\\r\\nThen I *think* it may not return the event on 2024-02-18 07:00 but it might return the event on 2024-02-11 07:00 ? I think this happens because it gets the days involved before checking the schedule.\\r\\n\\r\\nI imagine this doesn\\'t have a big impact in practice for the calendar UI based on how this is called, but i could see this being a problem for triggers where this gets called with a small window and if its not correct then nothing will get triggered and its hard to debug. \\r\\n\\r\\n(For what it\\'s worth, I have a very over designed solution to this problem for [rainbird sprinkler](#L79) using the same underlying libraries used by local calendar to generate a timeline based on a schedule and recurrence rules. You don\\'t need to use this or anything, but i was just sharing since i ran into a similar problem there ) The only thing that could\\'ve happened, is that we missed any events on the same weekday in the following week that were already ended at the current time. E.g. it is Sunday 08:01 and the next event is next Sunday 07:30 - 8:00 we would\\'ve missed that. I added an extra day to the date range, that should fix that problem. If the event is only at 08:30 we would get it twice, but since we only take the next occurence here, that\\'s no problem. The other thing to be careful of is returning an event before the range though too and omit those.\\n\\nThis may not cause a major problem for this integration since it\\'s once per day, but in general it will also screw up triggers since it assumes it can correctly iterate  through events by scanning the time range and see them only when they are supposed to be seen -- and I don\\'t want to have that pattern copied into other calendars. Not sure I understand what you mean. I\\'m already filtering out any events that are on the current day but have already ended.  Such an example is already part of the tests (Friday iirc) I am referring to the example in my comment. The start datetime is on a day present in the schedule and an event is returned outside of the range. My impression is the steps are this:\\r\\n- Call `async_get_events(2024-02-11 09:00, 2024-02-18 08:00)`\\r\\n- Call `_get_date_range(2024-02-11 09:00, 2024-02-18 08:00)`\\r\\n- _get_date_range yields `2024-02-11 09:00`\\r\\n- Call `_async_get_calendar_event(2024-02-11 09:00`\\r\\n- date.weekday is sunday\\r\\n- returns `CalendarEvent(start=2024-02-11 07:00, end=2024-02-11 07:30`\\r\\n\\r\\nMaybe this is prevented and i\\'m missing it. (My impression was that before your change that sunday event was returned outside the range. Now after your change, it returns a sunday event outside of the range and a sunday event within the range.) ah, I thought you were talking about the `property` and not `async_get_events`. Indeed that was possible (and actually I had exactly such a case in my snapshot test) for the function, but not the property. Moved the logic to a separate function, so it\\'s now handled and consistent. Yes i\\'m talking about `async_get_events` which has a start and end range and is what is called by the trigger.\\r\\n\\r\\nI still think there are some cases missed by the current logic.  Given a schedule of \"Every Sunday between 07:00 - 07:30\", I don\\'t think all of these cases are handled correctly:\\r\\n- start: 2024-02-11 06:00, end: 2024-02-18 06:00 => Includes 2024-02-12 07:00 only\\r\\n- start: 2024-02-11 07:15, end: 2024-02-18 06:00 => Includes 2024-02-12 07:00 only\\r\\n- start: 2024-02-11 09:00, end: 2024-02-18 07:15 => Includes 2024-02-18 07:00 only\\r\\n- start: 2024-02-11 09:00, end: 2024-02-18 08:00 => Includes 2024-02-18 07:00 only\\r\\n- start: 2024-02-11 09:00, end: 2024-02-18 06:00 => Includes none\\r\\n- start: 2024-02-11 06:00, end: 2024-02-18 08:00 => Includes both\\r\\n\\r\\nI think the current logic will still include events outside the range when the end date is a day that has an event scheduled, but the calendar event is outside the range. I think its because `_get_events` needs another check like the start date check but inverted for the end date check.\\r\\n\\r\\nA parameterized test case can be a straight forward way to exercise all of these cases with a single test I have to say, I\\'m impressed that you caught those without running the code! Indeed, there were a few of those which were wrong. I fixed them and added a test case as suggested. And thanks for the detailed explanation! Consider one-linter:\\r\\n I\\'ll add it, although I\\'m not sure I like it more in termsof readability...',\n",
       " \"I don't think we should add `CONF_ALLOW` at global `homeassistant.const` as it's only used here.\\r\\n\\r\\nAdd `CONF_ALLOW` locally, as `CONF_TITLE` do. Done, thanks! \\r\\n\\r\\nYou can even do this. Integration tests need to be updated @Quentame Had a stab at a test in  Hope this works?!\",\n",
       " \"Can be a shorthand Can use device class translations. So if there is no name or translation key set it will use the name of the device class\\r\\n _Could_ this use device class translations? So wait, the `dev` is now for example `v40_level_max`. And we loop over every entity description to find the right description with the key? Why don't you make the sensor_types a `dict[str, OSOEnergySensorEntityDescription]`? And have the value of the dict be the key as well and then just lookup? Is this cached in some kind of way or are we requesting data 10 times when initializing? The device/sensor data is cached. A configured ammount of time must pass before the update_data() mekas a request to the server to update the data. If that time has not passed the cached data will be returned here. Please remove the fallback and add an `options` field to show the possible solutions. idem Entities should not have the unit in the name (and preferably not the (translation) key either) Why does one have the circle and the other unicode? What's a FFR? FFR is a special mode that responds to measurements of the frequency of the electrical grid and certain points of time. It turns off the heating elements of the water heater when the measured frequency drops below a treshold for a small amount of time to reduce the load on the grid and prevent accidents/breakdowns on the electrical grid itself. I will add the full name to the translations - Fast Frequency Reserve Please also use sentence case \\r\\n\\r\\n(personal preference, rename osoenergy_device to device, looks better ;) ) Please bump in a separate PR For a followup PR, would be nice if this class could move to `entity.py` I will do the change in the next PR. Let's name this `value_fn` since it's a function\\r\\n Please better explain in the docstrings what these functions do and complete the type annotations;`_get_local_hour` is missing return value type, `_convert_profile_to_local` is missing both return value type and parameter type. Please share a screenshot + explanation of this sensor I don't think `device` is a great name here, all the sensors provide different measurements from the same boiler, right?\\r\\nI'd suggest to call it `sensor_data` or `sensor_state` or something like that. If you want to use the same name also in the water heater entity, maybe name it `endpoint_data` or `endpoint_state`. There's no need to set this to `None` since it's unconditionally set by `OSOEnergy.__init__`. Again, try to come up with a better name than `device`. With the addition of the sensor entity, `device` is no longer a good name, see the comments on `sensor.py`. Why are these removed?\",\n",
       " 'Please don\\'t make a breaking change instead:\\r\\n- disable the old entity by default\\r\\n- start deprecation period \\r\\n- create repair issue when the old entity is used in automations and scripts\\r\\n\\r\\nAfter the deprecation period, please remove in a follow-up the sensor\\r\\n Breaking change removed, just need to figure out how to work in the disabled by default to `BinarySensorEntityDescription` Ah yes, `entity_registry_enabled_default`. I think I might not remove it, but just leave it disabled. As Joostlek points out it may still be useful for automation. From the `strings.json` it looks like you know all possible values of this sensor.\\r\\nCan we set the device class to `SensorDeviceClass.ENUM` and specify the options? Oh yes, forgot about Enum types. I\\'ll do that. Done. Why is the instance check and lowering needed? Translation keys can only be lowercase.\\n\\nYou can\\'t run .lower() on a Sensor Value which can be an int. (Even though it never will be anything but one of the Enum values in this integration) > Translation keys can only be lowercase.\\r\\n> \\r\\n> You can\\'t run .lower() on a Sensor Value which can be an int. (Even though it never will be anything but one of the Enum values in this integration)\\r\\n\\r\\nWhen an int value is returned as value, it will raise an error as one of the options is expected.\\r\\nI would suggest refactoring the code so that we can avoid the instance check and only return string values. Ok it looks like translation keys are case insensitive, so I can remove the value_fn all together. Please use `@pytest.mark.usefixtures(\"entity_registry_enabled_by_default\") so you can also test disabled entities. Please revert it The options here do not match the keys defined in `strings.json`.\\r\\n\\r\\nPlease ensure that both are the same. Translation keys are case insensitive and must be lower case, the options list is case sensitive, so these do match. Discussed this point internally and we came the the conclusion, that state strings should always be lowercase snake_case. Snake case? does that mean I have to build a translation later from API strings to snake_case strings, making them lower case isnt enough? Ive added a dictionary to convert from the API TitleCase to this new requirement for snake_case Why are the device tracker snapshots changed? I know why, there was a bug which was fixed since this PR was raised. I\\'ll get this removed. This has been removed now.',\n",
       " \"Commenting so it is not accidently merged, as we discussed without changes `entity_category` doesn't work in this implementation. Changed PR to introduce script switch only. Rework will be done in a separate PR Entity category is working... why shouldn't we use the `diagnostic` category?\\r\\n\\r\\n![obraz](\\r\\n\\r\\n \\r\\nThis is the main device Switch output and not a config entity Changed PR to introduce script switch only. Rework will be done in a separate PR Fixed API changed over time, fixed. If I remember correctly we agreed that these entities should be disabled by default.\\r\\n If the user removes the script, the entity for it will remain in the registry. I suggest removing orphaned entities:\\r\\n\\r\\n Good point, added After some rethinking, I suggest these entities use the `config` category. Changing the script state is part of the device configuration.\\r\\n Back to the original code then\",\n",
       " \"Please remove these filters since the backing API does not support it. Good idea. Does not make sense if this service should return all possible routes Since the options are translated, it's probably not correct to sort the options here.\\r\\nInstead, set the `SelectSelectorConfig.sort` flag to True which makes frontend sort based on the translated options. Same comment for the other selectors. I think it would be more logical if this logic is moved to `async_get_travel_times` These should be removed, right? These too should be removed?\",\n",
       " \"Should we translate them?\\r\\nCurrently, we have eu,na,as,ww\\r\\nBut I don't know if there is one missing and Ecovacs is not sharing any information, therefore custom values are enabled We don't really do this anywhere else That's not true. `abode` and `adguard` is doing it to mention the first two Can't you use config validators for this? (I mean I saw you are implementing a nicer error message for those) The error messages from `voluptuous` are not translatable and only available in English.\\r\\n@MartinHjelmare What's your opinion on it? Should I use the `vol.Length` validator or leave the custom check above? Doesn't  provide something for this? Removed continent completely Why do we allow custom values. I don't expect a new continent to arise in the nearby future.\\r\\n\\r\\n(Or if you are going to create your own, let me know, I'm interested) The problem is that I have no way to identify all continents used by ecovacs as they use `CNAME` DNS entries, which can not queried to identify it.\\r\\n\\r\\nPreviously, this field was a normal string to which users could add different continents as the above ones.\\r\\nWe could also allow only the above ones, and if another continent is used, ask the user to create an issue.\\r\\n\\r\\n Removed continent completely Depends on the outcome below. If we leave the class variable support it must stay at it is Why do we actually do it this way? Some entities (which will be added in a follow-up) will pass the entity description as an init argument. Some other entities, like the vacuum, have set it as a class variable as it will not be dynamic.\\r\\n\\r\\nI can change if you want to pass it always as init argument Should we set `_attr_available = True` when this happens? Not required as that is the default value ah, this explains something Shouldn't these be HomeAssistantErrors? Removing the continent requires no migration, as no stable release included the config flow of ecovacs This makes the argument hard to read.\\r\\n\\r\\nCan we use keyword arguments here? Why do we check the continent above if we pop it here before passing the user input to the user step?  The yaml config has no constraints on the country and continent. After a quick analysis of the old library, it looked like there are the same requirements (alpha 2 code for country and a 2-letter country code), but ecovacs is not sharing any information and changed the API frequently in the past.\\r\\nThe new library included a reversed-engineered map from country to continent (for example there exists no continent Africa in ecovacs and countries in Africa need to use the worldwide). As these reversed-engineered map can contain errors I will check above if the country is the same as specified in yaml.\\r\\nIf yes we can omit it as it is not used anymore.\\r\\n\\r\\nAre you fine with it or should I change something?\\r\\n\\r\\n Why do we need these as properties instead of regular attributes? I copied the code from my custom component and as I'm coming from Java I'm used to creating getters. Will remove it I'd check if there's a flow started for the domain instead and what source it has.\",\n",
       " \"please move it to a separate `services.py` I'm afraid I am not as knowledgeable about the inner workings of HA as you are. Are you able to help out? > I'm afraid I am not as knowledgeable about the inner workings of HA as you are. Are you able to help out?\\r\\n\\r\\nYou can use the [Fastdotcom service](#L32) as an example (you can skip the coordinator part). Basically the idea is that service logic is separated from the rest, including registering.\\r\\nThe TadoConnector, per entry, is stored in `hass.data[DOMAIN][entry.entry_id][DATA]`. Just make sure to pass it through correctly to `services.py`. nothing special HA here, I just think it'll be easier to read and more future proof, if we move that function to a separate file (called `services.py`) and add a separate `async_setup_services` method. Look [here](#L17-L19) for an example > The TadoConnector, per entry, is stored in `hass.data[DOMAIN][entry.entry_id][DATA]`.\\r\\n\\r\\nJust to verify my understanding; the `entry.entry_id` is a reference to the Tado instance that was added to the config. There will in most cases be only one but can be many.\\r\\n\\r\\nHow do I make sure that the service call is performed only on the Tado instance (`entry.entry_id`) that it is meant for? by making the `config_entry` another input parameter to the service. `easyenergy` also does this. Thanks! I'll have a look at `easyenergy` > Just to verify my understanding; the `entry.entry_id` is a reference to the Tado instance that was added to the config. There will in most cases be only one but can be many.\\r\\n> \\r\\n> How do I make sure that the service call is performed only on the Tado instance (`entry.entry_id`) that it is meant for?\\r\\n\\r\\nThat's correct. We need to be specific on the entry, whereas we can't have it if people have multiple Tado accounts linked, all meter readings will be send to one instance. Take [a look here](#L92), on how to pass through the entry_id per instance. > please move it to a separate `services.py`\\r\\n\\r\\nPlease resolve conversation at your discretion. just resolve everything you consider done ðŸ™‚ I wanted to leave that to you so that you would have the opportunity to validate that it was indeed resolved. it is no longer allowed to register services in `async_setup_entry`, but only in `async_setup` This init file does not (yet) include an `async_setup` method. Can this be resovled with a simple cut and paste, leaving the rest of the `async_setup_entry` as it was? no, I'm afraid it's not gonna be that easy... You should leave the rest of the initialization where it is, but only move the service init to `async_setup`. The problem which you are gonna face is, that the `entry` is not available in there, so it's gonna be a bit more work to get the `entry.data` to init the `tadoconnector`. I'd suggest you take a look at the `lametric` or `easyenergy` components to see how they handle this. > it is no longer allowed to register services in `async_setup_entry`, but only in `async_setup`\\r\\n\\r\\nPlease resolve conversation at your discretion. You're not asserting anything here. Meaning, effectively nothing is being tested the add_meter_readings returned the right successful response. In the success response, nothing is raised or returned. Do I just add `assert True` as the last line of the test? added `assert response is None` to testcase Check if the error handling is done in the proper way, By indeed checking if the `ServiceValidationError` is successfully raised. I don't know for certain what response is passed through by PyTado, but if it contains content, assert this content in the test. assertion added Same here. Nothing is effectively tested: add the proper asserts. :) assertion added Assertions are needed as well. assertion added this is obsolete now, right? if this is not regarding validation error, but a general problem with the API call we should raise `HomeAssistantError`  instead I'm thinking of raising the `HomeAssistantError` in the  `set_meter_reading` instead of logging the error, intercepting it there rather then in the service call. That would make the `None` response handling obsolete. What do you think? can you reset your meter by sending a 0? then that'd be a bad idea in my opinion.\",\n",
       " \"Add some test cases for the negative checks. Added a test case I could think of.\\r\\n\\r\\nAlso, I noticed `datetime.date.today()` does not work in restricted scripts because `__import__` is not available (coincidentally I'd debugged that here:  Is that an issue that should be triaged? ðŸ¤”  I don't know if anyone is really using this integration. I think most people will use the `pyscript` custom component which is far more powerful. Well, this PR came about by someone on a Slack wondering why `+=` didn't work, so yeah, someone is using it! I don't think this requires a test since I (think I) mapped all of the operators; it's just here to avoid an ugly, confusing KeyError (and `.get` + `if not` is faster than `try: except KeyError: raise`).\",\n",
       " \"Let's pull this out for now. Once we merge everything this can be a future improvement We should log an error and return `False` here since the Home Assistant code will not know what to do with this exception.\\r\\n\\r\\nIdeally we can remove this and never get here because the config flow should refuse to create the entry if its not the primary hub. that makes sense - should i remove this completely and move the check to the ``validate_input`` in the ``config_flow.py`` now? exactly ðŸ‘  Let's remove the number platform from this PR. I'd like to merge this version back into `dev` before adding new platforms i thought the whole point of the 'powerview_3_integration' was to get all features added then merge the feature branch into dev ?\\r\\n\\r\\nWhy would i not just target the dev branch for these PR's otherwiese ?\\r\\n With the turns and merge issues, I think we may have lost sight of their original goal (or I did a poor job explaining it in the first place) \\n\\nI was working under the premise that the goal was merge in small digestible pieces into this branch (since the original PR was too large to properly review), test everything on the old models, and then start adding the v3 new platforms after it's merged to dev. If it would help to do a call to align on this, feel free to reach out on discord I think the only disconnect here was that the initial PR had to be large, because of the degree of change in the upstream API.\\r\\n\\r\\nThen i went and made a royal mess of the git history.\\r\\nIf you take a look at the individual commits I made you will see there wasnt much changed here.\\r\\n\\r\\nThe last PR was to bring the base functionality, this ones focus was to bring the number platform and should have only changed 3 files. But we also fixed the scene tests here\\r\\n\\r\\nI'll strip the number platform shortly, and then once merged to dev i will resubmit the PR etc It would be better to make a new named except like `CannotConnect` and let it be trapped below so we can give them a better error in the UI. Right now they would get a cannot connect error have added ``UnsupportedDevice`` to the code I think we want to trap this in `_async_validate_or_error` instead and change the error string returned so we can add it to `strings.json`\\r\\n Please move this block outside of the context manager since it is not expected to timeout it would be cleaner to do this check out side the `try:` block since we don't expect it to ever raise HUB_EXCEPTIONS \\r\\n\\r\\nPlease reverse conditionals and continue to avoid long indents We want to keep the continue pattern where possible to avoid creating long indent trees > Please reverse conditionals and continue to avoid long indents\\r\\n\\r\\nthis is effectively added back in by this change #r1476621073\\r\\n\\r\\n``shade.has_battery_info()`` replaces this statement and returns the required based on the hub version If we ever have more it would be better to write these as constant dict lookups to reduce time complexity\\r\\n\\r\\n\\r\\n\\r\\nfixture = DEVICE_JSON_FIXTURE[api_version] We want to avoid branching inside tests as it makes them harder to maintain and troubleshoot.\\r\\n\\r\\nPlease use pytest skipif or split the test into two tests > \\r\\n Please break long comments around max 88 characters per line.\",\n",
       " 'A much better option is to have CONF_ADDRESS be either an int or an array, no need for an extra parameter.\\r\\n\\r\\nPlease remember this needs to be copied for FAN_MODE. Hi @janiversen thanks for the review. With regards to the suggestion, I followed the same approach already implemented for the other parameters, in example [HVAC Mode](#write_registers), target temp and [hvac on off](#write_registers) In those cases, the address is an integer and using that option the user can force the system to use te modbus function write multiple registers (0x10) instead of the single (0x06). So I considered this approach as the \"suggested one\". Why  we should change it only for fan mode?  Because it simplifies the code, and that is the direction we are moving towards....of course not all of the old code is changed at this point in time. And if you look at e.g. the service set point, it does exactly that, can be called with an int or an array. I understand. \\r\\nBefore to apply the change, please, consider that in the future you can remove all the options \"write_registers\" for all except the target temperature, where the list will have a different sense.. (if you approve my PR, of course). This mean that to keep the \"write_registers\" option for all, will keep all the configuration coherent, else, you\\'ll have different meanings of the lists used in the configuration. \\r\\nLet me know\\r\\n \"Coherent\" is not an objective in itself, especially not if it implies expanding the code.\\r\\n\\r\\nPlease do not forget, your change is currently not working if you want to use modes....you need to do exact the same for each mode...and that explodes the code.  Basically all these \"mode\" parts (in different parts of climate) it something that needs to change to one uniform way of doing it, without X extra parameters.\\r\\n\\r\\nThe change could very well be (for all):\\r\\n\\r\\n- allow int or list in base address.\\r\\n- if list contains 1 element, it will use write_registers\\r\\n- if list contains the exact number of variants (in this case modes) use the correct int as address\\r\\n- if the entry in list is a list with 1 entry use write_registers.\\r\\n\\r\\nThis is not at all user friendly, but as noted earlier yaml is not user friendly....important here is that it is something that can be converted to a config_flow, which will be a lot more user friendly.\\r\\n > * if list contains the exact number of variants (in this case modes) use the correct int as address\\r\\n> \\r\\n> * if the entry in list is a list with 1 entry use write_registers.\\r\\n\\r\\nI really appreciate the condivision of your vision and I imagine that this proposal will make really complex the code. I know that my opinion is not important, but I miss something. Why do you want to move the code there? \\r\\nI mean, if we consider the Fan Mode example, the only need is to have the CONF_ADDRESS managed as int or list of one single int, because do you imagine that also the values will be expressed as list? What is the real use case that I miss?\\r\\n my bad, I took took the modes as separate registers, as you did earlier for target_temperature. Ok. So, should I replace actual implementation by managing int/list (only 1 element) for CONF_ADDRESS?  I was just applying the change when I thought that before to do it, probably I need to more information of the future because here we have mixed CONF_ADDRESS and modes.. \\r\\nActually the component uses only an int (CONF_ADDRESS) for the register, but we could have a list for the values. This because the pb_call accepts a list only for the value. \\r\\nGenerally speaking, the real use cases could include also the the need to write real multiple registers ans so you could have the need to manage a list also as registers. This could increase the complexity of the code, of course, because the options to manage increases. \\r\\n@janiversen, considering the actual code, probably to enable the write_registers support I should keep the CONF_ADDRESS as an int and manage int or list for each of the modes. \\r\\nIf you agree, I change the code in this way, instead of CONF_ADDRESS else please advise me \\r\\n the better option is to have CONF_ADDRESS as an int (write_register) or as a list of one (write_registers). That is the upcoming change for all write_registers You cannot just overwrite old tests, please leave them and make new tests. Duplicate code.',\n",
       " \"I'd put the default here instead so you can take it out below\\r\\n\\r\\n `async_services()` enumerates and makes a copy of all the services it would be would be better to do an `any` expression with `has_service` or check each one in a loop and remove Taking this a step further, would it be preferable to not even register services that aren't applicable to the hardware configuration? ie. If a salt chlorine generator is not configured, don't register the super chlorination services.\\n\\nThe pool controller does nothing with a command that isn't applicable so as it stands now, all services are registered regardless. But if we're looping through and running checks for each service, I could expand that pattern to registration as well. If we don't have any pools that support the service, its better not to register it I also have  in flight to reduce the overhead for fetching services by domain `hass.services.async_services_for_domain` is now available \\r\\n Integration services should nowadays be registered in `async_setup` regardless of config entry state.\\r\\n\\r\\nSee example in fully_kiosk integration.\\r\\n\\r\\nSee this conversation for the reason:\\r\\n#discussion_r1433754113 We shouldn't remove services when unloading the integration. The services don't seem to be device specific but config entry specific. Use the config entry selector instead.\",\n",
       " \"Please remove this Please remove empty entries Do we need to go down to microseconds ? I think so, it's good practice to not align on the second boundary to avoid stampedes.\\r\\n\\r\\n#L100-L104\",\n",
       " \"Use dict unpacking syntax\\r\\n Can we make a parameterized test out of it as this test tests the three different message formats ðŸ‘Œ  Yes, I can refactor those tests. :heavy_check_mark: done \\n Couldn't this be added as another parameterized option for `test_send_message`? Unfortunately I haven't find a way to check it using `matrix_bot._handle_multi_room_send.assert_called_once_with(...)` because the function call content (example: `tmpeno21kcu`) is a random-generated string:\\r\\n \\r\\n\\r\\nNo need to prefix them with test\\r\\n\\r\\nPlease adopt the values âœ… Done Can we add type hints for it?\\r\\nAre all arguments required? :heavy_check_mark:  add type hints\\r\\n:heavy_check_mark:  remove unused arguments Is test_name only used for naming the test? At least it looks like it...\\r\\nPlease use the parameter `ids` on `@pytest.mark.parametrize(` instead Yes. I used the `test_name` var only to see in the output which test is running.\\r\\nI can rename it to `ids` instead, if no better way to do it. âœ…  done \\r\\n\\r\\nI meant the following in #discussion_r1469629632 List of? Same question here Does each test need these lines? If yes, can we make a fixture or common function for it? We should check here also if the matrix_bot was called correctly Why can't this test be part of the above one?\",\n",
       " 'Why do we expect a non parseable response is an error?  What else should it be if I cannot parse the response json from the api/server? I mean, Imagine the service returning a 503 because someone messed up a server config. This would be something that could be fixed in an hour, thus I think retrying is something we should do. Ok, I can change it so the `JSONParse` errors are rather retried instead of aborted. So we are returning a list of lists? Yes, you can have multiple shopping lists (first list) with a list of items (second list). \\n Please remove the empty fields  ok We don\\'t want to switch contexts a lot, can we maybe make an inline function we run in the executor? You mean group both together? Yes:\\r\\n Why don\\'t we just pass in the list? Because I thought it might be good to know where the list comes from. But on the other hand, the user can do that himself if he needs it. No I mean, can\\'t we pass in the list to the entity instead of iterating over all lists in the entity and setting values outside of the object itself Ahh, I get it. Yes we should be able to do so.  Can be removed, is the default for a coordinator entity Can be set outside of the constructor true On naming. I think you can add some devices (with type service). Maybe checkout Our groceries to check how they did it and if you like that approach (not sure what your future plans are). This way you can just set the attr name to the list name. Not sure what you mean by \"add some devices\". I don\\'t see any devices in `ourgroceries`? Why do we do this? To get the correct shopping list from the coordinator, which loads the data for all bring lists at once. Since this function is this little, have you considered just using a property? It saves you the async_added_to_hass and _handle_coordinator_update. Can\\'t you maybe ask the coÃ¶rdinator to refresh instead? You mean `await self.coordinator.async_update_ha_state(force_refresh=True)`? no `await self.coordinator.async_refresh()` or something like that Ok I will see if possible',\n",
       " 'I think we should make our translation placeholder descriptive for the translator. Our translators don\\'t have to be developers (or very technical) to translate.\\r\\n\\r\\n`\"Disk free {argument}\"` -> I am guessing the location should be here, but I only know this since I saw the issues and the entities system monitor creates\\r\\n`\"IPv4 address {argument}\"` -> is argument an IP address? An internet adapter? That\\'s a bit the point. It\\'s different for different sensors so how would one make it more descriptive? Name it `{device}` ? Or `{interface}`? I constructed a solution so it puts a relevant placeholder \\r\\nWDYT?',\n",
       " 'If a state is unknown, we need to return `None`.',\n",
       " '\\r\\n\\r\\nRationale would be that you can start a single hose timer as well, and not only multiple at once. ðŸ‘ good point, will update.  This was needed to fix mypy complaints you can use \\r\\n\\r\\n\\r\\n\\r\\nBut there is usually a better resolution to refactor Do you think this still need to be changed to something else? #generic-properties\\r\\n\\r\\nWe generally don\\'t add new extra state attributes anymore and create them as separate sensors on the same device\\r\\n\\r\\n> Entities that generate a significant amount of state changes can quickly increase the size of the database when the extra_state_attributes also change frequently. Minimize the number of extra_state_attributes for these entities by removing non-critical attributes or creating additional sensor entities. Before you get too carried away I totally screwed up my commit history and I need to push another one to get back to where it was. Ok, so all of these should go? I\\'d drop them from this PR and add them as separate sensors in a followup PR if they are needed Since this has to do polling it would be better to use the `DataUpdateCoordinator` here \\r\\n\\r\\n#coordinated-single-api-poll-for-data-for-all-entities Yep that was in the latest version that I just broke, stand by This looks like something needs to be refactored if we need an ignore here Probably faster to len each and add that together (or itertools chain) Maybe start enough, It\\'s also possible they might want to target three different hose timers I wonder if we don\\'t need this if they\\'re implemented as valve entities  As opposed to switch entities?\\r\\n\\r\\nI was trying to come up with a name to differentiate from the start multiple zone service, but single isn\\'t exactly right either. Maybe just \"start watering\" since it can be used for timers and zones? We already have stop, pause and resume watering, and the start multiple zones schedule service is fairly self explanatory from the title.  \\r\\n\\r\\nIt also can start schedules if we make the duration optional, which would probably be a good idea, then it works on all the switch types. Sounds good to me  Missed this, its not needed, will remove in next commit. Line 568 that is It would be nice if data was a named tuple in the lib as it would be backward compat and we wouldn\\'t have the [1] everywhere  Iâ€™ll have a look a that, but I think this is the only place itâ€™s being used.  Let me know if thatâ€™s not what you had in mind.  sorry I wasn\\'t clear. I was thinking the change should be in library code as we could make all the `[1]` a lot easier to understand whats going on \\r\\n\\r\\n Ah I see. Is that something we could look into in a future PR?  \\r\\nbut it would be good to add typing on the Callable as well This could be `base_stations.extend` with a generator expression',\n",
       " \"The coordinator will have a `ConfigEntry` in `self.config_entry` as soon as you call `super.init()` so no need to pass it can we move that call inside the coordinator? `CONF_MAC` can be taken from homeassistant.const move up to get the `self.config_entry` metioned earlier can't we just add a custom key `sensor_type` here and avoid all the special arrays and `elif:`s? (You will need to add `kw_only=True` to the `@dataclass`) use snapshot testing here to be able to test all your sensors and loop over an array of all sensors (I called it `SENSORS` in the below example) \\r\\n Why do we need this #unacceptable-sources-for-a-unique-id Remove commented out code Timeout is something that should be part of the library preferably Last time you said you were looking into making different devices for each meter, what's up with that I added a 'sensor_type' parameter to distinguish the different types of devices, and now the different types of data in the panel are displayed in their respective forms. Can we split them on a physical device instead of type? I hope to be able to split by type, because I found in the local test that after adding new devices, the data of the sensor is classified and displayed on the homepage, and the default display effect looks very good. No. You told me that every channel is their own measuring point and its own physical device. Thus one channel is one device in HA. This also allows the user to rename the device to maybe where they placed the sensor to give it more context. Can I change it this way?\\r\\nThe identifiers are bound to the key of the sensor, which is different for each sensor, so that each entity will be a device. No. This is how our devices work as you can read in our dev docs. This will make this PR way smaller, consistent with the rest of the integrations and easier to manage Can you give me some hints on how to implement this in the code? If i understand correctly you have the main device, and sub devices. Give them all a different identifier and for the sub devices make sure you add the `via_device` and set it to the main device. I think checking the Dev docs on this is the best way. And if you have trouble, let me know and I can think of an example integration for your problem, can't think of any now  Please use `CONF_HOST` (from homeassistant.const) where have the channels gone? Can you move these checks to the library?\",\n",
       " 'Looks like `travel_count` needs a translation?',\n",
       " \"Small suggestion, but if you restructure the if/else logic a big then you don't have to check current_temperature is not None and them in the elif current_temperature is None. Thanks @dcmeglio for the suggestion. I've reordered the logic to clean it up.\",\n",
       " 'So what I was wondering, I think we can make these snake_case and provide translations for them Where can I find examples of options translations? #L319-L333 in combination with #L319-L333 > #L319-L333 in combination with #L319-L333\\r\\n\\r\\nthanks, i got it I think we can be more descriptive in the description. \"Repeat times\" -> \"The amount of times the text will be repeated.\" Can home_store be None? Can we also make these ones more descriptive? Good that you added this, I thought it was about the tone of voice :) We want integration services to be registered in `async_setup` instead. Otherwise the service can be missing if the config entry isn\\'t loaded, without a good explanation to the user. We want to raise an exception with a good message instead, if that\\'s the case, from the service call.\\r\\n\\r\\nExample:\\r\\n#L74-L79 We can get the config entry id from the device entry. We don\\'t need model and manufacturer filters if we set integration filter. model can filter out most devices as this service only works with SpeakerHub devices Ok. Just remove manufacturer then. This blank line makes it confusing to read the service fields.',\n",
       " 'Please add the battery sensor in a second PR after doing a PR to bump the library',\n",
       " \"please put the coordinator to a separate file what do you use that for? please do a ` await bzucoordinator.async_config_entry_first_refresh()` before assigning it to hass.data. this way we always have working components stored. only have code in the try: that can throw exceptions use `BinarySensorEntityDescription` instead. don't do IO in properties, the coordiantor should have updated this already what are you trying to achieve here? >what are you trying to achieve here?\\r\\n\\r\\ni though of it as a way to configure the integration using menus instead of forms, the async_step_optionN handles the selection, is there a more efficient way of doing it? heres how it is running right now\\r\\n\\r\\n![image]( Can you maybe give some more context on what this code is doing and what kind of purpose it serves? What kind of devices are you connecting with this integration? > Can you maybe give some more context on what this code is doing and what kind of purpose it serves? What kind of devices are you connecting with this integration?\\r\\n\\r\\nto get data from the API and register a new entity on HA the integration needs 4 informations, login data, Device Chip Id, Device port and Sensor on that port, so the config flow follow the steps: Ask for Login data, authenticate it through the API, gets device/chipids associated with that login data, show them in menu form for the user to select, stores the selected option in a configflow variable by clicking on one of the optionN menuoption, lists the available ports in that device (usually 4) and stores the selected port, then gets from the API the sensors on that DeviceChipid and that Port, lists them and stores it the same way as the Device and Port. Why can't we register all ports automatically? > Why can't we register all ports automatically?\\r\\n\\r\\nWhen developing i did not like how it felt when displaying every available sensor from a device at once, selecting the specific port and listing its sensors was more efficient and cleaner. Can you categorize them? Maybe disable the less used/interesting ones by default? > Can you categorize them? Maybe disable the less used/interesting ones by default?\\r\\n\\r\\ni am working on registering every sensor on a port of a device, so, instead of selecting one sensor of one port of a device, you select one port of a device and every sensor gets registered, do you think this approach would make it better? just use a class attribute to store those instead of writing them to `hass.data` the coordinator will automatically have a `self.config_entry` after `super.init()`. If you extract those in the coordinator you don't need to pass anything here, making your clean cleaner \\r\\nappears unused I really don't like this. The first part can run into an endless loop. The second part just repeats the part that just ran into an error. Rather throw a UpdateFailed error and just wait until the coordinator retries. remove empty keys if you're adding nothing to this, you can just use the normal `SensorEntityDescription` instead second coordinator? why can't this be in the array like all the others? what are trying to achieve here? You probably only want to return part of the data from the coordinator, you will probably want a `value_fn` in your `entity_description` for this set the unique here instead. The name should maybe just be the `key` of the entitiy, or ideally you set a `translation_key` and a more descriptive name in `strings.json`.  plase use consts for anything stored in the entry, as you're referring to it multiple times. Those are already str so casting is not necessary. you can use the `_attr` notation for that in the init Why do we set this already here?\",\n",
       " \"Please revert the changes in this file Yep, should have exclude it, my bad Can we bump in a separate PR? I check manifest history and there's multiple PR on functions that include the bump. Hence I choose the same. Can we add this in a separate PR? I guess so, but was trying to make sure all would be avaialble for same functionality when released\\n Removed from this PR, will post as seperate PR \\n\\nThis allows you to remove the default \\n Also, We now also have translation placeholders, maybe we can use that to avoid having 6 entities per phase * 3 = 18 entities. We could just have 6 in which we replace stuff. What do you think? Removed default and implemented translation placeholder.\",\n",
       " \"I think you can use `self._attr_extra_state_attributes` - this is predefined in a superclass and is specifically made for defining the extra state attributes. Maybe this didn't exist when I originally implemented this integration. Since `feed_entry.properties` could essentially contain anything (whatever the feed contains), it might be a good idea check what happens if the properties contain essential keys used by this integration, like for example `latitude`, `longitude`, `source`. Honestly, I'm not sure how `state_attributes` and `extra_state_attributes` behave if they both define the same key. And when using `self._attr_extra_state_attributes` you should be able remove this method altogether. Is there a reason to remove the external ID? I originally chose this because it's the only way to uniquely identify a geolocation entity from a feed. I am wondering if we should add some unit tests for this? Depending on how the feed entry's properties look like (i.e. what JSON structure it contains), this may or may not have undesirable side-effects.\\r\\n\\r\\nFor example:\\r\\n\\r\\nvs.\\r\\n\\r\\n Why is the external ID deleted in the tests? Good catch - that should be added back now.\",\n",
       " \"good catch here, seemed to have slipped through the cracks Was this meant to be here or was it meant to be an alternative version of the text in `alternative_speed_turn_off`? I would recommend you pass the result of `client.get_alternative_speed_status` in `setup_client` and feed that to the entity setup.\\r\\n\\r\\nThe way I did it was to put this in the coordinator.\\r\\n\\r\\n\\r\\nAnd have these as my entity description\\r\\n\\r\\n\\r\\n\\r\\nThat way the initial value is correct. Ok I see, I'll update this ! Thank you for the feedback .\\r\\n\\r\\nSorry for the delay, lot of personal stuff lately. Updated with the change you suggested, can you take a look ? LGTM, but the qbittorrent lib should probably be changed unless the author decides to wake up. Should we make this a defined data structure to plan for more data being passed down in the future? Along with it being clearer what the bool is currently for.\\n\\nI'm not opposed to leaving as a tuple for now, just want to put the idea out there if you want to swap it to a defined data structure Sound more interesting for future additions, so creating a dataclass in there ? Yeah, instead of using a tuple. \\n\\nProbably actually worth checking if there a good practice that other integrations use?\\n\\nI would check but only have my phone with me ðŸ˜… I'll check this, I will maybe wait for the change of lib so we can maybe use the lib type in this :+1:  Why is this changed? This was a key error, the correct key is `current_status` used [here](#L74) Oh, I see. Then please split this change out to a separate PR. Ok NP, I'll remove this form this PR Please open a PR with this fix, it seems to be needed to have the right entity name. Why are we mixing quoted and non-quoted class names in the type hints? Import annotations to make sure type annotations work as expected, including forward references.\\r\\n\\r\\n How come the device is not named? He get is name from `DeviceInfo` with `translation_key` I don't get it, there are no device name translations in `homeassistant/components/qbittorrent/strings.json`, and you don't set the device name either here or in the existing `sensor` entity. Sorry, it's via the `entity_description` that have the translation key [here](#L33) and you can find it in the string file [here](#L53), we use the same method for the sensors [here](#L99) refering to [this](#L48) OK, so the device will be named by the config entry, and the entity name is translated. That works ðŸ‘ \",\n",
       " \"\\r\\nNot sure if this is the right function, but shouldn't we use something like this instead? That works equally well. Thanks. \\n \\n\",\n",
       " 'Is this required? Yes, pylint will fail without it.',\n",
       " 'Const indicates its a value, but text indicates its a list of registers...one of those is wrong. @janiversen no problem, I\\'ll change also the const name as already done for the text.  For each register, you need to secure it is not used in any other configuration part (as done e.g. with sensors). \\r\\n @janiversen  This specific routine avoids registers overlapping inside the climate. The testing routine is called 3 times with a different register overlapping, so I have tested hvac mode register, hvac on/off and hvac fan mode. \\r\\nThe only register is admitted to overlap is the target_temp_register, the default one.   All options must be tested, also a test with duplicate options, and tests with duplicate addresses.\\r\\n\\r\\nThis integration have 100% test coverage, so you also need to secure that all lines are tested. Thanks @janiversen for the review. \\r\\nThe code has the same coverage of the whole previous code. (100%)\\r\\nDuplicated registers into the map cannot exist because I used a set.  I try to answer to your requests point by point. \\r\\nThanks again. \\r\\n  This looks like a constant, so why have an instance in each object....at the very least it should be a class variable. This is better done in the validator, always convert the parameter to an array...then we have less to do at runtime. If it is always an array, then this method can go away. Remark, I just make a short review, and in principle it looks good, but there are a couple of changes which affect most of the code. It is prepared in the validator so the int() should not be needed.\\n\\nIn general the function should be dissolved and the array indexing made directly, Hi @janiversen, this morning I waked up having the idea to restore the try/except block, but I see that you prefer to remove completely the routine. Are you confident that we can delete the whole defensive approach, I mean the try/except and the cast?  you should know that it\\'s your PR. But you are defending against yourself? Combine with next line. is the list() really needed ? its just confusing. [bad idea - removed the comment] Why is it a bad idea not to do list(var) on a var that is already a list()....you have removed the int part earlier. Yes, I have already optimized that routine and the other check about overlapping addresses.. I\\'m trying to understand your earlier comment about \"the init\" before to commit the new code.. But, I\\'m not so good at puzzles.. :)  It\\'s not a puzzle ! it\\'s quite obvious init contains voluptuous definitions ....you actually already added a validator, so you know it. Yes, but the puzzle is not the init itself, but how to change the execution order of the validation calls.. Debugger has been a friend..  The duplicate validator run last, so the value if present is a list. @janiversen When I tested this piece of code on a real env, I obtained an error caused by the iteration over an int, so it seems to me that it run before the validation. Am I wrong? Well your validator changes the config, like some of the others, so it is important it runs after those....if it does not correct it. @janiversen I spent some time using the debugger and also the other validators which change the output (i.e. number_validator, nan, struct_validator..) are called AFTER the duplicate_entity_validator. \\r\\nso it seems the the duplicate validator run as first, not the last. \\r\\nWhat I miss?!\\r\\n\\r\\n You miss that you need to change that. Dear @janiversen I really appreciate your patience and your (+/-) hidden suggestions; I tried to change the code every time you asked and I can assure that imagining what you have in mind was not so easy. But honestly speaking, this time I cannot rewrite/verify the whole validation process just to avoid an \"if/else\" inside a routine (we\\'ll have the same for fan_mode conf address of the other PR). \\r\\nThe debugger says that it is not true that _\"The duplicate validator run last [...]\"_ \\r\\nDomain level duplicate_entity_validator is executed BEFORE all, standard or custom field validators and in fact it is executed against fake values, if the config is wrong. I don\\'t know if it is right, because IMHO it is totally unuseful to check duplicates if the entity itself is wrong, but this is not my matter and I\\'m sure that who wrote that had a good reason. \\r\\nIf you have already an idea on how we should change the whole validation process, please, explain.. Else, I commit as it is this piece of code. \\r\\n Its a simple problem of looking in __init__, not a rewrite. What â€œIt is isâ€ not loaded p, the target temperature ? what â€œItâ€ What â€œItâ€',\n",
       " 'Does it not work if you add default values to these? The default values have to be set in `async_get_triggers`, otherwise the resulting yaml looks like this (even with default values provided in `async_get_trigger_capabilities`).\\r\\n\\r\\nEven worse, if the `default=True`, this will be applied, but all the switches in UI are \"off\" so it doesn\\'t represent what will be created at all.\\r\\n\\r\\nThe current implementation results in correct UI switches (on by default) and this yaml\\r\\n I tried using a `ConstantSelector` too, but this doesn\\'t show a checkbox (like shown in #constant-selector) so it isn\\'t de-selectable. Why do we need allow `None` here? See the PR description. There is also a blueprint example for this.\\r\\n> If destination is explicitly set to None, the trigger is a no-op. This can be used in blueprints to provide inputs for addresses that are optional. With an input with default: null the trigger will never fire if no address is provided.\\r\\n\\r\\n could supersede this.  OK If we could find a decision about the linked PR, this `None` handling option could be removed completely without further (breaking)changes or deprecations to this trigger to accomplish the same goal for blueprints. Instead of this, can trigger.py export something like:\\r\\n\\r\\n\\r\\nThen we can include it with `**TELEGRAM_TRIGGER_OPTIONS` both here and in `TELEGRAM_TRIGGER_SCHEMA` and avoid the risk of changing in one place and forgetting to update the other. This would be possible for now.\\r\\n\\r\\nI was planning to maybe change the extra_fields to selectors to be able to add descriptions once  is finished. I think selectors would not be valid for the `trigger.py` schema, would they? I guess not, but we should not worry about things which may happen in the future now IMHO.',\n",
       " 'Not needed Removed Only have stuff in the try block if it can raise Updated Updated to match the suggestion Modified the used key from invalid_api_key to invalid_auth in all relevant spots Why do we catch `KeyError` here? This was left over from a case where the returned data structure might not contain the key \"devices\", but this should not be possible anyway, so I have removed the KeyError handling. Updated to cannot_connect in all relevant places. Removed this section Please import `as vol` Updated as suggested Updated as suggested - this seems to be in use in various other places in the codebase, but it definitely still works as intended with this change. I\\'d suggest moving this to a coordinator Updated the setup code to use a coordinator instead. This definitely seems to speed up data availability on startup. If we only store one thing, no need for a dict\\r\\n Updated this to only hold the new coordinator, without a dict. Please look into `SensorEntityDescription`s, they will make this a lot easier Updated to use a sequence of `SensorEntityDescription`, also bringing in the suggested precision through there per your last comment. No need for a custom entity_id here/ New integration should use `has_entity_name = True`. Read more on #has_entity_name-true-mandatory-for-new-integrations Can we type this? Can be a shorthand attribute Has entity name will make life way better Please don\\'t round values, prefer to set `suggested_precision`',\n",
       " 'For integrations that connect to devices or services, we no longer accept new YAML configuration or changes.\\r\\n\\r\\nThis integration needs to be refactored first to use a configuration flow and config entries first.\\r\\n\\r\\nMore information about this can be found in Architecture Decision Record:\\r\\n\\r\\n- ADR-0010: <#decision>\\r\\n\\r\\nSee our developer documentation on how to get started creating a configuration flow for this integration:\\r\\n\\r\\n<\\r\\n\\r\\nAs these changes often involve a bit of work and some significant shift in the current code, we will close this PR for now.\\r\\n\\r\\nWe (and our community!) would really appreciate it if you could start on the refactoring of this integration in a new PR.\\r\\n\\r\\nThanks already! :+1:',\n",
       " \"This means that if someone has upgraded and configured a `switch_as_x` with `invert=True` and then downgrades it will change the option for that entry to `invert=False` hence changing how that entity works (even if the user then upgrade again).\\r\\n\\r\\nIt should probably only set this option if it's not already there? Fixed ðŸ‘  I'd think this should be an optional item with a default. Fixed ðŸ‘  I'd put the default as the else case and the special case as the if case. Fixed ðŸ‘  Isn't it possible to access the item by key in the schema? Then I'd just do that in the test instead of making this function that is only used once. Note that it's the *key* which has the suggestion, not the *item*, hence the sing-and-dance number to first find the key and then make sure the key has a `description` attribute with a suggested value I'd instead write this directly in the test:\\r\\n\\r\\n You asked:\\r\\n> Isn't it possible to access the item by key in the schema\\r\\n\\r\\nThat's not possible, but sure, the used-once-method can of course be inlined regardless of that ðŸ¤·  I'd invert this in the service calls too.\",\n",
       " \"just an idea: what do you think about using an `IntEnum` instead? Most other integrations I see just use int dicts, so this sticks with the status quo. Why is the name not translated? I just copied the the `schedulepart` `VenstarSensorEntityDescription` above and modified it for this. How would I make this a translatable string? You should set the `translation_key` (and optionally also the `translation_placeholders`) of the entity description and update `strings.json`.\\r\\n\\r\\nFor local testing, you need to run `python3 -m script.translations develop --all` for the (English) name to work. I already have translation_key on this entity description and have the translations in `strings.json`. Is there anything else I need to do? The translations in `strings.json` only translate the states, there's no translation of the name. I don't think this works, I think you also need to:\\r\\n- Update `VenstarSensorEntityDescription` to allow `name_fn` to be either `None` or a function returning a str\\r\\n- Update `VenstarSensor.__init__` like this:\\r\\n Let's sort the data\\r\\n\",\n",
       " 'This too needs the exclusive marker This property is not needed, `_request_data` is accessed directly by `async_update`.',\n",
       " \"The preferred interface for permitting with install codes is currently just `permit_with_link_key`, with the link key derived within the caller. I'm hoping to drop support for `permit_with_key` at some point.\\r\\n\\r\\nPerhaps it would be simpler to rename this method `def qr_to_link_key(qr_code: str) -> tuple[zigpy.types.EUI64, zigpy.types.KeyData]` and have the Bosch QR fall through as it does now, while returning a link key [derived from the install code](#L243-L253) in all other cases? That way, this is the only spot it needs to be special cased.\\r\\n\\r\\nThis should also clean up the websocket API too, as we would only ever need to call `permit_with_link_key`. Very good point! I updated this PR do replace `permit_with_key` by `permit_with_link_key`. Now `qr_to_install_code` and `convert_install_code` will supply directly KeyData.\",\n",
       " 'Please only have stuff in the try block that can raise Config flow tests should finish in either Create entry and abort to test they are able to complete If the authentication is incorrect, it will raise `ConfigEntryNotReady`. Can we also catch the AuthError and `return False` or `raise ConfigEntryError` to stop retrying? Why are we doing this instead of just testing that the flow succeeds? Success flows are above this.',\n",
       " 'This test is unclear to me for several reasons:\\r\\n\\r\\n1) I expect an arrange/act/assert structure for each test. This test asserts in between, it asserts on many unrelated things and it ends with an action that is never asserted upon.\\r\\n\\r\\n2) I would also expect a test which checks that a default profile name also shows up nicely  This makes sense, but I think it should be in a different PR? Shall i add that to the description of the PR?\\r\\nIf you want to, i can remove the code changes. Please move this and the removed check for `preset_mode` to a separate PR about improvin error handling in homematicip_cloud ðŸ‘  Why is this check removed? Because i was not able to test it. This case is already handled by home assistant. If a set_preset_mode is called with an unavilable preset_mode, there is a ServiceValidationError `homeassistant.exceptions.ServiceValidationError: The preset_mode dry is not a valid preset_mode: boost, eco, STD, Winter` Please add a type annotation to `profile` Done Please add a docstring explaining what the function does Done Nice ðŸ‘ ',\n",
       " \"Turn this into a guard clause. `if not no_states_error.area: return â€¦`.\\r\\n\\r\\nTurn the other if also into a return early.  I refactored the top guard clause to exit early if there isn't an area as well as at least one domain/device class.\\r\\nOtherwise, this suggestion could fail on `next(iter(no_states_error.domains))`\",\n",
       " 'Just a thought, let me know what you think of it.\\r\\n\\r\\nNow we are changing naming, can we also look at how the names look? Can we make it more descriptive:\\r\\n\\r\\nNAS xxx Network up (eth0) -> NAS xxx eth0 up\\r\\nNAS xxx Temperature (drive 1) -> NAS xxx drive 1 temperature I tried not to change the names but leave them as they\\'ve been before:\\r\\n\\r\\n<img width=\"238\" alt=\"Bildschirmfoto 2024-01-05 um 11 57 27\" src=\"\">\\r\\n I mean that\\'s also fine, but now we are changing names, might as well review them. I also know @disforw tried implementing translations, so maybe he also has an opinion. I was following that placeholder PR closely and saw it was merged yesterday, you guys beat me to it! ðŸ˜\\r\\n\\r\\n@joostlek if you\\'re looking for a unit name or identifier, that\\'s already being brought over using the device name.\\r\\n![Screenshot_20240105-071535](\\r\\n I know, but my question was more of the stuff behind it. Do we want to change that to make it more fluent or do we keep it like this',\n",
       " \"Remove this code and set the expected result as a test parameter instead. We can predict with the expected result will be. Please avoid branching in the tests. Set the expected result as a parameter instead. `output` is never `None`. I'd create a constant at the module level for a datetime instead. We aren't interested specifically in the `start_of_local_day` datetime or using the `today_at` template function. We want to test the `as_datetime` template function. Then it will be easier to set a parameter for the expected result. I was struggling with this one.\\r\\nI want to test with a datetime object as input (so not a datetime string). But if create a datetime object, and use it as input, it will use the python representation, so something like `datetime.datetime(2024, 1, 1, 0, 0, 0)` and then the tests will throw an error that it gets an integer where a comma is expected.\\r\\n\\r\\nThat's why I create a datetime object in the template itself.\\r\\nI did update the test. I fixed the date to 1st of January 2024 so the output can be expected.\\r\\nI could also use `as_datetime` instead of `today_at` but then I would be using the function I want to test in the test itself.\\r\\n\\r\\n`today_at` and `as_datetime` are the only options I could think of which give predictable output. `now()` will change while the test is ongoing.\\r\\n\\r\\nexample with a datetime.datetime as input:\\r\\n Changed it to use `as_datetime` for the input Why don't we just use the time string directly as input?\\r\\n\\r\\nThe resulting template can simply be.\\r\\n\\r\\nThe docstring for `as_datetime` reads:\\r\\n I want to add support for `datetime.datetime` and `datetime.date` as input.\\r\\nTo do that, they are parsed to a string.\\r\\n\\r\\nAn annoyance of the current filter/function is that it throws an error if you use it on a datetime.datetime. Now it returns the datetime.datetime back, it avoids the need to check on the type before you use `as_datetime`\\r\\n\\r\\nThis was even worse when there was no `datetime` test yet, you had to do someting as:\\r\\n```jinja\\r\\n{% set dt = [now() | now().isoformat] | random %}\\r\\n{% if dt is not iterable and not dt | is_number %}\\r\\n  {{ as_datetime(dt) %}\\r\\n{% else %}\\r\\n {{ dt }}\\r\\n{% endif %}\\r\\n\\r\\nI have updated the docstring. Ok. I suggest splitting this PR into three PRs, one per description bullet.\\r\\n\\r\\nI didn't notice that we're changing three things. Well, the to accept datetime objects and that it will no longer error on other types as `list` and `mapping` are both the result of parsing the value to a string before using it in `dt_util.parse_datetime()`. So I can't really split that out.\\r\\n\\r\\nI can remove the `default` parameter out of this PR, and create a separate PR for that. Changed the scope to only add support for the `default` parameter\\r\\n\\r\\nTo avoid breaking changes, a string input which can't be parsed to a datetime object returns `None` if no default is provided. In case a default is provided it will that for strings which can't be parsed to datetime. Please update the docstring. Noticed that, was awaiting the tests to complete so I was sure there wasn't something wrong missed by the local tests :) Please extend the comment with why we do this, ie to make it backwards compatible.\",\n",
       " \"Feels a bit weird for the comment about having both to be on the branch where we don't have the colour temp? Yeah its probably superfluous. I'll take out the second part f077024710f8707cca791eb63a6a40c4ee6f5622 Is it valid for the user to call us with a temp and h/s? What should happen in that case? Because if they do that on a bulb with no temp then this will throw away their h/s in favour of ours? I suspect in practice won't matter much, but wanted to check. Its not valid to call with both, only one or the other 8983f397a0b1006f874315bce6f36d525a0a7dee I think its actually possible for them to send both but one has to win 9c7dc85053c8ea6d90fdd500e3388b8ae445dfb6 I tweaked it a bit more. I'm not sure this would ever happen on purpose though (of course someone will do it though) \",\n",
       " \"ðŸ§  \\r\\n![image](\\r\\n I don't know what you're talking about\",\n",
       " \"Can this be a constant? I think in this case you can pass `update_on_add` to the `async_add_entities`. This will execute `async_update` before its added to the entities. This way you don't have to pass in the presets.\\r\\n The only thing you would have to add in `async_update` is `if self._attr_current_option is None: self._attr_current_option = self._attr_options[0]` Are you sure about this? In the previous PR I was requested to use a tuple. This gives an error in the pre-commit hook on line 51 and 57 assigning `str` to `None`. ah check, ignorethen \\r\\n\\r\\nIt doesn't look like async_update is implemented so I think you need to write state instead.\\r\\n\\r\\n Are you sure? Itâ€™s there on line 45.  Wow. not sure how I missed that one, must have been looking at the wrong file when I switched PRs. Sorry about that.\",\n",
       " '\\r\\nCurrently, it would allow the same device with different usernames. updated the code The `configuration_url` creates a \"Visit\" link on the device page to make it easy for users to go to the devices\\' page, so it should be something like `f\"https://{coordinator.api.host}\"` or however the format of the URL to the device looks like. \\r\\nCurrently, when you would try to add a second device, it would overwrite the coordinator of the first device. Would be good to put this as a constant in `conftest.py`, then you can reference it instead of repeating. is this auto generated code? i dont see it in my local branch or vscode and i didn\\'t write it This is part of the tests you wrote. \\r\\nThis should be enough to make it work. it was throwing erorrs with this change. not sure if i\\'m missing something in the code thats causing the failure\\r\\nAttributeError: \\'NoneType\\' object has no attribute \\'get\\'\\r\\nso i reverted it to         return self.coordinator.data[self.entity_description.key] or reverted it to         if self.coordinator.data:\\r\\n            return self.coordinator.data[self.entity_description.key]\\r\\n\\r\\nthere appears to be some condition in startup where self.coordinator.data is None so i guess the if statement is catching that i\\'ve updated it more after testing. not sure if i\\'m resolving this the correct way \\r\\nRegarding to further below in the file. Why are we talking about a speed test? Does this integration run a speed test? Please move the line(s) that can\\'t raise up outside the try...except block. How do we know that it\\'s a timeout? We\\'re just catching the general client error. I\\'d just say \"Failed to connect to\".\\r\\n',\n",
       " \"Why is an update service needed? Can we not use [`homeassistant.update_entity`](#service-homeassistantupdate_entity) instead? The coordinator has builtin support for it Service removed and `homeassistant.update_entity` service added to tests You were too fast :) Instead of removing we should deprecate the service for six releases and create a repair issue. So users have time to move to the other service.\\r\\n\\r\\nThe best would be to deprecate the service in a follow-up so we keep this PR small.\\r\\nSorry for the inconvenience. I wanted to ask why we need this update service. Hi, I re-instated and deprecated the service although I just realised you'd suggested to do the deprecation in a different PR.  If it's a big issue I can pull it out but at the moment it's just a test case and an issue entry so hopefully not too big for this PR. Ok deprecation is now in draft PR   This comment should be fully addressed. \\r\\nSo we do it only once instead for each device Done Done Can we use a [TaskGroup](#task-groups) for both api calls instead? Done Updated as per suggestion Updated as per suggestion \\r\\n\\r\\nShould not be needed Removed Please remove any commented out code Done Why is the parent function not called? The parent function updates the device I think it was like that before there was a null check in the parent but it's there now so I've updated it to call `super()` Can we use here maybe an instance check? Replaced with an instance check and also in the `light.py` where there was a similar check. `log_msg` is unsued. Is the test missing something? Ah yes, thanks so much.  The log message check is now added. Why aren't we calling `async_config_entry_first_refresh()` on this coordinator?\\r\\n\\r\\nWe should call it for each coordinator I think it was because it refreshes every 5 seconds I'd decided not to, but I now see there's extra logic in the `async_config_entry_first_refresh`.  I've updated it to call that and it all works ok.\",\n",
       " 'Can we move this to `entity.py`? Can we give this Coordinator a better name? The `config_entry` is set to `self.config_entry` after the coordinator init It would require you to pick a better name tho  Why do we do this? If I read correctly, we do this to sync the device with the config entry title.\\r\\n\\r\\nIn that case, you can just remove the `name` property from `device_info` and it will automatically use the config_entry name I want to sync my modified name on the front page, having removed unnecessary code. We can just say \"Unsupported device\", no need for the rest I found that \\'async_abort\\' could not be used to terminate the user\\'s process of adding a device.I\\'m a little confused. What is this timeout exactly? This is the timeout period used for device communication.If the device does not return data within this timeout period, an exception will be thrown. Only helpers are allowed to set a custom name. We should set the name to something the user can recognize You can use `config_entry.async_on_unload(......)` to pass in functions it should execute when it unloads. I think you can use it at some places That\\'s cool \\r\\nThis change would make it enough to have the device have the config entry name I think we can move this to the entity Why do we do this? We plan to include other types of devices, such as lights, which have different data acquisition functions. What is the context? Please move this to the base entity \\r\\nDRY :) None of these strings are currently used This can be a shorthand attribute created in the constructor `_attr_device_info = DeviceInfo(..` #device-properties -> Checkout connections and search the code for `dr.CONNECTION_NETWORK_MAC` to find an example',\n",
       " \"The GenericCamera isn't written or meant to be used as a helper for other integrations. If we want to allow that it needs to be refactored first to have a proper interface with keyword only arguments instead of passing a dict with config items. The class also needs to be exported from the generic package via `__all__` so it's clear that other integrations can import it.\\r\\n\\r\\nWe did the same changes for `MjpegCamera` earlier.\\r\\n\\r\\nI'll check with the core team of we think it's good to be able to reuse the generic camera. Okay. We can take a look at what was done with `MjpegCamera` and try to make a PR to see what that looks like for `GenericCamera`. The conclusion from the core team is it's ok to use the generic camera integration but the camera class should be refactored or split so that it gets an interface that other integrations can use, per my comment above.\",\n",
       " 'Misses `await hass.data.[DOMAIN][entry.entry_id].async_config_entry_first_refresh()`, this way you have fresh data when setting up the entities No need to mark this as `@callback`, as it is already async. `@callback` is used on sync functions to mark them as safe to run in the event loop No need for this, if you call `async_config_entry_first_refresh()` in `__init__.py` Not needed when you use the `native_value` property function below. \\r\\nNo need for `setdefault` here  Why not make use of the `native_value` property function?\\r\\n\\r\\nBesides, I would move the if to `async_setup_entry` and just setup entities if the description key is in the coordinator data. This way you wont end up with unavailable entities.\\r\\n\\r\\nAlso, the `CoordinatorEntity` takes care of `_attr_available` if a update fails Yes, you are right, thanks Please patch the package where used and not globally. I don\\'t quite understand what you mean with \"where used and not globally\". It is needed for the async_configure because of the validation. Sorry for not be specific here, hope the code explains it :)\\r\\n\\r\\n Ah, okay, I didn\\'t know that you can patch functions on the place where they are imported :sweat_smile:  Same Same Config flow tests should end with `ABORT` or `CREATE_ENTRY`, this way we can check that the config flow can recover from a error We do not want to collect names, you could use for example the host as title for the config entry. Not needed, this is handled by the core To be specific on this, I\\'m talking about the `issue_tracker` :) \\r\\n\\r\\nThis way you won\\'t end up with entities that have no data. It is missing the mandatory `_attr_has_entity_name` (#has_entity_name-true-mandatory-for-new-integrations) and thus you could make use of the `translation_key` in the entity descriptions. \\r\\n\\r\\nShouldn\\'t this be the coordinator? The question would be, how should I verify the user input? Currently I create a `WebminInstance` and try to connect to the device. Another option would be the create the coordinator and go through it. This is the setup of the integration itself, not the config flow. You want to patch the update function called by the coordinator, called in `_async_update_data`. Not needed, you already test this with the fixture Idk if we are allowed to this, but probably this ok, as there is no other way',\n",
       " \"We don't want these measurements as state attributes. Please move them to separate sensor entities. ap_mac is already a state attribute. from a templating perspective using attributes is much cleaner than separate sensors. Consider the following macro:\\r\\n\\r\\n{% macro track_device(entity_id) %}\\r\\n{%- if is_state(entity_id, 'home') -%}\\r\\n  {%- set ap_mac = state_attr(entity_id, 'ap_mac') -%}\\r\\n  {%- set signal = state_attr(entity_id, 'signal')|int -%}\\r\\n  ...\\r\\n{% endif %}\\r\\n{% endmacro %}\\r\\n\\r\\na single device tracker entity gets passed in, then based on connected ap and signal strength macro can work out what room the device is located in.\\r\\n\\r\\nwas hoping this would be simple enough to add signal and rssi attirbutes to the existing entity, but if not I can live with just patching my local installation. Please close the PR if you don't intend to address the requested changes. Thanks!\",\n",
       " 'Why is this a template instead of a fixed string? Can you give some example of where it\\'s useful to dynamically change the code format? This seemed to be the most straightforward way to support \"require no code at all to lock, but a certain code to unlock\". Or a well-known short code to lock, but a long (possibly dynamic) one to unlock.\\r\\nFrom a system design perspective, if so desired it is always possible to go to a \"secure\" state (locked) and you need knowledge to go to an \"insecure\" (unlocked) state. Or have it the other way around if the meaning of \"secure\" and \"insecure\" is swapped in a user\\'s context.\\r\\n\\r\\nThis works neatly with the frontend without introducing new attributes like [Template Alarm\\'s code_arm_required](#code_arm_required). OK I see. That makes the PR work around limitations in the lock entity IMHO, something which is not wanted. Please replace the `code_format_template` with a fixed `code_format` and hit the \"Ready for review\"-button when done. Naturally, I beg to differ ðŸ˜€ I think this makes template locks quite versatile in their application.\\r\\n\\r\\nWhat is the actual issue here? There are other examples where the current code format for a lock is computed on the fly inside the method, for instance in the implementation of matter locks:\\r\\n\\r\\n#L43-L60\\r\\n\\r\\nHere the return value, at least without forward tracing the code, could change during operation, which is exactly what can happen with a template for lock code formats as well. My conclusion is that there is no actual limitation in the lock entity and thus code formats can be dynamic without any issues.\\r\\n\\r\\nCan you elaborate? (Marking this PR as Ready for review again in order to make this comment visible) Right, the matter implementation computes the code format, but it seems clear from the code the intention is to do so based on properties of the remote lock device, not based on the state of the lock.\\r\\n\\r\\nIs the main driver of your PR to implement support for dynamic code formats? The long story is that I basically wanted to a) virtually secure certain switches/complex setups and b) have something similar to a switch that properly supports in-between-states. Meaning something complex is turned on (which I don\\'t want to happen by accident and not necessarily by anyone walking through our hallway), and while this is turning on, which can take quite some time, the UI controls display an intermediate state (like the lock that is \"unlocking\" and then is \"unlocked\"). The opposite is not true, so while I whish the turning on to be secured, turning off can happen anytime without securing it.\\r\\n\\r\\nThat drove me to template locks, which currently don\\'t support codes at all, and to make this available _and_ \"templateable.\" \\r\\n\\r\\nAs far as I see it, the main question is: does any existing code rely on the (undocumented, AFAIK) fact that a code format property of a lock never changes?  \\r\\nI guess the answer is no, because there are places where this can obviously occur, Matter being one example. If no one relies on constant code format, why not make it optionally dynamic for template locks (that target advanced users only) as well? And the format can be based on anything, really, not only locks\\' state.\\r\\n\\r\\nAnother application I have in mind is a dynamic automatic parental control where one can use something while parents are at home, but need to enter a code if they are not. (All this applies to control surfaces that are accessible to anyone in the house). OK, I see, your use case is essentially about (ab)using lock entities for things which are not actually locks.\\r\\n\\r\\nI think what you want to do is covered here  although there\\'s no solution in that discussion. My personal opinion is that we should allow users to set a flag on any entity marking it as requiring confirmation, optionally with a PIN. Frontend and voice assistants should be aware of that flag and show a confirmation dialog / verbally ask for confirmation.\\r\\n\\r\\nFor this PR, I would suggest to remove the templating to get the base functionality - adding code format support to template locks - merged. A follow-up PR could extend the code format with templates, and we can continue this discussion in that PR. It\\'s not more abuse than [using a light to control home theater volume](#theater-volume-control) ðŸ˜‰. I always fancy the template-integration to be something special that exactly enables flexibility like this. It\\'s kind of in its DNA.\\r\\n\\r\\n\\r\\nI am also on board with adding UI-security measures (UI also meaning interactions by voice assistants) to all interactable entities, also with custom messages as described in the linked frontend issue. However, there are three considerations with this idea and your proposed next steps for this PR (all IMO of course):\\r\\n\\r\\n1. This property (pin required/not required) needs to be templateable; user (or role) specific settings would be nice as I wouldn\\'t bother myself to enter a PIN to enable A/C, for instance, because I usually sometimes kind of tend to know what I do ðŸ˜‰ \\r\\n2. The place where the check happens should be customizable. This means that I expect the actual check (after the _requirement_ of a PIN/Code has been determined) to be offloaded to something else to be able to also support changing/rolling codes. Only supporting a static setting here would again severely limit flexibility.\\r\\n3. Introducing a `code_format` for template locks now would solve about half of my issues, but _if_ later we come to the conclusion that it indeed should be templatable, it would either not fit to the template entities config convention (`_template` suffix) or it would create a second property and deprecate the old one and we\\'d have to think about procedure when both are set and whatnot...\\r\\n\\r\\n\\r\\nYou think a discussion on the discord would provide more insights into what others think about this whole ordeal? Would it even make a difference? The template light example is not good, that example should be for a templated number instead; maybe the example was added before we had template number.\\r\\n\\r\\nNo matter that, and no matter the non-lock use case you have in mind, you\\'ve convinced me that there\\'s no reason to not allow templated `code_format`, and I checked with a couple of other core developers who also agree.\\r\\n\\r\\nCan you please add negative tests which show what happens if the template has a syntax error or raises an error during rendering? Will the result be that we accept any code or no code at all or something else?\\r\\n\\r\\nAlso, can you double confirm how frontend behaves when the `code_format` attribute changes? We don\\'t need to call super here\\r\\n Nice!\\r\\nPlease customize this so it\\'s clear what template errored, use a translated message with placeholders for the name of the failing template and the error message in the _code_format_template_error:\\r\\n\\r\\nSomething like:\\r\\n Now:\\r\\n![grafik](\\r\\n Why is this change required? Because tests fail otherwise ðŸ¤·\\u200dâ™‚ï¸ ðŸ˜‰ \\r\\n\\r\\nI chimed into the way the other tests in this file use this config preset to assess whether actions are called with correct parameters. That\\'s not an answer.\\r\\n\\r\\nThe code is needed only by your newly added tests. By reverting your changes in the test file, I can run all tests successfully. Seriously? If \"I chimed into the way the other tests in this file use this config preset to assess whether actions are called with correct parameters.\" is not an answer then I don\\'t know what is.\\r\\n\\r\\nI guess you know how the tests work in this file, so what\\'s the matter here? I honestly don\\'t get it ðŸ¤·  Providing a `code` is optional for the lock service calls.\\r\\nI would leave the current service as they are (meaning I would revert this change)\\r\\nIf your newly added tests need a code, they add it only for these particular tests.\\r\\nCould you also add a test in which a code_format is configured but no code is passed on the service call? I agree with @edenhaus, add a new config dict `OPTIMISTIC_LOCK_CONFIG_WITH_CODE` and use that in the new tests + add the negative test he requested.\\r\\n\\r\\nOnce that\\'s sorted, this PR is good to go ðŸ‘  That test that @edenhaus mentioned is already there; however I made that section a little more complete. Specific lock config for new tests is there as well.',\n",
       " \"There's no need to add these state attributes, it's enough to add the sensors.\",\n",
       " 'Schouldn\\'t we poll for the state of the switch every x minutes?\\r\\nNow if someone changes the value in the goodwe app/SEMS app, it will never be updated in HomeAssistant untill you restart the integration....\\r\\n I used the same logic as for grid_export_limit. these can only be changed via the PV master app (and maybe another app for different inverters), but these are not accessible in the SEMS portal (as of my knowledge).\\r\\n\\r\\nI will implement the async_update @starkillerOG Actually, I probably wouldn\\'t poll (just) the switch state.\\r\\nThere are already other \"settings\" (not sensors) managed by the HA (like DoD, export limit) and those are so far NOT polled from inverter.\\r\\nThe approach was simple - one should manage the inverter either by HA or by its mobile app.\\r\\nIf we add this polling/synchronization just here, it would be confusing why something is and something is not synchronized.\\r\\nSo I suggest to remove the polling from here for now and if we really intend to implement it, then we should do it for all settings, not just switch ...\\r\\n\\r\\n The proper thing in my opinion would then be to create a dataupdatecoordinator and start polling those settings at a low poll interval (once every hour or so) to at least keep it in sync. I think it is better to read back the value from the inverter instead of just assuming it has been set correctly.\\r\\nUse: `await inverter.read_setting(description.key)` or even better request it through the update function I think we should implement or the update_coordinator. will do See above \\r\\n\\r\\nSo `kw_only=True` shoul be there too? added, thanks The \"Number\" is most likely copy/paste mistake, right ?\\r\\n oh, I had no idea :) that is good to know, thanks :)\\r\\nI will close this PR and compare my changes with the `beta` repo',\n",
       " 'Other components should not directly use these.\\r\\n\\r\\nAs a matter of fact, we shouldn\\'t be crossing/mixing components. Can you provide a concrete use case where this is used?\\r\\n\\r\\n../Frenck Sure.\\r\\n\\r\\nRight now, I want to use a schedule helper to manage the schedule for my [Power Pet Door]( which is an integration I have written.\\r\\n\\r\\nFor now, I have created a [Schedule entity](#L215) - which can read the current schedule from the power pet door, and update it on the device if I set one.\\r\\n\\r\\nHOWEVER, while this does create an entity that shows up in the helper list, because it\\'s not actually stored in the backing store, the UI associated with Schedules (which uses websockets) can\\'t edit it.  There is no way for me to actually edit my schedule via. the UI of HA.\\r\\n\\r\\nThe Schedule UI / entity is actually perfect for my needs, it\\'s clean, simple, and has a weekly schedule.  I would LOVE to re-use the schedule component.\\r\\n\\r\\nHOWEVER, in order to re-use the Schedule component/entity (and it\\'s UI), I need to be able to:\\r\\n1. Listen for changes to the schedule entity, and use that to send an update to the Power Pet Door device.\\r\\n2. When I read the schedule from the power pet door device, I need to be able to update/replace the schedule in the Schedule entity (which has to update the backing store), so that the UI via. websockets can see the updates and render them if I click on the entity.\\r\\n\\r\\nThe only way to do this right now would be some REALLY kludgy work trying to invoke the websockets API directly from my component, etc.  Or essentially copy/paste the schedule UI stuff and create my own websockets API (which is unnecessary and something I don\\'t want to maintain).\\r\\n\\r\\nThe solution in this PR, while not perfect, allows me to re-write my custom schedule entity to use a standard schedule entity, then listen for changes on it, or invoke the update directly to the storage, which achieves my intended goal.\\r\\n\\r\\nIf Schedule was a \\'first class\\' entity, like Switch, or Cover, with the associated UI changes to allow for editing a schedule (ie. the UI that exists for the helper Schedule entity) - as was proposed [here]( this would not be as necessary.  I could create an instance of a Schedule and it would be editable just fine - with functions I could override.  Like any switch, cover, etc.  No problem.  But Schedule is not a \\'first class\\' entity, so I\\'m trying to work around it, by being able to interact with the underlying storage directly.  Which only works if I have a reference to the underlying storage. If you have a better idea of how I could use a Schedule helper with my integration so that 1) the schedule edit UI works, 2) when a schedule is edited, I can be notified of the changes and send them to my device, and 3) when I read the schedule from my device it can update the schedule helper, then I\\'m all ears. > Right now, I want to use a schedule helper to manage the schedule for my [Power Pet Door]( which is an integration I have written.\\r\\n\\r\\nThis is not an entity component platform, this should not be used by, or be provided by,  other integrations. The provided use case isn\\'t valid.\\r\\n\\r\\n> If you have a better idea of how I could use a Schedule helper with my integration \\r\\n\\r\\nYes: Don\\'t. They are not designed for that purpose.\\r\\n Sure.  But it\\'s very clear that you\\'re never going to actually create a Schedule entity that IS fit for purpose (feature request  that\\'s not just a helper.  So what you\\'re essentially saying is that schedules are unsupported by Home Assistant.\\r\\n\\r\\nSure, there is a helper, but that should ONLY be edited via. the UI.  And should ONLY be used to indicate if you are in or out of the scheduled times (show a value of on or off).  NOT for actually storing a schedule that can be used by anything else, or passed around as a full schedule, etc.\\r\\n\\r\\nI mean, sure it\\'s not what it was designed for, but if you\\'re not going to make something that IS fit for purpose, what\\'s the harm in giving people the ability to MAKE it work for them if they can?\\r\\nIn the words of NASA, \"I don\\'t care what it\\'s designed to do, I want to know what it CAN do...\"\\r\\n\\r\\nie. try the Linux model, enabling hackers to hack, not the Apple model, of locking everything down. I mean, they can just create a local calendar and put automations to turn something on or off. With recurring calendar items this is quite easy to do.\\n\\nThis approach will suit your basic users and advanced users which might want to take holidays in account or the location of the pet since they can edit their own automations to whatever they want. The problem is, **the device itself** has a schedule.  This is not a case of me wanting to create a schedule and have home assistant fire events at those scheduled times.\\r\\n\\r\\nThe schedule is stored IN THE HARDWARE device itself.  Once you send the schedule, the device itself turns things on or off based on that schedule.  Even if Home Assistant goes away entirely.\\r\\n\\r\\nSo I need a way to edit said schedule **and send it to the device**, or read the schedule from the device **and update the home assistant entity**\\r\\n\\r\\nThe schedule in the hardware is a weekly schedule only (it only stores Monday - Sunday, 00:00 - 23:59).  Not a calendar.\\r\\n\\r\\nIf this was just a case of me wanting to send an event to the hardware at specific times, I could EASILY create a schedule, or calendar event and fire events off that in Home Assistant.  But that\\'s not what I\\'m trying to achieve.  I\\'m trying to support the built-in schedule in the hardware.',\n",
       " 'No real need to make these private Why do we do this? Not needed. Sorry, it\\'s my first integration, I took a pattern from other integrations and I left it by mistake.  Please only assign the coordinator to hass.data after this line Should this `await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)` be before the `async_config_entry_first_refresh`? Nope.\\r\\nCreate coordinator -> first_refresh -> hass.data[...] = coordinator -> forward_entry_setups Okay, so now it looks good. Please only have 1 platform in the initial PR This should go into a PyPi library as it\\'s connecting with an external service. Please only have 1 platform in the initial PR I left the Sensor platform as the only one for the initial PR. Should we change this into \"unknown\"? \\n I think this is already set in the coordinator constructor A timeout is part of the connection logic, so we prefer to have this in the library Please only have stuff in the try block that can raise Consider using a data class or a typed dict for data transfer, it\\'s more typesafe You\\'re not allowed to catch broad exceptions here \\n Oh and I prefer the name value_fn as its more descriptive than attr Why do we even have this function?  \\n \\n Name is filled with config entry.title, which is changeable by the user. This is a bad unique id. Please use the serial number for that Please use serial number \\n Can we maybe only do the manufacturer? The user can find the right device via the device info I think this is a global const Since these will be in the unique_id, having them snake_case would be very nice',\n",
       " \"We shouldn't ignore coverage on individual lines. There's no reason to do that here. Probably test this by updating the device so that this function is called again for the same mac address.\\r\\n We shouldn't need to patch a mock. If it's a mock we should just be able to customize the mock attributes as needed here in the test. I'd expect us to be able to customize `fh_class_mock` here. If we can't do that we haven't approached the mocking correctly.\\r\\n\\r\\nThe problem looks to be that we set `new` in the `patch` call as a real class instead of the default MagicMock. Why don't we just patch the two methods `get_mesh_topology` and `get_hosts_attributes` of `FritzHosts` if we want to use the rest of `FritzHosts` without mocking? I have just stumbled across this as well ... will rework this now ðŸ‘  i think for now the tests are good - nevertheless the `fritz` tests should be overhauled at all in a separate PR We have a fixture for this.\\r\\n\\r\\n#L40-L47 It's a bit unclear what the change in state is after the device change. Maybe assert that this state was missing before the device change, if that's what we want to test? I prefer using `Mock.call_count` to avoid the risk of using the wrong attribute, eg due to a typo, which will pass unless we spec the mock.\\r\\n\\r\\n mhhh ... using `assert_called_once()` seems to be quiet common (_used ~650 times in our tests_) Yeah, unfortunately. I think it should be easily to be replace with a simple search&replace regex (_sure, not in this PR_ ðŸ˜)\\r\\nbut just for a better understanding of the possible risk - do you have an example of such a typo? Here's an example:\\r\\n\\r\\n uhhh ... that's really nasty :hushed: maybe we should discuss this in the members channel and try to get rid of `assert_called_once()` in all our tests? Maybe. It's a bit of an uphill battle since it's part of standard library. If there's a linter that could check it, sure.\",\n",
       " 'Done in 1ee48f0c4f9b892b825ef4b43441bc1d4edded53',\n",
       " \"Can we move this to `__init__.py`? Do you mean to move the entire code of async_setup_entry in the one in the __init__.py? We want to create the coordinator in the init file, not in a platform file Since we're only doing UDP discovery, isn't a config flow like Gree better? Are there reasons why someone has a different port for UDP discovery? Yeah, probably chainging the ports (or even the multicast address) is not necessary, since they cannot be changed on the Govee side.\\nI'll check the Gree flow and update this one Regarding this, I'm almost done, but I didn't find a way to keep the OptionsFlow.\\r\\nIs there a way to keep it? It's not really needed but we will lose the possibility to change the discovery interval.\\r\\n\\r\\nAlso, looking at the Gree integration, I had a couple of ideas:\\r\\n* Would be better to use `async_dispatcher_send` when a device is discovered?\\r\\n* Currently the discovery it is done using the `govee_local_api` library (internally it uses a `call_later` on the same Home Assistant event loop) but, since this can be disabled, could be better if the update function is triggered using something like `async_track_time_interval`?\\r\\n Why would one change the discovery interval?\\r\\n\\r\\nWhat do you mean with the config flow can be disabled? Also, Optionsflow should be in a follow up PR. If with the gree config flow no options flow is possible and we still want one, I'd rather fix something in core so we are able to add an options flow after the `super().__init__()`, `self.config_entry` is set to the config entry. Please retype `config_entry` to `ConfigEntry` tho. Checkout the youtube coordinator on how to do that why do we do this? This is an excellent question ðŸ˜… I remember writing this in an early draft of the code, but it makes little sense now `CoordinatorEntity` will set the `coordinator` to `self.coordinator` The default implementation is already returning self._attr_unique_id Please remove empty fields. Also remove the quality scale. I would prefer to have that done in a separate PR Please revert this Coordinator is not setup at this point, like never, so we can remove it here. This unload is lacking unloading platforms You can add `entry.async_on_unload(coordinator.cleanup)` in the setup, this removes the need to do it here as well Please check other unload entries, as this is wrong These 3 parameters are unneeded imo This isn't doing anything useful? This should go in the init file This too device_info can be set in the constructor with `_attr_device_info`. Then you can set `_attr_name = None` and the entity will follow the device name It's cleanup. Please fix this in the code or it'll probably stay here forever  I was able to get it wrong also in the library ðŸ˜“ I'll also fix there\",\n",
       " \"Create one coordinator class per measurement call type instead. Each measurement will have a different return value type that will correspond to the coordinator data type. I think we can make a base class with the default init method and keep it generic via a type var for the coordinator data value. Then we don't need to repeat the init method in every coordinator, unless we need to customize the init method.\\r\\n\\r\\n\\r\\n\\r\\nNote that I added a default executor job since all the measurement calls are sync. Need to split it up even further than current so makes sense.\\r\\nWe can add the argument always to the base class so then we never need to repeat `__init__` Look at the renault sensor platform for how we can type the entity and entity description generic and have a single description method to calculate the native value. We don't want to create one coordinator per sensor. Multiple sensors will share the same coordinator but just take a different view of the coordinator data. Eg there are three sensors that should use the same swap memory coordinator. I'm not sure we want to request a refresh here. It would mean that there will be at least a second refresh after the cooldown time (10 seconds) if more than one entity shares the same coordinator.\\r\\n\\r\\nProbably refresh the coordinators before creating the entities and then pass each entity its coordinator.  We should make it non protected if it needs to be imported to another module. I don't think argument and type belongs on the coordinator, besides the disk coordinator which needs the argument. For the rest the argument and type are specific for each entity not for each coordinator. The coordinators should just return the measurement from the measurement api call. Then it's up to each entity and its entity description to parse the measurement result and set a state.\\r\\n\\r\\nThe `psutil.net_io_counters(pernic=True)` call just needs to go in one coordinator and all the net io sensors can use that coordinator. I think we should remove argument and type from the common class and just add argument to the disk coordinator. Look at the renault sensor platform that passes an entity to the description value method. I think we can do it like that to be able to set entity attributes and store data that we need.\\r\\n\\r\\nSide note: Calculating state like this isn't really allowed but we should keep it for now. This seems like its going to create a lot more executor jobs which is one of the problems we had with the original design.\\r\\n\\r\\nMaybe its better to have each sensor flip on parts of the update when its added to hass ? After the first refresh the coordinator won't update if there are no enabled entities attached to it. Oh right, it probably won't matter that much in that case. We already have protection built into the coordinators to avoid accidental synchronization so we shouldn't have a thundering herd problem either This should not be a single function with checks for all entities. Each entity description should have a function that does needed parsing on the coordinator data. Yes. Was just parking it yesterday. Will be individual functions.  Maybe add a comment there is no gather here on purpose to avoid swamping the executor to prevent someone from adding one later Side note: An on/off state for a non binary sensor is weird. Agree We don't need a mixin if we set `kw_only=True`.\\r\\n Maybe put all these calls in a single function that we schedule once on the executor, and return a dict or a dataclass with the result eg? For all three entities (`systemd`, `git`, `python`) I get `process node for argument systemd`\\r\\nSo I'm clearly missing something somewhere but can't see why `entity.argument` always resolves to `systemd` regardless. I'm guessing we're consuming the iterator the first time we iterate it. Copy it to a list in the coordinator if we want to be able to iterate multiple times. Thanks!! Was looking at that far too long. In these functions we know what the generic type is. So we should replace the generic type with the actual type, I think. That should allow us to remove the use of cast below. Why is this function just returning the result of `get_network`? Ie, why do we need it? We don't. I just created them one by one as a first step to make sure it all works before cleaning it up and consolidating where possible.\\r\\nNeed to solve some issues first, see #discussion_r1446666406\",\n",
       " \"Please use parentheses for multi-line lambdas \\r\\nlast thing, than this good to go if the docs PR is there Well, maybe that was a mistake on my part, sqft could be zero, without `is not None` this would return `None` and make the sensor `unknown` Could you please revert this change, sorry about that, my fault Yes will revert it. No problem. Use a walrus and store the value in a local variable so we don't need to look it up twice.\",\n",
       " 'Can be inlined Maybe flipping the logic in this step makes it more readable and easier to manage, (So from `if user_input is None:` to `if user_input is not None:`) Can the api token change? Can you revoke it? If so, this isn\\'t a good unique_id The token doesn\\'t ever change - but it can be revoked.\\n\\n- A token maps to a \"set\" of devices.\\n- If you add more devices to your account then they would be attached to existing tokens...\\n- There doesn\\'t seem to be any other way to uniquely identify a set of devices... \\n- A token can be deleted but they never expire\\n\\nMy thought process was I don\\'t want to allow a user to enter the same token twice, but if say I had multipel tokens (my house, my rental, my parents) I\\'d want to allow for 3 entries into HA.\\n\\nAny thoughts on alternatives? Use `_async_abort_entries_match()` instead and make a reauth flow so the token can be fixed if neccessary. Agreed Like so or do I nix the `self._abort_if_unique_id_configured()`\\r\\n\\r\\n\\r\\n![image](\\r\\n Remove both unique_id lines And add pass user_input to the `self._async_abort_entries_match()` Please only put stuff in the try block that can raise module wide logger shouldn\\'t be private\\r\\n If you put this to the top of the file, `self.config_entry` will be set by the constructor of the DUC. Please overwrite the type in the coordinator, check the Youtube coordinator for an example I think I got this working... whatever you return in this function will be set to `self.data` by the superclass, so please only return here Please be more specific, catching bare exceptions is only allowed in the config flow Please remove empty fields On naming: I\\'d suggest naming the device to the station name. Then you can set `_attr_name = None`. What are we doing here? Getting the id from 1st outdoor sensor ... added a comment and a new method I think this is already set in the update coordinator init Can be set outside of the constructor Why isn\\'t this just called `weatherflow`? This tells me we should have a `reauth` flow as well and handle that in the coordinator coordinator is already telling when it\\'s updating\\r\\n \\r\\nTitle automatically gets added from the integration name `_async_abort_entries_match()` gives back `already_configured`',\n",
       " 'Mapping of uom to device class is not unique for `percent`, so we skip it. Is there a way to translate these? How could I lookup if there are already translations for these in the defaults? If the value is Unknown, we should return `None` as sensor value instead Just like this? \\r\\n No I mean in the code, so currently we return \"unknown\" when its unknown (the native value of the entity), but it should return None Can this be done in the lambda? it could be a \"return if ... is \"unknown\" None else ...\" thing. But if it spans more than 1 line it should be a separate function see  It would be maybe nicer to put in a separate function What does Nothing and Production mean? I am trying to put it in a question like: \"What\\'s the solar state?\" - \"Production\" or \"Nothing\". Doesn\\'t really fit imo.\\r\\n\\r\\nMaybe \"Idle\" and \"In production\"/\"Producing\"/\"Active\"? @CHTHSCH @DenisFFM can you shed some light on this as you own such devices? You could remove this one and the translation key for the device class translations What\\'s a PCC? *Point of common coupling*, the point where the public grid connects to the home grid. Is this a common ViCare term? Would using Grid maybe make more sense in the naming? No, had to look it up, but seems to be common in electrical area.\\r\\n\\r\\n> As per IEEE, the PCC can be defined as the point in the power system at which the electric utility and the customer interface occurs. Typically this point is the customer side of the utility revenue meter.\\r\\n\\r\\n#:~:text=3.1%20Point%20of%20common%20coupling,of%20the%20utility%20revenue%20meter.\\r\\n\\r\\nWhat about this?\\r\\n Sounds good, what about the power exchange? Please take in account, this is stuff in the try block that doesn\\'t raise, If you could move it out, that\\'d be great ~~This is based on `self.entity_description.unit_getter` which can raise an exception.~~ Done',\n",
       " 'Should this log really say \"Active source\" or should it be changed like this:\\r\\n `out` is not a good name for the iterator variable, maybe name it `mode` or just name it `val`:\\r\\n Stale print. Again, `src` is not a good variable name here This is also poor naming due to copy-paste This should be imported in the `from songpal import ()` block as it\\'s exported through the main module (i.e., it\\'s part of the public api). Alas, the setting is not (currently) exposed. I agree, but was not exported at the time I did it. I changed it for the SettingChange import. It\\'s been a while since I have touched the library code, but should `isAvailable` check be done prior to the conditional above assigning `active_sound_mode`? I just tested with my soundbar, and yes if an option was selected (Cinema) and I change the input to bluetooth receiver that doesn\\'t support Cinema, the soundfield value is not Cinema anymore, and it became Cinema again if I change again to an input that support it. So you are right, better to do the check before. This could also be done inside the `from songpal import` block. Other than that, I have no more suggestions at the moment. Not sure to understand how?\\r\\nBecause currently SettingChange is not exported, no the only way I see is like\\r\\n\\r\\nAnd in the code use `notification.SettingChange`, but personally I find the \"double from\" better.\\r\\nDid I miss an other way to do it? I meant directly importing `SettingChange` from `songpal` package, as it\\'s part of the public API. It\\'s a very minor nit, and there\\'s necessary no need for action, especially as this is (just) test code. \\r\\nRe my other comment below, shouldn\\'t this work? Yes yes, you are right, I failed in my demonstration, because it was about Setting and not SettingChange.\\r\\nI already have changed the SettingChange to import it in the songpal in the last commit, only \\r\\n\\r\\nremains, but this one is not exported. Yeah, maybe the upstream lib should export that and maybe more, but we shouldn\\'t block this PR for that. I\\'m fine with this PR as it is, so we are just waiting for @emontnemery to approve.\\r\\n\\r\\nIf you want to improve this meanwhile, you could add tests for those error cases that are causing the drop in coverage. Could this be an issue as the list of sound modes is only initialized during the first update / when connection breaks?\\r\\n\\r\\nYou mention in the docstring below that the sound mode might not be available on all inputs/outputs, so I\\'m wondering what happens when we populate this only during `update()` which happens only during the initial update or if the connection breaks?',\n",
       " 'does this actually get reported? The spec says it is a read attribute (the spec doesn\\'t always correctly state reporting...) \\r\\n\\r\\n![image](\\r\\n Oops, I completely misread the spec. things like this should use the Zigpy types.  Zigpy types don\\'t seem to have the ability to convert signed integers to decimals, but there is no reason to make it that complicated anyway, so I just supplied the decimal. I think this should rather be \"Max heat setpoint limit\", and the same everywhere for the translations.\\r\\nSee:  Done Should this rather be `MULTI_MATCH` instead? Since the entity category isn\\'t set to diagnostic or config from what I can see. I changed the category to config, because it should actually have been that. Use `UnitOfTemperature.CELSIUS` Agree. minor, but you wanna remove the empty line in between here?\\r\\n(I don\\'t think the empty line helps readability) Done I think this should rather use `CONFIG_DIAGNOSTIC_MATCH`, as the entity category is set to \"diagnostic\" below. I looked at other sensor entities in the category diagnostic and those were all matched using MULTI_MATCH. I agree that they probably should be matched with CONFIG_DIAGNOSTIC_MATCH, but maybe that should be done in a separate PR? Uh, weird. That shouldn\\'t be the case I think. Don\\'t update the existing ones, but you can add this at the top:\\r\\n\\r\\nand only use that for your diagnostic entity.\\r\\n\\r\\nIIRC there\\'s no real difference between `MULTI_MATCH` and `CONFIG_DIAGNOSTIC_MATCH`, other than that they use a separate registry for the matches and that `MULTI_MATCH` only matches on \"unclaimed cluster handlers\"(?) Done. > Uh, weird. That shouldn\\'t be the case I think. Don\\'t update the existing ones, but you can add this at the top:\\r\\n> \\r\\n> \\r\\n> \\r\\n> and only use that for your diagnostic entity.\\r\\n> \\r\\n> IIRC there\\'s no real difference between `MULTI_MATCH` and `CONFIG_DIAGNOSTIC_MATCH`, other than that they use a separate registry for the matches and that `MULTI_MATCH` only matches on \"unclaimed cluster handlers\"(?)\\r\\n\\r\\nYeah itâ€™s the claiming semantics that are different.  `Thermostat.AttributeDefs.setpoint_change_source.id` instead of `0x0030` Done\\r\\n `Thermostat.AttributeDefs.pi_heating_demand.id` instead of `0x0008` Done Should this also be a diagnostic sensor?  I have been on the fence about that. It depends on the definition of diagnostic in this context. I did indeed write \"heating power used\", but the official specification says: \"level of heating demanded\". This information is not the primary function of the device. A door sensor would have the opening entity not as diagnostic, but the magnetic force would be. I think you\\'re right. I changed it. (If so, also change to diagnostic match) Thanks, I forgot. uh, I\\'ll need to have another look why changing from multi match to a diagnostic match causes this to no longer be covered supposedly. It looks a little bit like a bug to me in the coverage calculation, because it seems to think an empty line is not covered. I\\'ll just try to rebase before anything else. Seems like the rebase fixed it. Looks better now.\\r\\n',\n",
       " \"Config payload is not sent from the device periodically, in the case of `temperature hysteresis` no information about the value change is sent from the device. How will this value be updated in HA when the user changes it in the device UI? When a config parameter is changed in the device UI, then a Event for it is generated and the `config_entry` is reloaded. This makes the value update.\\r\\n So we don't have real-time entity state updates, we need to wait 60 seconds for the config entry to reload. In my opinion, for the implementation of such an entity to make sense, the device must send the `temperature hysteresis` value periodically. Without this, value synchronization only occurs in one direction. We need to ask the Shelly team again for this feature. Please try again, I did already twice.\\r\\nIndeed would be the best solution.\\r\\n Final decision from Shelly is that we need to re-fetch config once we get the notification is changed.\\r\\nThis value won't be ever exposed as a status update.\\r\\n In such case, in my opinion we should drop the implementation of this entity. Its usefulness in automations is very low, the user will change it once, maybe twice during device configuration, so he or she might as well do it from the device's configuration panel. The device user interface uses the name `Temperature hysteresis`, I think we should keep this name. Good point, will change.\",\n",
       " \"When you're always overwriting, you don't need to store your native UoM here How much more sensors will you add with dynamic uom? If this is the only one in the foreseeable future, I'd recommend going for the smaller implementation I put in that other PR to keep the code more readable  can be removed Can also be removed Can we set `_attr_native_unit_of_measurement` in the entity init method instead or may the unit change during the entity lifetime? Oh that's a good point, haven't thought of this idea\",\n",
       " 'I think our general consensus is now that we want this to be in `async_setup`, otherwise the service is dependent on the config entry.\\r\\n\\r\\nI am also not sure how this exactly works when you have 2 config entries for qbittorrent Lemme take a look at this and check Can we completely type this? This should raise a `ServiceValidationError` Please annotate the return type This too should raise a `ServiceValidationError` `total_torrents` is a bit weird for something which is a list, `torrents` would be better. I think the service handlers need to catch this and reraise a translated `HomeAssistantError` Pass in the device_id instead, for a more readable error message:\\r\\n Shouldn\\'t this be translated, or can `LoginRequired` happen in many cases? I handled this how I found other integrations were but i can change this to be a translated string.\\r\\n\\r\\nI believe this is a very rare occurance as it should only happen if a user changes the username/password of their qBittorrent software after adding to HA. As this is a local program running that would be very rare and there isn\\'t a need to change that for security. What\\'s the difference between the manual formatting and the output of the `isoformat` method? Why do we format it at all? Was making sure the format was the same as Transmission\\'s integration but that looks to be the same except with `+0000` on the end, so can format that way. I\\'m missing a service validation schema for the services. These are not state attributes. Please rename the constants. We don\\'t need constants for strings that are only used once. Commented code. Please remove it. These instance attributes are never used. Please remove them. Why did we change the exception in this PR? That looks unrelated to the new services. The parameter is missing a type annotation. Please type the whole signature when adding type annotations. \"grab the list\" is too colloquial English and not correctly explained what it\\'s referring to.',\n",
       " \"Please remove this, integration debug level is controlled via `logger` in `configuration.yaml` Please also add `async_unload_entry` Either change the integration to `zcc` or change the docstring to `zimi` Please remove this Don't directly open sockets from the event loop since this is blocking. Instead, hand this off to an executor job (`hass.async_add_executor_job`). Also, this check would better be managed by your library. Please modify this function such that the controller's mac is used as source for config entry unique id Remove This doesn't seem reasonable. Shouldn't we make sure this connects to the correct controller, not just any controller? A user will only have one Zimi controller on their network. The discover() method searches for a Zimi controller on the user's network without knowing the device's ip address. It is not connecting to any random controller, but searching for their controller on their network. I don't think this should be a user setting. What does the watchdog do? The config flow needs to be 100% covered by tests, please add tests to ensure that's the case.\\r\\n\\r\\nWhen testing locally, you can do like this to monitor test coverage:\\r\\n\\r\\n\",\n",
       " \"I'd make 0 and 1 named constants so open and closed don't get accidentally confused in future refactoring some years down the road Good Idea, Done.\",\n",
       " 'Remove commented out code Fixed Already called down the line, can be removed We should use the Huum stored in Haas.data here Just to be clear, would this be what you are looking for ?\\r\\n So I don\\'t need to get the status of the divide when settings it up?\\r\\nWell, I\\'m all for less code, so I can change it to the way to suggested ðŸ˜„  The explanation is somewhere down in one of the hidden comments (github collapsed them because there were too many) Fixed according to suggestion New integrations should use the new entity naming. Checkout the entity docs on the developer docs.\\n\\nIn your case it would be, setting `_attr_has_entity_name = True` and `_attr_name = None` and adding a DeviceInfo  By \"adding a DeviceInfo\" do you refer to this documentation #defining-devices\\r\\n\\r\\nSo I would add a `device_info` property function that returns a `DeviceInfo`? or `_attr_device_info` in the constructor, which might be cleaner to do But yes In this case, I can\\'t get a unique identifier of the sauna entity. Is it OK to just hard-code the name \"Huum Sauna\" as the name, so that the settings would be something in the line of:\\r\\n Please then set the config_entry.entry_id as unique_id for both the entity and the device Will there be more platforms in the future? If so, please consider a coordinator  Huum does not provide other things that I know of at the moment, so I think we are good \\n\\nIf you update on add, it will run the update function before storing the state so you don\\'t have to pass in the initial state. Please use constants here (CONF_USERNAME) This function is fairly small, I would inline it in where you use it \\n Please remove all the huumtest files Ah, forgot to push the change, sorry, will fix This is not needed? Could very well be yes, I copied some of the tests from and modified. There are just so many things to keep in mind implementing everything ðŸ˜„  I\\'ll remove. Constants Please finish config flows in either Create entry or abort so we also test that the config flow can recover from an error  Checkout `@pytest.mark.parametrize`. you can make all these error tests parameterized so you don\\'t have to have the same test logic thrice  I agree that there are some redundant code here, but I personally like to keep tests separate like this to have better naming and better control over possible extra data that might be needed when possible future issues needs to be tested with regards to the same errors. Personal opinion I guess, hope that you are OK with me leaving it without the parameterization, but I can change if that is something that is required by the codebase. I mean, I am really a fan of keeping tests small and maintainable. With the requirement that config entry tests should end in create entry or abort, your tests will get big and parametrize is a perfect tool for this.\\r\\n\\r\\nKeep in mind, design code on what you think is going to change. The only changes I usually see with config flows are 2 things: 1. a big overhaul where everything is changed 2. an extra exception (maybe your sauna needs to be on when you set it up to collect all data, and you found a way to catch that error in the lib and want to raise a separate error to give the user a better error message).\\r\\n\\r\\nWith the first case you probably always need to rewrite the tests, with the second one you just have to add an extra testcase and you are done.\\r\\n\\r\\nThis isn\\'t a blocker, but I do have a strong preference',\n",
       " '',\n",
       " '\\n \\n Ah cool, didn\\'t know that this was possible! \\n Please bump in separate PR  The bump was already done, just forgot to rebase. Let\\'s bump this since review is not ready yet\\r\\n It\\'s kind of weird to use selectors here since the user will never see this. The media player platform schema had a default username and password, why don\\'t we use those here? In the default configuration of Enigma2 devices, there is no username and password set, so this is not needed (and even when, the \"root\"/\"dreambox\" would only fit to not many devices, because Dreamboxes are only a part of all devices with Enigma2). OK, I see. We create an issue in the import flow, that should be enough? Please don\\'t use `dict.get` for keys which are guaranteed to be in the config In the YAML config, only the host is required, everything else is optional. That\\'s because you modified the platform schema to remove the defaults, please revert that change. We don\\'t need this check, it\\'s checked in the import flow This is not correct, it should be like this since the media player entity is the main feature of the device\\r\\n Even when I want to add more entities afterwards? Yes, unless the media player entity will no longer the main feature of the Enigma device.\\r\\nI don\\'t think that\\'s likely though? That\\'s true, the media player is the main feature. Thanks! What\\'s this for? Forgot to clean it up. Nothing is calling this method, remove it if it\\'s not needed. I don\\'t think it\\'s valid to remove the defaults here? This is given a default value by the schema:\\r\\n The mac address configured for wake on LAN is not imported, should that be mentioned in the breaking change section? Although based on the code it seems like that functionality was not working? It\\'s not OK to have mutable class variables, please move this to an `__init__` method. After import, these can\\'t be changed. Will this be configurable in an options flow added by a follow-up PR? Yes, options flow will be the next step.',\n",
       " '@engrbm87 I am a bit surprised that the GPU memory is registered as a string in Home Assistant state, while the sensor for RAM memory use looks very similar and does not need the string cast in the test here. Any idea what\\'s causing this? I can see that the GPU sensors are mostly percentages. For the memory sensors there is actual memory and memory usage as percentage.\\r\\n[This link]( shows the UOM for the GPU sensors, please double check that they are the same in our code here.\\r\\nAs for the string issue I am not sure, what error are you getting in the test if you don\\'t cast as str. The HA `state` for the GPU sensors is a string, even though the input data (`HA_SENSOR_DATA` in glances_api) is int or float. Not sure why the sensor state becomes string, as the sensors above in this test seem to have the same sensor implementation but do have a *numerical* HA state (docker memory use for example). I did some digging and found that the sensors tests added in PR #93542 is not using the correct `entity_id`. Because it is using an if statement to get the state variable the assertion is not getting executed which is why we are not getting an assertion error. I think the tests should be fixed in a preliminary PR.\\r\\nAs for the `str` casting, I think this is required because the entity state will always be a string. this is what I get from the glancesapi library. Shall I put in some string manipulation to clean that up or request changes upstream? Hello, I think you should move the icon to file `icons.json` Thanks, done! Same here Same here Same here Wouldn\\'t it be simpler to change the key formatting for gpu in python-glances-api and avoid having a special case for Gpu here ?\\r\\n#L185 By the way I can submit the PR to python-glances-api if you want to got this way. I already have another PR open for `network` which will require a new version of the library. Thanks, yes please! I was being impatient and hacky, hoping to get the change in before I would have less time. Wrong mindset. It is obviously better to change the formatting in the package itself than add complexity here.\\r\\nThank you for your offer to add the PR in there, I am still very busy. Hi @fhoekstra , I have drafted a pull request here:\\r\\n\\r\\n\\r\\nThe proposed format for the GPU name is:\\r\\n`f\"{sensor[\\'name\\']} (GPU {sensor[\\'gpu_id\\']})\"`\\r\\nwhich translates to : \\r\\n\\r\\nIf you can have a quick look, I\\'ll submit it to the library maintainer. PR submitted to python-glances-api Version 0.6.0 is now available with the formatting change on GPU name Version 0.6.0 has been merged into dev branch Thanks for the quick action, I\\'ve rebased the branch. Also moving the icon definitions but have some trouble with my local dev setup. If I can\\'t figure it out quickly, I could give you write access to the branch so I\\'m not blocking you any longer Good idea! \\r\\nIs the default',\n",
       " \"Wait, instead of transforming it to KM, can we maybe set the native UoM to the unit of the record? I did is this way as i deemed it easier and since none of the other sensors have a dynamic UoM. \\r\\nIf i were to change this approach should i then also make a new Callable for each existing sensor description? \\r\\nWhat do you think of this? You could extract that dict out of the function, but now you get the full picture I think that's a very good solution thank you! I will do it that way. \",\n",
       " \"Please keep it alphabetically \\r\\n(Can you also do this at the others?) Added in 323dffb78d9a05f17dd971b112e9da7f4e18ae07. Can we type this? Added in 323dffb78d9a05f17dd971b112e9da7f4e18ae07. \\r\\nIsn't this better? @joostlek  Yes, but mypy blows up if the return value is not `Any`.  Check out my changes in 274b76d3ff0a8ee054b85f76338262ecca36d699 and see what you think.  Not trying to make excuses, but I'm an embedded C developer and I'm still learning the subtleties of Python... Thanks for the guidance. I'm not accusing you of making excuses, you can just reply that mypy is annoying and I get that :).\\r\\n\\r\\nI just now see that this was in the switch.py. Does mypy also complain on the select one? Yes, they both need to declare a return value of `Any` to keep mypy happy.  The suggestion you made was for select.py, but switch.py has the same declaration so I was trying to keep them in sync.  I just saw a comment from @jbouwh about modifying the switch.py declaration in a separate PR, so I'll remove that change from this one. Oh, when the changes are this small I don't mind a little code cleanup :) Fixed in a019ea53b7232b2ebcdf8c19d1c787f1a7f52ab1. Oh we already made a separate PR for it so you would not have to do it  Please raise `ServiceValidationError` is the option is not in `PROTECT_MODE_OPTIONS`\\r\\nNote that a translation key can be added to support translations. Thanks for the translation key suggestion.  I added that in 7a031bcff0c9631def3e3968b9fe045a5d322dc9.  I'm glad I did that now because I had to push the values to lower-case to appease one of the linters, and that meant changing the API in my device firmware.  Much easier before it is released.\\r\\n\\r\\nIf I add an `else: raise ServiceValidationError` to `async_select_option()`, I can't seem to hit that line in my tests.  If I call `hass.services.async_call()` with an invalid value in a test, something else raises a `ValueError` exception before `async_select_option()` even fires.  It seems like I should just remove the `if option in PROTECT_MODE_OPTIONS:` test altogether because it is always true.  Thoughts? My fault. It seems SelectEntity does a validation check that calls value Error.\\nThis means you can remove the check to see if the option is valid here, and there is no need to raise.\\n Thanks for verifying.  I removed the check in 0a100876bb02c292b07cfc9135615e5f471255f7. Not sure if the typing is correct here. I might have missed that with the Switch PR. Left suggestions to improve the typing. Please open a separate PR to correct this for switch \\r\\n\\r\\nPlease open a seperate PR for this. See:  We can use `Awaitable`. Fixed in b259dd4d91e0cbad3a762f33c372769bd3327f98. Like you did for the other methods you can omit passing the default values.\\r\\n\\r\\n Ah, yes.  Thanks for noticing that.  Fixed in b5bba9d5f87109e9237337130cf5f4eb96986907.\",\n",
       " \"The device should update the state instead. Good point, especially at QOS 0.  Changed in 4e2f7e54d6cc6c5a8dbf10b96a6baafa996c15c9. Same here Changed in 4e2f7e54d6cc6c5a8dbf10b96a6baafa996c15c9. \\r\\n\\r\\nIMO we should try to set this during the coordinator update. To add, there are only 2 description types, why do we even fallback to entity description icon I used this approach specifically so I could get 100% coverage in my unit test.  At the moment, all of the switches have dynamic icons, but I didn't want to make the assumption that would always be the case.  By setting a return value and then optionally overriding it I don't miss the final return value with the two switches I'm currently implementing.  I know it's slightly odd, but can I leave this one alone so I can keep my 100% coverage score? > To add, there are only 2 description types, why do we even fallback to entity description icon\\r\\n\\r\\nWe have plans in the works for adding additional device types that will have switches without dynamic icons.  The fallback is just planning ahead for future additions.  I'm certainly willing to simplify and remove the fallback knowing that I will probably need to put it back in when new switches are added. I went ahead and simplified the icon property in 8ad8014c75e5574b29cf506bd7a03f402b738ccc just so the unnecessary fallback case isn't an issue here. Please handle this from the coordinator update that is called instead. The code could be moved to the `DROPEntity` base entity class Here you can set `_attr_icon`, make constants for the icons. For binary sensors you could make a mapping. @jbouwh  Sorry, I don't think I'm understanding this.  Are you saying I should create a new switch subclass in entity.py and move the icon property there?  Something like this:\\r\\n\\r\\n\\r\\n\\r\\n... and then use `DROPSwitchEntity` in switch.py?  Would this also apply to the other properties (such as `is_on()`) in switch.py?  You also mentioned binary sensors; do you want me to refactor the (already merged) sensors and binary sensors as part of this PR as well?\\r\\n\\r\\nI guess I don't understand why it is a problem to have the `icon` property in switch.py.  It appears the most integrations do it that way and since it is using `self.is_on` to determine state, it is already changing based on updates from the DROP hub via the API.  It seems like a lot of unnecessary complexity, and I feel like switch properties belong in switch.py.\\r\\n Left some suggestion on your last commit. Lets use `DROPSwitchEntity` as you initially implemented.  The state will be `UNKNOWN`. To test the state update simulate the response using ` async_fire_mqtt_message` or update the state result to `STATE_UNKNOWN`. Simulated responses added in 3948169222a3743e712a49c113cc543ae06af544. \\r\\n Updated in 00255a784e537b659831511f69d179a6c646d4bc, though the `ICON_VALVE` dict needed to be keyed on bools and include the None type. Changed in 00255a784e537b659831511f69d179a6c646d4bc. Can we have a keyed form here to like we have for ICON. Consider constants for the states to be exposed by the API (can be added later).\\r\\nWe can just use `.get` so it returns `None` as default. @jbouwh  I made the change in 84fe270e264702233497985739d2cc79226189cd, but I had to include a reflexive mapping for None to keep mypy happy.  Please let me know if there's a better way to do this. Left some suggestions Implemented in fe7791d5eecacc13382467baaffac4cddd05e01f. Why are we setting a state? That shouldn't be needed. Missed that, only asserting the state should be enough\",\n",
       " \"Please move this one to the coordinator.py file I think we should create the coordinator in `__init__.py` like we normally do Not sayings its correct, but the `tibber` integration also creates its coordinator in its platform async_setup_entry. I can do this but I think its going to require a code change in every single platform Tibber isn't a good example imo. The coordinator can create entities directly :s\",\n",
       " 'This domain is incorrect (and all other too). Spaces in names, should result in an `_` in the integration domain. None of these used that.',\n",
       " '\\r\\nNot sure if they are named arguments, but this is way better imo What do you think about flipping the logic? Checkout Suez Water for example Not used Can we fetch a list of all stations? I\\'ll have to check the docs ... (Mark as TODO) So it does look like in the docs we have a - get all stations for a user.\\r\\n\\r\\n<img width=\"998\" alt=\"image\" src=\"\">\\r\\n\\r\\nSo the question is:\\r\\n\\r\\n- A) User enters credentials - and forecasts get automatically created for all available weather stations... - some what of a redesign - but probably more user friendly at first\\r\\n\\r\\n- B) User enters credentials - and is then presented a list of possible stations to choose from - they select a station ... if only 1 station its automatically created.\\r\\n\\r\\nKeeping in mind that the next PR will allow a user to enable Cloud Sensors for a specific weather station - does one option seem better than the other?\\r\\n\\r\\nIf @briis has time to look over this as well - I\\'d like to get his opinion.\\r\\n\\r\\n_I think the simplest option is to just store `API_TOKEN` and calculate everything else at startup time by hitting the /stations api._\\r\\n\\r\\n I think both would work. I think I would prefer the first. This way is the most simple and I can\\'t really imagine why you don\\'t want to add a certain weather station to your instance\\n If you don\\'t want to see it you can disable it. I have only 1 station, so I am not sure if you get an API Token per Station or per user. If it is per station, then option A is the only possibility. If it is per user, I would go for option B, as the users should have the freedom to select what they want to add per station. It\\'s not what they want to add per station, but what station they want to add Based on the API I have to assume that 1 toke gives you multiple stations because of this endpoint:\\r\\n\\r\\n<img width=\"270\" alt=\"image\" src=\"\">\\r\\n\\r\\n(Happy Boxing Day if any of you are form England?) que? I donno seems like maybe we should just do it every 15/30 mins.\\r\\n\\r\\n@briis why did you select a random 25-35 minute window? \\r\\n\\r\\nI\\'ll change it :) Why don\\'t we merge this with the coordinator? Remove empty fields We don\\'t even store a name In the current code it is storing a name. Although I went back and forth on this:\\r\\n\\r\\n<img width=\"545\" alt=\"image\" src=\"\">\\r\\n\\r\\nAt a minimum we could just store the credentials and at startup figure out which stations to add...\\r\\n\\r\\n Oh lol, I forgot this was a thing. But I actually prefer to store as less as possible. This way if the station name changes HA can pick it up without updating the config entry I\\'m hoping we can just store a SINGLE api token which would be awesome.  There\\'s no legacy anymore since this is core Where identifier? If its not available, why do we add it?',\n",
       " \"As a note, in the future we may want to use this here: \\r\\n`greenpower.GreenPowerProxy.ServerCommandDefs.notification.name`\\r\\nHowever, that would depend on the zigpy ZGP PR  Right now, this PR is independent of that.\\r\\n\\r\\n(Relevant PR for other zigpy def changes:  Thanks for your patience as we work thru the issues surrounding the tree that crashed into our house a little over a month ago haha. \\r\\n\\r\\nThe intentions of this PR were twofold:\\r\\n- Allow this PR to be reviewed independently of the larger ZGP patch\\r\\n- Keep the code changes as minimal as possible to allow for expedited review\\r\\n\\r\\nIf you'd like to wait for the main PR to hit first so we can use the name reference as opposed to a magic string I totally get that. No problem on my end.\",\n",
       " \"This could be problematic when `.get` returns `None`. Yeah, in theory it never will, because this field always exists, but I did wonder if I should None check it, or not use get. Can you maybe add a build number to the fixture and test if this is split correctly? There is a build in the fixture already.\\r\\n#L204\\r\\n\\r\\nEDIT: I'll add an assertion Oh I was looking at the 2 changed lines in the fixture  Yeah that does not have a build, hence why I wanted to normalize it. By the way, doesn't INSTALL say it also supports installing the software? Yep, which it does, but I removed that functionality to make this PR smaller. Ill remove that feature. Because, shouldn't I see an install function then? Yeah I removed it, I've also now removed the supported feature. Ill add them both back later.\",\n",
       " 'Instead of adding this check, we can refactor the parameter to be a dict that we always use to update the service data. The two cases would be a dict with the conversation id and an empty dict. Would it be something like this then for `data`?\\r\\n\\r\\n Something like this:\\r\\n\\r\\n\\r\\nWe can replace `agent_id` similarly.',\n",
       " 'Done.\\r\\n If you move this to the top of the constructor. The super constructor will set self.config_entry. you have to retype it tho, check out the YouTube coordinator for an example Done, I moved it to the top of the constructor. Just for reference, I based my work on the WLED integration, which calls the super constructor last. Please split this from the PR Done. Can this become an enum sensor? Which has all the possible options in the options field? Please don\\'t use numbers as state but make it a snake case value  I did the change but I\\'m not sure I did exactly what you asked, especially because of the part \"Please don\\'t use numbers as state but make it a snake case value\". The values returned by the API are numbers. \\r\\n\\r\\nIs your recommendation that I should I take care of the conversion in the TechnoVE python library instead of here? Yes, that would be awesome when the library has a Enum for the status, because in most cases an user can\\'t do much with an arbitrary number. I think it\\'s best to make sure that the state of the enum sensor is a snake case string.\\n\\nEnums are lovely! Thanks to both of you for the helpful feedback. I\\'ve implemented the status as an enum now. Can use device class translations, so you can remove this Done. \\nOnly uppercase a word when it\\'s a brand Done. Errors is always set\\n\\n\\n \\n Without zeroconf this isn\\'t needed right? If I understand correctly, could this still happen if a user manually enters the same IP address twice? Can also be removed Done. \\n \\n Is this doing anything? You\\'re using `self.coordinator.data` a lot, maybe store it in a local var to make it cleaner and a bit more performant? I think you could move the unique id to the parent entity. Just create a constructor that can accept a coordinator and a key Sure, done. ðŸ¤” Oh no! That\\'s embarassing. That\\'s a leftover from a copy paste that I missed. Sorry, fixed. You\\'re already doing this in the parent',\n",
       " \"Taking the difference between two constants gives another constant. Define that constant at the module level. \\r\\n\\r\\nwould this be ok to just have `SIGNIFICANT_ATTRIBUTES`? if yes, i'll create a PR or maybe this one (_imo looks more readable_)ðŸ¤” \\r\\n Yes, but note that the difference is not the same as the symmetric difference of two sets. uhhh ... good to known ðŸ‘ \\r\\n\\r\\n\\r\\n\\r\\nthan it should be like this, right?\\r\\n\\r\\n Yes. ðŸ‘  - #106727 âœ… \",\n",
       " 'Can be removed Ok, so let me try to explain what\\'s going on. I am not an expert of the hass internals at all and unfortunately the documentation seems kind of poor when it comes to describing how all the config setup works internally.\\r\\n\\r\\nHere\\'s what I understand:\\r\\nThere\\'s an old and a new way of setting up components and entries. The modern way to set up integrations for platforms is to forward the entry setup to the corresponding platforms like this:\\r\\n\\r\\n\\r\\nHowever, the `notify` integration seems to be the only one that is stuck with the legacy way of setting up things. This means that the above call will fail with `AttributeError: module \\'homeassistant.components.notify\\' has no attribute \\'async_setup_entry\\'` for notify.\\r\\n\\r\\nThis is the reason why for example the slack integration separates the behavior for notify like this:\\r\\n#L72\\r\\nNote the `if platform != Platform.NOTIFY` and the `async_load_platform` call above.\\r\\n\\r\\nThis seems to be a common way to setup notify platforms, here they even have an explanation:\\r\\n#L137\\r\\n\\r\\n`no entry support for notify platform yet, have to use discovery to load platform.`\\r\\n\\r\\nSeems everyone else does the same. You can also check the `discord` integration or others.\\r\\nThis is why I use `discovery.async_load_platform`.\\r\\nNow let\\'s come back to how this is related to keeping `def async_setup`:\\r\\n\\r\\nIn the above method which you suggested to remove, I store the hass `config` in `hass.data[DATA_HASS_CONFIG]`.\\r\\nLater on, this variable is needed in the call to `discovery.async_load_platform`, see the requirement here: \\r\\n#L154\\r\\n\\r\\nHence, it seems I cannot remove `async_setup`. Let me know if I\\'m missing something here.  Remember when I said that a notify integration to config flow isn\\'t that different? I take that back. This is awful ðŸ˜‚ (not because of you btw, you\\'re putting in great effort, I just don\\'t like how it differs from the rest)\\n\\nLike I\\'ve seen some pass by but I did not know all these pieces were needed. So I guess I\\'m also still learning here. Can we mark this resolved? I\\'m on mobile right now, I\\'ll drive into this tomorrow If we don\\'t need to set anything we can also choose to don\\'t set anything.\\r\\n\\r\\n But we do need the `entry.data`. This is used when setting up the `SIPCallNotificationService`, which gets the credentials from the config flow through that. But you\\'re also passing the entry data in the discovery stuff, can\\'t you use that instead? Ok gotcha now. You are totally right, let me fix this. I don\\'t know how SIP works, but is it maybe possible to check beforehand if we can connect to the server? To check if our credentials are still valid and we know the server is online and reachable? This can be very nice in both the init and in the config flow. Well... It would be doable if my nanosip implementation also supported the REGISTER method which is used to receive calls. But the aim of all this is to make it as simple as possible. \\r\\nSo we can only verify the credentials by making a call, and I guess we don\\'t want to do that during the config flow. I mean yes we like simple, but we love this as well. If you can guard people from setting up a config entry without ever testing it the data is correct, that\\'d be the best. Otherwise you\\'re getting issues like \"yea I have this entry setup and my device doesn\\'t appear\".\\n\\nThe config flow is the most user friendliest way of saying to the user they f*cked up and that it\\'s their problem For this, I will need to make some changes to `nanosip`. It still won\\'t support `REGISTER`, but the config flow can allow the user to make a test call and show if there were errors. As you\\'re the one knowing a lot about this, what would your ideal way of checking this be? You said about register, what does that do and would that work here? Why/why not?\\n\\nA test call would be nice, it\\'s something. Sadly we still can\\'t verify if it worked ourselves  I don\\'t we\\'re unloading anything so we can remove this function We are popping the entry configuration from the config dict. This is to prevent a memory leak. I think it makes sense to keep it I wrote this with the understanding of that we should not need the data stored in hass\\nData Removed \\r\\nNo need to store the name twice It won\\'t work without this. The notify platform entry needs a name. See also [here](#L70). I can see that we add it, but I can\\'t see where we use it. Can you point me to that? It is used [here](#L117). It goes through `slugify` to make the service name.\\r\\n Interesting one, I\\'ll try to find some people to discuss this with. Thanks Yeah it\\'s a bit annoying, because if the user changes the `title` of the config entry, it won\\'t change the underlying name of the service to call. Would be nice if the user could change that too I know for a fact that there are some ideas to phase out this type of notify services and introduce some kind of NotifyEntity to call a generic service onto an entity instead of having a service per entity, that wouldve been ideal here Let me know when there\\'s a shiny new notify implementation ;)  Remove empty fields Makes sense, I will remove those. I still see 2 empty ones Sorry, removed now.',\n",
       " \"This shouldnt be needed? It could be just  `self._attr_icon = description.icon` but the linter complains because `icon` could be `None` Yea but the standard implementation of the `icon` property first check if entity description is set, if so, it will get the icon from there. So I'm not sure why this wouldn't work here. (This would require removing both lines) In `SleepIQBedEntity` the line `_attr_icon = ICON_OCCUPIED` is overriding it.  Without it being set here it doesn't get set This can be set outside of the constructor I do still have one remark. We should use prefer to use `snake_case` for options. This way you can add the possible values to the translations file and have the values be translated. I'd rather fix it now than having to create a breaking change for everyone in a later release. Did you test this? I thought it had to be entity -> select -> foot_warmer_temp instead That's what I originally had, but the docs say to use the selector key: #selectors I think that's only for selectors as in selectors, not as in the select entity iirc Ah I see, didn't realize those were a different thing Removed it since you're still including names and this PR needs entity translations as a whole to be implemented\",\n",
       " \"Until now, `TemperatureControlTrait` has only been used for temperature sensors, and we also mention this in the docstring:\\r\\n\\r\\n\\r\\nWe should rewrite the doscstring since this is no longer true, maybe:\\r\\n\\r\\n It is still a work-a-round for temperature sensors. Updated the docstr though Let's swap the order to match the order in `sync_attributes` below in `query_attributes`, please do that here too.\",\n",
       " \"Please avoid putting complex objects in the config entry data Please check the latest commit. In 2024.1, minor versions are added, I think this would be a good example to add it to. Let me double check with someone if this is indeed a good example. Any updates on this please. They are still going to write a blogpost, but I just saw an example PR fly by:  Documentation about minor version is available under #config-entry-migration I think I prefer the structure as described in the docs. done In the new config flow you are also setting an unique_id, I think it would be wise to apply this to the migration as well. done I _think_ the default is already the home location, can you double check? I tried removing the default value but then the config flow no longer opens (in the UI). I am not sure if the location selector tries to auto detect the location or uses the stored home location. I prefer to make the default as the stored home location. That's fine by me! I think the coordinator would benefit from setting a lot of the properties in the constructor instead of accessing them every update done Don't patch our code in the config flow. Patch the library client. This is the correct patch target.\",\n",
       " 'It would maybe be preferable to have >1 banned IP as part of test setup and then assert that only a single IP was removed from the ban list. Reason: a call to `manager.ip_bans_lookup.clear()` would pass this test. If I understand correctly this is now asserting that the each service is contained in`msg[\"result\"]`, but there might be extra services or domains in `msg[\"result\"]` and the test would still pass whereas previously it would have failed\\r\\n\\r\\nI\\'m wondering why this needed to be modified? `async_services()` returns a dict of `service`, while `msg[\"result\"]` contains the deserialized JSON representation of this dict, so this is not directly comparable. The test was previously successful as both sides were `{}`.\\r\\n\\r\\nWriting this, I think we could use snapshots here. Might be better to use `save_yaml` here?\\r\\n\\r\\n#L31-L33 Hm we could use this yes, but I try to have the same output as before (`\\\\n` between the ban blocks) When `_write_bans` runs in a thread it will observe the latest state of `self.ip_bans_lookup`, which by that point in time may be different to what it was when line 298 runs.\\r\\n\\r\\nI don\\'t think there are any serious problems (race conditions) that can come of it but thought I would mention it since it\\'s different to `async_add_ban`, which passes the IP to add by value. These changes don\\'t seem related to the newly added service.\\r\\nShould probably best be split off into a separate PR. Hmm yes, would indeed be better, even if this was noticed and needed by this change.\\r\\n\\r\\nBefore the PR, `hass.services.async_services()` returned an empty dict as the components being loaded in those tests (e.g. http) had no services. Since we now have a service in HTTP, the comparison fails because `msg[\"result\"]` is a JSON representation and `hass.services.async_services()` is a Object representation These changes don\\'t seem related to the newly added service.\\r\\nShould probably best be split off into a separate PR. Should use early return pattern.\\r\\n\\r\\nE.g.:\\r\\n Makes sense, thanks :) I\\'m sure this was considered, but it looks like `async_add_ban` adds to the memory dict, and then calls `_add_ban` which appends the address while and the new `_write_bans` method writes the entire file. This means that `_write_bans`, which sounds pretty generic, is really only used in one circumstance.\\r\\n\\r\\nIt probably doesn\\'t make sense to use this for `add` because append should be more efficient, but probably worth a comment. True, append is more efficient then writing the whole file over and over again. `dict`s are unordered, so this is going to lose ordering of all bans in a file.\\r\\n\\r\\nI realize you\\'re using a `dict` here because the original structure is a `dict` and then using `yaml.dump`, however order could be preserved by instead sorting and generating each line as it\\'s own dict, similar to how add works.\\r\\n\\r\\n What do you think about using `OrderedDict` instead? @ViViDboarder Python dicts are not unordered, are you referring to yaml dicts? Oh, interesting. Looks like as of Python 3.7, dictionaries preserve insertion order like `OrderedDict`. I wasn\\'t aware!\\r\\n\\r\\nDoes `yaml.load` preserve the order from the YAML file? If so, this should not be a concern.',\n",
       " \"i think this could also be a function in `homeassistant.helpers.significant_change`, because this logic is already used in other `significant_change.py`'s - will move there in a follow up PR #106005\",\n",
       " 'I think that is it isn\\'t classified, it is hard to judge if the change is significant or not? maybe we should return `None` in that case? Shouldn\\'t we consider it significant in those cases for any change? (as we don\\'t known) In the sensor platform, we return None in case it is unclassified ... tbh this sounds reasonable, because we can not judge it\\'s significance and as per docs `None` means \"we so not know\" ðŸ¤”  Sounds good ðŸ‘ ',\n",
       " \"Let's set this in the PR which fixes volume since volume control is broken currently. That wasn't meant to be there indeed. Fixed now. Can dunehd play just about any kind of local media?  It depends a bit on the player model, but they do have very broad format support in general.  \\r\\nFor example the Smartbox 4K Plus, that I'm using, supports below formats:\\r\\n\\r\\n\\r\\nSource:  OK, I guess it's OK to not add any filtering then. You have tried this with a local media library, and it works as intended? Video and audio files work. Image files do not work currently, but that seems to be a bug in the player OS that it can't handle a dot in the URL query string.\\r\\nI have reported that issue to the Dune support, no response so far.\",\n",
       " \"This has impact on our models. This needs to be proposed, discussed and approved in our architectural repository before creating a PR for it.\\r\\n\\r\\nPlease open a proposal there first.\\r\\n\\r\\n../Frenck As you wish:  Thanks! Let's add beaufort to the existing catch-all `UnitOfSpeed` enum This is not correct; 1 Beaufort is not 1 m/s, shouldn't this just be removed since Beaufort has special handling? When line this is removed, I get the error: homeassistant.exceptions.HomeAssistantError: Bft is not a recognized speed unit. \\r\\nAny value here will be overwritten by the outcome of the conversion. So indeed, 1 is incorrect. But also never used as actual value. Are you sure about this? The error you mention will be raised if the unit is missing from `SpeedConverter.VALID_UNITS`, not if it's missing from `SpeedConverter._UNIT_CONVERSION` Just tested it again:\\r\\n\\r\\nThis is the class:\\r\\n\\r\\n\\r\\n\\r\\nError:\\r\\n\\r\\n Why do we need to limit the size, and if we do, where does the number 8 come from? This is basically a copy of the temperature conversion below. What do you suggest? OK, I see. @bdraco can you comment on why we limit the cache size of `TemperatureConverter.converter_factory`? I don't think it should be needed considering the small number of permutations. I also don't think it's needed here. There is no good reason to limit it anymore Thanks, the cache size limit is removed by this PR: < We should add this also to the docstring of `SPEED` above You're right Yes, so can you do that change please :) Sorry, only now I see what's missing Please remove this and update the test instead as explained here: #discussion_r1469234638 What happened here, why is it changed? This was auto-changed by the formatter, I use the Dev Container...  Let's revert unrelated changes\\r\\n\",\n",
       " 'I am not sure about these functions. I kinda feel like they should be part of the library, even tho they aren\\'t part of the connection to the service it could be used in combination with an abstraction to return an object with full data What do you think @bachya? Do you want me to put it in `aioambient`? @thomaskistler I\\'m aligned with them living in the library. ðŸ‘ðŸ» Why do we need this? I added it as a user convenience. We create and suggest a 3-4 letter name/mnemonic for the station(s) that are added. Instead of having the sensor names show up as sensor.bunny_ranch_weather_station_tempf, they will show up with something like sensor.brws_tempf. It\\'s not strictly necessary. I can remove it if you feel strongly about it. I prefer the first one actually and people can rename the device themselves if they think it\\'s too long Ok. Removed. Removed. Why do we convert a static value? Fixed. So if I understand correctly, someone chooses a location and radius and we get all stations from inside that radius and ask the user to add it.\\r\\n\\r\\nThis means 1 config entry -> n stations.\\r\\n\\r\\nHave you considered 1 config entry -> 1 station? I have this setup at WAQI. This way you can avoid people adding stations twice. Someone chooses a location and radius and we will display all stations that are discovered inside that radius. The user can then select whether they want to pick a single station (in which case we add one config entry that directly tracks this one station), or whether they want to track multiple stations (in which case we will add one config entry that \"averages\" the data from all selected stations). The latter is really important because many of the local private weather stations are not setup ideally and you can have significant outliers in terms of temperature, wind, and precipitation. But then my question is, home assistant has a lot of different features, why don\\'t we let the user do this themselves? Then they can also exclude stations themselves etc scan_interval is static, no need to make it a parameter Fixed. Fixed. You can overwrite the type of the config entry in the coordinator. checkout the youtube coordinator for an example Fixed. Fixed. No? Have you generated translations? Yes. Translations are set up [here](#diff-826a69d62aa78ee1eba2a0563411e60ab894202e56847985f6658b537f3b3e8cR40).\\r\\n haven\\'t checked your tests yet, but I expect this would\\'ve been covered Fixed the tests and removed pragmas. please us an `@abstractmethod` instead Fixed. Please bump in a separate PR Ok. Will do. ',\n",
       " \"I'll start.\\r\\n\\r\\nShould I add a new assistant to distinguish between OpenAI and native conversation engine, or will it create more hassle because both are 'conversation' (I mean, 'Assist')? Should I create a new config parameter to enable or disable this functionality, or the Expose control is enough? Is there a way to update the default prompt for existing installations, or we should ask the user to do that? Do I have to replace those with respective constants?\",\n",
       " 'not needed addressed with\\r\\n This should use CONFIG_DIAGNOSTIC_MATCH defined on line 38 addressed with\\r\\n stop_on_match_group is meant to prevent different implementations for the same functionality from being matched. Do you need this for this entity? addressed with\\r\\n We should still include the model in this matcher so it is t matched for every device unless it is a standard zigbee attribute  But this is a standard Zigbee attribute as described in ZCL 6.3.2.2.2.1 (Thermostat Settings Attribute Set attribute id 0x0010 \\'LocalTemperatureCalibration\\')\\r\\nWhat would be specified as a model in the matcher? all good I just hadn\\'t checked the spec this is inherited. No need to redefine it \"_attr_entity_category\", right? yes no problem\\r\\n',\n",
       " 'If you reverse the condition and return here when it is valid, you can save some indent',\n",
       " '\\n',\n",
       " '\\n I think you can just omit the unit specifier if there are no units. Oh lol, apparently I have a draft review comment saying it should be \"satellites\" ![image](\\r\\nLooks strange. I looked at the GitHub integration and it specifies custom units for each type of counting sensor (Issues, Forks, Stars, etc).\\n\\nWhat looks strange? GPS Satellites: 9 satellites\\r\\nStrange to duplicate \"satellites\" here I mean usually we exclude the UoM from the entity name, but in this case there is no real alternative (Like \"total kWh\" would become \"total energy\", but in this case removing satellites leaves us with an entity without a lot of context).\\r\\n\\r\\nI think there is no better alternative',\n",
       " 'this should not be included in the PR what is this for? The idea was to add general handler for binary outputs. Binary Output, as specified in ZCL, has ActiveText, InactiveText, Description and other Attributes. I\\'ve tried different approaches to use these Attributes to populate Select Input in the following way: Cluster description to be used as attribute name (which is achieved), ActiveText and InactiveText should\\'ve been added as an Enum properties. I couldn\\'t find a proper way to dynamically populate Enum object with properties.\\r\\nI didn\\'t want to change the \"types.enum8\" definition to add a method which will create new property during execution of the code as I was unable to analyse further the HA Core code and foresee any arising problems due to the change, due to my lack of knowledge.\\r\\nFinally I\\'ve just decided to define different clusters states in Python as shown. As a result, I needed to add some device filters, so these properties apply only to this particular device and not to every device that has Binary Output Cluster defined.\\r\\n\\r\\nI am willing to try my best to write a general Binary Output Cluster integration in ZHA, but I will most definitelly need some help from HA Community or Developers. It should render in user interface dynamic Select Input options read from the cluster attributes. Sorry I meant why are there 2 marchers on this? And why are you trying to match just â€œmanufacturerâ€',\n",
       " \"This change requires an architecture discussion.\\r\\n\\r\\n#changing-the-entity-model I'll create a discussion then. Let's leave this as a draft until a decision is made. Let's close it until it is approved.\",\n",
       " \"Since this is going to get immediately shadowed on the first update, and there doesn't seem to be any need to share the value between instances, wouldn't it be better to just declare in the initialiser?\\n\\nAlso the retry limit '2' is a magic number used in more than one place, so might be more maintainable to use a constant. Use constant instead of '2'? See above. Why not just continue using the previous patch since it is identical?\",\n",
       " \"So the thing is, we should not use YAML anymore. Instead we want to import the YAML using an import flow which creates a config entry for the YAML config. @joostlek Do you mean, it should not be possible anymore to configure via `configuration.yaml`? Yes Ohh, that is sad...\\r\\nBut removing it will be a breaking change and I would rather not do that.\\r\\n\\r\\nBut I don't think this is up to me to decide. What you would say @fabaff ?  Well, we have an import flow for that. You can then import the YAML so it will create an entry for you Ok, have not yet looked at that.  @joostlek Did you refer to this when you were talking about `import flow`?\\r\\n Nope: checkout #diff-3f88feab5a41e23e0057f3117af8a8effc16d9a136c2dbb07e293286a9acb0ab\\r\\n\\r\\n(This is just to show how an import would work. I changed this code up a bit as its now a bit cleaner, so please checkout the version of suez water on dev) Thanks for this hint. I have a new proposition for it based on the Suez example. Can we initialize the api client here, do a quick check if the service is working and then store it in the data? \\r\\n\\r\\nPlease define a PLATFORMS with all the platforms you use (which is only Sensor in this case) Only helpers are allowed to have a name for the config entry. Instead we should set the config entry name to something the user can recognize You mean, using the `from` and `to` config values for example, to build a entry id? Yep Can we do a check if the entered stations are correct?  ~The api will match it to the closest station, even when I type `X` and `Y` for `from` and `to`, the api request will succeed.~\\r\\n\\r\\nNot true Test added Can we maybe get a more descriptive name? Start station id/start station name/etc You can just put this function in async_setup_entry, it's not that big (and it gives a better overview of the setup) For the import issues, please check the current state of suez_water at the dev branch. Also, deprecation period is 6 months The import issues now use the same implementation as suez_water. I'm currently in the bus, let me link you a PR when I'm home. feel free to ping me when I forget Why do we store the config entry data here? This is also being passed on to the async setup entries in the other platforms, so is there any need to store it here? I think there are 2 things we should try and catch. Because we already check if the stations exist in the config flow, we know that _in theory_ the stations exist and that this can work. But there are 2 possibilities where we can't get data.\\n\\n1. The service is down. In this case we want to raise a ConfigEntryNotReady exception. This makes it retry a bit later again.\\n2. The stations don't exist anymore. (I'm just doing a guess this is something that can happen). In this case, our config entry just doesn't work. In the future, if you feel really fancy you could work on raising a repair issue to notify the user that they should repair their config entry. For now, please log that the call failed and raise ConfigEntryError instead.\\n\\nThis is the ideal solution, but this also requires the library to raise different issues on the different causes. Is there any way you can maybe tinker around with this and check if we can catch specifics? Can be removed Please only keep stuff in the try block that can raise  I think only the start and destination separated by a space would be enough. \\n I think the platform schema should stay in this file \\n\",\n",
       " \"@teharris1 I think you might have forgotten to clean up helpers in this file which are no longer needed, for example `add_x10_device`. Could you double check? Yup. I confirmed all unused items are removed now. I don't think this is very idiomatic, I'd expect something like this:\\r\\n Use `any` instead of the loop:\\r\\n Instead of the untyped dict, can we make it a TypedDict to make the code easier to understand?\\r\\nSame comment for the override functions.\\r\\n\\r\\n\\r\\n     Why do we need this special case, the list comprehension below will still work even if there are no devices, right? What's the purpose of this guard, it means we don't allow removing the last device, is that intentional? Please use same variable name in the functions, it makes the code easier to read Why do we need the `options_config` variable, we can just do:\\r\\n This is not OK, we're mutating the original list. Instead, do `override_config = override_config + [override]` I am confused by the concern. The first thing I do is copy the original list with `options_config = {**config_entry.options}` so any manipulation from there is changing the copy. Why is that an issue? NM, with the other comment below, I am removing the lines you are concerned about anyway.  Same comment as before, why do we have a special case for this? Yeah, I see what you are saying. This, combined with the `if new_overrides:` below was intended to avoid an empty list but that is really not helpful. Same comment as before, why can't we remove the last override? We can use the `send_json_auto_id` helper so we don't need to include an id count.\",\n",
       " \"We don't sort imports like this in this project, please revert this change Why is the formatting changed here? Please revert unwanted import changes\",\n",
       " 'I guess this should be \"median\" Same here, should be \"mode\" or \"Mode\". \\n \\n',\n",
       " \"This doesn't look like the right patch target\",\n",
       " 'Why does this happen? Should we differentiate?\\n\\nYou can raise ConfigEntryNotReady when HA should try again later, or ConfigEntryAuthFailed when the API key expired (but this requires reauth flow so this one is out of the picture for now to keep the PR small)\\n\\nAre you the owner of the lib? If so maybe it\\'s an idea to raise different errors on these events to catch them properly so you don\\'t have to compare http status codes here Thanks for the pointers. I wrote the underlying library. I implemented better error-handling there and updated this code too. We only allow helpers to set names in the config flow.  Noted, updated. To continue on not setting a name, is it possible to get an user recognizable name from the API? The API is pretty simple and has no specific identifiers but I implemented an identifier in the underlying library (based on hashing the API key, which is a fixed key for each access).\\r\\n\\r\\nCode is updated to create a name from the ID, something like \"API-12345678\".\\r\\n\\r\\nEdit: I also sent a mail to the API owner to expose the name of the Hot Tub which is available in their system but not in the API. Coordinator is already available in `self.coordinator` Thanks! That helped simplify things a lot. So you are setting self._status, which you expose at self.status.\\n\\nWhatever you return in this function will be set in coordinator.data. Thanks! That helped simplify things a lot. I\\'m fairly new to the Home Assistant source code. Is the device id a str or what else? Shouldn\\'t both be made str? Good point. I moved the whole logic into the underlying library, and more importantly, I made sure it\\'s already a string. Not needed Removed! Always happy to simplify!\\r\\n\\r\\nEdit: I removed the wrong entry first but in a subsequent commit, corrected the issue. Oh I now see the device id is this. Can we get an id from the API? if the API key ever expires all entities get doubled and automations will break. Unfortunately, the API is fairly simple and does not handle sessions at all. You always have to provide the fixed API key for every request.\\r\\n\\r\\nBut a good point is made, I moved the whole logic into the underlying library. When they update the API to have IDs, it will be less intrusive for the Home Assistant codebase. This class should be moved to the lib  Good point! The whole class turned out to be unnecessary. Removed. Please remove the empty fields Done! \\n Done! Is there a reason for such a low update interval? Is 10 or 15 seconds not enough? Good point, I think I just wanted a more responsive interface during testing. I\\'m raising it to 15 seconds in the next commit. \\r\\nFor what I can see, an API key corresponds to exactly one device? When raising this error you need to have a reauth flow. Since adding this would be a bit too big for this PR, raise a ConfigEntryError instead. (This way it won\\'t retry again).\\n\\nYou can implement reauth in a followup This function is fairly small. I think we can move this into the config flow step completely; this allows you to get rid of the custom exceptions. This ID is now unique for every hottub right? \\n I am wondering, will we support more platforms in the future? Or are we just controlling the lights and that is it?\\n\\n',\n",
       " 'Can we maybe disable some by default? I can imagine these are quite specific (and since they go up the same rate, do we really need all of them available?) From a user perspective, I would like to have access to the total gas consumption by default. A more specific consumption like \"fuel cell\" or \"peak load boiler\" (which is missing here) could be optional. But you don\\'t need the consumption this week, month and year all at once \"Today\" could be enough. HA Energy dashboard can do calculations for the rest.  > Can we maybe disable some by default?\\r\\n\\r\\nI think so too. I suggest we disable all but the *today* sensor by default. \\r\\n\\r\\nI already prepared a PR for the existing entities to do so.\\r\\n @joostlek what is the recommended state, hide or disable? If the sensor is just hidden, one would already collect long term statistics for later use, right? I mean, what\\'s the point of collecting LTS four times (as in, the increase is the same)\\r\\n\\r\\nAlso, the stateclass is Total increasing, while it seems like it will reset at least every day/month/year/week. I think the state class should be Total From the [description](#state-class-total_increasing) `total_increasing` perfectly fits in my eyes.\\r\\n Oh you\\'re right added `entity_registry_enabled_default=False` @borys-kupar what was the difference between this one and `gas_consumption_total_today` again? Does it really make sense to have both?  Total gas consumption consists of 2 items for me: \"fuel cell\" and \"peak load boiler\". Those are optional things, that helps you understand better how gas is being consumed. See the screenshot from the ViCare app:\\r\\n![Screenshot 2024-01-31 at 12 53 06](\\r\\n And \"fuel cell\" and \"peak load boiler\" are two different heating systems?\\r\\nI guess it would be nice to see that as well (maybe in another pr). Just had another look, peak load boiler is not exposed in the library. To me it\\'s not clear what each value represents and what is a sum of what? \\r\\n\\r\\n- \"heating.gas.consumption.total\"\\r\\n- \"heating.gas.consumption.summary.dhw\"\\r\\n- \"heating.gas.consumption.dhw\"\\r\\n- \"heating.gas.consumption.summary.heating\"\\r\\n- \"heating.gas.consumption.heating\"\\r\\n- \"heating.gas.consumption.fuelCell\"\\r\\n\\r\\nIs the peak load boiler the dhw? @borys-kupar Can you file a feature request with the [library]( it\\'s probably dhw, I\\'ll confirm and file a request if needed.',\n",
       " 'I think this should not accumulate. \\r\\n\\r\\n`async_call_later` returns a cancelling callback. Need to store it so when new `set_interface_state` request comes we cancel any pending `deferred_update` This call will remove the state. But if the interface later becomes available again nothing will resurrect the state instance since its name will be already in `tracked` variable (inside `async_setup_entry`) therefore `update_items` will ignore it.',\n",
       " 'Please only patch out the library Do you mean `with patch(\"tessie_api.set_seat_heat\",` because that does not work.',\n",
       " 'You can\\'t control individual windows? No, you cant :(\\r\\nThe function call lowers or raises all windows\\r\\nReference:  How come we need to change 4 different states? The car opens and closes all 4 windows with the one function call. But we can\\'t manage each window separately, but we have to still give the separate state of every window for it to work? Odd Yeah I know, we get the state of each window, but cannot control them individually. I could expose binary sensors for each window, but I am not sure how much value that has.\\r\\n\\r\\nMaybe I\\'ll add state attributes in the future. Vent? So it doesnt actually open the windows fully, it only opens them a little bit to \"vent\" the air. The API call is literally `vent-windows`.  Aaah',\n",
       " \"Please sort them alphabetically Done You use a coordinator, this doesn't work with PARALLEL_UPDATES Removed I think for the strings we want all snake_case, for keys it doesn't matter, but for translation keys it does iirc So you want me to use _ instead of - right? This has been changed You're also not checking for entity description translation keys Ok ill revert this change. I dont think I need it anyway. Please keep the names in Sentence case instead of Title Case Add _new_ strings have been renamed. \\r\\n\\r\\nCan be a generator expression here Must have missed this one. Thanks Please adjust the entity/coordinator/sensor in a separate PR. Once we merge that one, this one should be limited to binary sensors This was feedback from @joostlek. I'll try smash out a seperate PR now. I agree with his comments. It should still be a separate PR. Finally been able to get that changed raised seperately:\\r\\n Looks like unrelated changes? Yes, has been removed from this PR. \\r\\n\\r\\nThe second one could be cleaned up more. It looks like some sensor changes accidentally made it in with merges self.value got removed in this PR.\\r\\nI have pulled this change out into  Thanks, this PR doesnt touch sensors anymore. In a followup these should be changed due to a recent change  This will come up a few times in the other platforms, but ill look at addressing them all once I fully understand the repercussions. OFFON isn't used. Ah yes, that was an idea I gave up on. I'll raise a PR to remove it.\",\n",
       " \"\\r\\n\\r\\nNone is already the default value \\r\\n\\r\\nPlease create the repair issue here depending if there is an error or not. See the Ecovacs integration as example In the config flow, this means an invalid id, and here, it means we should retry later as it is a temporary error. What is correct? Please use a [Coordinator](#coordinated-single-api-poll-for-data-for-all-entities) instead \\r\\n\\r\\nNot used Should create in the import step as we have different errors Please use references where possible.\\r\\nAlso `cannot_connect` is missing We should deprecate the entity with a 6 month deprecation period instead of directly removing it. \\r\\n\\r\\nWe should use the name of the station for new config entries Can you give a short explanation why the name shouldn't be user configurable? Is it best practice to choose a name  automatically and let the user deal with renaming devices and entities afterwards manually? > Is it best practice to choose a name automatically and let the user deal with renaming devices and entities afterwards manually?\\r\\n\\r\\nExactly and I assume most of the user will use the station name I see, I removed the optional parameter in the last commit. Adding a new platform should be done in a follow-up to keep this PR as small as possible. Please remove this file \\r\\n\\r\\nYou currently don't need to reload it\",\n",
       " \"`self._reauth_email` doesn't appear to be set to something else than `None` when in the user flow. We can initialize it to `None` as a class attribute above.\",\n",
       " \"Might want to guard it's an actual number. `state.state.isnumeric()`\",\n",
       " \"Just in case unifi might introduce new values, wouldn't it be better to default to UNKNOWN in case we don't find the state? The enum should default to unknown by itself.\",\n",
       " '',\n",
       " \"\\nplease use constants. (Not sure if this one exists but I'm guessing so) Please add reauth in a follow up PR Is this a requirement? It doesn't add much complexity and I'd really prefer to have it in this PR if possible. But if this is a blocker to merging then I'm ok with moving it out of this PR. When I [previously submitted an integration]( having reauth in the initial PR wasn't an issue. I think I am going to put this as a requirement. Google Tasks also didn't come with a reauth flow. I think this PR looks quite done, I'll take a look at the tests now. After this PR you can add the reauth flow and I'll happily take a look at it Removed reauth from this PR. Will submit in a follow-up PR. This function is quite small, I would inline it into where you use it Move this to `__init__.py` as you're not using it here Can we type this? I added a generic type parameter to the `DataUpdateCoordinator` so now this method is implicitly given a return type. Ah cool! But can we still add this type as `-> ..`? I really enjoy well typed code as it also enables others to see what's happening. Fixed. I'd rather see the coordinator data to be a dict[str, device] than a list[device] Can we also check super().available  Please remove the empty fields At this point, all devices are already present in coordinator.data, no? \\nwdyt You just iterated over them, can you maybe use that list? I'm not sure what you mean with this suggestion, can you give more details please? Oh I thought you could've used the operation list, but vacation mode gets translated to off and that's filtered out Shouldn't the timeout be relocated in the library? Also, can you change your email? Don't think you need this one (I also removed this from the config flow scaffold recently) Can we make the config flow tests end in either Create entry or Abort? This way we test if the config flow is able to recover from an error. (This can simply be just adding the successful path to these tests) Maybe checkout `@pytest.mark.parametrize` so you can merge this test and the invalid Auth one  Oh i see you know about the function, i think it would benefit here Device registry is available as test fixture, let me know if you can't find them as I'm on the public transport right now  Maybe look into snapshot testing, that would make this test way cleaner Please use the freezer for changing time Freezer Snapshot testing would work wonderful here\",\n",
       " 'Can we maybe just update the options dict we pass in if its a file instead of duplicating the creation of the object Or use `options |= {\"cookiefile\": cookies_file}` its not incredibly obvious how to use `options |= {\"cookiefile\": cookies_file}` but I did the former requested change Please don\\'t use info, debug would be more fitting here no problem, fixed. I got the advice to use path lib for this, I am currently in the train so can\\'t really check  I don\\'t see any advantage in this but if that\\'s the prefered way I\\'ll use it. It means creating a complex type that has to be converted back to a string to be used.',\n",
       " 'Instead of serializing the calls and timeouts, can we do one timeout and one gather of all the coroutines? Could you add some context for this change? I copied the existing `LyricEntity` class, so I want to make sure there\\'s a good reason for this entity to be defined differently.\\r\\n\\r\\nAlso I\\'m a bit confused that this comment is suggesting I set `_attr_device_info` to `self._key` while the next comment is suggesting that I set it to the result of `_get_lyric_device_info`. Set this in `__init__` instead:\\r\\n```py\\r\\n        self._attr_device_info = _get_lyric_device_info(self.device) Same here: I\\'d like to keep this as close as possible to the existing `LyricEntity` class unless there\\'s a good reason for it to be different.\\r\\n\\r\\nI also personally prefer to use properties for data that is derived from a member so that you can\\'t have members that get out of sync. Why is the name composed like this? What\\'s the device\\'s name? Great question: these entities represent the state of individual sensors that are placed in each room. However, the data is not being reported from those sensor devices directly; it\\'s being collected and reported by the thermostat device. So the device might be \"Living Room Thermostat\", but the entity might represent a sensor in the Kitchen. I don\\'t want these entities showing up as \"Living Room Kitchen Temperature\" because that doesn\\'t make sense, so I\\'m omitting the device name and using the room name that is configured in Lyric instead.\\r\\n\\r\\nIf you can think of a better way to do this I\\'m open to it! Does the dependency bump need to happen together with adding the room entities, or can it be separated? I submitted a patch to that library that is necessary for this change to work, so the dependency bump could be done separately, but it would have to be submitted first.\\r\\n\\r\\nHappy to do that if you think that\\'s the right approach and you\\'re willing to stamp that PR for me! Same question about the name \"Overall motion\" read a bit funny, why not\\'s just \"motion\"? You\\'re right, it does read funny, and it might not translate very well either. \\r\\n\\r\\nI used the actual term that the Lyric API uses (the field is `overallMotion`). They use that term because the value is an aggregation of one or more motion sensors. If you had two sensors in one room, for example, this would be true if either sensor detected motion.\\r\\n\\r\\nSimilar reason why the above sensors are \"Average temperature\" and not just \"Temperature\". It\\'s not accurate to say \"average\" for the motion, though. \\r\\n\\r\\nWith that context, if it still sounds too weird I can just call it \"Motion\".',\n",
       " \"Consider moving this to the backend. I invited you as a collaborator. I've moved the code to the backend and pushed a new release and updated the dependencies Why is this statement needed? Good spot, it's left over from the auto discovery logic that I removed from the initial commit, where `CONF_HOST` becomes an optional field and I was setting the default based on the value from `user_input` if available (otherwise it's empty). But it is unnecessary for the basic config flow implementation. I will remove it This line is now removed We should provide `MODEL_NAME` in the `model` field of device info. In the `name` field we can also provide `MANUFACTURER_NAME + MODEL_NAME` or we can use device `friendly_name`. In case of export, we need to use the name from YAML to avoid breaking changes.\\r\\n\\r\\nSee example: #L24-L28\\r\\n\\r\\nor \\r\\n#L291-L295\\r\\n We also should set `_attr_has_entity_name = True` and `_attr_name = None` in the `MediaPlayerEntity`. See  > We should provide `MODEL_NAME` in the `model` field of device info. In the `name` field we can also provide `MANUFACTURER_NAME + MODEL_NAME` or we can use device `friendly_name`. In case of export, we need to use the name from YAML to avoid breaking changes.\\r\\n\\r\\nI was already generating a `CONF_NAME` but wasn't exposing that through - so I've now switched that to using just the friendly name and there was already a check to check to use the YAML name, which should now be picked up.\\r\\n\\r\\n\\r\\n\\r\\n> We also should set `_attr_has_entity_name = True` and `_attr_name = None` in the `MediaPlayerEntity`. See \\r\\n\\r\\nDone Let's add host field description.\\r\\n\\r\\nExample:\\r\\n#L6-L11 This has been added When I re-added the device, after entering the IP address, the integration asks to enter an access token, but the TV does not show it. To see it I had to enter `0000`. Maybe we should do this automatically like the Bravia integration does (`self.client.pair` trying to connect with `0000` PIN which causes a popup on the TV)?\\r\\n\\r\\n#L163-L166 When no access token is provided it is sending an auth token request already, however I have seen similar issues to what you've described. I think it's related to some timers in the TV as it is seemingly random. The way I had intended to handle this was by submitting an empty access token to force the auth to happen again, which in my testing usually works. But I note that this wasn't obvious this was possible.\\r\\n\\r\\nI've now implemented the ability for the flow to regularly send the auth request every second whilst we're waiting for the access token to improve the user experience, which should handle both the prompt not appearing (or briefly appearing and then immediately disappearing), but also removes the time sensitivity that was there previously.\\r\\n\\r\\nIf you find that you still need to send an invalid token I can modify this to do so.   Can we add a function `async def async_unload_entry` too? The way in which we distinguish between these two cases is not correct, because it makes no difference to the user.\\r\\nInstead, we should distinguish between:\\r\\n1. The import is done, and the user should remove YAML\\r\\n2. Something went wrong when doing import (if this can happen, for example in the authorize step, and we can't leave the flow import for the user to finish) If this is only here to make mypy happy, do like this instead:\\r\\n Please remove these constants, they're only used once, in config_flow.py Move this to config_flow.py Do we really need these helpers which are only used once? Not necessarily, but I was following the same pattern that is found in the [samsungtv](#L16), and [webostv](#L16) components which perform near-identical tasks.\\r\\n\\r\\nSo I didn't want to break existing convention, but it might be worth refactoring all of these helpers so that the core logic can be shared. Does the dependency bump need to go hand in hand with adding the config flow? If not, please move the dependency bump to a separate PR. Yes, the dependency bump is here because we've added the `query_device_info` function that is used in the config_flow to get the UUID, model name and friendly name and of the TV. I think we should also raise an issue here, telling the user the import is pending because we can not connect to the TV and will be retried, the issue should be removed when import suceeds. There's no reason the unique_id should be optional?\\r\\n Agreed - this is left from the original implementation that didn't migrate the YAML (and discover the unique_id) we know this entity has a unique id, hence there's no need to check this Sure, I think this is mainly here to keep the type checker happy (and is the same structure as the samgsung and webostv and webostv components) but I can instead turn this into a `TYPING_CHECKING` assert check instead. If the turn on action is now a coroutine, this can be simplified to:\\r\\n\",\n",
       " 'Why not make this `self._min_state_duration = min_state_duration.total_seconds()` and get rid of `min_state_timestamp`?',\n",
       " 'I would move this list into consts.py Does this do blocking I/O? Yes ðŸ‘  Typo in function name \\r\\n We don\\'t need to get the disk mounts more than once. Same for network interfaces and cpu temperature. Break out those calls from the loop. Side note: The sensor update seems really inefficient now as it updates all sensor registry items even though the corresponding entities may be disabled. Maybe we already have plans to refactor that later? Yes, we should refactor that after this PR as it will now create a lot of sensors (even if they are disabled) I think we should import the config and enable the configured sensors by default. Otherwise configured sensors may get disabled. This could happen if the user would add the YAML configuration during the deprecation period, ie the user didn\\'t have the integration setup before. The result would be unexpected as the configuration doesn\\'t create enabled entities anymore. I guess we can add that without too much effort but seems a bit strange to \"support\" this as there will be nothing hinting anymore to setup from YAML. I think it\\'s better to be safe than sorry. We can remove all that logic when we remove the import after the deprecation period. I made some comments to it in the code so it should be pretty easy for someone to cleanup once deprecation is over \\r\\n\\r\\nIt would be good to allow the user to specify processes which are not currently running. Currently it seems that with each adding of a process, a `{\\'process\\': \\'<process_name>\\'}` is added to the options. Maybe it would be better to have a single process key and the processes as a list in the value.',\n",
       " \"Groups of binary sensors still have the domain `binary_sensor`. It's legacy groups that have the domain `group`. I don't think we should allow those groups.\",\n",
       " 'I am not seeing this option in the platform schema, was it removed in an earlier change? It is included in `BASE_PLATFORM_SCHEMA`, which is extended in line 33. Ah okay',\n",
       " '',\n",
       " \"Isn't this one obsolete because of the SIGNIFICANT_ATTRIBUTE check below? uhhh ... you're right ðŸ‘  7aa5e47\",\n",
       " 'This is not needed. `async_write_ha_state` is called after we call `async_update`. #L680 well but async_update is only called for entities that need to be polled.\\r\\n\\'_on_matter_event\\' is called when there\\'s a push update from the device itself ah... now I get what you mean... good morning. Probably use the debounce helper instead. Currently the `loop.call_later` call is not a debounce, it\\'s just a delay. Each event will still schedule a new poll and state update. If we want to debounce the events we need to have debounce logic.\\r\\n\\r\\nExample:\\r\\n#L106-L117\\r\\n\\r\\nWe should test the logic here with a matter event.\\r\\n\\r\\nExample of how to patch the debouncer:\\r\\n\\r\\n#L140-L158\\r\\n Sorry, the comment is wrong here, we just want to delay it, not debounce Why do we want to delay the poll and state update? to read the energy meter value after the relay was toggled, consider it an extra service to the user otherwise it looks weird when you toggle the relay you wait up to 60 second to see the wattage change What Martin is saying still holds: how to avoid scheduling 5 polls when 5 events come in within a second.  Use `helpers.event.async_call_later`.\\r\\n\\r\\nMake a constant for the time to make it easy to patch in tests. The async_call_later only seems to take a coroutine function and not a regular function ?\\r\\nI want to pass it \"async_schedule_update_ha_state\" including argument \"force_refresh\".\\r\\n\\r\\nI could pass it \"async_update_ha_state\" instead without any side effects ? Make a callback helper method on the entity that calls `async_schedule_update_ha_state`. The helper should accept one parameter for the time of the event and return `None`. Thanks, first time I had to use this async_call_later helper.\\r\\nAnyways, I\\'ve adjusted te logic a bit to use the helper and define the delay in a constant. We need to patch the debounce time to 0 too. Maybe update the code so we call it with kwargs in all places to make this a bit easier?\\r\\n\\r\\nThe callback parameter, the first positional parameter, isn\\'t optional. So if we\\'re using kwargs it\\'s always there.  Yeah, let\\'s do that as this is a bit cumbersome like this. I\\'ll just adjust the implementation.  done.',\n",
       " \"Are you able to add the other models of humidifiers? Models are listed here:  done Great work! I was just about to start working on this today! \\r\\n\\r\\nAre you able to take a look at this attempt and incorporate where makes sense? In particular the modes and other models.  You may actually be able to use the majority of this file: \\r\\n\\r\\n \\r\\n\\r\\nThis came from a previous PR that was too large to merge: #diff-4537c0d070b59657c8d13492856bea3d35a4f04be9fde4468634b82276316162 hopefully done Please make a separate PR where we import all the available modes here.\\r\\n\\r\\n#L4-L12 I'm not quite sure I understand correctly.\\nInstead of just `MODE_SLEEP` I should add all missing `MODE_*` (in a separate pr)\\nIs that right? Yes, please. All of these modes are documented in our dev docs and should be available in the humidifier package for other integrations to import.\",\n",
       " 'It would be better to let stdlib do the validation by creating a UUID object \\r\\n#uuid.UUID Done.\\r\\n\\r\\nAlso added another test to reach the codecov target (we were below by some tiny number). This is likely to break in the future since there is no guarentee that the mobile app will continue to use this convention.\\r\\n\\r\\nIf we want to do something like this, we would need to add a published api (in another PR) to the mobile_app integration to get the list of UUIDs instead so we could be sure it keeps working if the mobile_app changes how it registers these in the future.\\r\\n\\r\\nI\\'d pull this out of this PR for now since there are multiple new features in this PR which should be two (or more) PRs:\\r\\n1. allow list for specific uuid\\r\\n2. mobile_app integration I\\'m all for clean APIs, but is there someone willing to make a PR on mobile_app and have it merged quickly? (I don\\'t have the cycles) If not I suggest we keep this feature for the following reasons:\\r\\n\\r\\n- We\\'d lose a good-enough fix for an ongoing problem (original issue is more than a year old) breaking functionality for many users while waiting potentially another year for the perfect fix.\\r\\n- We\\'re not doing any crazy hacks with the internals of mobile_app, just reading public entities, the risk of breaking is arguably tolerable\\r\\n- Even if it breaks in the future, the worst that can happen is to ignore beacons, which is exactly what happens now. So we\\'d be keeping a currenlty broken system out of fear of having the exact same broken system in the future.\\r\\n\\r\\nYour call, let me know if you insist on droping this.\\r\\n\\r\\n I think @bdraco is right for this specific part. We can also see translated of renamed entities that would mess with this specific \"magic\" feature. I would advise to just remove that part, the allow list is already a giant step forward and still relatively easy for end users to voluntary whitelist (allow) what they want, and finally be able to track nameless beacons.\\r\\n\\r\\nPersonally, I would even remove the 40004 trick, even if it\\'s already merged on mobile. I think this could cause privacy issues because this means that I can be tracked / or inadvertently track other HA Mobile users when they are around my house. I am not saying this is something new, but it would become more obvious that new HA mobiles are automatically tracked.\\r\\n\\r\\nHonestly, the basic allow list is the perfect and simple solution. We just need that and documentation (web site + in the sensor description) for the fact that BLE Transmitter ID needs to be manually added to HA to track the mobile app. @bdraco : how do you want to proceed?\\r\\n\\r\\nBtw this PR was meant to replace the 40004 trick, but we could also combine the two if we want a no-config solution for companion users. (Concerning privacy, the real problem is the unique constant UUID, changing the minor doesn\\'t make it more trackable.) Let\\'s take out the mobile_app / _async_refresh_companion_uuids related code here and only do the allow list.  Integration with mobile_app can be added later if an api is merged to the mobile_app.\\r\\n\\r\\n Done. Let me know if anything else is needed. Save `self._entry.options.get(CONF_ALLOW_NAMELESS_UUIDS, [])` in a `set` in the object to avoid having to do a linear search over it each time Done. Update the set when the entry changes here \\r\\n\\r\\nPlease add missing coverage for this line Do you know how to make `async_last_service_info` return an empty result in a test after `inject_bluetooth_service_info` was used to simulate a beacon?\\r\\n\\r\\nBtw there\\'s a [similar line](#L402-L403) that\\'s also not covered. Move time forward enough that the service info expires.\\r\\n\\r\\nExamples in xiaomi_ble and bthome tests Done. This leaks an update listener because its never unsubscribed Fixed.',\n",
       " \"As discussed on Discord, I'm not a fan of the fixed interval. We should push updates to the receiver when the image entity is updated. The interval seems to be coming from the client side in the camera platform - I'm still trying to figure it out We don't need to explain coroutine functions need to be run in the event loop anymore.\\r\\n This should be a module level constant Why can't we write `\\\\r\\\\n--frameboundary\\\\r\\\\n` here, what do the extra ` --` do? Please explain it in a comment. Instead of this, I think working on a [`bytearray`](#func-bytearray) object makes more sense. This comment should be in `camera.async def async_get_still_stream` too.\\r\\nShould we also explain here we consider the bandwidth waste a non issue because of the intended low framerate of `image` entities? Will address in a separate PR Why do we need to call `drain`, is it to ensure we write to the socket now and not later? Should we explain it in a comment? `async_track_state_change_event` accepts a string\\r\\n Please explain, in a comment, the error handling happening here. We're guarding against errors raised when writing to the socket, and we want to make sure we call `remove()`, correct?\",\n",
       " '\\r\\nYou\\'re using a coordinator so data is already present when you add entities, no need to do another update What does this return? We want to avoid putting a lot of data in these state attributes as they can blow up the state machine It\\'s for getting games data to display it elsewhere (frontend, notification ...)\\r\\n\\r\\nSee\\r\\n![image](\\r\\n\\r\\nWhile writting I thought that making a service also be a great solution.\\r\\nEmmm, can we call service and use its result in templates ? (as we can\\'t in automations without a script) Yes we can! Since this PR can\\'t make 2024.2, I think we can make some nice services in a follow up to have it ready with 2024.3 Fixed in 73c20f34803b0a0ec242bf0740494f17a68f6f59 Apply fix again in f3d475385aa2fb8e6c994237e000270e4ab095f8 I think what we are ultimately catching is a KeyError right? `TypeError` or `KeyError`, more a Type as on test `tests/components/epic_games_store/test_config_flow.py::test_form_cannot_connect_wrong_param`\\r\\n\\r\\nSee\\r\\n\\r\\n\\r\\n\\r\\nBut this case should not happen now as of new version of lib, so I refactored it in c0a3429e6063c38f7f67d0d56159df7f5077b2fd fixed in 14ca00a3c56cea41965ac676943957d035a86f37 unused Fixed in 040cf945bb5346b6d42b3782b5061a13fb7b1f6b `CONF_LANGUAGE` is available in `homeassistant.const`. Done in 724ce255805e57ea05a7040f6e19d2b945ff67c7 Done in 724ce255805e57ea05a7040f6e19d2b945ff67c7 We don\\'t need to check this, the base entity validates this constraint\\r\\n Done in 8b1d9ba Done in 8b1d9ba Move this to const.py Done in 10d0083 I don\\'t think `\"zh-Hant\": \"CN\"` is correct, traditional Chinese writing is not used in mainland China. It is however used in Hong Kong, Singapore and Taiwan.\\r\\n\\r\\nI\\'d suggest to double check where the epic game store is available, and add options for that to the config flow instead of trying to guess it here, for example, maybe add zh-Hant-sg if the store is available in traditional Chinese in Singapore and so on. Fixed with 7a53234, the only thing the country change is the currency & price.\\r\\n\\r\\nTested with weird combinaisons, and working fine.\\r\\nI put the selector is the config flow so Chinese people living in France (or anywhere else ðŸ˜„) could get the local currency & price, with his native language ðŸ˜‰ ',\n",
       " 'Fixed Done These 2 coordinators really look a lot like each other. Can\\'t you maybe create 1 superclass with all the logic and then 2 subclasses which implement the update data function Done Makes `pylance` unhappy These aren\\'t constants anymore so please use lowecase Done I think these functions could be one. If you make that superclass thing work, maybe you can just add a method to close the coordinator Done Can we use constants for this? I don\\'t get what you looking for.\\r\\n I don\\'t know what `home_p1` means. Something like `AREA_ARMED_STATUS_HOME` or something like that would be clearer to read. What does this mean? If the Alarm device is in a non working state, the entity is marked unavailable. Can we maybe use a reverse map for this?\\r\\n\\r\\nso it would be like\\r\\n\\r\\n`ALARM_AREA_STATES[self._area.human_status]` Dont\\' know how to handle `AlarmAreaState.ARMED` as there are 3 sub-types.\\r\\n You can at least change these 4 to using the dict Makes `pylance` unhappy Since the superclass `ComelitCommonApi` contains both `.logout()` and `.close()` you can make this one function again and then only check what type the entry is to define which platforms to unload Done Are all these three used right now? 2 out of 3, \"Zone\" will be used by sensor. Can we implement this in that PR?',\n",
       " \"While not required - I think it is typically better for these to be in const I checked a few other integrations and this always seems to be in init. anymore context we can give with these exceptions? UpdateFailed should typically explain why the update failed as it is user facing. I could be wrong, but since since I create the exception from e it should get its context from the upstream error. Turns out the update coordinator logs better error messages for these anyway, so Im going to leverage them. Why are you setting domain as a class variable here? I don't see why this is needed I dont know either, I did it in my other integrations (which I copied to make this one), ill check if its required. I dont think the if CONF_ACCESS_TOKEN in user_input is needed, as it is required in the schema user_input can be null, for example when the form is first opened. Oh I see what your saying, let me try that. This probably belongs in const This is probably opinion, but does it below on const if this is the only file that will use it? Not a bad idea regardless. Moved for all of these, name is not needed when you specify translation_key Thanks, I've done that now. I would add an icon here to make it clearer what this is, since it will not automatically get one like you other sensors typing Done, Thanks you need to add an entry for each of your translation keys Oh right... From what I have been told in the past, you should just always set up all platforms, just to make sure one platform doesn't cause an issue with another. Personally, I'd recommend splitting this out into it's own class. It will give you more flexibility in the future and helps with readability. But I don't think it is required. I was skeptical, but I tried it and I do agree its nicer. coordinator.py has been implemented now. I believe this should only ever be raised in init. Since you are passing this in the coordinator, this could get called anytime the coordinator updates, which i'm not sure how it will be handled. I'd test this to make sure. I started rewriting this, but it turns out the update coordinator catches ConfigEntryAuthFailed and triggers the reauth flow. It looks like reauth will be a problem as the unique id should not change for the life of the config entry\\r\\n\\r\\nIs there a better unique id available such as the account id ?\\r\\n\",\n",
       " \"Why is this necessary? The service is linked to this method so the only reason this should be called is if the `SERVICE_PLAY_ON_SPEAKER_HUB` service is requested. Unnecessary code removed There's a recent blogpost about entity descriptions please check it out\\n\\nAlso. Look in the code for kw_only. It can make you remove the mixin i will create a new PR for this \\n \\n \\n\",\n",
       " 'This can be a walrus. This too. Should we test creating items with the added data too? Done.',\n",
       " '',\n",
       " \"Should this rather avoid a default value to make sure all future PRs will not forget defining it? This would require converting this to a mixin and inheriting the `HuaweiSelectEntityDescription` from it and from the `SelectEntityDescription`. Yeah, why not, done in 8544e2451f5498ca0838b611930b49e0cd4340ca Just a suggestion, but maybe create a module global for the select entities and loop them over here for creation? Will avoid need to refactor in the future when new selects are added. I thought about it when working on this and in a sense agree. But I've taught myself to resist such refactorings until actually known that they'll be needed, an how. For this particular case it would seem future selects would fit in the way we'd do the refactoring at this point with the data at hand, but one cannot know for certain if some other things are called for at that point, and then we would have refactored twice.\\r\\n\\r\\nCertainly not a biggie and I can do it either way though. Your call, this looks good to me :-) We can use `kw_only=True` in the `dataclass` decorator to avoid the mixin for required attributes. We should assert the state of the entity in the state machine too. Please sort :abcd:.\",\n",
       " 'This would break any configuration which uses CONF_HVAC_MODE_VALUES, that is not allowed !\\r\\n\\r\\nYou can deprecate a configuration keyword, but it must be supported for at least 4-5 months, and users using it, must be given an issue, so they are aware that they should change. Happy to address this, but just to double-check my understanding of what is and isn\\'t allowed. Since I\\'ve not changed the user-facing configuration keyword nested under `hvac_mode_register` (which remains `value`), I thought this was permissible and not really a user-facing deprecation?\\r\\n\\r\\nI have created a second static `CONF_FAN_MODE_VALUES = \"value\"` to keep them both independent and leave the `CONF_HVAC_MODE_VALUES` static class variable name untouched. Why should it be a list, are there fans that needs multiple values send to multiple registers to be set.\\n\\nYour documentation also do not explain this. I had only made this a list to ensure consistent configuration options to `CONF_HVAC_MODE_VALUES`.\\n\\nI agree with you, I can find no real-world examples where this would be needed. What happens if this is false, and the values are defined as lists ??\\n\\nWhat happens if one value if an int and another a list ?\\n\\nIn short this is opening up for a lot of wrong configurations, the right way is to have CONF_WRITE_REGISTERS and values only as int. I\\'m totally convinced.\\n\\nDo you know of any real-world examples where HVAC MODE requires a list?\\n\\nIs it possible that that is just a legacy from when some part of this had less good multi-byte support?\\n\\nHappy to propose a deprecation as a follow-on PR if you\\'d like that changed to match this. With the current configuration, you will actually call with [[value]] I\\'ve removed the `CALL_TYPE_WRITE_REGISTERS` (plural) code paths for Fan Mode and all support for lists. Why do we need a loop, it should just be indexed. I have copied the approach 15 lines above. I think the objective here for HVAC may have been to support many-to-one mappings where the external system had multiple modbus values that would map onto a HA state.',\n",
       " 'We no longer accept additions or changes to the yaml config of integrations. See: \\r\\n\\r\\nThis integration needs to be refactored to use a config flow and config entries.\\r\\n\\r\\n',\n",
       " \"This should not log on a warning level.\\r\\n\\r\\nThe same for the ones below actually.\\r\\n\\r\\nWe should only log 1 time, of which the DataUpdateCoordinator takes care. Just raise an `UpdateFailed` (instead of logging manually). Thanks for the review!\\r\\n\\r\\nOk, I understand that no explicit logging is needed here. \\r\\nIf I raise an error, it won't retry immediately - I was hoping to prevent gaps in data caused by communication glitches which seem to happen with this device.  I don't see a way of raising an exception and also retrying.\\r\\n\\r\\nIf the solution is to wait for the next update interval then the retry logic is probably unnecessary.\\r\\n\\r\\nThe issue of raising an error vs warning came up on the previous PR. #discussion_r1305557202.  I'm trying to not generate errors during normal operation (sunset).\\r\\n\",\n",
       " 'This endpoint doesn\\'t return any data, right? Why would you need a `DataUpdateCoordinator` for this? Perhaps you can use `async_track_time_interval` from `homeassistant.helpers.event` to call update_dings on a time interval.\\r\\n\\r\\n(or maybe I misunderstood what you are trying to achieve here? The endpoint does return data which is stored internally in the api objects `dings_data` variable.  The entity then accesses the data via the `active_alerts()` method which does some filtering based on timestamps/expirey.  It\\'s a bit confusing but it\\'s the logic that was already in place. However the next PR is going to drop this polling coordinator altogether and replace it with realtime push so it doesn\\'t make sense to change this much now. Resolving conversation as @iMicknl gave a thumbs up Have you checked if you can inherit from the CoordinatorEntity here? That would be the preferred way for entities that are based on a DataUpdateCoordinator. See #L18 for an example. This would make your code also cleaner since you don\\'t have to implement `_handle_coordinator_update` everywhere, but you can just focus on your entity logic.\\r\\n\\r\\nCould be part of a follow-up PR as well, if this would add a lot of changes to your current implementation. All the entities are inheriting from the `RingEntity` which does inherit from the `CoordinatorEntity`.  I\\'ve renamed `RingEntityMixin` to `RingEntity` in case that was causing confusion, so it\\'s more inline with OverkizEntity naming now.  Regarding the `_handle_coordinator_update` implementations I *think* I\\'m only implementing them when I need to, i.e. when there is logic specific to the derived entity but let me know if you think I\\'m missing something. Resolving conversation as I\\'ve clarified that we are inheriting from `CoordinatorEntity`. \\r\\n\\r\\nWould it be an idea to add typings to cade you touch as well? Not a requirement, but would make the code a lot easier to read. And perhaps eventually (in a follow-up PR) you can get rid of the broad `import ring_doorbell` as well. Done, I\\'ve added typing to all touched code.  Regarding the broad import of `ring_doorbell` I do that because when I then mock/patch for testing I\\'ve always patched in the right place, i.e `patch(\"ring_doorbell.SomeRingObject\")` always works and I don\\'t have to patch each module that imports a `ring_doorbell` object directly.  What do you think?  Resolving conversation as typing added to all touched code.',\n",
       " 'I don\\'t like this solution. I\\'ve a PR pending that exposes the circuit name ( that can later on be used here for circuits. \\r\\nFor Burners / Compressors I would at least omit the number if only once is present. I agree, we should try to solve this upstream.\\r\\nNot sure why we\\'re appending a random incremental number anyhow to these? They devices doesn\\'t have proper names? The heating device can have one or multiple burners / compressors and one or multiple heating circuits depending on the model. Each of these *components* have sensor values in the api (like circuit temp, operating hours, ..), so similar entities are created multiple times. \\r\\nCurrently they are all assigned to the heating device itself and to distinguish them entity names get the component id (0, 1, 2, ...) appended to the name. Thus I currently cannot implements translation keys.\\r\\n\\r\\n> Not sure why we\\'re appending a random incremental number anyhow to these?\\r\\n\\r\\nThis I did to not list \"burner 0\" but \"burner 1\" as the first device. I meant that you are appending the number since I assume these actually don\\'t have proper names provided by the api?\\r\\nGiven the user can\\'t diff between burners and compressors anyhow why not just name them without the number? Changed to use simple names \"Compressor\" and \"Burner\". `device.getName` is not async safe. Can a constructor be async or how could I solve this? No, the constructor can\\'t await. Probably get the name before creating the entity and pass the name to the entity when creating it. I\\'d keep the name as it\\'s called in the library. Is there a reason to rename it? Renaming it makes it harder to look it up in the library. Please see my explanation in this PR: #r1406576321 Right, but that\\'s a problem that the library should solve. We shouldn\\'t change the name here unless it\\'s clearer but I don\\'t think it is clearer. Do these components really qualify as separate devices according to our current guidelines? Aren\\'t these components just different parts of the same device in the same location?\\r\\n\\r\\n#what-is-a-device Yes, that\\'s correct. I would agree for burners / compressors. \\r\\nBut for heating circuits I think this is justified as the circuits usually supply different areas of the building.\\r\\n\\r\\nAs seen here #issuecomment-1786002580 it could get pretty confusing with multiple circuits, burners/compressors on one device view. Grouping the entities together would also ease a proper (re)naming. We need to follow our architecture guidelines. If the circuits qualify as separate devices, it\\'s ok to add devices for those. But we shouldn\\'t do it for the other components that don\\'t qualify.\\r\\n\\r\\nWe\\'re adding translation placeholders for entity names which can help clarify the context of different entities.\\r\\n\\r\\n > We\\'re adding translation placeholders for entity names which can help clarify the context of different entities.\\r\\n\\r\\nðŸ‘ That\\'s great!\\r\\n\\r\\nI consider this to be true for heating circuits. I will remove the feature for burners / compressors.\\r\\n> A device that offers multiple endpoints, where parts of the device sense or output in different areas, should be split into separate devices and refer back to parent device with the via_device attribute. This allows the separate endpoints to be assigned to different areas in the building. This leads to an error, so reverted the change.\\r\\n Thanks, done! Please define constants that are only used in a single module in that module. done I\\'d not try to have a common base for attributes that aren\\'t common. Don\\'t pass different types of objects for the same parameter `device`. Just put the logic and parameters that are the same for all entities in the common base class. The things that are different should either go in a different base class that can be shared, if more than one entity type can share it, or be put in each entity class if it\\'s specific to each entity class.',\n",
       " 'Why is the mac address added as an identifier, is it to make `via_device` work for the sub devices? Correct. The class name suggests plural, but the variable name suggests singular. Which one is it? Its singular.  Looks like its misnamed in the aiolyric library that his object comes from.   Please explain in the docstring that these entities will be subdevices to a thermostat Good call. Clarification has been added. One question that I have, currently an Accessory is bound to a room. Are there more types of accessories? Are all accessories bound to a room? I\\'m not aware of any other thermostat accessories for this device, but they all appear to have the same data structure from the Lyric API.  The only values I have observed for accessories are `Thermostat` (which is a duplicate of the parent thermostat) and `IndoorAirSensor`, and looking at their product pages I can only find the one model of air sensor and no other accessories. `IndoorAirSensor` is the only value they use from within their API reference as well.\\r\\n\\r\\nAir sensors must assigned a \"room\" from the Honeywell app in order to be operable, yes.  Unless there is a reason why `accessory.temperature` isn\\'t Trueish in some cases. This also prevents a bug where the sensor isn\\'t added if the accessory temperature is exactly 0 (since translating that to a bool makes it false) Nice catch!  This has been fixed in my most recent commit. Nice catch!  This has been fixed in my most recent commit. Maybe it would be more performant to await all promises altogether?\\r\\n\\r\\n#asyncio.gather I agree with @t3hk0d3, please use asyncio.gather instead, something like:\\r\\n Updated per suggestion; thanks for the code snippet.  Re-tested locally and it continues to work as expected.',\n",
       " \"If config version is 1 then definitely these keys won't be in `data`  So you would suggest by removing that check altogether  because it is practically meaningless? Same here Entry migration happens under `async_setup_entry` inside `__init__.py`. The tests should reflect the same. I'm not entirely sure what you mean by this, do you want the test itself to be renamed or moved to another location?  Should this go into `test_init.py`? @engrbm87 I did not get notified on this reaction, so it took some time for this to happen; I moved it to test_init.py, let me know if there is anything else that needs changing You should not call the class method directly. Instead await `hass.config_entries.async_setup(entry.entry_id)` and ensure that the integration loaded successfully and that the config entry version is updated. Please implemented the above suggestion I've changed it in the way you suggested! its loading the component and after that it checks the migration Please increase only the minor version and leave the version as it is as this change is not a breaking change.\\r\\nSee #config-entry-migration Ahh ok, I missed that there was a minor attribute in the version for components when I created it, I'll try to work on it soon when I have some time! Thanks for the feedback btw! :pray:  Updated accordingly!  Please add the attribute sorted correctly Hey @edenhaus do you mean alpabatically sorted? Because if that's the case, I need to sort also entries that I did not add. \\r\\n\\r\\nIf there is another sorting method being used, can you share me where to find this? Because the docs don't seem to mention one Yes, please sort all items, existing and the ones you add, alphabetically ðŸ‘  Did this! Please specify the version directly in config_flow.py Changed it and its now in the config_flow Used your suggested change! It's not clear what path this is.\\r\\nPlease add a `data_description` dictionary with a `path` key explaining to the user what this setting does. @emontnemery  Would it make sense to also add it to the rest, because if I add en explanation to one, it definitely looks weird (see the example) :')\\r\\n\\r\\nI went ahead and only added the change you requested for now so at-least this issue should be resolved\\r\\n\\r\\n![image](\\r\\n \\r\\nWith a full example here:\\r\\n![image](\\r\\n Yes, of course it's beneficial if you add the description to all the fields ðŸ‘ \",\n",
       " \"A coroutine function isn't a callback. We can remove the decorator. We should not need to access the controller since we know the host and site from the config entry data. I think we've talked about this before. :smile:  Probably ðŸ˜… , thanks for your attention to details Martin! I will add this to my list of improvements :)\",\n",
       " 'I simplified the initialization in 0b5411d4ea64a5bd9f76186ae596dbd5d0e60348 as such:\\r\\n\\r\\n`hass.data.setdefault(DROP_DOMAIN, {})[config_entry.entry_id] = {}`\\r\\n`hass.data[DROP_DOMAIN][config_entry.entry_id][CONF_COORDINATOR] = DROP_DeviceDataUpdateCoordinator(hass, config_entry)`\\r\\n\\r\\nYour suggestion was good, but fails because the `[config_entry.entry_id]` key needs to exist before the `[CONF_COORDINATOR]` key can be created. Any reason you are prefixing the DOMAIN constant with DROP_DOMAIN? Not necessary imo, and in this case it only confused me at first.\\r\\n\\r\\n![image]( ðŸ˜… we should not use such short \"magic\" word for an integrations name ... how is about `drop_connect` as the website calls itself and all the apps, too. I agree the \\'DROP_\\' prefix is unnecessary and have removed it across the board in 1a3b630b474c551054932330a8763dabed553c04.  It was just a pattern I saw in other integration projects as I was getting familiar with HA.\\r\\n\\r\\nI also agree that changing the `drop` domain to `drop_connect` is reasonable.  Our product line is just called \\'DROP\\', but marketing started using \\'DROP Connect\\' when we couldn\\'t secure drop.com many years ago.  Since then, it does get used for disambiguation from time to time.  I\\'ll make that change after I\\'ve worked through the rest of your (appreciated) suggestions.\\r\\n Changed across the board in d5a6dca2cbfcecb1030fb0bbcb64b020f3c48412. Are you sure this is required? My belief was that having `mqtt` as a dependency would be enough when using `async_setup_entry`. The Tasmota integration is not doing this either.\\r\\n\\r\\nBut a core reviewer with more experience can verify this probably. I think it is cleaner as-is.  If I disable or remove the MQTT integration I see the expected \\'MQTT integration is not available\\' entries in the log at startup.  Without this test, I see stack traces instead as the MQTT subscriptions fail. nit: you could also move LOGGER to const.py and import it where required.\\r\\n\\r\\n I actually started with the logger defined in const.py but later moved it to each module so that log entries include the module name, which I found helpful.  A cursory survey of other integrations shows that this approach is very common, so I\\'d like to leave it as-is if possible. \\r\\n\\r\\nDo you need a constructor here? Should be fine with having them as class variables. You could also think about setting them to `str | None` and setting the initial value to None instead of an empty string. It works fine without the constructor and initial values were changed to None where appropriate.  Changes in 653064f6c4ebe83b575342e0dd428cd0436a34d8. Is there no way to set this up manually, in case discovery doesn\\'t work? No, there really isn\\'t.  The MQTT discovery payloads include a device ID number used by DROP to address individual devices.  (e.g., you can have 50 leak detectors on one DROP system)  There isn\\'t any way for a user to be able to predict that device ID number, and it\\'s used to construct the MQTT topics used by the device. Addressed in d5a6dca2cbfcecb1030fb0bbcb64b020f3c48412. \\r\\n\\r\\nHave you checked if you can inherit from the CoordinatorEntity here? That would be the preferred way for entities that are based on a DataUpdateCoordinator. See #L18 as an example. Good suggestion.  Changes are in 5d3cf3a467b61af05cc6bc64d0a99d5ea15b7663. \\r\\n\\r\\nPlease use the enum values here, and best is to set a device class where applicable and not set a custom icon. This applies to all other sensors in this file as well. Good call; I patterned my first sensor off of an example that doesn\\'t have a SensorDeviceClass element and then ran with it.  I set the device class where applicable in f670c323d74e2ce21a05f08b0824c637ec257cf4. There is a lot of duplication in sensor.py. Did you have a look at the EntityDescription class?\\r\\n\\r\\nSee #entity-description\\r\\n\\r\\nExample:  Yes, I looked at the class toward the end of initial development but I didn\\'t see much of an advantage to refactoring it. I did clean up a lot of obvious duplication in 4123fbef4d086586be50e633ba84f619fcc3ff8e. I\\'m going to mark this resolved for the time being, and if you (or another reviewer) feels strongly that I need to use the EntityDescription class then we can reopen it and discuss further. I\\'m old enough that two spaces after a period was once required.  Can\\'t seem to shake it. ;)  Addressed in 35b94a287d99d6ac74f337b4b8d1b8a83dcbcfd0. I agree this is more clear.  Changed in 2ad2977100239bde557e0203a206667b39b621c8. Please don\\'t mix Pascal_Case with CamelCase. I would prefer to see all CamelCase I think you should take a look at entity descriptions. It\\'s a quick way to create more sensors with the same logic. For a simple example checkout the `youtube` integration. ',\n",
       " \"Do we need to reload the integration? Where does that happen?\\r\\n\\r\\nThe device is removed now for this case, and if the device will be added again by the driver there will be an event for that and it should just work without reload, I'm thinking. to be honest I am not sure why I changed this notification. I don't think this change reloads the integration, it just removes the device. So I think I can just revert this and change it back, let me know if you see any things I missed where we actually reload the integration Yes, I don't think we need to reload. I'm missing some new assertions for the changed notification message and behavior, if that should change. and I think if this revert is accurate, this is also not needed? We should assert that the Home Assistant device was removed from the device registry.\",\n",
       " 'Why don\\'t we set the device name here? `self._device.device_name` Device name would then be \"HvacFnct21y_A\" (for my unit). Or should we try to get the model here instead. I.e. in my case that would be \"Flexit Nordic S4\". As long as the user can identify it Fair point! I will set the device name. I am no expert on climate entities, but have a read at  Okay, it seems that auxiliary heater on a climate entity is deprecated? \\r\\n\\r\\nSo then we should add \"a switching entity and add it to the device\" or simply remove the aux heater in this PR for now? Removed This function is fairly small, I wouldn\\'t mind if you inlined this Fixed Maybe move these to conftest.py? Do you mean like:  ? Done Checkout `@pytest.mark.parametrize` you can easily throw different parameters at your test. checkout the Lastfm config flow for an example Fixed! I think the device name would be friendlier to use here I don\\'t think I really understand, can you give me an example? Oh! You mean to return `device.device_name` instead of `device.serial_number` in validate_input? So that title becomes the device name instead of the serial number. Fixed Done Can be put on top Done Removed Removed Fixed',\n",
       " 'Is it intended that this is the same key as in the description above? Yes, because only one of the two can be present.\\r\\nIt is basically the same feature: Animal detection is the extended version of Pet detection.\\r\\nThis is done so users on older firmwares that have Pet detection will not need to change there entities when upgrading there firmware to get animal detection instead of pet detection. Okay, perfect, I just wanted to be sure, but I suspected something like this ðŸ‘  Same as above Same Please use a parenthesis and indentation or break out to a separate function to make it easier to read. Lambdas that span more than one line without parenthesis are hard to read. Thanks for the feedback, I fixed it in this PR: ',\n",
       " 'Outside of constructor What do you mean? It\\'s in `__init__`? It\\'s set to a static value, so it can be set outside of the constructor Right, so the opposite ;)\\r\\nTried to not touch the existing stuff but mypy complained to much ðŸ—¡ï¸ \\r\\n\\r\\nbtw: with this the Name becomes \"Time & Date Date Time\" (as example for a date & time sensor. The naming of device + sensor on this one looks really strange. Any idea? Same This could be rewritten as a list comprehension:\\r\\n\\r\\n\\r\\nBut I don\\'t know what the preferred way is here. I\\'ll change that. Why do we overwrite entity id? This allows integrations to suggest an entity id, at the same time I\\'m not sure why that is added in this PR. I know, but I don\\'t really see the point why we should add it It\\'s to avoid having entities like `sensor.time_date_date_time` which makes no sense That\\'s a good point lol We still need to fix the naming issue on this one.\\r\\nWe can\\'t have Names like \"Time & Date Date & Time\". I\\'d like to have the device but I\\'d like to get rid of it\\'s function for the naming but haven\\'t looked too much at it yet. Hmm, there\\'s an architecture discussion for exactly this issue:  Yes and no I guess but if we could get placeholders I could at least put `-` in between the device and entity name or such to make it somewhat better looking.\\r\\nAt the moment not having that is a showstopper unless I abuse the entity internals. This integration can only exist once and will always work this way afaict. Is there a reason to add the entry_id as well? Not including the unique id means entity registry UUID as well as entity_id will be stable if the config entry is removed and then readded. That\\'s probably a good thing, and we can omit the entry id. WDYT @gjohansson-ST ? Seems legit. It\\'s just a habit to add `entry_id` from my side. idem We need *some* kind of identifier though. Maybe just `(DOMAIN, DOMAIN)`? I\\'ve seen that before, that works I\\'m assuming we\\'ll get rid of the direct entity tests and move to tests via the state machine in a follow up PR? In a follow up PR we can use snapshots for this This title should be translated, but maybe that\\'s not possible? Not possible to translate the config entry title as far as I know Let\\'s not make it a helper, similar to how sun and moon are not helpers.\\r\\n\\r\\n Maybe service would be better? Hub doesn\\'t really fit as well. ',\n",
       " 'This is already the default provided by the CoordinatorEntity, and thus can be omitted.',\n",
       " \"This seems like a personal mount. btw, if you open 2 dev containers but use same disk, you can just access the other files.  ðŸ¤¦ðŸ¼  This is already validated by the previous validator used, `cv.datetime`. Validation happens sequentially and the output from the previous validator is input to the next validator. OK, I went ahead and just removed the validator and replaced it with a direct usage of `dt_util.as_local` in the schema. This seems to be a duplicate of the line above? Removed line above. I think we should name these similar to the existing ones. Eg: `SET_DUE_DATE_ON_ITEM`. Renamed. These aren't really configuration, I think. It's more attributes.\\r\\n\",\n",
       " 'There is already a service for setting temperature so this only makes sense if end_datetime is not optional. See `_async_service_set_preset_mode_with_end_datetime()` which had the same comments in a previous PR That had confused me a little as to why the end date time was required when it is not for the API. \\r\\n\\r\\nI understand wanting to differentiate between `climate.set_temperature` and `netatmo.set_temperature`. It made more sense to me to have it as `set_temperature` as that is what it is primarily doing, just with some additional optional functionality which the netatmo ecosystem provides. This is currently only a single additional argument but that might not always be the case and there may be many combinations of available parameters in future. Having it optional also provides the user with the guidance that it will use the netatmo default if not provided. The set temperature service currently does this silently (3 hours).\\r\\n\\r\\nI can change it if you still prefer. I certainly don\\'t like it being inconsistent with the set preset service. It just felt like the more sensible name to me for future maintenance and possible expansion.\\r\\n\\r\\nI\\'ve looked through the other PR. As far as I can tell the naming is the only issue so far. I\\'m not clear on the process so I\\'ve marked it as ready for review again for this comment to be considered. Apologies if that is wrong. > I also realised my use case (and I expect many other automation use cases) would require the use of jinja to determine the end date & time. It seemed to make sense to have a service to handle time period as well so I\\'ve added that.\\r\\n\\r\\nI think we should probably try to mimic what\\'s in the \"official app/device\". Do you select an end time or a run time?\\r\\nWe could of course do both services but I wonder if it really makes sense. For setting the value, the app shows the time period as a slider and defaults to 3h. For displaying the current manual boost, it shows the time it is active until. The API works by timestamp.\\r\\n\\r\\nI added the extra processing required for time period to avoid having to use as much jinja in automations, but I can see a use case for either. e.g. Set temperature for 3h while clothes are drying or set temperature until 5pm when finishing work.\\r\\n\\r\\nTo set until a given time today, jinja would still be required to work out the date, but it would be much simpler than calculating the time period (e.g. `{{ states(\\'sensor.date\\') + \\' 17:00:00\\' }}`).\\r\\n\\r\\nLikewise, having a service to boost for a given timespan would potentially satisfy most use cases in the UI. Working only by datetime would involve some complex jinja to calculate the correct end time.\\r\\n\\r\\nMaybe HA could handle this automatically in future by having the datetime selector work with times relative to the point when they are triggered, but that is a very different feature.  I guess with either one implemented, the alternative can become a blueprint script.\\r\\n\\r\\nHow would you like to proceed?  For preset we implemented it with and end datetime. What\\'s there in the app? For preset you activate it indefinitely, then can \"edit\" to a specific date and time. There is no time period option for preset in the app.\\r\\n\\r\\nDisplay of preset:\\r\\n![Screenshot_2023-11-20-11-10-56-24_2ac22f0e18cbfbeda85a7e653b55b2c6 (Small)](\\r\\n\\r\\nEdit preset:\\r\\n![Screenshot_2023-11-20-11-11-03-08_2ac22f0e18cbfbeda85a7e653b55b2c6 (Small)](\\r\\n\\r\\nEdit temperature (select time period but end time also visible):\\r\\n![Screenshot_2023-11-20-11-11-14-73_2ac22f0e18cbfbeda85a7e653b55b2c6 (Small)](\\r\\n\\r\\nDisplay manual temperature:\\r\\n![Screenshot_2023-11-20-11-11-19-98_2ac22f0e18cbfbeda85a7e653b55b2c6 (Small)](\\r\\n I guess it can make sense to have both then. Thanks Does this really test anything as it already was auto? I\\'m a bit unsure about all of the tests here tbh. This is probably one for @cgtobi to comment on.\\r\\n\\r\\nThe process of the services is:\\r\\n\\r\\n1. User makes service call\\r\\n2. Call to API is made through external library\\r\\n3. Netatmo sends a request to webhook\\r\\n4. HA updates devices based on webhook\\r\\n\\r\\nFrom what I can tell of the tests, only 1, 3 and 4 are being checked.\\r\\n\\r\\nTo compartmentalise the tests, I expect it would be better to have tests to check parts 1 and 2, then separate tests to check parts 3 and 4. I\\'m not familiar enough with the testing in HA though to know how to do that. It would also increase the scope of this PR by quite a lot to change this. I mean in the last test just add so it does\\r\\n1. Make service call to set a temperature with an end datetime\\r\\n2. Check result\\r\\n3. Make service call (with new service `async_service_clear_temperature_setting()`) to clear the setting\\r\\n4. Check result\\r\\n\\r\\nOn the current test we\\'re only asserting the state which is `auto` before and after so actually nothing changes in the test.\\r\\nIt\\'s only doing 3 and 4 right now. Ah I see what you mean. I\\'ll update the test. Please use \"links\" when the phrases matches up\\r\\nExample `[%key:component::netatmo::services::xyz::xyz%]` Think that should have sorted it.\\r\\n\\r\\nThanks for your patience with this PR. The quick responses have certainly been appreciated.',\n",
       " 'Can be removed  Should not be an extra function done If I see correctly we allow more instances of this integration right? Should we store data in hass.data[DOMAIN][entry.entry_id]? I use the devices property to store the instances. Just like abode and owntracks. This also means the heartbeat won\\'t be stored for every entry, only the last one if I see this correct? Why do we make this so complicated and not just a list/set with the types? This is for the new devices that will follow. A device may have multiple functions. But isn\\'t this the same as:\\n\\n{\\nEHUB: sensor,\\n...: sensor,\\n...: sensor\\n}\\n? I don\\'t think this error message makes a lot of sense as this is only checking against a list. I don\\'t think it will suddenly lose an entry. Integration may not yet be supported when users use a new type of device. Yes, but the \"If it worked before\" doesn\\'t make sense. Also, we use GitHub issues for bugs and not for feature requests, so I\\'m a bit doubting with this one (like, yes it\\'s not working thus a bug, but it was never in the scope, thus a feature request) We don\\'t need to import here done It\\'s still there? Should we log something? Does this mean the device is off forever? Why don\\'t we raise ConfigEntryNotReady? Please move reauth to a follow up PR  Do we know what the possible values can be? Why isn\\'t this a coordinator Entity? I\\'m sorry for the trouble I caused. Please check: ',\n",
       " \"This seems to be outside of the scope of the PR.\\r\\n\\r\\nIs it related? The code suggests the function tests if *any* camera is in use, is that the case? If so, update the docstring to:\\r\\n\\r\\n Please rename this to value_fn since it's a function, that should be done in a separate PR though.\\r\\n\",\n",
       " \"If you feel extra fancy, maybe you can do  (but in a separate PR of course) the fields in there are `device_info` and `name` right? Is there a reason we call them `Device` and `Name` here? The backticks will make them look like they are code, but apparently they are not Personally I'd use more constants here, because you're also going to reference these fields later on and it avoids typos and stuff. But not a blocker What's GA? Side note: do we have multiple places within `hass.data` where we store KNX data? Ideally we only use the `hass.data[DOMAIN]` How often will both be true? If it will be for most of the time, rather group the entities and call `async_add_entities` once Why only set `_attr_has_entity_name = True` when there is device info present? Not sure if we have guidelines with test coverage and websocket calls If its an object:\\r\\n\\r\\nif its an array\\r\\n Typing? Stale\",\n",
       " '',\n",
       " \"Be more specific e.g. `bool | float` I guess I think it's better to overwrite this in the platforms if we need it to be more specific (Number, BinarySensor). ? Use translation key. Should not be done in separate PR (that can cover the other platforms afterwards) The entity names are based on the number of heating circuits that are installed and get the heating circuit number appended to them. To using translation keys is not possible as far as I know.\\r\\nAn idea would be to have circuits in general as own devices provided by the heating device and to so also for burners and compressors. > The entity names are based on the number of heating circuits that are installed and get the heating circuit number appended to them\\r\\n\\r\\nThat sounds like that should be part of the device name and the entity name should only be `Normal temperature` which is appended to the device name.\\r\\nI would suggest to make a preliminary PR to fix this prior to this PR ~~Addressed~~ First step done with  Don't like spaces or such in keys Why isn't this just inside `async_setup_entry()`? I just copied the structure from the other platform and didn't change it. There it it done because there are some blocking function calls in there. Will check if we can refactor this here. Why isn't this just inside `async_setup_entry()`? We can just set this once during `__init__` addressed with  Can we do something better here than flooding the log in case there is repeating errors? We probably could raise `PlatformNotReady` instead, but I suggest to handle that as a whole for the other platforms as well. This should probably have a `DataUpdateCoordinator` anyhow but was more thinking can we log once instead of repeating every x seconds when it tries to refresh the data. By accident translation keys have already been added with  Why the addition of float? This should return a number already or None (which would not work)? The lambda returns a float, that's true. But [the getter](#L39) is defined in the interface to return a bool. Then I suppose you should overwrite it here or probably fix the base entity description as it can clearly return not only bool. Actually the library is not really types and the function just return `Any`. Is it now better to use `Any` as well or assume the types based on the api description?\\r\\nProbably on the long run the library should be typed. We should set the right `NumberDeviceClass` and then we can remove the icon I think as frontend would set the right one.\",\n",
       " \"Will pull this into a separate PR  I added test coverage for all integrations because they all have slightly unique ways they update state.\\r\\n\\r\\nQuestion for reviewers: This does not seem like a common pattern, so wanted to double check there isn't a better way. Essentially, we want to send an update every type there is a potential state change or refresh of data that works across all the todo entity integrations, given the list of items is updated via state change. I think it's ok. Platforms or other parts of integrations should use an event listener to track state changes, but if we would do that here, I think it would be unnecessary overhead, performance wise.\",\n",
       " '```suggestion\\r\\n        if not self.status[\"enable\"]:\\r\\n              return HVACMode.OFF\\r\\n\\r\\n        return HVACMode.COOL if self._thermostat_type == \"cooling\" else HVACMode.HEAT  Can you add a test for this guard?\\r\\nThere is an example in Gen1:\\r\\n#L119-L130 Done',\n",
       " \"Only use `dict.get(key)` if we don't know that the key is in the dict. If it's only used for typing we can import it under a `TYPE_CHECKING` check at the top. Should we consider to make this a decorator?  Currently, this code is used only once in the entire code base. We could make a decorator out of it when we implement it a second time, or are there other features pending that should be available only on a local IP? Let's convert it into a decorator as soon as we have more use-cases. additional data is never reset, so any auth provider after `trusted_networks` will have the keys added to the result Nice catch :) Fixed with [ed5fdc9]( No need to create a new dictionary. You can assign a key to the existing `additional_data` dict for this loop iteration. \",\n",
       " \"\\n Can we use translation keys? Not sure\\n\\n\\n\\n \\n \\n \\r\\n\\r\\njust a personal preference. \\r\\n\\r\\njust a personal preference. Is there a better way to get `hass` than handing it in the entity here? self.hass will be set on the entity once its been async_added_to_hass Totally forgotten that Python already has a built-in `ConnectionError`. So you would need to rename this. Ok, nvm, you already did this These values are picked from my heating device, but the vary a little bit on the min values for other devices (e.g. [VitovalorPT2](#L439-L463C10), [Vitocal300G](#L335-L350), [Solar](#L17-L40), [VitolaUniferral](#L1910-L1933)). But  will add the functionality to read this values from the API.\\r\\n\\r\\n\\r\\n Is there a way to avoid the get before setting? I had no idea how. The api exposes only the ability to change both at the same time. Would it be better to have that operation inside the library? I think that's fine. Workarounds based on the states or similar would be too error-prone, I think. Ah, just one small thing I learned lately: use parenthesis for multi-line lambdas Like this? \\r\\n\\r\\n Nearly, when running `black` it looks like this, which is more readable: \\r\\n\\r\\n Oh I just saw this, you can use `set_native_value` here instead of the async one.  The `await self.hass.async_add_executor_job` isn't needed as well. We're not allowed to use the async API from sync context. Use `self.schedule_update_ha_state` to update state from sync context. Thanks for spotting that! \",\n",
       " '> The sensor has a limited set of (non-numeric) states. The options property must be set to a list of possible states when using this device class.\\r\\n\\r\\nI think we should have the `options` defined here as well. only I don\\'t know which values to expect here, so far I have only seen \"ready\" on my heatpump, others have seen other values   if we don\\'t know all possible values please remove the device class\\r\\n\\r\\n I wonder if this should be added to [`UnitOfVolumeFlowRate`](#L776C37-L776C37). not sure, since native unit is \"liter\" according the vicare api (which should be \"liter/hour\" offcourse) and UnitOfVolumeFlowRate doesn\\'t support \"l/h\".',\n",
       " 'You can use `entry.async_on_unload` here to remove the listener on unload --> 44ffcb0 All this code is duplicated from the original call to add entities. Better to have a common function for both. There is always the additional ckeck `if ain in event.data.get(\"ains\", [])` included, to just add new devices. So it needs a common function, which can differentiate between \"add all\" or \"add only the new one\" ðŸ¤”  They will always be new the first time around. Just have the set of added devices always available Don\\'t use the event bus for intra integration communication. We have the dispatcher helper for that purpose. You could keep a local list in this platform with added devices. Now its somewhat racy for coordinator to know when to clear that list.  the coordinator clears this list at every data update run, the platforms only check this list, after the update run has completed, so this list should always be up-to-date and platforms should only \"see\" really new devices.\\r\\nhopefully i do not miss something ðŸ¤”  The signal listeners may not execute right away. So the signaller will run async from this and might end up updating again (somewhat unlikely but possible) Missing `@callback` marking. Right now its executing in executors. Just have \\r\\ndevices = set()\\r\\n\\r\\nlocally here instead. Or pass the new devices as an argument to the signal. you mean something like this?\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n_`hass.data[DOMAIN][entry.entry_id][PLATFORM_DOMAIN]` would be initialized during entry setup_ added_devices = [] is perfectly enough. It does not need to be shared between platforms. you never stop learning ðŸ¤“ i assumed that i\\'ve to \"store `added_devices` somewhere\" to have it persistent for upcoming calls via a signal call ðŸ™ˆ  `@callback` is still missing  a set would have been better here to avoid linear search. I missed this. You will trigger this on each data update. It will iterate ALL devices in each platform on every data update, this is too much.\\r\\n\\r\\nYour old new_devices solution was actually better. Sorry :)\\r\\n\\r\\nThe alternative would be to have _add_devices take a parameter with a list of ains to add. Then have coordinator keep track of when a new device shows up and trigger a dispatcher event for this. (I thought you already used a dispatcher event).\\r\\n\\r\\nBut.. since you are piggy backing on the coordinator listener your old solution could have worked. We generally dont use that for non entity updates, but i dont see why we cant. So might be better to revert to your old version. what do you think about this solution: e511040 (_only applied for binary sensors as showcase, when agreed i\\'ll add it to all platforms_) This is guaranteed now. So just remove that check. Just calculate the new data here instead.\\r\\n\\r\\n\\r\\n I\\'d inline this code. We can remove the brackets to make it a generator expression instead of a list comprehension. #104267',\n",
       " 'For this code base we want ternaries that span multiple lines to be converted to if blocks Ah yes they are way easier to understand =) \\r\\n\\r\\nunreachable since its guarded in base climate entity\\r\\n\\r\\n Guarded in base entity class\\r\\n\\r\\n Aux heat had been deprecated. Should we revert this PR?\\n\\n/CC @jesserockz @bdraco ',\n",
       " 'Does this automatically localize the name of the holiday? Good catch, thanks. Now it does. When is country not set given that it is required? Seems like this is always true so the if statement can be omitted. I got some mypy errors in between, so I added that. I\\'ll remove it. Is there a case where list_supported_countries returns something different than whether or not this supports subdivisions? I was wondering if only using list_supported_countries and seeing if its empty is equivalent, then both the provice list and this check we know are consistent since they are using the same source.\\r\\n\\r\\n(also we already call `list_supported_countries` once for the schema here, so there is an opportunity to only call it once and get all the data needed for the entire flow) The description presented to the user for this step are \"Name\" and \"Country\" and i\\'m not exactly sure what we\\'re asking the user to enter here. Is name needed or can it be omitted, and just set the title automatically based on the country name? I was thinking about that, but I wanted the users to have the possibility to set names so they can e.g. set it to the names of friends or collegues who live in different countries. I thought this would be more flexible for users, but it\\'s fine for me to omit the name completely and set it based on country/subdivision. OK, in that case my thought is that given the integration is using unique ids, users are able to use the built in features from Home Assistant to rename the calendar or the entity id like they can with any other entity. Your use case makes a lot of sense, though it is not unique for this integration and can be achieved using the already supported method. Early exit could improve readability by removing the indent. Flip the if around and return early? Same as above, I got some mypy errors in between, so I added that. I\\'ll remove the if statement. This returns events that are outside of the range requested which breaks the API semantics. See #get-events for the expectations. The parent class already sets a `location` attribute from the `CalendarEvent` so I don\\'t think this needs to override that. Set it via the `CalendarEvent`? See #calendarevent for the supported fields on the dataclass. Is this here and below handling timezones correctly? I think this ignores the home assistant timezone so it may be off. I think `_event` can be removed from this class? e.g.\\r\\n This seems to me something that belongs in the config entry setup flow, and not in the options flow. You mean like `STEP_USER_DATA_SCHEMA`? How can I pass `self.data[CONF_COUNTRY]` then? > How can I pass self.data[CONF_COUNTRY] then?\\r\\n\\r\\nMake it a two step flow. Sorry, I still don\\'t understand. Can you point me to some example or documentation? Just wanted to say I\\'m also not sure what the gap is here. I currently read the code as being a two step config flow and not part of the options flow. \\n\\nMy impression is options flow means the flow where you change configuration options for the integration after it is set up, which I don\\'t see being used here.\\n\\nProbably something subtle I\\'m missing so clarification would be appreciated, thanks! We should default it to the setting of the Home Assistant system by default. I just took it from here: #L135\\r\\n\\r\\nWhich setting do you mean? I mean the Home Assistant core configuration itself now contains a country field. Done. This is missing the device info Added. I didn\\'t look myself yet (as I will do it for workday) but is the languages really matching up and what happens if the country does not support the language set in HA? Should already be a string?',\n",
       " 'Move here and below out of the try/except to minimize the except scope to just what is needed. Perhals an `else:`. That\\'s done.  Also done in `async_step_user` for consistency. Can you also test where the user fixes the error and goes on to succeed? Helpful just to make sure the combination of flows still gets the user to the right spot. Done While you\\'re here changing this, it could switch to `mock_ring_auth` too That\\'s done.  Also done in `test_form` for consistency Can you send this as a separate dependency bump? Makes it easier to review when the PR is doing fewer things. In this instance the dependency bump needs to go in at the same time as the code change.  This is because the new exception types in the ring_doorbell library are raised in the case of authentication errors and the oauthlib exceptions that the ring integration currently catches are no longer raised.  If the bump goes in without this change the existing authorisation flow in async_step_user will break. My assumption is that doing the bump and swapping exceptions is a little more mechanical (and can still preserve existing behavior) then actual reauth support is added second. I may have misunderstood though. Understood, that\\'s now done, see  It seems like the 2fa_user and 2fa_reauth flows could be combined, where differences are fairly minimal (just the schema?) and be handled by checking for the presence of `self.reauth_entry`.\\r\\n\\r\\nI would suggest just inlining `_show_reauth_form` and `_show_user_form` -- while the overall method would be more verbose, its easier to understand what is happening if its in a single place without jumping up and down in the file. Both these suggestions are now done. I\\'d say inline this Done Here and above: The preferred approach is just have the patch method as the parameterized method, avoiding conditionals in tests. (Then If the behavior varies too much, then just copying the test and code is preferred) Fixed It\\'s good to use a constant for strings that are used more than once. I\\'d use a constant `CONF_TOKEN` for `\"token\"`. Hi Martin, yes agreed. I started to introduce constants with this PR and thought about replacing all the existing instances of \"username\", \"password\" and \"token\" in the integration then decided to do that in a separate PR.  I should have brought the CONF_TOKEN in at this stage but will definitely get to it. (I\\'m hoping to get the integration to platinum level soon and I know this is a base requirement :) Good, thanks!',\n",
       " \"This is only ever run once, so you can use `hass.data[DOMAIN]=` \\r\\n\\r\\nunique ids are per domain/platform so you can drop `binary_sensor` \\r\\n\\r\\n#L36 You can set this as `self._attr_entity_registry_enabled_default`\\r\\n\\r\\n~~I'm also not clear why you would create one if it would be disabled?~~ the source will already be SOURCE_IMPORT so I think this line is redundant Oh, I see you are combining `device_tracker` and `binary_sensor`\\r\\n\\r\\nI guess this makes sense Yes, I combine them and only want to activate the sensor that the user has configured in YAML. I'm pretty sure this platform supports shorthand `_attr` as well Yes, `_attr_unique_id` and `_attr_ entity_registry_enabled_default` are supported. I need to use the property attributes ( the shorthand `_attr` are not supported. I'm not sure we should import them at all since we want to allow both like \\r\\n\\r\\nAlso this would avoid this problem: #unacceptable-sources-for-a-unique-id\\r\\n Reverted the import completely. \\r\\n\\r\\n Generally we try to avoid collecting a name if we can.\\r\\n\\r\\nAnother option is to use the config entry title to generate the name so when they rename the config entry, it would generate a reload ie `entry.async_on_unload(entry.add_update_listener(_async_update_listener))`\\r\\n\\r\\nWe use this pattern in a few other integrations to still give the user the flexibility to rename and its also nice not to have to manage the name in two places There is an example of this in `flux_led`.  I think `wled` might do this as well Thanks a lot, will have a look Have changed this now \\r\\n\\r\\nSince we have both sync and async code in this code base, please prefix function that are safe to run in the event loop with `async_`\",\n",
       " 'This test is for `SHMOS-01`, there is no change log for this device so the result should be `None`. But I agree this is misleading. I just added more parameters for this test.',\n",
       " 'Can use device class translations  \\n',\n",
       " 'We can leave this out, it will pick up the name from the config entry as a fallback automatically. This is mostly mean to connect devices, not services. This last addition doesn\\'t make much sense to me.\\r\\n\\r\\nEven connected through the internet, these are still cameras.\\r\\n\\r\\n\\r\\n\\r\\nIf this was done because of providing images, then the answer is: This domain should no longer be used for that (we now have an image entity for those).\\r\\n\\r\\n../Frenck Oh yes, I didn\\'t have the \"image\" entity in mind anymore, that makes perfect sense then. Will revert this.',\n",
       " \"Suggestion accepted, thanks. Suggestion accepted, thanks. \\r\\n\\r\\nThis is now part of the manifest Suggestion accepted, thanks. Please move this to your __init__.py. The logic for connecting should not be part of your cover.py.\\r\\n\\r\\nSee  (and many other integration) for an example. Thank you for your suggestion.\\r\\nMy understanding is that since a leviosa shades can spawn multiple entities, this curtain controller is essentially a wifi to IR device, but it can control up to six groups of covers, so it will derive up to seven entities, such as `group1` - `group6` and `group_ALL`, so we need to call the `async_add_entities` method inside the `async_setup_entry` method, but obviously the `async_setup_entry` method in `__init__.py` doesn't have an `AddEntitiesCallback` parameter, so it's not possible to call `async_add_entities` inside `async_setup_entry` in __init__,py anymore.\\r\\nI'm currently stuck at this point and don't know how to proceed from here, again I'll ask you for your advice, thanks! By the way, I looked at your sample code and I see that your scenario is logging into a cloud account and then being able to register multiple `devices`, not `entities`, And the situation I encountered is that one `device` supports multiple `entities` I refer to: #L22C13-L22C13 @greg-ha-1990 in the example you link to, the hub is instantiated in `__init__.py` and retrieved via the `hass.data`. This is the same as my suggestion. Set up the connections etc. in `__init__` and create your specific entities in cover.py.\\r\\n\\r\\n\\r\\n\\r\\nPlease don't resolve conversations that you didn't fix. This makes it hard for reviewers to look at the open issues. Best to remove this from your initial PR. It is not required as base functionality and can be added in a follow-up PR.\\r\\n\\r\\nIn the future, it would be good to add comments here to clarify what this does. See #service-descriptions. There is ambiguity here, what it really means is for the motor of the cover to advance the cover to the next `position`, I will update the naming of this service to make it easier to understand and avoid ambiguity. What kind of discovery is this? Normally we should not use the user flow for discovery, but the existing SSDP / DHCP discovery. We use the SSDP protocol for device discovery, and I know HA already supports SSDP-based auto-discovery, but I still prefer to put it inside leviosa_shades instead of reusing the public SSDP discovery functionality because I want to customize the presentation of the device discovery page in a way that can help users understand the difference between different leviosa shades, and I don't want to scatter discovered leviosa shades in a massive list of chanting HA auto-discovered devices; in fact, I'll even hit the `ignore all` buttonï¼ŒAnd sometimes the public device discovery function cannot complete all device discovery well.\\r\\n\\r\\nCan I keep it in my own integration?\\r\\n No, you should use the built-in SSDP flow for this. You can set a name / description for any discovered device, thus you are able to customize the presentation of your devices.\\r\\n\\r\\nYou can still add a regular config flow where people can add the integration manually (by IP e.g.) if that is possible. Suggestion accepted, thanks. And perhaps you can even use the EntityDescription here, since most values are set to a static value anyways. But might be overkill if you only have a single cover configuration possible. Suggestion accepted, thanks. Suggestion accepted, thanks. \\r\\n\\r\\nFalse by default Suggestion accepted, thanks. \\r\\n\\r\\nTrue by default Suggestion accepted, thanks. Suggestion accepted, thanks. \\r\\n\\r\\nThis is why I was confused by no state in your integration. If you have a stateless integration (as you described in the reply, added below), your iot class is assumed state. See #iot-class.\\r\\n\\r\\n> This is a wifi to remote device, it can't actively know the state of the cover because there is no network connection between them, just as there is no way to ask the TV remote which channel is playing on the TV right now. We can only save the cached state values when actively controlling a wifi to IR device, and besides, cover can only be controlled by this IR device, so there's no ambiguity about it.\\r\\n\\r\\n\",\n",
       " 'Does it work to call `on_message_received` to avoid the message parser and just pass in the `RoborockMessage` directly here? Yes that works - there was a problem that made me not originally do that - but I must have solved the problem because it worked perfect this time. Thanks appreciate the review - this looks a lot saner now',\n",
       " \"Please set these in the constructor, having mutable dicts outside of the constructor can have unwanted side effects In fact we don't need to init them here, since `_set_fan_speeds` is already doing that, so I will remove the `= {}` from here.\\r\\nSorry, I just copied this from the airzone integration: #L118-L119 > In fact we don't need to init them here, since `_set_fan_speeds` is already doing that, so I will remove the `= {}` from here. Sorry, I just copied this from the airzone integration:\\r\\n> \\r\\n> #L118-L119\\r\\n\\r\\nDone in cdbe317185844534075504d610aec0a92beb640e I don't know if its possible, but can we give the names some more context? We now have `speeds`, `_speeds`, `self._speeds` and its kinda confusing Done in cdbe317185844534075504d610aec0a92beb640e I have the feeling this function is probably a tad too complex, but I have no better way.\\r\\n\\r\\nBut if I understand correctly, we will create fan modes depending on what the fan can do. Is this maybe something to move to the lib? Is this HA specific? This is pretty similar to #L152-L171 but as opposed to the local integration, in which all devices seems to support 0 (auto) speed, some older cloud devices can only be set to manual speeds... Also, for me this is more Home Assistant specific, since this function allows us to expose common fan modes such as `LOW`, `MEDIUM` and `HIGH`, but it also adds the rest of the speeds as a percentage. This is done so these speeds can be exposed to Alexa, Homekit...\\r\\nSee #issuecomment-1542049704 Done in 1feff044ffb5fa9a53c77b06e531587d3216da4d I think the way this is written is almost unreadable, I suggest to just write it out; the total is even shorter this way:\\r\\n @emontnemery I'm OK with the change proposed. I just did it as suggested by @bdraco on the local integration:\\r\\n#discussion_r1191977727\\r\\n#L56-L70 Done in 1feff044ffb5fa9a53c77b06e531587d3216da4d The docstring says we're initializing, I think that would work better in the method name too\\r\\n Done in edea3571bba63f7041003dede1eb5225caca5302 I suggest styling it like this instead, i.e. with a space before the %-sign:\\r\\n I prefer to keep it without a whitespace, since that's how I implemented it in the local integration:\\r\\n#L169 Why do we want the list to be:\\r\\n\\r\\n\\r\\nInstead of:\\r\\n\\r\\n\\r\\nIf there's a good reason, it wouldn't hurt to explain it in a comment.\\r\\n Because only the default speeds are exposed via Homekit/Alexa, and this is the only way of having N speeds and also getting the default ones exposed. Done in 0f4566fd7b73df8542737d0ae8a6c9adc66bc820 > only the default speeds are exposed via Homekit/Alexa\\r\\n\\r\\nThe Alexa integration does not support fan speeds for climate entities.\\r\\n\\r\\nFor homekit there is such a limitation though\\r\\n#L313-L317\\r\\n\\r\\nI'd like a second opinion on this design, integrations should not have to solve limitations in voice assistant integrations.\\r\\n\\r\\n`gree` adds additional fan modes with a list like this, but maybe it doesn't work here if there can be many fan speeds:\\r\\n > I'd like a second opinion on this design, integrations should not have to solve limitations in voice assistant integrations.\\r\\n\\r\\n@emontnemery this was already proposed by @bdraco during the same review for the local Airzone integration, see #discussion_r1191986188\\r\\nThe Airzone local integration code: #L158-L177\\r\\n\\r\\n> gree adds additional fan modes with a list like this, but maybe it doesn't work here if there can be many fan speeds\\r\\n\\r\\nAccording to Airzone there can be up to 8 speeds (+ Auto). > The Alexa integration does not support fan speeds for climate entities.\\r\\n\\r\\nYou're right, comment fixed in 681967f516b31703c9114f6a36548a20a2215530 > this was already proposed by @bdraco during the same review for the local Airzone integration\\r\\n\\r\\nThat's not a good proposal though, other integrations should not have to implement workarounds because of limitations in `homekit`, please change to a consistent naming both in this PR and in the `airzone` integration.\\r\\n\\r\\nMaybe the climate integration could make use of some clarification of the fan modes, or splitting between an ordered list of fan speed and fan modes (such as auto), that'd need an architecture discussion though. > That's not a good proposal though, other integrations should not have to implement workarounds because of limitations in `homekit`, please change to a consistent naming both in this PR and in the `airzone` integration.\\r\\n\\r\\nDone in 438c5b6e32483f276b47cb0d5e4747ee5b031d78.\\r\\nI don't think that doing it for the local integration is a good idea since it will break the compatibility for existing users...\\r\\n When does this happen, is it if we pick an item in `FAN_SPEED_MAPS` and the device does not have an automatic speed? Please add a comment. Exactly, it's only for the case that you've mentioned.\\r\\nI can either add the comment or refactor the code removing 0 from FAN_SPEED_MAPS and adding it only if the device supports the auto speed. Done in 2d63accac765cc94515ca58f2e8ce0af3eef493d\\r\\nPlease let me know if it's more clear now or if we still need a comment for this. `max_speeds` can be `2` or `3` I guess. But `int(round((max_speed + 1) / 2, 0))` is always `2` if `max_speed` is `2` or `3`. May be the code can be made much easier to read? Or may be I am wrong? @jbouwh you're wrong, because that code you're mentioning won't be executed if max_speed is 2 or 3, since it will get the speeds from FAN_SPEED_MAPS in that case.\",\n",
       " 'Please sort this alphabetically I think \\r\\n\\r\\nmight work better as you\\'re also using `opengarage` as variable name at some places \\r\\nPersonal preference For certain platform you can add a device class and it will take the name of the device class. So if you remove the translation key here and from strings.json, the button will be called \"Restart\" (which is also in line with other integrations) \\r\\nApparently you can give the `OpenGarageEntity` an entity description and it will set the entity description and the unique_id. no need to do that here as well',\n",
       " \"Wouldn't it be better to check if the process is found, if not, raise an HomeAssistantError (they can even be translated nowadays). We dislike to log on info, but I see that you do this on more places, can you maybe fix this in a followup? Will do, I've changed the ones here to debug level I think this should be a `ServiceValidationError`, because the user supplied an invalid process ID and there's no reason why we should spew a stack trace in the log when that happens.\\r\\n\\r\\nBackground in  Changed ðŸ‘ \",\n",
       " \"We won't accept more code that includes protocol details in this integration. Those should be extracted to a 3rd party library.\",\n",
       " 'Since you\\'re the dev behind the library, maybe add a `py.typed` file in the library to avoid these imports  I don\\'t really like the way this is set up. Can the MotionMount lib maybe create a function to add a listener afterwards instead of during construct? This can raise, but we don\\'t handle it Hi @joostlek, This is not the same: the mac address can be either None or EMPTY_MAC to be invalid in this context. oooh, my mistake! I don\\'t think we need to store the name in the config entry data For the callback, can\\'t we instead ask the coordinator to do a refresh? I\\'m sorry, but the exact working of the `DataUpdateCoordinator` is a bit mysterious to me. You mean I call `await self.async_request_refresh()` in this callback and merge `_get_data_from_motionmount()` into `_async_update_data()`? Hi @joostlek, I tried to get such a thing working, but since the callback is a synchronous function I can\\'t call `await self.async_request_refresh()`. Due you have a suggestion here? This can be a shorthand property (`_attr_device_info`) (if doing that, ignore my comment about removing the constructor) Can you elaborate on \\'my comment about removing the constructor\\'. I don\\'t see a comment about that. Sorry, I missed the hidden comments.... Can we use entity translations? Can we use entity translations? \\r\\nJust asked someone else, can you give this a shot? That gives me \"\\'NoneType\\' object is not callable\".\\r\\nIt works if I move this new code into the `motionmount_callback()`, but it makes the system rather slow in updates as the update request is delayed. This might be a feature, but it is nice to see the sliders respond almost instantly to updates. I think there is also an `async_refresh` `request` waits a few seconds to group any other requests Indeed! I\\'ve updated the code. It still uses the `motionmount_callback()` to avoid the \\'object not callable\\' error. \\r\\nWhat do you think of this setup? This way you keep the logic to get the native value at one place and don\\'t duplicate it. Other solution would be to extract the setting of `_attr_*` in a separate function. Checkout Airzone (or cloud, don\\'t know out of the top of my head) Are you going to add more entities? Maybe take a look at the entity descriptions. This way you create 1 generic NumberEntity, and then use descriptions to make it specific for that one. I couldn\\'t find any documentation about the entity descriptions. I\\'m going to make more entities, but not number entities. There will be 1 binary sensor, 1 select and 1 sensor added. Will it then still be useful to use the entity description? In that case I think this is fine. It could make the code a bit cleaner but that\\'s no requirement for this PR imo. (Checkout youtube/sensor.py for an example for how the entity descriptions work). But I\\'ll leave that up to you. The coordinator already catches their own exception, can be put outside of the try block\\r\\n Please specify what Exception you are catching',\n",
       " \"Please don't implement tests of the remote entity in `test_media_player`. Instead, refactor the relevant media player tests to extract a common helper for testing services, and store that in `tests/components/androidtv/common.py` Done as requested (with some PR in the middleðŸ¤£) Isn't the naming here confusing, the patch is not the service call, it's the API endpoint we expect to be called by the service call? Yes, fixed We should also assert:\\r\\n- The number of calls\\r\\n- Call parameters Added checks It's not clear to me how the tests shows how the `UnicodeDecodeError` is handled. This was because the decorator normally set the entity as not available, but for sure was missing a `cap_log` check. Anyway I changed the logic to raise a `ServiceValidationError` and so I changed the tests Shouldn't we raise a `ServiceValidationError` instead, since the `UnicodeDecodeError` is a result of the user passing in invalid data? Yes, done. I also changed the decorator to allow the raised exception to be thrown.\",\n",
       " \"\\r\\n\\r\\nWhy must this key be required? I think optional is fine. When we use optional for this new option, we don't need to change the version and therefore we don't need a migration. You're right... I removed that. Why are you setting this to `None` as the default value? We should avoid if statements in tests. Please create a own test for it Removed, this is already handled in `test_state_always_available`. Same here. Please create a test for yaml and one for config flow. You can create a protected function for the shared code, so you don't need to duplicate it The pattern used in testing this integration is to test the sensor coming from the yaml configuration or configuration entry in the same test (see `test_state`), I just kept this pattern.\\r\\n\\r\\nDo you want me to separate the `test_state_always_available` test into two to handle the yaml configuration and configuration entry in separate tests? I would like you to confirm this before I change it. Okay we can leave it for now and we should refactor the whole file in the future. Please add a new config flow test about the new field Added to the existing `test_options` test Could you please add a test where you are also setting always available during config flow? Included the `test_always_available` test for this.\",\n",
       " 'Does this need to support unregistration when the config entry is unloaded or the entity its supporting is disabled, etc? My impression is that this returns an unregister callback. at the moment (_only the `Proximity` entity is there_) there is no configuration entry, nor is the Proximity entity configurable via the UI, IMO those this support of unregistration needs to be added at least when the configflow (_those the config entry_) is introduced to the integration. Is this valid? The default is `None` but not represented in the type? should be more clear or better resolved with 9c0bdb3 Given this is not polling, and registering its own callbacks for tracking state changes, i this really meeting the spirit of a `DataUpdateCoordinator`? It seems like it may just be its own object for tracking state so i\\'m wondering if perhaps its not getting value from subclassing this, or if its not a good idea to subclass. i considered to go with `DataUpdateCoordinator` because it already brings everything needed, so registered entities get notified and values updates as soon as the data update on the coordinator was successful. this is also to be seen as prework for adding the sensor entities. What does it mean to have new state? I\\'m wondering if it means the data is unavailable and should return `None` vs preserving existing data. Curious to learn more about when this can happen and what it means. this all is moving existing code, so tbh i\\'m not sure in which circumstances the `new_state` could be `None`, but it seems to be foreseen, as the `async_track_state_change` use it as signature for the to be called function:\\r\\n#L170 Agreed, I see that now, thanks. Are these devices or entities? Given its pulling `hass.states` i\\'m assuming they are entities, so wondering if the variables should be renamed, or if there is something else here specific to home assistant devices.\\r\\n\\r\\nI realize this is moving existing code so it could also be future cleanup. you are right, these are actually entities of type `person` or `device_tracker` ... but as you mentioned, this is moving existing code, therefore i tried to change only the needed parts and leave the rest as it is In these cases where the return values are creating new data, I don\\'t think it\\'s worth updating all the fields in a local variable. I\\'d suggest removing `data` then returning a new dict like this:\\r\\n\\r\\n\\r\\n\\r\\nSame below as well. --> 258d5b3 Consider defining a dataclass with the 3 fields as the return value instead. It can help enforce types (like elsewhere I saw there were some calls to convert the return values to strings) and it can handle the default values cases. i already tried to define an own dataclass for this, but TBH did not get it work nor get mypy happy ðŸ™ˆ \\r\\nbut yes, this should be done ... will try again --> 005ba6d i think this check could already be handled by the `async_check_proximity_state_change` above, to avoid unnecessary state change triggers to registered coordinator entities in case data are not changed anyway (_same counts below_) --> d88a9c9 This isn\\'t a config entry setup so we can\\'t use this coordinator method. 3ac7fc09475e8f2d31db690c3472809dd00a3646 The `async_added_to_hass` method should be called before the first default state write. f2d551a0d92caff4d695c297772d1facc4b317fc I think this constitutes a side effect. I suggest we break it out to a method that we can call specifically to setup the tracking. Use a walrus so we don\\'t need to access the attribute again below. Use an f-string instead of string concatenation. Can the proximity be 0? Should we handle that the same as `None`? this seems to be wrong and will be fixed in another PR which will also include additional tests for all these \"abort conditions\" Why do we use something that we call the coordinator\\'s friendly name to create what looks like an entity_id?\\r\\n\\r\\nIf we want to log an entity_id, why not log the entity_id of the entity we\\'re interested in? I\\'d not log this above debug level.',\n",
       " \"Hey @bajansen, do you still want to be a codeowner? That would be great. You can put your name first if you want/if it means anything to you. Nah lets keep it alphabetical ðŸ‘  Please run hassfest as it should also add you to the tests as code owner hassfest did not do this for me, but manually added it now Now hassfest rejects.. ðŸ¤·\\u200dâ™‚ï¸ That's interesting Can we add reauth in a follow up PR? Removed Reauth handling, token renewal is still included as the token expires after 7 days. Can you maybe tell a bit more on how the authentication works? When does one need it? User can get publicly available market prices for electricity and gas without signing in. \\r\\n\\r\\nWhen authenticated, the user gets price data personalised (e.g. different 'inkoopvergoeding'). And billing information (invoices and cost until now) Technically is it just retrieving a JWT to authenticate for different API endpoints. Personalised API's are not available without. Right, in other integrations where authentication is optional (Forecast.solar and opensky) we do authentication in an options flow. Let me check with some people if this is a must or that this solution would be good as well. What is raising `UpdateFailed` here? Ah this was when we did the API calls directly from HA. Removed! \\r\\nIt's the only object you're currently storing, so no real need for a separate key Personally I think the comments don't add much value here, up to you if you want to keep them Why do we have errors as parameter? Double check, users can't change username? I have seen this without the `exc_info=ex` before, mind giving it a try?\\r\\n Oh right, I now see why you had errors in the parameters. Suggestion: maybe you can turn this function around\\r\\n```py\\r\\nerrors: dict[str, str] = {}\\r\\nif user_input:\\r\\n    # logic to verify it works and create entry, else we set errors\\r\\nreturn self.async_show_form(........, errors=errors) Does this API maybe use oauth that we can use? I mean, the tokens are JWT right? We should be able to recoginze when a token expired and act before requesting data Also since you're requesting every 60 minutes, that would leave a gap of an hour every so often. You don't have a reauth flow yet, so this would raise an error. I think you should raise `ConfigEntryError` I think we should not put json data in state attributes as this isn't user friendly as it's shown in the UI. If a user wants this data, can we maybe use a service call? You can remove the square brackets, this saves a bit because it doesnt have to create a list The coordinator already provides data for the sensors, so we don't need to update them on add\",\n",
       " \"This is the default.\\r\\n Empty string doesn't seem like a good summary. In the dev docs we write that uid is required for the entity state. Isn't it required here then? Thanks, missed that. Will add more tests for cases that need uids when we get to mutations. Can we use an f-string instead? I'd do one iteration over the results to create the final list instead of two iterations. Updated. I didn't realize i could do the alligator and list comprehension together.\",\n",
       " 'Please sort this list Why do we first declare data before getting api, why don\\'t we get api directly  This can be inline (without creating entity first) Will you be adding more buttons? Currently this platform is using 2 ways of declaring entities, I would prefer that we choose one of them to increase maintainability. I currently don\\'t plan on adding more buttons, what do you mean by \"2 ways of declaring entities\"? You\\'re using both entity descriptions as just creating a specific class for an entity. I would say use one or the other. Ok, I\\'ve changed ButtonEntityDescription to EntityDescription That wasn\\'t the change I mean.\\n\\nUsually we use entity descriptions to quickly create entities. For this we create a generic entity that holds the description.\\n\\nWhen you have less entities, or very specific ones, you create a class per entity.\\n\\nCurrently, you have it 50/50. You have a class specific for the boil water button, but you also use a entity description for the rest of the button. in this case I would prefer to choose one or the other. Since you won\\'t be adding more, I would suggest moving the entity description fields as shorthand attributes in the class itself I\\'m inhering from Tami4EdgeBaseEntity which accepts an EntityDescription parameter and uses it to set other attributes.\\r\\nTami4EdgeBaseEntity is being used in other entities.\\r\\nShould I change Tami4EdgeBaseEntity to work without EntityDescription as well, or would something like this be okay?\\r\\n\\r\\n\\r\\n If you change the super init to `super().__init__(...)` I think we can make it work It still needs an EntityDescription \\n Please add this file to .coveragerc',\n",
       " \"I think this function is that small that you can just inline it Both are already handled by the coordinator  I guess `test_coordinator.py` isn't needed in that case either? That was the only thing it was testing Not really. A coordinator test is always a bit meh in my opinion as you want to test what the result of the issue is. So if the request times out, what is the effect on the entities. Please remove empty keys I think you can remove this one Please make sure this test ends in either a CREATE_ENTRY or ABORT to show the config flow is able to recover from an error  I would say in the case of InvalidLoginException, raise a ConfigEntryError or return False. Otherwise it will keep retrying to log in with invalid credentials  New integrations have to use `_attr_has_entity_name = True`. There are some docs on it but I'm on mobile right now.\\n I thought that's only relevant when there's a device. Looking at other Todo implementations, they don't seem to be implementing devices. Hmm, that should not be happening (must say that the Todo stuff was added quite late in the release so it might have slipped, I'll double-check this when I'm at my desktop).\\n\\nIn this case I would just enable it. Add a device with entry type service and call it a day Please don't use if statements in your tests I think you can move these tests to the Todo tests for style. This isn't a blocker tho, just personal preference can creating this raise? If not, move it out of the try catch block I think that maybe 1 device for 1 account would work best since you don't create 1 device (/service) per list for only 1 entity. would love to hear what you think The problem with one service is naming it - the best candidate would be the email used to login, but that ends up as a prefix to the entity name, and you can't even see the actual list name in the to-do lists screen.\\r\\nGiven no other todo integration creates devices, I really think we shouldn't either. oooh right, that's true. OK, I removed the devices and addressed the other comment `already_configured` string isn't used. If we want to use it we should use the `already_configured_service` reference. This can be a module level function or entity method instead of a nested function. In the delete todo items service handler we gather the work. Can we do that here too?\",\n",
       " \"They shouldn't be able to change the unique id `user_id` via reauth Ah, good catch. Fixed! I guess the form needs a schema for what to fill? I think it would look cleaner to have these additions for reauth in `async_step_reauth_confirm`.\\r\\nNot sure it gives any value with mixing it with the user step. Should this not return the errors if any? It modifies the `errors` dict that's passed as an argument. Right, don't like but I guess that's fine. I changed it to return the errors instead of taking it as a parameter. Could use the same schema I guess and even allow to change the username? I'm not sure changing the username makes sense? That would be a different account with different locks, and it would change the unique id associated with the entry (since the user id would change).  The reason I asked was because I wasn't sure the user_id is the e-mail address or not so it could then be possible for the user to actually change his e-mail address. But I guess that's not the case so that's fine. We don't have an abort with reason unknown I think? Good catch! Fixed. Missing the field for password.\\r\\n Done.\",\n",
       " 'You should be able to avoid multiple comprehensions here. Done',\n",
       " 'Why would we add this attribute? I oriented myself in other parts, so I added that. Should I do this instead?\\r\\n\\r\\n No, I mean why are we adding this attribute? What would a user do with it? You can display the name of today\\'s holiday, e.g. in a markdown card. I was thinking if there was a use-case for actually making it a sensor and not only adding it as an attribute. Wouldn\\'t it make more sense than to have a \"holiday\" integration like  which provides e.g. a calendar entity? Yes. I have thought about it before but never came around to do it. \\nI agree that would be a better fit @jrieger you want to change this PR into a calendar entity instead? I\\'ll have a look. Thinking a bit more on this I probably would say both the attribute, a sensor and a calendar entity would be out of scope for this integration as it targets workdays and not holidays. \\nShould probably be it\\'s own integration with only a calendar entity for holidays.  See ',\n",
       " 'It would be good to start adding `translation_key`\\r\\n\\r\\n The Withings integration also has a \"Height\" string. Should I add this to the common ones in homeassistant/strings.json? Or maybe to sensor/strings.json No Could/should we add `_attr_suggested_display_precision` to suggest the number of decimals as default? done This will make an extra state update besides the default state update at the end of entity addition. We should separate the native value attribute update from the state update if we need to update the native value here.',\n",
       " \"We should remove all duplicate lines if possible.\\r\\nIn this concrete example we don't need to specify the `off` state as it will fallback to the icon specified in the `icon` key, which is the same\\r\\n\\r\\n Even if the class is currently protected, we should still mark variables that should not be accessed from outside the class as protected. This is no the same, this will create a new cache instance to pass into the method everytime this part of the code is called (while it is being omitted constantly, as it already existed). This is a side-effect from passing it in an an argument. To reduce code duplication we could use `partial` for `cv.schema_with_slug_keys(` with `slug_validator=translation_key_validator,` as it is used multiple times here Is an empty json file intended? Please mark also these two variable protected Are these two not so common that we should add them to the entity component? Swing modes are free-for-all strings, there is no standard in that \\r\\n\\r\\nSame as default Should we mark it as protected? Should we mark it as protected? Should we require that an entity component has at least `_` (for fallback) defined? Good question, we don't require it for translations and we do have a generic fallback icon as well ðŸ¤·  \\r\\n\\r\\nMaybe we could also declare it outside of the function \\r\\n\\r\\nWe should get the schema after loading the json Why didn't you add type hints for `ws_client`? \\r\\n\\r\\nEasier to read imo \\r\\n\\r\\nTo make it consistent with the actual result type\",\n",
       " 'Should this indicate that the default, if not specified, is to only include items with a `needs_action` status? Yes, agreed, done. In #102534 and #102481 we currently have the suggestion to name the services `forecast` and `events` respectively. To match that I think `items` might be more fitting.\\r\\n\\r\\nEDIT: I do however think that `list_items` is more descriptive albeit not \"aligned\" As I understand it, new services are being introduced with those slightly different names because the old versions will be deprecated for a period of time, and the old services should be available under the same name for that time so that existing automations don\\'t break.\\r\\n\\r\\nShould this dictate the names of services going forward? I understand why the change is made, but personally think `list_items` is much better than just `items`. IMO, services should have a \"verb,\" especially since there are other services that act on todo items in this case (`add_item`, `remove_item`, etc), so `items` breaks this pattern and would make users ask \"well, do _what_ with the items?\"\\r\\n\\r\\nMy two cents as a user :) I changed the PR for other two services so that they would be called `weather.get_forecasts` and `calendar.get_events`. To align this service could be called `todo.get_items` Sounds like a great solution. Updated to `todo.get_items` I think we need to remove the default here from the service schema, and only add the default to the service description.\\r\\n\\r\\nThat way, the default will be set when using the UI (filter by needs action), but providing no status filter will return the complete list.\\r\\n\\r\\nCalling the service with any filter, should not just go and filter by its own. Additionally, if you want all, you\\'d now have to provide a status filter to get to that (which is odd).\\r\\n\\r\\nI get the intention of the default, but we should set that as a UI feature instead. Great catch, thank you for the thorough explanation. I have moved the default to `services.yaml`.',\n",
       " \"Don't both log and raise error. The exception argument will be logged automatically.\\r\\n Are we going to deprecate the `is_offset_reached` for the legacy entities or deprecate the legacy entities? If so, I think this is ok, but otherwise our standard nowadays is to set the state attribute to `None` when we don't know it for the entity. Yeah I would generally like to make it go away slowly, given its weird and hacky and triggers should be the new way to handle this. My thought was to no longer support it from the UI but preserve it for existing yaml users.  We could technically support it here since its just pulled from the titles of the calendars.\\r\\n\\r\\nI was thinking this needed to be announced when making yaml go away, but perhaps i need to start shifting the docs since I kind of punted on what to do about existing yaml for now, assuming it will be possible to deprecate in the future. (I think we may need a better solution for search still like a calendar helper to fully make it go away)\\r\\n We probably need to at least say in the docs if it's not supported when setting up the integration from the UI. Thanks, i've added a documentation PR (which was missing in the first place) and have addressed this. Move this line that can't raise down out of the try... except block. We should probably abort if the user enters the same url and username as an existing config entry.\\r\\n\\r\\n#L1489-L1493 `CONF_VERIFY_SSL` doesn't seem used. Thanks, i added support for this everywhere.\\r\\n\\r\\nI am not sure this is high priority to support in the UI, but figured it wasn't hard to add. Other option is to not support it. It's ok to add it. There's no unique_id at the moment.\",\n",
       " 'On this line I think you should have a pair of values like :\\r\\n(\"uptime\", \"uptime\"): GlancesSensorEntityDescription( This line should not be useful as the previous \"for\" loop already handles all sensors I would suggest isolating this code in a separate function as it is specfific to the uptime sensor Missing unit of measurement Do you need to update the data in the source structure ?\\r\\nI would move this whole block after the generic \"value = ..\" and only update the value, like this :\\r\\n\\r\\nvalue = self.coordinator.data[self.entity_description.type]\\r\\n\\r\\nif self.entity_description.type == \"uptime\":\\r\\n    value = convert_uptime_to_timestamp(value) Should not have these kind of \"calculations\" in the properties.\\r\\nWhy not just adding the starting time instead as I would understand is the base here? I believe glances sends uptime as a formatted string like \"12 days, 3:42:29\", not the original startup time, so converting to a timestamp needs calculations.\\r\\nThe other issue I see is that the calculation will not be very precise, so the computed Timestamp will change slightly at each update.\\r\\nMaybe passing along the uptime as a string without computing a timestamp would be fine ? Ah. Didn\\'t look that careful but just assumed.\\r\\nWe should provide it as a proper timestamp.\\r\\n\\r\\nBut the calculation should be in the `DataUpdateCoordinator` and not here (would also remove a few comments as below) Thanks, I will move the calculations, but as @wittypluck already mentioned glances doesn\\'t provide a proper timestamp, but instead a human readable form.',\n",
       " \"You need to patch where this is getting used. i.e. homeassistant.components.octoprint.coordinator.OctoprintClient.shutdown\\r\\n\\r\\nOr something similar\\r\\n\\r\\nYou should avoid doing global patches Is this needed? Looking at the init_integration function, it by defaults set to default printer, which has these attributes with a bit more. You also should not do anything to the coordinator inside of tests. You instead should patch when you need the coordinator to change values You cannot access hass.data in tests Why can't I? I have now removed it because it's not needed in my tests but it was working.\\r\\nI've copied it from the other existing tests in this file. So are they wrong too?\\r\\nWhat would be the correct way (e.g. for the other tests)?\\r\\n We don't want the tests to directly mess with integration internals, in this case you're testing the button platform and you should need access to the data coordinator to do that. Instead, your test should, as a general rule of thumb, check the state in the state machine, call the button's press service, and by mocking the 3rd party supporting library check that pressing the button has the intended side effects. You should also freeze time and then check that the buttons state is equal to that time. \\r\\n\\r\\nButtons states are equal to when they were last pressed, so by checking that, you can be sure that it successfully ran. I'm pretty sure this is the default behavior and is not needed? This goes for all of these No that's not default behavior. The default also checks if the printer is connected. But since this button is only for controlling OctoPrint and not the printer it would not make sense only being able to e.g. shutdown OctoPrint if it has a connection to the printer. Apply my above comments here as well These both should get the RESTART device class. I'm not sure if anything gets weird if two entities have restart device class, so you should test it Make a new base class `OctoprintOnlyButton`, or something like that, so we don't need to implement the simpler availability check three times. We really should not keep adding natural language names like this, octoprint should be migrated to translated entity names. That's for a different PR though.\",\n",
       " \"remove unused properties please set `_attr_has_entity_name = True` (#has_entity_name-true-mandatory-for-new-integrations) can we move block out of here? Maybe to tests? needs to move to external PyPi package ( needs to move to external PyPi package ( should probably also move to pypi package What do you use that update_listener for? You don't seem to have an options flow Thanks for that, that was some left over from a copy paste Will you add more Platforms later? Then I'd definitely add a common base class, if not I'd still think about it to reduce some of the duplicate code in the inits. Have added a common base class in entity.py (Saw other integrations did this, lmk if this isn't correct practice) I believe you don't need those if you also inherit from `CoordinatorEntity` same here is it possible to use `translation_key` here and move the nae to `strings.json`? Would allow for better localization support (applies to all sensors) sorry missed that one: please remove that empty key No worries - Done :)\",\n",
       " 'Are defaults allowed here as this is giving the password in plain text? At least for the client ID it is convenient for me to have that printed out to double check. It\\'s up to the integration to show the password or not Ok. How could this work with your suggested changes? I need to set the default just for this usage. Ah, missed one suggestion that covers this, I\\'ll try that. Is there a way to use the localized `invalid_auth` text here? Not yet. There is a PR open to start implementing translatable errors, but it still needs to be merged. We can add translations for it at a later moment. Correct once #103111 is approved.\\r\\n\\r\\n \\r\\n\\r\\nIs this working as you expect it? If my suggestion below is fine we could remove it\\r\\n\\r\\n Since you are using `unique_id`, you could do the following:\\r\\n\\r\\n Or just simply set \"entry_id\" on the MockConfigEntry If you set \"entry_id\" as mentioned above, you need to set \"entry_id\" here as well. \\r\\n\\r\\nCan be simplified as the schema includes at least one required key',\n",
       " '\\r\\n\\r\\nPlease remove any commented out code.\\r\\nn this specific case, the logger can be set to debug via  Thanks! Will next commits of this PR Remove empty keys Done. Why do you need this? For new integrations, we require the following:\\r\\n- Support for [the new entity naming](#has_entity_name-true-mandatory-for-new-integrations)\\r\\n- Services must be [translatable](\\r\\n- Entities and their attributes should be [translatable](\\r\\n\\r\\nPlease adopt your code to add support for it. Thanks. Will include it in next commits. Vs code should not create any files inside your component. Why do you need this? Old stuff. I can remove it, if you prefer Why is this comment out? Just clutter. I will remove it and resubmit. Sorry. The level info is reserved for the core. Please use debug\\r\\n Will fix in next Commit Will fix in next commits Can we use a Coordinator instead? We can certainly. Is there a specific reason to do so? Anyway, will address this in next commits The coordinator does the scheduling and co already and we should reuse it instead of creating all by our own. Please add a coordinator\\r\\n\\r\\nAlso if the user disable a certain device, it looks like this API is still polling the information about that device, which can be omitted by using a coordinator This file needs to be removed Ack Above, you set `_attr_name=None` to use the device name. Why are you creating this property? Clutter. Will remove it \\r\\n\\r\\nCan never happen \\r\\n\\r\\nCan never happen as you set it in the init file Ack Why is the sleep required? Can this ever happen? Lines 35-36, were already removed to address another comment. If you mean line 38, I will anyhow remove it',\n",
       " 'Instead of using magic number 4 everywhere, we should make a constant `DEFAULT_TIMEOUT` or something, but that could happen in a separate PR.\\r\\nAlso, it doesn\\'t seem like anything is catching the timeout errors, which means that users will see stack traces if it happens. The timeout errors should be caught and nicely logged IMO. Again, that can happen in a separate PR since it also affects already existing code. Opened a new issue to deal with this later, thanks!\\r\\n There\\'s no need for the mixin class, instead enable `kw_only=True` on the  `StarlinkTimeEntityDescription`\\r\\n\\r\\n Does this apply to other sensors too? I can open a PR to update the rest of that\\'s the case Yes, it applies also to other sensors. @joostlek may have already done that though. Could we gather the calls to `status_data`, `location_data` and `get_sleep_config` or do they need to be called sequentially? I\\'m not sure what you mean by \"gather\", but if there\\'s a better approach to calling these then let\\'s do it I mean use [`asyncio.gather`](#asyncio.gather) to run the three corutines in parallel Done, thanks! Don\\'t create concurrent executor jobs. We\\'re not allowed to create more than one executor job at a time. Please run all sync work inside a single function that we schedule once on the executor.',\n",
       " 'Needs to use translations As my setup is English (only), I cannot test translations - is adding a translation-key sufficient? Adding support for translations is mandatory for any new addition to our codebase. support for translations was added What is mist? Is it described somewhere in the API documentation?\\r\\nDoes it have known values? I updated the PR description to answer your questions:\\r\\n\\r\\n\"My fan has a \"mist\"-feature, that means it has a water tank from which water gets vaporized via ultra-sound and injected into the air stream to cool down the room\"\\r\\n\"As this is completely undocumented in the Tuya docs, I implemented it as a simple enum since I don\\'t know what other devices might report\" > I implemented it as a simple enum\\r\\n\\r\\nRight, but what does it mean? Shouldn\\'t it be a number entity instead?\\r\\nAs in, seems like you can select levels? Do they need textual representation? Well, the mist-feature of **my** fan probably should be a number entity...\\r\\nIt\\'s just the amount of mist that get injected into the air stream, it doesn\\'t have a textual representation - in the tuya app and the vendor\\'s app it\\'s also just shown as [0..3].\\r\\nAs the feature is not documented, I chose an Enum to also support devices having non-numeric values.\\r\\nIt would really be nicer in the UI to make it a number entity, but would rule out devices having a non-numeric value here.\\r\\n\\r\\nWhat do you recommend?\\r\\nSwitching to a numeric entity?! I took another look at it, I suggest to accept the PR as it is because of:\\r\\n- Tuya returns an Enum, implementing it as an Enum seems to be the safest and most logical way (as possible return values are unknown because this feature is not documented in the API)\\r\\n- The Tuya-integration does not support creating a NumericEntity out of an Enum\\r\\n- Other fan-features that are \"Enums returned by Tuya\" (like \"countdown\") are implemented exactly the same way it\\'s done in this PR',\n",
       " \"I don't think this file is needed.\\n\\nThe majority of other virtual integrations I checked do not have this. It was required the last time I added a virtual integration.\\n\\n#pullrequestreview-1663799125 Ok! Thanks! Ok! Thanks!\",\n",
       " 'Does only the delete API return errors with an `error` key in the returned dict, or could this also be applied to some of the other api calls here like list or insert? The others apply this too, for example in `_execute` below on line 137. Delete is just different because it is a batch API, but it is sharing that part. Manually applied after merge conflict (resolved in the wrong order)',\n",
       " \"Would it be possible to enumerate all the settings and get their current state and create entities instead of a custom service? Yes, that is possible. Is that generally the preference? It would be more user friendly.\\r\\n\\r\\nIt looks like it will return 27 speakers and their settings, even if you don't use them all. I for example only have 8 speakers in use.\\r\\n\\r\\nI would say this is probably less useful for people, mine isn't a unique use case, but I don't know if there would be many others - I use the 360 Spatial Sound Mapping, but I have different settings based on the input used. My receiver has profiles, but there doesn't appear to be a way to select a profile via API, so I just update each speaker.\\r\\n\\r\\nChanging set_sound_setting to get the current state with associated entities would make more sense to me, as it would be more useful to users. Can we distinguish the speakers that are in use from the speakers not in use ? I had assumed no, but looking at the API response it is possible. It indicates if the speaker is a candidate (assuming speaker configuration ie 7.1) and if you are using it/have it connected. Eg: 7.1 configuration has different patterns, so 11 speakers are available, but only 8 would be in use. So some options. The Sony 'Music Center' app shows all 11 for me, with the 3 I don't use greyed out.\\r\\n\\r\\nThat makes the option more viable. Not sure what a soundbar looks like for speaker settings, but it would have been ugly to create 27 entities when it is probably just Left, Right, and Center, maybe a Subwoofer. Maybe create one Home Assistant device per speaker in use and connect the settings entities to the corresponding device? Mark the entities as entity category config.  There is an unfinished PR #63145 which aimed to add separate entities for settings, but it was abandoned. Maybe it's worth checking out if reviving it would make sense? Wow, that is a big change but would improve the integration. I will close this PR and when I get some time look at PR #63145. Thanks. Yeah, maybe it was a bit too much in a one go indeed.. It's probably better to make this by refactoring to use the `DataUpdateCoordinator` with one platform, and then improve platform-by-platform to speed up the review. Some of the code introduced in that PR might also be better suited to be included directly in the python-songpal.\\r\\n\\r\\nI'm not sure if @Flameeyes is still interested on working to get these changes in, but as my old soundbar seems to be still working, I can help you with some testing & code reviews as needed. Yeah, I would break it up into many smaller changes, so that it can be chipped away at. My biggest issue is that I will now need to learn the ins and outs of Hass, instead of a small copy of something that is already there :)\\r\\n\\r\\nI also don't really need this as I can already do it another way, but could be useful for others. I do like making things better, and more useful for people :)\\r\\n\\r\\nI don't know, that PR is almost two years old.\",\n",
       " 'Can you add a comment about what this is doing? Want to extract a constant here? Seems worth extracting a constant for 90 and giving it a helpful name (MAP_REFRESH_INTERVAL or CACHE_INTERVAL something more accurate) It would be good to also exercise the image fetch side of this since it has interesting code in it and it can get the coverage numbers up. I was playing with this last week, something like:\\r\\n\\r\\n\\r\\n\\r\\nThen it could also be possible to start `patch`ing things and playing with the `should_update` logic as well. Partially implemented - haven\\'t added anything for patching should update yet - not 100% best way to tackle that yet tbh I realize this roborock API is probably a little \"unique\", but perhaps you can explain to me what is happening here. \\r\\n\\r\\nIt loops over maps and returns an entitiy for each one loading each map. But then it also loads the current map (is this /again/ or the only time else?), but doesn\\'t add any extra entities for that last map call?\\r\\n\\r\\nI think adding a little more to the pydoc about how this works as well as elaborating on why it has to be synchronous (e.g. because the server can only load one map per device at a time?) would be useful documentation. Exactly - only one map per device at a time. I\\'ll add a bunch of comments Given the name \"update\" has a specific name for entities and this uses an update coordinator, would a name like `is_cache_expired` be more accurate? My impression is that `ImageEntity.__init__` calls this function. Is this needed? Don\\'t think so - I added it when I was first debugging and running into some issues. Check out #image which says that the frontend will only fetch the image when this property changes, and it is not expected to update this from within this call.\\r\\n I don\\'t think this has been addressed to follow the developer guidance. Ah I thought I handled this - my bad. But to be honest, I don\\'t really get what the docs means is best practice in this case.  I think it is saying that the data fetch should not be happening in the image serving path, but instead should happen when data and state is normally updated (e.g.  `async_update` etc).\\r\\n\\r\\nSo as a concrete example of what it is saying could be appropriate could be: \\r\\n- from `_handle_coordinator_update` start another background task to fetch the cloud image, then as that finishes it sets the image update time.   Maybe the logic in `is_cache_expired` needs to run there and adaptively fetch? My understanding is that you\\'re trying to only update the map when it has interesting changes when the vacuum is running. Perhaps this means some of the caching logic isn\\'t needed, and it just turns into logic of when to fetch new data.\\r\\n- fetch from the coordinator. this could put all the fetching in one place, but then maybe you have less control e.g. to disable the entity to stop map fetching if you don\\'t want it Yeah is_cached_expired only updates the map when it is interesting.\\r\\n\\r\\nI\\'m still a bit confused\\r\\n\\r\\n\\r\\n\\r\\nBut the issue is - the frontend will repeatedly call async_image if i refresh or open up the image, it doesn\\'t seem to care about image_last_updated OK.. maybe its more about subscribing to updates and knowing when to refresh rather than to avoid refreshing too often. You may want to kick off the image fetch when the coordinator update finishes, then update the image and state at the same time.\\r\\n\\r\\n(Overall the down side is the map will be getting refreshed when the robot is active even if nobody is looking, but that doesn\\'t seem so bad given its only when the robot is active.) I don\\'t fully follow the docs logic though still\\r\\n\\r\\nasync_image gets called whenever I look at the image, if I handle updating the image there and also setting last_image_updated there, then it kind of solves all of the problems, no?\\r\\n\\r\\nThe map will get refreshed when someone looks at it and it needs to and the last_image_updated reflects when the image was last updated. But i\\'m still not sure what last_image_updated is actually used for\\r\\n\\r\\nPerhaps I do what fritz is doing?\\r\\n\\r\\n It may be that the frontend is not yet taking advantage of this, but it is the currently specified API contract that it can if it needs to.\\r\\n\\r\\nYes, what fritz is doing is fine in general, but the complexity added in your case is the active map is determined by the update coordinator so I assume you\\'ll want to run after it has the latest active map data. Should be resolved now Thanks, the comments are really helpful.\\r\\n\\r\\nSo technically, you could skip some calls here in cases where the current map is not changing and things are already loaded? Given there is a pretty huge sleep here, i\\'m wondering if there is a common case that has a fast path: For example, is it common to only have one map? Sorry to jump in but I\\'m also very interested to this great feature. \\r\\nTo answer you last question I think many people have one map, but as soon as your house has 2 floors or there are stairs/steps the vacuum can\\'t overcome, than you certainly have more than one map.  Yeah I now check if we only have one map for this device and then if we do - I don\\'t bother changing maps or sleeping\\r\\n\\r\\nI can probably take it a step further by doing the cur_map first, then doing any other maps Cool, this is great. You could also consider doing the current map last since i believe it needs to be restored at the end anyway. It might mean there are fewer places to have the multimap load call (just in the loop is ok) Having it last would actually slow us down I think\\r\\n\\r\\nWith two maps:\\r\\n\\r\\nCur map = 0 \\r\\n\\r\\nDon\\'t change maps, as we are already on cur map.\\r\\nDon\\'t sleep\\r\\nParse map\\r\\n\\r\\nChange to map = 1\\r\\nSleep\\r\\nParse map\\r\\n\\r\\nChange to map 0\\r\\n\\r\\nsleeps = 1\\r\\nMap changes = 2\\r\\n\\r\\nvs\\r\\n\\r\\nChange map to map 1\\r\\nSleep\\r\\nParse map\\r\\n\\r\\nChange map to map 0\\r\\nsleep\\r\\nParse map\\r\\n\\r\\ndon\\'t change map\\r\\n\\r\\nSleep = 2\\r\\nMap change = 1\\r\\n\\r\\nThere are less map changes, but we have to sleep more times, which slows us down Got it, thank you. Is it worth skipping updates when `is_map_valid` is False? (no changes because its not cleaning, or map is not active, etc) That makes sense to me - changed. Should the cached map be reused when the image hasn\\'t been updated since the last call? I believe so- that should be what is happening This comment looks stale since i think this is the first call.  Perhaps the positioning changes slightly given the update coordinator is now happening?',\n",
       " \"Naming should be rethought, \\r\\n\\r\\nActive Sensor makes it sounds like it is a property of the sensor, but in fact it's a property of the schedule/comfort settings.  Maybe `set_participating_sensors`? That would be closer to what ecobee calls the functionality. I am open to changing it to whatever makes the most sense. I like that better \\r\\n\\r\\nother options\\r\\n\\r\\n`set_sensors_used_in_climate`\\r\\n This PR does two things:\\r\\n- bumping the dependency\\r\\n- adding the new service\\r\\n\\r\\nThe two things can be split, so they should be split into two PRs.\\r\\nPlease move the dependency bump into a new PR. Leave this PR in draft until the other one is merged. Have removed from this pr and added to  \\r\\n\\r\\nWill be automatically added by `async_register_entity_service` Removed the erroneous line. \\r\\n\\r\\nPlease move this step before you access the device registry Changed to msg format (sorry about that... should have noticed it was dumb to do it that way). Moved this check before the device registry lookup. Same here This check uses information from the device registry lookup. I do not know how I would move it before it? Unless you are just talking about the msg format. In which case, I changed it. Same here This check uses information from the device registry lookup. I do not know how I would move it before it? Unless you are just talking about the msg format. In which case, I changed it. please adjust variable name to new naming ideal Good catch, sorry I missed that. Updated. Adjust naming Updated. For some reason, chaning it to the `if not x:` format failed mypy. I left it the same. \\r\\n\\r\\nThe raised exception will be logged Please use a `ServiceValidationError` instead and it would be nice to add [localization](#exceptions) for it.\\r\\n\\r\\nPlease also adopt the other places I am not sure what the difference will be in this instance? I will update with commit, but if you could let me know for the future why using elif in this case would be better. I think we should rename `climate_name` to `preset_mode`or something similar as it would be easier for the user to understand it\\r\\n\\r\\n Will update with commit. \\r\\n\\r\\nPlease mark internally used functions as protected \\r\\n\\r\\nCan be removed as the value is a valid preset_mode Are you sure, you want return `None` in the list?\\r\\nAre `sensors` and `name` not always present?\",\n",
       " \"ðŸ¤« For new entities, we require the following:\\r\\n- Support for [the new entity naming](#has_entity_name-true-mandatory-for-new-integrations)\\r\\n- Entities and their attributes should be [translatable](\\r\\n\\r\\nPlease adopt your code to add support for it.\\r\\n\\r\\nIs it correct that the picnic todo entity doesn't support any modification?\\r\\nSee `TodoListEntityFeature` Sure!\\r\\n\\r\\nAlso please see \\r\\n\\r\\nWe can add items and maybe delete them. But keeping the PR as small as possible. I would suggest making the name translatable We don't accept any test written with `unittest`. Please see the pytest style instead Just used the same test structure as used in sensor.py to be consistent\\r\\n\\r\\nI will see if I can convert the the other format. Test in test_todo.py have been updated to pytest style. Tests in test_sensor.py can be done in a followup PR. Please note that none of the To-do have this one covered. Ah ðŸ˜¬ðŸ‘Œ The only question I have is about the price. Should we really add it? What is the advantage to have it? First thought was â€œwhy notâ€. But removing it fixes the incorrect price handling when selecting special offers.\\r\\n\\r\\nSo letâ€™s remove it? Please invert the inheritance order. Also add a type annotation to the generic `CoordinatorEntity` what coordinator type it holds. Please move the comment above the line to decrease the line length.\",\n",
       " '@patrickhilker are you fine to be a codeowner if I move this to core, or should I remove you? Awesome - I\\'m fine beeing a codeowner. I\\'d like to have an opinion here please: Should I leave that endpoint authenticated only (which requires to send a long lived access token unencrypted every time, which grants access to the entire HA instance), or should I make it unauthenticated (it is only used to update status information anyways)? Please assign the coordinator to hass.data after you know init was successful\\r\\n\\r\\n\\r\\n ~~I personally have no preference here, but it was requested like I have it from another reviewer in my other PR.~~\\nActually, not true. Not possible because setup would fail, as the platforms are retrieving the coordinator from the entry.  fixed \\r\\n\\r\\nPersonally I would prefer this Also, what actually would happen when no token is found? I think I test for \"\" because it might be the empty string coming from the options flow. If no token is found, then the websocket part is not initialized and we only rely on polls for updates. \\r\\n\\r\\nNot sure if this is _exactly_ the same, but IMO it is more readable if it does not the same. My code ensures that if one of `CONF_HOST`, `CONF_LOCAL_ACCESS_TOKEN` is set, the other must be set as well, but if you leave both of them empty that\\'s fine (you must set the `INIT_CLOUD` then though). Your code would make any of them mandatory. Not needed Yes, let\\'s automatically break all other entries when you reload one :p\\r\\n\\r\\n\\r\\n Can be removed for now honestly this function can be inlined in the config flow If we can\\'t connect to the device or have invalid auth, will this function behave the same as `tedee_client.get_locks()`? Why not use this function call for validation? Can be removed Your whole flow is in 1 function, can be removed I dont think we need this Only put stuff in the try block that can raise We never even set this value In this function `self.config_entry` will be set to the current entry, so if you move this function to the top you can remove the `entry` parameter of this class Please raise `ConfigEntryError` for now as you don\\'t have reauth flow in this PR Only have stuff in the try block that can raise What kind of special unique_ids will be added? If nothing special, there\\'s nothing wrong with just a plain old `f\"{lock.lock_id}-{entity_description.key}\"`. This whole setup btw requires every entity to have an entity description, is that the case? \\r\\nWhy do we string the lock_id, what\\'s the base type? The lock is the main feature of this device, consider setting the name to None so the entity name will follow the device name.',\n",
       " \"We're introducing a new intent. Shouldn't we just aim to do the right thing and set the state as-is instead of making fake states Yeah, I agree. I've fixed it here, and I will make sure to migrate the sentences before marking `HassClimateGetTemperature` as supported in the intents repo. We shouldn't need to assert if we raise above.\",\n",
       " \"Scan interval shouldn't be configurable. You can disable polling and call the home assistant.update_entity service to update sensors.  Why not reload the entry?\",\n",
       " \"What does it mean to not pass the previous uid? It means move to first I'm in the list (there is no previous items therefore it's the first) Is it standard to set a default argument or none for something like this? I think it's ok to have None as default but I suggest we document what it means in the docstring and in the dev docs. Can we make the previous uid a test parameter instead? We don't know it until it is created since uids are created on the fly. We could seed with a fixed database, or mock out uid creation deep in the library, though my thought is that might be too tight of a coupling with an internal detail. However ical does this for it's own tests so there are some util hooks for that. (I was replying for ical though same techniques could be used across both) Hmm ok. I guess it's ok like this then.\",\n",
       " 'With tests â¤ï¸! Cant ruin all the hard work you did to get the coverage up =) validated against the docs \\r\\n\\r\\nlooks good ðŸ‘ ',\n",
       " 'Maybe you can add `native_unit_of_measurement=\"ignitions\"` as well The ignitions are just a numerical value, is there any unit measure for that? I mean, it\\'s counting the amount of ignitions right, you can put custom values as unit of measurement',\n",
       " \"I made this flexible so we can add more combinations later without having to add a lot more complexity May be you could use a named tuple?\\r\\n#collections.namedtuple Since we never access the data in the tuple as its only used for the hash key, I'm not sure if that would be worth the additional complexity.\",\n",
       " 'can this happen ? I don\\'t know if it can *actually* happen, but mypy threw a fit until I did this. The definition of entity name includes `UndefinedType`: #L470 ah check, yeah ok.  Using `async_match_states` now I\\'ve been thinking about this. For backwards compat today we could just target the list that is created by the shopping list integration.  What if we add an optional `domain_hint` slot to the intent that defaults to `shopping_list`? This causes the todo entity search to prefer a specific domain, both with and without a name.\\r\\n\\r\\nThis would let us support sentences like \"add X to todoist\" (with `domain_hint` set to `todoist` by the sentence data) and it would add X to the first todoist list. It also provides a way to target lists with the same name from different domains. I guess that results in the same backwards compat behavior, so I guess ok? I don\\'t see how the domain hint would get set in other situations (as one cannot say \"todoist\" and expect STT to pick that up)',\n",
       " 'Maybe the function name as a filter should be \"hebrew_date\"? It matches better the Jinja semantics. Same here \"zmanim\" should suffice. I think these changes are unrelated.',\n",
       " 'Shouldn\\'t we add this directly to `HomeAssistantError`? `HomeAssistantError` is may be too broard. But the way it is implemented now could also be applied to `HomeAssistantError`. In that case may be add an option to suppress the stack trace? Added translation support for `HomeAssistantError` and sub classes (like `ServiceValidationError`) including `ServiceNotFound` (also a subclass of `HomeAssistantError`). I was suprised when I saw this, that we set the translation key in the place where we handle the exception. If that is needed I\\'m wondering if the exception is the correct place to hold the translation info. Alternative this could be set in the class definition. But it seems we have 2 variants with different descriptions. This seems the only places where we raise a `ServiceNotFound` error.\\r\\n\\r\\n#L1980\\r\\n\\r\\nAnd it\\'s called from:\\r\\n[homeassistant/components/websocket_api/commands.py](#diff-ae1571378111595f87a494f6e575eae8865050a436257b01d336b96744c30a03) Not sure when `if err.domain == msg[\"domain\"] and err.service == msg[\"service\"]:` is not true BTW. As discussed on Discord, this should be implemented in frontend. Instead of translating in core, core should send translation key etc. in the error messages. Removed, this will be planned to be processed in the frontend. Why do we need these default values? If translation domain is not set (e.g. for `ServiceNotFound`) it defaults to `websocket_api`. I do not want to import the domain const to the exception. Do you think I should do that?\\r\\nPlaceholders are added if the `translation_key` is set, may be this is not strictly needed. Added a comment to explain why a default for `translation_domain` was added. I don\\'t think it\\'s a good solution to have to copy translations of exceptions to the `websocket_api` integration.\\r\\nEither we give some special meaning to a `None` `translation_key` so frontend knows to pick them from `common::exceptions`, or we move the standard exception translations to the `homeassisant` integration. This doesn\\'t seem to be used? Right, it is a leftover. These do not match what\\'s sent by websocket_api ~~They do afain.~~ It seems there was a `__repr__` method that differed, hence the message set when initializing `ServiceNotFound` did not match since it was was overridden. Why is this marked as resolved?\\r\\nThese strings still do not match what\\'s sent by websocket_api; websocket_api only uses translation_key `other_service_not_found`, but strings define two other keys: `service_not_found` and `service_child_not_found`. Sorry, I kept the original error text\\'s. I have synced every thing now, also the `__repr__` variant and places the translation strings under the `homeassistant` integration. Also added placeholders. Why do we need to guard? May be we don\\'t need to do that Tried to remove it, but reverted that, it seems a lot of CI tests assert on the whole payload. If we leave the guard, we need to adjust all the tests.\\r\\nI suggest that if this is needed we do this in a different PR. We shouldn\\'t complicate the code to avoid updating tests. Check with frontend developers if they prefer to have the keys always there or only there when needed.\\r\\nThere\\'s no need consider saving data here IMHO since sending error responses is not the common case. Right, I do not think it matters in the frontend, as there is no explit typing for the error responses. But we need to update quite a few tests. I would prefer to remove the guard in a different PR to avoid this one to become even bigger.\\r\\nI asked Paul, if he says we should not add it, then we do not need to change is, but I assume he\\'ll say that it does not matter. This should be in `homeassistant/components/websocket_api/strings.json` We do we add the string version of the exception to the translation placeholders? Frontend should allow this to be null or a map\\r\\n I don\\'t think this is needed?\\r\\n',\n",
       " 'Please don\\'t access hass.data in new tests. Instead use the async_fire_timed_changed test helper  Done. As above  Done. Useless pass? Removed. As above  Done. Please patch the pypi code and avoid patching the integration (except for async_setup_entry) Please patch the pypi code and avoid patching the integration (except for async_setup_entry) Please patch the pypi code and avoid patching the integration (except for async_setup_entry) Ok to patch the Bluetooth public api  Looks like there is no need to make a list and a generator expression can be passed to async_add_entities  I *definitely* didn\\'t steal this from another integration without thinking twice about it :laughing: \\r\\n\\r\\nDone. Doesn\\'t seem updated, did you forget to push? Please use f-strings  Done. Please use f-strings  Done. This looks unreachable through the normal flow AIUI and as my experiments show this gets called -  at the BT discovery step (`async_step_bluetooth`). Given the entire integration is reverse engineered and there\\'s no documentation for the device I think actually communicating with the device like we do here is the only way to find out if it is what we think it is. \\r\\n\\r\\nI\\'m of course happy to take advice on the matter as my experience with HA design principles and best practices is... limited. Please don\\'t set anything in hass.data until after passing the first refresh successfully  Done. Please see\\n\\n#has_entity_name-true-mandatory-for-new-integrations The entire naming section is a great piece of documentation I was looking for and didn\\'t find. Can we reference it from somewhere underneath the \"Integrations 101\" section?\\r\\n\\r\\nApplied for the PR. Please add entity_category so diagnostic entities don\\'t appear on default dashboard  Done - can you please double check the classification makes sense? The ones that aren\\'t marked as Diagnostic can technically be updated (not through HA yet, it\\'s coming in a subsequent PR) but Config can\\'t be set for them (\"#L278\"). \\r\\n\\r\\nShould I leave them as-is, or mark everything as Diagnostic for the time being and revisit when they\\'re updatable?  Please move specific uuids to the pypi code and import instead  Looks like this isn\\'t using f-strings  Different local workflows apparently. I tick off all items I\\'ve addressed locally and consider PRs in draft mode as a scratch space which should only be reviewed when explicitly marked as such. Apologies for wasting your time if you\\'re used to a different paradigm. Let me finish this round of comments my way and I\\'ll behave better next time :).',\n",
       " \"Besides adding a fixture, you also need to add an actual test that verifies metric values, similar to the one we have for `input_number`:\\r\\n#L272 I believe I already did that, but it was in a different commit:\\r\\n\\r\\n#L296-L317 Instead of copy-pasting the handler, may I suggest moving shared code to a separate method and calling it from both handlers? Something like this:\\r\\n\\r\\n\\r\\n\\r\\n(this applies to the code of the integration itself, it's fine to have duplicate similar code in unit tests) Thanks, what a blunder on my site. Fixed in the latest commit.\",\n",
       " \"Fetch time outside of the loop Unpack `hass.data[DOMAIN][entry.entry_id]` into a local var so you don't have to keep doing dict lookups here I have a separate PR to make it a dataclass ðŸ‘ \",\n",
       " \"Add the event entity in the event platform. This isn't straightforward.\\r\\n\\r\\nThe `media_players` in roon aren't static - the roon system creates them dynamically as devices become available (and deletes then too). So the media player creating code tracks what players come back from the roon api as things updates - and creates any that don't yet exist via a callback. You can see the code here:\\r\\n\\r\\n\\r\\n\\r\\nIf you feel strongly that event entities should only be created inside the event platform - then I'd need to create another callback inside `async_setup_entry` in the event platform.\\r\\n\\r\\nNot sure this would be clearer - but happy to do so if you think it's better. Yes. Platforms aren't allowed to depend on another platform. Thanks so much - and sorry for my foolishness! Don't create the entity directly. Set up the integration while patching the library and assert the entity state in the state machine.\\r\\n\\r\\n#writing-tests-for-integrations Call the callback via the patched library call arguments. @MartinHjelmare The roon integration hasn't previous had proper tests . I think from your comments above I'd need to look at patching parts of the roon library - and working out how to mock some of the async updates thet the library provides (which trigger creating HA entities)\\r\\n\\r\\nIn development terms I think this  is going to be more involved that what is currently in the PR.\\r\\n\\r\\nIt it now a requirement that new entities (like the one her) require this sort of test?  Tests are not required but if you want to add tests they should be written according to what I described. Thanks. Given the challenges I'll remove for now.\\r\\n\\r\\nAt some point I may take another look . The best place to start would be the media_player. Please sort ðŸ”¡. Remove these type ignores. They shouldn't be needed. These constants are never used. We can remove this. Please type the whole signature when adding type annotations. Don't log at info level unless targeting users. Use debug level. Connect this entity to the same Home Assistant device as the media player by setting `device_info`.\\r\\n\\r\\n#defining-devices Shouldn't we use the roon device id to id the device in the roon api? The entity_id is Home Assistant specific. It's just a reference key so that you can update the callback if you need to - so `entity_id` seemed like a good key since it's related to this entity. I'd still use the device id. It's weird to pass a Home Assistant API specific string to another API. Or better, pass the unique_id. The user can't change that and it's currently the same as the device id, right? And if we would add more entities to this platform in the future it would still be unique for this platform. Follow up PR should preferably take care of this comment:\\r\\n\\r\\n#L162\\r\\n\\r\\n#entity-naming We can set `self._attr_device_info` in the init method instead. Where is the unique_id set? It wasn't - sorted. Do we need to unregister the callback when removing the entity? There isn't currently an pyroon api call to do this.\\r\\n\\r\\nPyroon is reverse engineered and when I investigated I couldn't find how to unregister these. I'm assuming it's possible although the official roon node api examples don't do so.\\r\\n\\r\\nThe pyroon mapping layer has a broad exception catch when it calls the callback - so if there is a problem it will catch it and report an error (although to date  I've never seen this)\\r\\n\\r\\nFrom a roon perspective if the client goes away - then the volume hooks are removed at some point. I meant to remove the stored callback. Currently there's a memory leak here since the entity can be removed and added but the callback remains and whenever the entity is added, eg when changing the entity_id, a new callback will be stored. Generally there should be a way to remove callbacks if we can register callbacks. As I said there currently isn't a way to do this in the pyroon api.\\r\\n\\r\\nAll pyroon stores is the provided key and the call back - so even if entities were being created and destroyed (which they generally aren't) it would be a very small growth in memory use\\r\\n\\r\\nI guess it would be possible to remove the callback dictionary entry in pyroon - but I'm not convinced it's a great idea without also removing the matching entry via the roon_api..\\r\\n\\r\\nThere is a mechanism where roon to re-requests all the volume endpoints - which again makes me cautious about not having the two sides of the api match. \",\n",
       " \"If you plan on adding more buttons in the future it might be easier to use ButtonEntityDescription and add a press_fn\\n\\n\\nThere are a few examples in the codebase already of this. Let me know if you need help finding them Done, I think. Let me know if that is not what you had in mind It looks like the pattern is going to be common so it might be nicer to have a base entity class in an entity.py that took care of setting the properties that are the same  With the ButtonEntityDescription change, this is not duplicated anymore, so I think it is fine to leave it in button.py for now? Its fine for this PR, next PR should be to create an `entity.py` for a shared base class ie `IdenDeskEntity` before adding any more platforms @bdraco  I was now looking into this for another PR, but I am not sure what the IdasenDeskEntity class would have. Only a single line for the `self._attr_device_info = device_info` ? Because everything else is not common for the current platforms. If there isn't anything common yet then it might not worth be doing until there is.  Usually at some point there is #has_entity_name-true-mandatory-for-new-integrations\\n\\nYou can use has entity name instead  If unset uses this already #L442 oh, nice! If unset, uses this already #L565 We usually sort these in order A future improvement would be to make the button unavailable when its already connected or disconnected Good idea. I'll add that to my ToDo list!\",\n",
       " \"Please also assert that there's still a climate entity state discovered. Please address the comment by Keith above.\",\n",
       " 'Move the coordinator to its own file coordinator.py for ease of use Thank you, I moved it. Probably worth ensuring that coordinator.last_update_success is True. unless I am mistaken, UpdateFailed() being raise d in your coordinator will not interrupt this part of the flow Thank you, I added it. Why make these global variables on the object instead of member variables of the class? And _last_client_refresh doesn\\'t seem to be used Thank you, I made the proposed changes. hass is set in super() init so this isn\\'t needed Thank you, I deleted it. remove the unused keys to make this easier to read Thank you, I removed the unused keys. I don\\'t know if it is strictly required, but you should add translation keys and remove name to these descriptions.\\r\\nProbably icons as well. Entity Categories as well are best practice Thank you, I think I made the proposed changes: added translation_key, removed name. The default icons are ok. Instead of using separate lists, it may be worth considering adding a  supported lambda, then evaluate that when adding the entities below. I don\\'t think theres anything wrong with this as it is, but that is how a lot of the integrations do it. Probably worth raising PlatformNotReady here? Not sure - but just something to look into Thank you, I added it. If you plan to have more platforms than just sensor, I would add a LektricoEntity class that all the others can be subclasses of. For any init logic that will be repeated such as device info. Thank you, I created LektricoEntity class as you proposed. CoordinatorEntity[LektricoDeviceDataUpdateCoordinator] Thank you, I made the proposed change. Why is this optional none? You seem to always do it Thank you for your help.\\r\\nI\\'m having problems with this proposed change:\\r\\nIf I replace\\r\\nvalue: Callable[[Any], float | str | int] | None = None\\r\\nwith\\r\\nvalue: Callable[[Any], float | str | int]\\r\\nand I remove None from def native_value(self),  I get this error:\\r\\n\\r\\n2023-11-02 09:00:06.149 ERROR (MainThread) [homeassistant.loader] Unexpected exception importing platform homeassistant.components.lektrico.sensor\\r\\nTraceback (most recent call last):\\r\\n  File \"/workspaces/core/homeassistant/loader.py\", line 836, in get_platform\\r\\n    cache[full_name] = self._import_platform(platform_name)\\r\\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/workspaces/core/homeassistant/loader.py\", line 853, in _import_platform\\r\\n    return importlib.import_module(f\"{self.pkg_path}.{platform_name}\")\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/local/lib/python3.11/importlib/__init__.py\", line 126, in import_module\\r\\n    return _bootstrap._gcd_import(name[level:], package, level)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\\r\\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\\r\\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\\r\\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\\r\\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\\r\\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\r\\n  File \"/workspaces/core/homeassistant/components/lektrico/sensor.py\", line 36, in <module>\\r\\n    @dataclass\\r\\n     ^^^^^^^^^\\r\\n  File \"/usr/local/lib/python3.11/dataclasses.py\", line 1230, in dataclass\\r\\n    return wrap(cls)\\r\\n           ^^^^^^^^^\\r\\n  File \"/usr/local/lib/python3.11/dataclasses.py\", line 1220, in wrap\\r\\n    return _process_class(cls, init, repr, eq, order, unsafe_hash,\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/usr/local/lib/python3.11/dataclasses.py\", line 1027, in _process_class\\r\\n    _init_fn(all_init_fields,\\r\\n  File \"/usr/local/lib/python3.11/dataclasses.py\", line 545, in _init_fn\\r\\n    raise TypeError(f\\'non-default argument {f.name!r} \\'\\r\\nTypeError: non-default argument \\'value\\' follows default argument\\r\\n2023-11-02 09:00:06.164 ERROR (MainThread) [homeassistant.setup] Unable to prepare setup for platform lektrico.sensor: Platform not found (Exception importing homeassistant.components.lektrico.sensor). So this sensor would just always be none? Change like this, then you don\\'t need the unwanted default value for the `value`\\r\\n value_fn would be easier to understand\\r\\n Is this really needed? This doesn\\'t seem to be used why do we pass the caught exception to the `ConfigEntryNotReady` constructor? And if it didn\\'t suceed, what do we do? Is this possible, don\\'t we check this in the config flow?\\r\\nIf it\\'s not really possible, I think the current code is acceptable to guard for unexpected behavior. If it is likely to happen, we need better error handling where we inform the user what happened and what they need to do.',\n",
       " \"Can be removed because you are not using a YAML configuration, so this would be empty. Removed. This can be removed since you are not using it. Removed `DATA_HASS_CONFIG`, but cannot remove `DOMAIN` and `PLATFORMS` since its using in `async_setup_entry` and `async_unload_entry` methods. I completely missed the unloading at the end. Can be removed when L17-L23 in `__init__.py` is removed. Removed `DATA_HASS_CONFIG`. Can be removed, as you don't store anything in `hass.data`. Removed it. \\r\\n\\r\\nWould make more sense, as you don't store anything in `hass.data[DATA_HASS_CONFIG]` or use it elsewhere. Changed to {} as suggested \\r\\n\\r\\nSame Removed \\r\\n\\r\\nSame Removed \\r\\n\\r\\nNo need for this Removed Removed Can we use a built in function? HA may have a function for this, but I'm not 100% sure. In fact, i wanted to use any built-in helper functions. however, I couldn't find any matching function as per my requirement.\\r\\nI have asked about in discord dev channel as well: \\r\\n\\r\\nI have removed the method from notify.py and implemented it in python module.\\r\\n You could utilize `pytest.mark.parametrize` here instead of coping the code. It makes the file cleaner and it is easier to add new errors later.\\r\\n\\r\\nAlso, we like config flow tests to end with either `FlowResultType.CREATE_ENTRY` or `FlowResultType.ABORT`. Fixed Maybe we could also use `pytest.mark.parametrize` here, the file is quite long and contains a lot of duplicate code. Fixed Same as in `_is_valid_url`. Is there a particular reason why you pass in `is_allowed_path`?\\r\\n\\r\\nOtherwise this could be removed along with L78. Removed Would `device` make more sense here, since you only connect to a single device per configuration entry?\\r\\n\\r\\n#integration-type\",\n",
       " 'Why bother with this vs just making the entity_description a required field? This would return `unknown` for a color. How about you return the RGB value in that case? The name doesn\\'t feel right, perhaps would `hyperion_visible_priority` be better? The constant name should be more specific, it\\'s not really a \"base\" unless you implement the idea below about making a generic base sensor class. Since you went with the base class idea, I\\'d suggest:\\r\\n\\r\\n\\r\\n\\r\\n... and then use that below as part of the unique_id. ... and here you\\'d include the base in the unique_id, \\r\\n\\r\\n Should should not be set in the base class. Other Hyperion entities don\\'t log, suggest we not don\\'t either. Ditto, superfluous logging. This assumes English language. I\\'m not sure if there\\'s a way to use translations in the state value (one of the next reviewers may know, but it\\'s probably not a good idea anyway). A simpler fix would just be use the Hyperion keywords. I think the `owner` field probably still works okay for other components (except color, e.g. for V4L owner is `V4L2` which seems like a fine state). i.e. I\\'d suggest you treat color specially, and for everything else use owner. Needs a new `test_sensor.py` file that verifies the new code functions correctly. Nit: Comment is not really conveying anything that is not obvious from the code. Nit: Comment is not really conveying anything that is not obvious from the code. Why bother with this line since `state_value` is set below anyway? Where is `self._state` used? The entity description is constant. We don\\'t need to create it every time we create an entity. Just define the description as a constant at the module level. enabled is the default. We can remove `entity_registry_enabled_default`. Please sort ðŸ”¡. What is it we need to slugify? I only see slugs. If there\\'s only one sensor to append we don\\'t need to use append. Just put the sensor inside the list when creating the list. Combine these two checks, invert them and `continue` if true. Then we can outdent below. If we don\\'t know a state attribute or it\\'s not applicable we default it to `None` nowadays. All attribute keys should always be present. Please use f-strings instead of string concatenation.',\n",
       " 'Remove empty keys @rccoleman Are you willing to be a code owner? removed Rob for the moment to avoid blocking this PR. Will gladly add you back if I hear from you! We don\\'t allow to catch the bare Exception outside the config flow. Please only catch specific exceptions Where is this value used?\\r\\nIt looks like it is unused. Please remove all unused variables/code those are used in platforms/services, which are not part of this initial PR - should I remove them anyways? \\r\\n\\r\\nEasier to read Why are you doing this?\\r\\nThe coordinator polls the data on a fixed interval. true, if someone executes a command, say \"turn off\", that state will be written to HA immediately. Then since commands can be sent through the cloud, I\\'m checking after the `UPDATE_DELAY` if that state update actually happened on the machine, so I don\\'t have to wait up to 30 seconds to get the actual state to reflect in HA. Please use short hand notation as class variable similar to `_attr_has_entity_name = True`  Same here This PR is huge and introduces many features, which are currently not used.\\r\\nTo reduce the PR size and we also don\\'t accept unused code, please remove all feature, which are not used in this PR. These features can be added in a later PR, if required\\r\\n\\r\\n can we really remove all of that? Isn\\'t line 16 a requirement for all integrations that are only configurable through config flow? I got some checks failing if I don\\'t have that line. You can keep the line but the only thing it will do is create a repair issue if you use yaml. Move this outside the try/except block Here, you set the unique_id to address, which will be overwritten in `async_step_machine_selection` with the serial number. This makes no sense.\\r\\n\\r\\nPlease explain when the Bluetooth discovery will be used? Selecting a device from multiple makes no sense to me when Bluetooth initializes the config flow.',\n",
       " 'Updated, will do the same on `light.py` :no_good:, fixed :no_good:, fixed :no_good:, fixed',\n",
       " \"The config flow has to be 100% unit tested I have no idea what is missing here. Please give some doc links of what I should do to 100% unit test the config flow.\\r\\n\\r\\nI can't run `pytest tests` as it fails while finding dependencies on upstream components.\\r\\n Well, you have to write unit tests for the config flow. Please checkout any `test_config_flow.py` file and you can see what happens. You can run the tests by running `pytest tests/components/climaveneta_imxw` I think you still need to run hassfest as the file isnt complete Can we retry this? You can do that by raising `ConfigEntryNotReady` Can this also raise other exceptions? Can this be moved to `coordinator.py`? The docstrings in this file can be improved Can we add types? Can we type this? Right, this integration doesn't use a library to connect with an external device as required in #5-communication-with-devicesservices. Although I am not sure how this works together with modbus, so I already asked someone if he knows an example for you to look at. This integration was largely based on Flexit integration. We want to avoid users setting custom names in config flows. Instead, please use a device_info object. Users can then rename the device_info. `_attr_name` should be set to `None`. Can we initialize these outside the constructor and with types where possible? I think you need to overwrite a different function here for it to work since you're using a coordinator. Can we move this above the Climate entity? \\r\\nSeems unused Everything here is in one step, so I don't think you need the `__init__` at all your schema is already checking this This is only used in `__init__.py` please move it to there I think this one might be already set in `homeassistant.const` You can use references here \\r\\n\",\n",
       " 'Since ViCare uses `has_entity_name = True` I would suggest to remove the name, it will fallback to the device class name This would mean I need to rework the base class. Or can it simply be `\"\"`? I am guessing you made this a separate class to make sure its always available, but when I look at `ViCareBinarySensor`, available is only False when `self._attr_is_on is not None` so would the trick be to make sure the `value_getter` function never returns `None`? I think `available` should consider the `isOnline` status of the device config in the end. ',\n",
       " 'This was actually sending the wrong object, but it had the properties that were needed so it worked',\n",
       " 'coil is a bit that only have true/false command_on/should not be a byte.',\n",
       " 'Why do we need this? Hmmmm not needed anymore. I thought I needed it for something with discovery, but I don\\'t anymore. Thanks for the comment! ðŸ™  Can we move this to `__init__.py` and use `Platform.LIGHT`? Yeah I don\\'t even think this is used. Will remove. \\r\\nWhen you want to use __package__, please move it to const.py Got it, thanks! Actually, I\\'m not sure I fully understand this. Python is not my normal language. Should I be changing the __init__.py _LOGGER as well to use `__name__` instead?  local loggers (`_LOGGER` usually) have to use `__name__` while global loggers (`LOGGER`) have to use `__package__`. Global ones are usually defined in `const.py` Please make this a shorthand attribute Don\\'t use ternaries (or however you call them) when they span multiple lines Please make this a shorthand attribute New Integration have to use `has_entity_name = True`.\\r\\n#has_entity_name-true-mandatory-for-new-integrations Thanks! Didn\\'t catch that. Why do we check this? pydeako returns a state dict and so getting the \"power\" key returns type `Any` which mypy complains about. I\\'m planning a refactor of the state management in pydeako that will return correctly types, but not sure when I\\'ll get around to it.\\r\\n\\r\\nI think it\\'s safe to just typecast Currently you are requesting the state for every property every update. I would suggest moving the whole update into `update` or `async_update` depending if the call is async or not. You can then set all the properties using shorthands. Good point ðŸ¤” thanks! Expected? This could be more descriptive ðŸ‘  If we\\'re using zeroconf, why aren\\'t we setting up the devices with 1 device = 1 config entry? (note, I don\\'t have much experience with zeroconf, but please explain a bit more on how the device works) Yeah for sure. Good question. We have some devices that can discovered with mdns. We pick one to the be \"bridge\". It can be any of them that are on wifi at the time. That device is then responsible for bridging tcp to ble as not all deako devices are on wifi at all times. Once a device is selected to be the bridge, it will stay on wifi as the local integration device. All other devices periodically get on wifi to check in, send logs, etc. \\r\\n\\r\\nSince we only really connect to one device, one config entry. All other devices are then exposed through that device using the local API. This is only used in light.py now. `const.py` is used for constants used in more files so please move this to `light.py`. Can be set outside of the constructor can be set outside of the constructor',\n",
       " 'We should not add device-level sensors like RSSI for child sockets, add a new field to the description for this case?',\n",
       " \"I don't see how this should be used. For valves that can open half way (not all of them do) there might be a reason to start opening or closing a valve and then stop at whatever the current % is (e.g. The when you're satisfied with the current flow rate of water in your garden's waterfall)\\r\\n\\r\\nIt's not an use case I have myself, but from my understanding of the discussion over in the architecture repo, it was supposed to work as covers do. I left a reaction in at the architectural discussion. Mainly a valve looks like a cover, but stopping a valve does not make sense to me, may be a valve can get `stuck`. I don't mind removing it. If @emontnemery can chime in to confirm I'm happy to remove it. There are very few things I like more than deleting code. I suggest we leave this part out. Please don't add device automations in the first PR. That can be three follow up PRs. Same with group, intent and reproduce state. Why is this file added? Damn, sorry, I must have switched branches and this shouldn't have been committed. I'll remove it. It seems the file is still there It also causes the CI tests to fail Please remove the device automations, actions, conditions and triggers for now. This requires adding a `valve.py` platform here:\\r\\n\\r\\n Remove this. It's not used. gone I suggest we remove the defaults and let the implementing platform decide the supported features.\\r\\n\\r\\nJust do it like this:\\r\\n\\r\\n#L93-L96 Well, I'd say that open and close are the very minimum for a valve to be able to act as a valve, so maybe we should signal that by making those the default? Maybe it can only set a position? I suggest we don't set defaults. Do it like this:\\r\\n\\r\\n#L78 Please test this case. We always want to set the state attributes. If we don't have a value we set it to `None` I wonder if we should add a default implementation of `is_closed` property that represents this logic so the platform can just set the current position if it knows that and have the closed state be calculated by the default property. Would it be weird that even for valves that don't allow any intermediate positions but fully opened and fully closed that we set the position? I was thinking we add a default for `is_closed`, not a default for `current_valve_position`. Don't add deprecated code. Remove the kwargs.\\r\\n Keep the `DEVICE_CLASSES_SCHEMA`.\",\n",
       " 'I think it\\'s mandatory to define these with default values to avoid mypy\\'s `error: Attributes without a default cannot follow attributes with one  [misc]`.\\r\\n\\r\\nI\\'m open for suggestions, as it\\'s not really nice as this will require checking these later for Noneness. You can instead use a \"Mixin\" with double inheritance. Great, thanks for the tip! This was moved from below here to allow passing it as `value_fn` for the sensor definitions. This `None` check would be nice to avoid by forcing passing a `value_fn` in the definition, which does not work due to the aforementioned issue with \"Attributes without a default cannot follow attributes with one\". Ideas to make this cleaner are welcome! I just realized that this information is only available if the device is on, so we may need to add a parameter to force the creation of sensors even if their value is `None` at the time of the initialization.\\r\\n\\r\\nAlso, I suppose this might also apply for the emeter sensors, too.',\n",
       " \"This would be better implemented in aiohomekit This can be done in a future PR though added to my notes to clean this up later in aiohomekit I made this a callback so we don't have races when adding/removing\\r\\n\\r\\nThe subscriptions now happen 0.25s later and we group them together. Brilliant. I always hated that this was async and gnarly.\",\n",
       " \"Please remove the brand as it has only one integration The description and co should go into `strings.json` so the can't be translated. Please see #translations We no longer accept the possibility of changing the scan interval via the config flow.\\r\\nPlease use a fixed update interval. If the user wants a different update interval, he/she can create an automation that calls `homeassistant.update_entity` on their specific needs.\\r\\n\\r\\nSee also #polling-api-endpoints In this instance, it is needed, as it depends on the amount of devices the user has. If they have many Olarm devices, they will need to set this to a higher value or the integration will experience issues where some devices will update and other devices will not. This is due to Olarm having a API limiter in place that cause a lot of issues. Please add only files which are added in this PR Forgot about those. I will fix them now.\\r\\n\",\n",
       " \"Since this never changes, this should be moved to class level:\\r\\n\\r\\n_attr_fan_modes = [*FAN_MODES_TO_OVERKIZ] Please reformat this to a short summary, followed by a blank line, then multiple lines with detailed explanation, maybe:\\r\\n Please line break this and all the other long comments My preference would be to not add a lot of constants for these parameters. These enums are not used a lot, and are very readable already. Introducing another constant to just point to the ENUM makes it not very readable in my opinion.\\r\\n\\r\\nWould you mind removing all these extra variables? The ones for temperature you can keep. Makes sense. I would like to keep `FAN_SILENT`, though, because it is missing in the Overkiz library enum, and I want the code to look consistent where we use the `FAN_HIGH`, `FAN_LOW`... etc. Best is to set FAN_SILENT to a string. It is not directly coupled to the Overkiz command name. Why isn't this set in the entity? \\r\\nNo need to cast before creating a new int with it \\r\\n\\r\\nif you are only checking if they are not None, it should be\\r\\n\\r\\n this is not good as it overrides the existing dictionary.  I am not sure if I fully understand. We set a default value in the entity.py, where we first check if the device has a specific vendor name, and otherwise fallback to the hub vendor (e.g. Atlantic or Somfy). For this device they don't provide the vendor name in the device information, and falling back to the hub vendor name doesn't make sense. Hence we overwrite the current value with 'Hitachi', which is the vendor of this specific device.\\r\\n\\r\\nThis pattern is used more broadly in Overkiz, so I will make more changes depending on the outcome :). Ah jus checked the other code, looks like it's fine. I thought it was overriding a key in a global dictionary but it's generated in the constructor. \",\n",
       " \"This is existing code, but it doesn't seem covered by a test. Would be good to follow up with that. better to do it here because I found a bug!\",\n",
       " \"This method should mirror `async_close_cover` (e.g. the `isinstance` check can be removed and an exception should be raised if the command fails). To avoid hardcoding magic numbers, these attributes are accessible as:\\r\\n\\r\\n What does this branch add? It seems like it changes the functionality of lift. If it's not required for this PR, let's omit it for now and then address it in a followup PR (probably #99646) I think this can be removed thanks to `super().async_update()` calls `cluster_handler.XXX.async_update()`, which (in this case) also reads attribute values and updates the state. Unrelated fix.\",\n",
       " 'This belongs in the 3rd party library.',\n",
       " \"We should return the datetime as an iso-formatted string in the attributes I've made the requested change, but out of curiosityâ€”I think I saw `datetime` objects returned elsewhere in `extra_state_attributes`. Is there a reason to prefer converting it here over (what I assume) having it automatically converted/handled later? For attributes it's not handled later so therefore we need to make sure we store it properly here.\",\n",
       " \"This doesn't matter anymore since pyhap will clamp them anyways, and if the underlying value changes we now rebuild the accessory anyways so it never gets here.\",\n",
       " \"You can import this from homeassistant.const Would it not be cleaner to convert to UTC, then you don't need to use the replace function?\\nIs there a reason to store the time zone in the object? I modeled it after [this code](#L144).\\r\\n\\r\\n`mypy` is complaining about this needing to be a string, so I'll take a closer look. If objects are acceptable, I see no reason not to pass a `datetime` with `tzinfo`, but if it has to be a string, I'll check to see how that's normally done by looking at some other integrations.\\r\\n\\r\\n(This is my first PR and I thought things were passing locally, but maybe I need to double check it since it's failing here.)\",\n",
       " \"Do we really need this special translation key? Doesn't Problem already cover it? Yea, let's go with the standard device class name here. Why did this remove a key? It's a base fan, no point in calling it an IKEA fan. And why did this gain one? Imho a group a fans is different from a single fan. This was odd before, seems the group would done some weird device name default. \\r\\ndevice class \\r\\nLokalise UI doesn't really like translation references deeper than 1 key\",\n",
       " 'When can the case that the climate entity no longer exist while the device still does happen?',\n",
       " 'This is too much protocol details. Those should be kept in the 3rd party library.',\n",
       " 'This is incorrect. We should use entity ID + wake word ID as we cannot guarantee wake word IDs to be globally unique. ',\n",
       " \"Instead of this code, please something like #L178\\r\\n\\r\\nThe advantage is that you don't need to modify the `WallboxNumber`, when you add another number entity I think I changed my approach to something resembling the unifi component. Please let me know if this is what you had in mind. yes, that's better indeed I think we can make this inline as well yes, can change that Can we maybe get the if statement out of the cast?  sure These can be inline as well I don't think I can do a lambda function when its async right? I think you can, let me check ok, I made changes for the other suggestions Hmm, you're right. I think this might be able to do nice, but I would have no clue It is possible, see my comment :) \\r\\nNot sure if this is a right suggestion, but it looks a bit better. I mean, can we get the code to look like\\r\\n\\r\\nWe don't really like multiline if statements as they decrease the readability hahaha, misunderstood. Sure, done. I made it slightly different now (also wasn't content with the first attempt), can you have another look In a follow-up PR please refactor all the protected functions as the all need authentication and have the same error handling.\\r\\n\\r\\nProbably you could solve it with a decorator:\\r\\nCould be something like this (untested)\\r\\n Maybe we could use a decorator here too. Please evaluate this in a follow up PR. nice solution, didn't know this was an option What's the reason for dumping and immeditaly loading it again?\\r\\n\\r\\n I am guessing a copy, since this is how you do that in javascript I use this to load a nested json result quickly. Might be an ugly solution, but its the quickest for me and gives me valid datatypes in the result. If you have a good alternative I could change it (maybe seperate PR, I use this in more tests)\",\n",
       " \"It would be nice if the lib provided this so we don't hard code it here Done! In a future PR, it would be nice to make this a dataclass It would be nice if the library handled this in the future instead of having the sleep in HA I will do so in a later version of the lib. I also work on new features and this PR is the last hurdle to continue The linear search here could probably be avoided by indexing the categories in the future with a dict that points to the coordinators for each category I think this would work well with the dataclass\",\n",
       " \"You can use syrupy for these assertions. Checkout for example the youtube snapshots. if you make the code like that you can run `pytest ./tests/components/minecraft_server --snapshot-update` and it will generate the .ambr files I'm not familiar with syrupy, but I'll have a look at it ðŸ‘ It's awesome, trust me :) How does this even work? It's like magic ðŸ˜† \\r\\nDone. Told ya :D and you can directly return this dict instead of creating something in between Can we maybe parametrize this test? Done (I hope I did it right?). \\r\\nDo we need this? Looks like `None` is the default for `side_effect` --> Removed ðŸ‘ \",\n",
       " 'Please remove all empty keys Please avoid `assert` in production code. Please specify a schema for this kind of validation.\\r\\nPlease adopt other places, too. Please add a schema for all services remove all comment out code\\r\\n Please make the options translatable, or are these always the same names in any language?\\r\\nSee #selectors Please avoid multiline ternary operators. Please use an if statement instead If you translate the options you can the set the keys directly to these values and we can avoid this step. Use constants for the keys so you can reuse it in the service call Opening a file is IO and this should not be done in the event loop to avoid blocking it. Please refactor it, that the IO is done in a function, which is run by the executor Same here What are you doing here? `base64.b64encode` returns bytes, and this looks like trying to convert it to a string in a hacky way. Please search online for the proper way. This is creating an embeddable version of the image to be used in the `img_src` return value of the detection and classification services rather than depending on filesystem paths.  Still all replaces look hacky and I still think you are converting bytes to string in a hacky way or please give me the reason why you need all these replaces \\r\\n\\r\\nPlease adopt the other places too Use SelectSelector and SelectSelectorConfig instead \\r\\n\\r\\nCheck if for the other keys also constants exists Please recheck this code part as I think the image will be from the camera or None. The fiepath-image will be always overwritten.\\r\\n\\r\\nAlso the ternary operator makes it hard to read, please avoid it here  Please use the constants here too I think we can remove the hub class and declare the content directly here as it is used only here.\\r\\n You should always call the client close and not only when you create the entry Use constants here',\n",
       " \"Please use `_attr_has_entity_name = True` instead in your `MonzoBaseEntity` and put your names in the `strings.json` The names of the account type are being provided by the external API so that new/unexpected account types are handled or can be added easily, while pot names are created by the user in the Monzo app. Unless I'm mistaken, that makes it unsuitable for strings.json Fair enough.  `_attr_has_entity_name = True` is still a requirement (#has_entity_name-true-mandatory-for-new-integrations), but leave your names where they are then Actually, reading that you were right in the first place. The device name comes from the api but the entity names are constant, then HA can produce the friendly name. I'll fix it now, thanks! Can you maybe explain a bit on how the webhooks work? What data do we get from them?  The webhooks are used for the event triggers. When registered, Monzo will hit HA with a `transaction.created` event which can be used to trigger automations and contains lots of extra data you can use such as `amount` and `merchant`. A full list of the data provided can be found in [Monzo's docs](#list-webhooks) Consider extracting the coordinator into a `coordinator.py`. I will greatly improve code quality I'd agree if I was creating my own coordinator, but there's nothing to extract here really. Checking around, I'm only finding integrations which have their own derived coordinator with `coordinator.py` files, while integrations that just use the basic `DataUpdateCoordinator` don't. Correct me if I'm misunderstanding though! Please add reauth in a separate PR Not needed Removing it throws an error ðŸ¤·  Remove commented out code Please initialize this field in a constructor Sorry, I'm a bit confused here. There's nothing to init it with until it's set in `async_oayth_create_entry` I agree, the current code is preferred over initializing it. Please split off device triggers Can be set outside of the constructor Remove empty fields Data classes should now be frozen. You can remove the Mixin by using `kw_only=True` checkout Withings on how that works Move services to a separete PR after this one is merged `native_unit_of_measurement` should be GBP to ensure Home Assistant places the currency symbol in the correct place. Should this be using the constants from `.const`? ðŸ‘€ Definitely, thanks! Make this a dataclass instead:\\r\\n\\r\\n The class name is a bit weird IMHO These only seem to be used in application_credentials.py, if that's the case, move them there. This doesn't seem to be used, please remove it.\",\n",
       " \"Need reload  Can be private  Can be private  Can be privat  Can be private  Can be private?  Can be private  Needs reload\\n\\n\\nReload_on_changed_atteibute  This isn't needed anymore since we just reload the accessory This gets detected higher up now and we reload Should this docstring be updated? d3b7d8e3675f933e4be7f986503b050d4a81b286 How come this is changed? Should it be in another PR? I wrote the test for this and than I realized it didn't work because the check for the device class was missing.\\r\\n\\r\\nI'll break it out into another PR\",\n",
       " \"When  gets merged, it might be better to use `endpoint.device.quirk_id` here.\\r\\nIt's `None` or a `str` with the quirk ID.\\r\\n\\r\\n(There's a difference between the ZHA endpoint and zigpy endpoint, as well as the ZHA device and the zigpy device.) Thanks, I changed the code a little to work nicely with that assumption.\",\n",
       " 'We can check already here in the schema with `vol.In` Great catch. Thanks. Not optional If we do the check in the schema this would not be neccessary `preset_mode` and `kwargs.get(ATTR_PRESET_MODE)` is the same thing right? Maybe expand the descriptions slightly more than just the name? \\r\\nor black will fail',\n",
       " \"As discussed on Discord, implementing a `__getattribute__` with a special treatment should have a higher chance of success.\\r\\n\\r\\nMaybe something like this will work:\\r\\n This moves to `__getattribute__` instead as `intÂ´ with `ClimateEntityFeature` always results in a `ClimateEntityFeature` so we need to make the check and log before. We already called this above, I think we can reuse the result here? The entity implements a method, not a service The PR which adds the toggle method adds turn_off + turn_on to the base class. Should we maybe do it already here, otherwise that PR will have to be careful to not break the checks here. The condition means we'll log a warning for all entities which support `HVACMode.OFF`, that can't be correct? In the decision it says:\\r\\n\\r\\nSo if mode `off` is supported then we should set the off feature flag and log a warning.\\r\\nThe integration does not need to implement a `turn_off` method as it can be handled by `ClimateEntity.async_turn_off`.\\r\\n\\r\\nI think there is no other way as effectively if an integration supports mode `off` it also supports turning the entity off.\\r\\n\\r\\nHowever I think perhaps we should make a slightly different message in the log then. What you quote talks about automatically setting the new feature flag. My concern is that the implementation in this PR logs a warning regardless of if the implementation itself sets the new flags or not. I noticed this so that's fixed and also a test added to ensure no adding or warning if it's already there. The condition means we'll log a warning for all entities which support more than one modes, that can't be correct? The logic does not appear to be correct, we should automatically set `ClimateEntityFeature.TURN_OFF` if *either* (inclusive) of the following is true:\\r\\n- The derived class overrides the default implementation of climate.turn_on or climate.turn_off\\r\\n- The required HVAC modes are supported Same comment, the logic does not appear to be correct I think this would be more pythonic, but it's a matter of taste I guess:\\r\\n\",\n",
       " \"This changes our entity component, for which an architectural discussion and approval is required before changing it.\\r\\n\\r\\nI suggest removing it from this PR, as it seems unrelated.\\r\\n\\r\\n../Frenck This looks like it could be a dict lookup with a default value instead This looks like it could be a dict lookup with a default value instead This looks like it should use the fan platform??? @bdraco Oh there was a Fan platform!\\r\\n\\r\\nThe documentation for the climate platform says:\\r\\n> Climate Entity\\r\\n> A climate entity controls temperature, humidity, or **fans**, such as A/C systems and humidifiers. \\r\\n\\r\\nMaybe we should edit it? I got tricked lol\\r\\nDo you want me to make a separate PR for the fan on the fan platform? > Do you want me to make a separate PR for the fan on the fan platform?\\r\\n\\r\\nYes please. This should come out of this PR, and the next PR can be to add the fan platform Reading more in details, the fan platform has less features. It does not handle vertical and horizontal oscillations... Well I say that but does not handle it by default either lol\\r\\n If it doesn't support HVAC modes it shouldn't be a climate entity > Reading more in details, the fan platform has less features. It does not handle vertical and horizontal oscillations...\\n\\nIf the fan platforms oscillation support is too limited you can add a select entity to adjust the oscillation in more detail  We should only iterate the devices once and put them into the expected buckets. As this grows to support more devices we want to avoid a pattern where we iterate all the devices in a way that performs poorly because we iterate O(devices * device_types) Does the device not know the current temp, and current target temp? It does not know, it is infra red so no feedback... Let's set `_attr_assumed_state = True`\\r\\n\\r\\nAlso please add a comment that explains that its using IR so we don't know the state Maybe make 4 and 1 a named constant to better show intent here Can we pass these as kwargs instead of constructing a string? The send command is generic for all devices in Switchbot and the Air Conditioner is the only device asking for building a string so I would rather to push that in the library for a specific case. I agree it looks ugly though... There's no `discovery_info` parameter in the `async_setup_entry` interface. Please limit docstrings to max 72 characters per line. The first line is a header and should be a single sentence. Then an optional body. Do we support setting 0 degrees? In that case we need to check for `None` explicitly here. For Air Conditioner, it usually does not go bellow 15 degrees:\\r\\n\\r\\n Ok. Don't we need to update state here?\",\n",
       " \"Ut would be better to use `from homeassistant.const import Platform` and `Platform.COVER` Thank you for your suggestion, I have taken it into account and modified it. \\r\\n\\r\\nCan replace the loop Thank you for your suggestion, I have taken it into account and modified it. Is there anything you can replace by a constant from:\\r\\n`/workspaces/home-assistant-switchbot-via-api/homeassistant/const.py` ? Thank you for your suggestion, I have taken it into account and modified it. I think it would be better to use more often translations from `homeassistant/strings.json` and more generic messages when possible to decrease the amount of translation needed.\\r\\n\\r\\nAbbreviations like `pos` should be avoided too I believe. Thank you for your suggestion, I have taken it into account and modified it. What happens if all is not good ? The implementation of `getHubInfo` is as followsï¼ˆthis part of the code is in `leviosapy`ï¼‰:\\r\\n\\r\\n\\r\\nYou can see that this method just tries to update the `hub_fw_v` attribute, i.e., in order to go and update the version number of the hub, so what happens when this attribute is `invalid`?\\r\\nLet's go back to `leviosa_shades`.\\r\\n\\r\\n\\r\\n\\r\\nYou can see that if `hub.fwVer` is `invalid`, then it triggers `CannotConnect` error.\\r\\nAbove, is the explanation to your query. I understand that the `CannotConnect` error can be raised in the config flow, but the `async_setup_entry` in `cover.py` is run every time Home Assistant starts I think so we need to handle the issue here too. \\r\\n`getHubInfo` should raise an error instead of using a side effect. There is also the possibility that `self.get` raises a `LvsaApiConnectionError` error but it is not handled. I've updated the getHubInfo method to handle various exceptions inside, so it will be safer to use externally It might be possible to set each property with 1 line of code instead of 3+ as class properties `_attr_XXX` in the class itself of the constructor sorry I don't get you.\\r\\nAre you referring to programming style issues? Or do we have to name private attribute definitions in subclasses starting with `_attr_`? Sorry, I mean that instead of defining properties like:\\r\\n\\r\\n\\r\\nYou can instead use in the constructor:\\r\\n\\r\\n\\r\\nI think most of the properties have a corresponding `_attr_xxx` attribute, maybe should take a look at:\\r\\n[homeassistant/components/cover/__init__.py](#L222C14-L222C14)\\r\\nand\\r\\n#L240\\r\\n\\r\\nIt is just a programming style issue but having a briefer code would help readability I believe. Your suggestions are very constructive, but I'd like to focus my time on all the code style issues (not just this one project), so would it be possible to allow this pending style change to go through first, and update it later, I don't want to spend my energy on just this one code style change. I think we should avoid abbreviations when possible, `devs_2b` made me bug a little.  OK, I'll changed it to `devs_to_be_removed`\",\n",
       " 'We only create brands if we have more than 1 integration. Please move it.',\n",
       " \"This line is not covered by tests. We require 100% test coverage on our config flows.\\r\\n\\r\\n../Frenck Using both the `exception` logging method and `exc_info` isn't needed.\\r\\n\\r\\nWe normally don't log the stack trace if the exception is known.\",\n",
       " 'any hints are highly welcome about making mypy happy about this ðŸ™ˆ  \\r\\n\\r\\n 91d2a6b Where does \"not set\" come from? It\\'s from the constants DEFAULT_NEAREST etc. Would \"unavailable\" or \"unknown\" be better in those cases? The \"not set\" is part of the legacy proximity entity and will not be used further for the new sensor entities. \\r\\n i did not want to change the behavior of the legacy proximity entity for now, so users are not tackled by an breaking change for existing proximities, but have the change to smoothly migrate their automations etc. to the new approach What does \"not set\" mean? If it means we don\\'t know what the sensor state is, then we should use \"unknown\" instead, yes. There\\'s two slugify calls?\\r\\n\\r\\nWhat happens if the tracked entity_id changes?\\r\\n\\r\\nIncluding a name in the unique_id isn\\'t good. When we allow the user to set the unique_id it is an explicit setting for unique_id. If we take the name the unique_id setting isn\\'t clear anymore to the user.\\r\\n\\r\\nIf we\\'re going to add a config entry to this integration I suggest we wait with adding unique_id until we  have a config flow. When we have that we can use the config entry id as unique id. > There\\'s two slugify calls?\\r\\n\\r\\nfixed ðŸ‘ \\r\\n\\r\\n> What happens if the tracked entity_id changes?\\r\\n>\\r\\n> Including a name in the unique_id isn\\'t good. When we allow the user to set the unique_id it is an explicit setting for unique_id. If we take the name the unique_id setting isn\\'t clear anymore to the user.\\r\\n\\r\\nthe user sets explicit the tracked entity ids in the config (_later via config flow_) so they cannot change by accident (_eq. user renames the entity_), but explizit by the user when changing the proximity configuration.\\r\\n\\r\\n> If we\\'re going to add a config entry to this integration I suggest we wait with adding unique_id until we have a config flow. When we have that we can use the config entry id as unique id.\\r\\n\\r\\ni don\\'t think this will work, because we can have multiple tracked entity ids per config entry, so config entry id would still not be unique. SO i\\'m not sure what unique source for a tracked entity we could use (_maybe the unique_id of the tracked entity - in case there is one_) ðŸ¤”  My point is that it\\'s not clear that the user is setting a unique_id when they set the zone to be monitored.\\r\\n\\r\\nI meant that we can use the config entry id instead of the name of the zone. We\\'d still need to append the entity_id of the tracked entity, or some other id for each tracked entity, yes.\\r\\n\\r\\nYes, the tracked entity cannot be changed implicitly, but what should happen when the user changes the tracked entities? Should the stale sensor entities be cleaned up? Should sensor customizations be migrated to the new sensor? Or should we not allow changing tracked entities for a config entry? > My point is that it\\'s not clear that the user is setting a unique_id when they set the zone to be monitored.\\r\\n\\r\\nah ... i misunderstood it (_I thought you meant the id of the tracked entities_).\\r\\nThe `coordinator.friendly_name` is not the monitored zone, but just a name the user gives this particular configuration (_see [`friendly_name`](#friendly_name) parameter in the docs_)\\r\\nBut sure, we can wait for the configflow PR and add unique_ids there ðŸ‘ \\r\\n\\r\\n---\\r\\n\\r\\n> Yes, the tracked entity cannot be changed implicitly, but what should happen when the user changes the tracked entities? Should the stale sensor entities be cleaned up? Should sensor customizations be migrated to the new sensor? Or should we not allow changing tracked entities for a config entry?\\r\\n\\r\\nThe idea is to make at least the list of tracked entities adjustable via an additional optionsflow.\\r\\nWhen the user changes this list, new sensor entities will be created, but yes we should think about an automatic cleanup of stale sensors in this case - maybe as an improvement in an upcoming PR ðŸ¤” \\r\\nFurther when the user renames an entity_id via the UI the user is warned like:\\r\\n\\r\\n> Do you also want to rename the entity IDs of your entities?\\r\\n> This will not change any configuration (like automations, scripts, scenes, dashboards) that is currently using these entities! You will have to update them yourself to use the new entity IDs! How do the new sensor measurements compare with the existing entity measurements? It doesn\\'t seem to be a 1:1 map. The PR description doesn\\'t talk about this. sorry, forgot to update the description (_only updated the docs PR_) - breaking change message, as also PR description has been updated. hope the description is ok and clear Should this be an enum sensor? sorry, but i do not get it There\\'s a sensor device class called `enum`.\\r\\n\\r\\n#available-device-classes uhhh ... looks interesting ... I will rework this sensor ðŸ‘  Optional:\\r\\nCan this be done outside the loop as a final pass? I think it just might slightly increase readability to not have to be indented.\\r\\n\\r\\nYou could consider handling the `arrived` case as checking if distance is zero to not need to lookup device_state again.\\r\\n\\r\\n\\r\\nYou could also consider if this can be done outside the loop, though i realize it may need some duplicate  after some thinking about the \"ignored zone\" part, I\\'m not sure what was the original intention of this? Should the sensor go to `unavailable` as long as the entity resits in an ignored zone? Or should the Sensor just be excluded from the \"nearest\" sensor, but still calculate distance and dir-of-travel? In previous code of the proximity entity (as far as i understood it) an entity in ignored zone was just ignored during recalculation ... but the legacy proximity entity always combined all tracked entities into one single proximity entity. ðŸ¤”  i would vote for\\r\\n\\r\\n> Or should the Sensor just be excluded from the \"nearest\" sensor, but still calculate distance and dir-of-travel or maybe adding an additional binary sensor which shows if the tracked entity is in an ignored zone ðŸ¤”  I interpret it to mean that when its in the ignored zone it is not computed in the final distance.\\r\\n\\r\\nAside: Often when i\\'m doing cleanup of old features in yaml i end up making the entity configured from a config flow without supporting the options in yaml, then come up with a deprecation plan if they no longer  make as much sense in retrospect or just aren\\'t a priority, fwiw. Perhaps the check for the device state being an ignored zone could be handled near the top of this loop once so that it doesn\\'t need to be checked later Would \"unavailable\" or \"unknown\" be better in these cases? answered this above in #discussion_r1397413488 My impression is this state value is for the new sensor not the legacy sensor?',\n",
       " 'Does it differ that much that it needs its own (duplicated) class ?\\r\\nNot possible to create a Base model and inherit the sub types from that ? yeah it\\'s possible and I thought of doing so but then forgot. Will look into it again turns out while `ZwaveLight` has a bunch of extra logic not needed here, because of the way it is written, we are still good to use that logic for the Basic CC light! The terminology \"basic light\" is a bit misleading imo. Better use \"basic_cc_light\" which is more describing  I would use Basic CC or basic_cc here to make it more descriptive as now it more looks like a \"basic light\" instead of \"a light based on Basic CC\"',\n",
       " \"Can we move this code down to the existing if-check on result. Moved If you don't know which one will be the wake word and which one isn't, your snapshot checks can fail.  Should we return an error code to indicate to the satellite that a wake word was found but it was a duplicate?  We can do that maybe in the future.\",\n",
       " 'I don\\'t think we should extend the search config option feature. I rather think we should deprecate the whole custom calendars option in caldav. We have the calendar trigger that can be used to trigger automations that searches for matching events in a condition.\\r\\n\\r\\nIf we need better GUI options for calendars to customize the display that should be solved generally for all calendar entities and not per integrating integration. (via architecture discussion) Agree, i think there may still be something here around the calendar helper:  but it needs to be revisited or a little more thought.\\r\\n\\r\\nWe can also consider adding \"categories\" to the calendar event model since it is part of the rfc.\\r\\n\\r\\n',\n",
       " \"Please raise `ServiceValidationError` instead, and it would be nice if we could make it translatable too.\\r\\n\\r\\nSee \\r\\n \\r\\n\\r\\nSidenote: Catching the bare exception is only allowed in the config flow I think it would be great to extend the third-party library to allow passing the `incl_vat` as setting and restoring is hacking and there could be some race conditions @klaasnicolaas is this the correct way to solve this issue:  Yes, but superseded by a PR of mine ðŸ˜… I will create a separate PR for the dependency bump. If it is allowed, I can also just include it here as I need the updated version anyway? You can update the dependency locally, just don't commit it. Once the PR (#105080) has been merged, you only need to rebase your branch so that you are up to date with all changes from dev. Why is this being removed? \\n So I think we have more options here:\\r\\n- Or make the attribute not a boolean but a string/enum like the EnergyZero package\\r\\n- Or keep it a boolean. Then I think the name ATTR_INCL_VAT is more clear on what it actually means.\\r\\n\\r\\nWhich one do you prefer? Perhaps it is best to use the enum and a select list in Home Assistant UI? I've been playing around a bit with the services in the UI, but I don't get a default value in a dropdown list. I would say give it a try yourself, but...Perhaps it is better to implement the boolean option, but set it as required and default true. I don't think you use `pytestmark` anymore Use references for all duplicate strings I think the `example` is not needed here Use partials instead of calling the extra function above, [example](#diff-8162f13dcf871fea4e83ae6cb8fadf9adfe6ddcaa58e6da14edb5478041106a0R105). \\r\\nI think this function should be async Why? It does not do anything async, only pass async functions around? Or should the `hass.services.async_register` be awaited? The `hass.services.async_register` is not a async function so it cannot be awaited?\\r\\n\\r\\n![image](\\r\\n No you only should await the `async_setup_services`, it is used somewhat mixed in other integrations. Personally, I'm used to these kinds of functions being async, but maybe someone else can answer that better. I cannot see the benefit of creating an async function that is not doing any awaiting, but sure.... \\r\\n\\r\\nSee  for explanations\",\n",
       " 'Should this be a function. Looks like the same pattern is used above `mqtt_data.open_config_issues` is an object (`set[str]`)set thought a `dataclass` using a default factory.\\r\\nThe intention is pop an item (containing an issue_id) and remove the registered issue. I was just thinking that \\r\\n\\r\\n\\r\\n\\r\\ncould be a function since you do it in two places Ah, okay, now I see what you mean. Good point. done Note to self: check this block to see if there are any opportunities to make it more dry  @bdraco In  (the light follow up PR this code part gets some refactoring) Isn\\'t this breaking since the user can no longer test specific options with dev tools check yaml config before restarting?\\n\\nI\\'m not sure that\\'s actually valuable though as the issue is way more helpful but they will only see it after they restart  Good point. I\\'ll add a not in breaking change section. done. Please rewrite this to use the issue registry to list open issues, there\\'s no reason why MQTT should keep track of issue registry issues. This is basically a copy of `async_setup_entry_helper`. Will `async_setup_entry_helper` be removed once all platforms are migrated? It will remain for tag and device_automation, but some parts of the code will be cleaned up at the end:\\r\\n\\r\\n[Clean up code]( If `async_setup_entry_helper` will not be removed in the end, please refactor `async_setup_entry_helper` and `async_mqtt_entry_helper` to avoid the duplication of code.\\r\\nAlso, please give them better names, I guess one is for setting up entities and one is for setting up non entities after these changes? Agree, but can we do this at the end of migrating the platforms as it would spare a lot work. I\\'ll add a commit to de-duplicate the code of the two helpers in #101649 I think this is more idiomatic:\\r\\n Why is this a coroutine function and not a callback? I don\\'t see any await inside. They could be callback\\'s for the entity platform. The non-entity platforms: `tag` and `device_automation` are set up differently and need coroutines. If we don\\'t need to await inside we can make this a callback. Same here: might work for entity platforms but not for the entity-platforms.\\r\\n The grammar isn\\'t correct here. It should be \"Invalidly\". Maybe rewrite it to something else though?  See  manually configured',\n",
       " 'I think it would be better to compare if the version changed before we try to update it, since thins update happens on every status from the device, what I noticed in Gen1 that calling this method does many comparisons internally.\\r\\n\\r\\nExample in Gen1:\\r\\n#L381-L382 Good point! My intention in my previous comment was that we do this comparison before we call `device_update_info`, but doing the check inside this method is better, but I would move it to be the first thing (we can supply the current FW as a parameter), before we try to get the device from the registry and we can also remove the check from gen1 after we do it here (now we have a double check for Gen1)',\n",
       " 'We should not add a unique ID to this integration, instead this should be moved to an configuration flow.',\n",
       " \"That's already handled in xknx\\r\\n#L191\",\n",
       " \"\\r\\n\\r\\nAs this code is called on setup and therefore on each startup, we don't need to persistent the repair issue. \\r\\n\\r\\nI would also remove the invalid holiday name from the suggested values I suggest validating the options here too, like in the config flow. \\r\\n\\r\\nCan be removed as the schema has only `CONF_REMOVE_HOLIDAYS` Only double checking...\\r\\nCan we leave options empty? Will the user has than any possibility to select something?? They can't choose from anything but they can add custom values to the list.\\r\\nIt's the same logic as in the regular config flow to potentially remove holidays from the object.\",\n",
       " 'We should check the registry to see if the mocked device is removed instead of checking a total.\\r\\n Yes, sure, will update the test later today. Updated as suggested. - I don\\'t think dummy was supposed to be here?\\r\\n- Also, it shouldn\\'t be needed to track these? Feels weird? On the use of \"dummy\", the init needs to have the strings in place, I could change it to `{(\"\",\"\")}` that works too.\\r\\nBut `{()}` doesn\\'t work, mypy is not happy with this.\\r\\n\\r\\nNot needed to track these: you mean track the `self.current_entities`? \\r\\nThis self contains the set of actual entities created during the initialization of the integration.\\r\\nThis set is compared to what is present in the entity_registry, if there are more entities present in the entity_registry then in the set, it means some cleaning can be done. @frenck I\\'m seeing that ISY994 uses this as init:\\r\\n\\r\\nI can follow this idea and create a better but still a dummy entry in the set.\\r\\nThe dummy can be there, it does not harm anything because the difference-function in this `set(entities.keys()).difference(isy_data.unique_ids)` only leaves the entities that are present in the entity_registry and that are not present in the set with current_unique_ids. Some improvements have been implemented. @frenck looking forward to receiving your feedback on the latest changes :)',\n",
       " \"Can we make this a fixture? Would be nice, but options :)\\r\\n\\r\\nMaybe for a future PR Post merge, following up on the fixture comment since i'm happy to explore it in a future PR.\\r\\n\\r\\nThis is used with `mock_events_list_items` which is a fixture. That is used at different points in the test to change the next response when events are listed, so the API is now something like:\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nor if testing a special case, something like this:\\r\\n\\r\\n\\r\\n\\r\\nor for tests that are not using freezer:\\r\\n\\r\\n\\r\\n\\r\\nSo its definitely used as an input to a fixture, but its just a variable to help with creating new events for composing them.\\r\\n\\r\\nSo at best we could make another fixture that is a simpler fixture that already takes in the TEST_EVENT as a default and the caller passes in the deltas for the test, but I didn't think having multiple fixtures was worthwhile, and so that is why its composition via `TEST_EVENT`\\r\\n\\r\\nIf you have other ideas happy to explore them, but also this isn't a pain right now.\\r\\n\\r\\nThanks!\",\n",
       " \"This change is out of scope of this PR. Please keep the PR to the scope defined.  out of scope Out of scope Out of scope Out of scope Why wouldn't a fan swtich go into the `fan` platform rather than the `switch` platform? Out of scope Out of scope\",\n",
       " 'Optional suggestion: Outside of this PR, you may want to consider using composition rather than inheritance given the number of double subclasses going on in this integration. > Optional suggestion: Outside of this PR, you may want to consider using composition rather than inheritance given the number of double subclasses going on in this integration.\\r\\n\\r\\nOk, I will look into it for future PRs.\\r\\nThanks for the suggestion @allenporter :) Done in 76940724d61cfd07afc5f515f7d90d91acbec322 Done in 76940724d61cfd07afc5f515f7d90d91acbec322 Please use `[]` here as the key should not be missing Done 76940724d61cfd07afc5f515f7d90d91acbec322',\n",
       " 'Forecasting cannot carry a state_class, as it is meant for current data only.\\r\\n\\r\\n We should not use the translation key for it. The translation key should only be used for translations.\\r\\n\\r\\n',\n",
       " '\\r\\nDevice class translations Indeed, I forgot about those. Thx! Can we use translations for these? Indeed, I forgot about those. Thx! Can we use translations for these? Indeed, I forgot about those. Thx! Can we use translations for these? Indeed, I forgot about those. Thx! This one can be removed as the device class gives the translation :) Yeah, noticed right after the commit ;-)',\n",
       " \"I don't think this is a good name, `get_forecast_extreme` might be better? Wrong spelling. Please don't use magic strings, but ATTR_WEATHER-constants instead to avoid that. I guess we should all of the float ones, as example `wind_gust_speed` would be missing Maybe allow any attribute which is included in forecasts? Why not 10 days ?\\r\\n I got only 216 forecasted hours as output. I am implementing a check to avoid array out of range exceptions, so it doesn't matter I think it depends on weather integrations and/or location to provide different forecasted hours range.\\r\\n\\r\\nSo out of range should be handled nicely to prevent errors.\\r\\n\\r\\nAnd I think we prefer a calculated value to easily see how long the limit is 9/10 days (216 = 24 * 9) Why is this only supported for hourly forecast? Because of the hours based filter Right, but we know that the other forecasts are 12 and 24 hours respectively. Maybe the service handler should pick from available forecasts in the priority order hourly, twice daily, daily? @gjohansson-ST WDYT? I don't see a reason to limit this. I think we should support all forecast types but probably we leave it as an option in the schema but default to `hourly` Implemented FORECAST_TWICE_DAILY and FORECAST_DAILY The schema marks this as required:\\r\\n The schema sets a default:\\r\\n When can this happen? The service only allows calls on entities which supports forecasts? Since we call `weather.async_forecast_hourly()` we should check if the entity supports it\\nI looked at `def async_get_forecast_service` Right, but the `get_forecast` service can be called for an entity which supports hourly, twice daily or daily forecasts.\\r\\nThe service added by this can only be called if the entity supports hourly forecast so we don't need to check it again. Obsolete by implementing daily forecasts This is already checked in the schema, it only allows 1..216 I'm not sure we should include calculations in the service parameters. I think calculations should be kept in a template as different calculations may be wanted by different users. Calculations are not dependent on the service result, but could be anything. Filtering is more dependent on the the service and service result, so is more acceptable as service parameters. Agree. The output can contain both min and max. Possibly also avg. WDYT? No, I don't think we should have any calculations in services. My idea was to retrieve the extreme values via a service and make all my sensors with templates redundant. If we do not use the calculation in services, this service is useless.\\n\\nWe could implement the hour filter in the normal forecast service instead. I think it would still make sense to extract a single attribute with a time-limit. Removed calculations and renamed service When can this happen? We require at least one of the supported features when registering the service. Min max isn't used. I also still think the user should be able to select which forecast to pick from + limit_hours should be renamed to be a fit for all three types. What's extra?\",\n",
       " 'I see you love migrations, but they still aren\\'t backwards compatible. Since we\\'re now only adding a server type, can\\'t we just make the code use Java as fallback? Thanks so much for your VERY fast review :smile: \\r\\n\\r\\nWhy aren\\'t they backwards compatible? I think I didn\\'t get this point.\\r\\n\\r\\nThe problem would be long update times, because the API currently tries to fetch data 3 times with 3s timeout each. That\\'s why I thought it\\'s the best to store the server type to get fetch the data faster. Well, the new config entry has version 4, if someone reverts to 2023.9, the config entry version is 1, which is not 4, so it won\\'t load.\\r\\n\\r\\nI agree with storing the server type, but that doesnt have to be inside a migration. checkout:\\r\\n#L103-L114 Aaaah you meant incompatibility when downgrading. Yes, that\\'s true. Yeah maybe I can fallback to \"Java Edition\" in case the key `TYPE` is missing in the config entry data. I\\'ll try that out. If you check the code I linked, you can do something like,\\r\\n\\r\\n Done. Reverted version 4 and moved migration from async_migrate_entry to async_setup_entry. Why not just make it return a list:\\r\\n That sounds like a better idea. I\\'ll try this later, thanks :+1:  Done Please make sure your config flow tests ends either in a config entry created or abort to show it can recover from a failure In each test I already check for `FORM` or `CREATE_ENTRY`. Do you mean the order of the asserts? Should the check for flow result be always the last assert in the test function? Or do you mean something else? you only check for form, but we want to see that after an error message, the flow is able to succeed Sorry, I\\'m a bit lost here. I checked a few other integrations and didn\\'t see much of a difference. The config flow of Minecraft Server either is successful (`CREATE_ENTRY`) or it cannot connect. In that case the same `FORM` is shown only with a difference, that the error message is shown additionally. In that form the user can correct the user input and retry. It\\'s something that we like new tests to have, to avoid code that could stick around and put the config flow in some kind of lock. So the trick is to finish the FORM, so it will become either a CREATE_ENTRY or an ABORT My problem is, that I don\\'t abort my config flow, therefore (if I understood correctly) I can never reach the ABORT state. Let me try to make this more clear with screenshots.\\r\\n\\r\\nThis is the initial form. I entered an invalid input and after confirming we come to the second screenshot.\\r\\n![Bildschirmfoto vom 2023-09-27 10-19-02](\\r\\n\\r\\nAfter the config flow detected a connection error, the same form is shown with additionally the error message.\\r\\n![Bildschirmfoto vom 2023-09-27 10-19-40](\\r\\n\\r\\nSo the config flow doesn\\'t abort the flow, even if a connection error is detected. Understood, but then we would like the tests to first reach the state where we show the user an error, and then retry again with valid info, making it succeed. This is to make sure the config flow doesn\\'t end up in an unsolvable state. This is something I can add, no problem. Thanks :+1:  hah, explaining isn\\'t my strongest point, but we got there in the end :) Done, added a new test case for config flow recovery (successful connection after a failed one). I know it\\'s because of debug log lines, but this is a lot of lines for essentially 10 lines of code. You mean that I have to many debug logs? I could remove the good case logs if you want? Obsolete --> Please re-check with latest commit. bedrock isnt async? Should it run in the executor? The lookup function isn\\'t async. But you\\'re right, I forgot to run it in the executor :+1:  I like the idea! I don\\'t really like the idea of splitting up the retrieving logic into the coordinator and this api class.\\r\\n\\r\\nWhat if in the `__init__.py` you (use a helper to) try to lookup the server type, after which we pass the MCServer to the coordinator. With as added benefit, if the server can\\'t be looked up, we can say that the config entry is not ready.\\r\\n\\r\\nThen you can put the rest of the mapping logic in helpers to not make the coordinator one big pile of code. I think it would be nice if the coordinator shouldn\\'t have to know what kind of server he is talking with and put those specifics away in functions, making the coordinator clean Good point, thanks :+1: \\r\\n\\r\\nI create now the API instance (`MinecraftServer`) in `__init__.py` and pass it to the coordinator. If a problem with the config entry is detected, `ConfigEntryError` is now raised (before, `HomeAssistantError` was raised instead in the coordinator).\\r\\n\\r\\nI also reached now a state, where I cannot further simplify the coordinator. It\\'s now as simple as it can get :smile: \\r\\n\\r\\nI still stick to the server type stored in the config entry data and not to detect the server type in `__init__.py` due to the possibly long waiting times I mentioned before.\\r\\n\\r\\nBTW: `ConfigEntryNotReady` is already handled by `coordinator.async_config_entry_first_refresh`, called in `async_setup_entry.`  \\r\\n\\r\\nPlease use the `entry.data.get(CONF_TYPE, MinecraftServerType.JAVA_EDITION)` \\r\\n\\r\\nswap around them to use a loop in the config flow',\n",
       " \"Is there a translation string to clean up? Good point Shouldn't we unregister all the listeners when unloading the config entry? You mean the cloud listeners? All the event listeners, like `async_call_later`. Probably use this helper instead:\\r\\n#L73 We shouldn't use this signal directly. It should be triggered from the cloud integration somehow. Do you have any tips on how to trigger it? I think we could make a common test helper that uses the dispatcher signal. That way we don't need to mock out the cloud integration in the tests of other integrations and we don't use cloud integration details in the tests of other integrations. So we still use this same piece of code but we encapsulate it in a helper? Yes. What would the best place for this helper be? Probably `tests/common.py`.\",\n",
       " \"Since the device you set as device info has the same name as this entity. This will name the entity to the device. Please sort :abcd: . We don't pass the unique_id of the config entry. Either we pass the wrong thing or the parameter is incorrectly named. Thx for spotting. Will rename the parameter. We try to avoid guards like this in service handlers in polling integrations. If we would have the wrong state, we'd be unable to call services.\\r\\n\\r\\nThe only valid case for guards like this in polling integrations is when the device can't handle the service call during certain states. Unfortunately there is no native stop command for Comelit.\\r\\nInstead the way to go is send the opposite action: if closing send open; if opening send close.\\r\\n\\r\\nBut this means that I have to know the device is moving before doing so. Otherwise it won't stop but instead start moving.\\r\\n Ok\",\n",
       " 'âœï¸ \\r\\n If the incoming request does not have the `\"X-Telegram-Bot-Api-Secret-Token\"` header, this will raise a KeyError. Let\\'s check for that ðŸ‘  Why do we need to check this?\\r\\nAn ephemeral secret token is unconditionally created when the config entry is set up. In the current setting, yes, the token is unconditionally created as a non-empty string. This check is to ensure if any changes were made to the creation of the token or the initialization of `PushBotView`, we are still verifying against a valid token. I can remove it if you think this is unnecessary. We should not patch the code we\\'re testing.\\r\\nInstead, do like this, calls to `secrets.choice` will now iterate over `mock_secret_token`:\\r\\n I think this was just added for testing? If so, inline it again. Yes. I have rolled it back to inline. Please use f-strings instead of string concatenation.',\n",
       " \"\\r\\n\\r\\nWe now have an optional selectSelector. See also  \\r\\n\\r\\nSo we don't need to convert the MappingProxingType to a dict \\r\\n\\r\\nWe should match the error message to be sure the correct one is raised\",\n",
       " \"This doesn't match the docstring. This is a weird check. I think we should change the last part of the config entry setup like we have done in the matter integration:\\r\\n\\r\\n#L107-L114\\r\\n\\r\\nThen we can guarantee that the driver attribute is set when the config entry is setup. We can change that in a follow up. this was actually an extra commit that I was using to figure out how to get another unrelated test to not fail. I will refactor this in another PR to be cleaner and will try your suggestion This constant should probably move so we don't need to depend on the logger integration. Events go through the core and should not require a dependency. \\r\\n\\r\\nlet me know which order you'd like to merge these in. We can merge this and then rebase the other and fix, or vice versa\",\n",
       " \"It would be better if the library handled managing the connection and the switch entity told the library to disable the connection logic, or re-enable it.\\r\\n\\r\\nWe want to keep at little logic as possible in Home Assistant itself. That's a good idea indeed! It will remove a bunch of complexity from this switch.\\r\\n\\r\\nI'll move it and the tests to the library then!  It would be better to flip a flag and let the coordinator handle this as its a bit of a seperation of concerns issue to have it inside the entity Makes sense!  I plan to add better support for the device disappearing and coming back in another PR. This PR is getting a bit large, I would move the coordinator changes to another PR (with it defaulted to on) and introduce the switch here with the ability to flip it from on to off Done:  Same comment from the previous PR You might want to store it as `data.name` so you can avoid the dict lookups and typing run around > You might want to store it as `data.name` so you can avoid the dict lookups and typing run around\\r\\n\\r\\nI think I had that initially, but removed it to avoid duplicating the string. After looking through this, I realized this is a virtual entity as it doesn't represent the state of the device, but instead represents the state of Home Assistant config entry / integration.\\r\\n\\r\\nWe currently don't allow virtual entities to be added to integrations.\\r\\n\\r\\nAn alternative would be to make it a config entry option via an options flow, but the downside of course would be you couldn't use an in an automation, but I'm not sure if there is a use case for that here anyways. The reasoning for the switch is the limited number of active connections on bluetooth radios (ESPHome only allows 3, for example). If you have multiple devices (not only desks), you can have an automation to only connect to the desk when you want to move it. An alternative would be too add `homeassistant.disable_config_entry` and `homeassistant.enable_config_entry`, as we already have `homeassistant.reload_config_entry` Looks like there is a feature request for that  It looks like a previous PR has was not accepted that implemented that  In in ideal world the desk broadcasts it state via the advertisement and you only connect to it when you need to make a change.\\r\\n\\r\\nI don't have one of these so I have no idea whats in the advertisement Another option would be to add a button entity to connect the desk and one to disconnect the desk.  That would avoid the whole virtual entity problem. Unfortunately the desk only sends data to the device connected to it. Also, it only connects to a single device at a time, so the user needs to be able to disconnect it from HA to use the Linak app.\\r\\n\\r\\nIs the only reason this is not allowed the fact that the state of the switch does not reflect some state on the device? That is why buttons would be accepted instead? > Is the only reason this is not allowed the fact that the state of the switch does not reflect some state on the device? That is why buttons would be accepted instead?\\r\\n\\r\\nThat is exactly the reason.\\r\\n\\r\\nThe test for a virtual entity is generally this:\\r\\n\\r\\nDelete the integration/config entry, add it back, if the entity is not in the same state as it was before, it might be considered a virtual entity. Right. I'm fine in switching to buttons. I will update this PR.\\r\\n\\r\\nI do like the fact that the switch gave some feedback about whether or not the integration was trying to connect or not (instead of just connected/disconnected), but it is not critical I guess. Another downside with the buttons is that after HA starts, it will always connect to the desk, while the switch restored the last state. You could also add options flow to change the connected state at startup (in another PR) Good idea\",\n",
       " \"Duplicated Duplicated I guess that was due to a misunderstanding on how that function works exactly. I thought the first list is for (realtime) sensors, and the second for forecasts. Are they all equally available? (Why the differentiation then?) That's correct, but you have duplicates in this list. Also, move the added items to the bottom instead of adding at the top. Replace the list with the following.\\r\\n\\r\\n Change the field order to match the order the fields were requested in __init__.py or the order they are present in the `weather` component's forecast entry type.\",\n",
       " \"This is really ugly. We should name the test `list`, not `is_list`. Same for the other tests. I was following the `is_number` convention. Agreed it's ugly, but the advantage is that it distinguishes between the test/check and the functions to convert the value to the given type. So there are two options:\\r\\n\\r\\n1. Leave it as is, and have two different names for converting a type vs checking a type\\r\\n2. Use the same name for converting and checking. That means `list` is a test that checks the type, but is a function and filter that converts the type\\r\\n\\r\\nWhich is more desirable?\\r\\n the `number` test was already in use as a built in test, which only returns `true` if the value actually is a number (so not when it is a string)\\r\\n\\r\\n\\r\\nPoint 2 is similar with the built in function/filter `string` which converts the type, and the test `string` good point. Thanks! What's the reason to have all the `is_*` as globals? it's just a convenience thing so you can do `is_list(x)` or `x | is_list` The name is somewhat misleading since it returns False for other iterables than strings.\\r\\nShould we name this `is_iterable` and just document that it returns `False` if the object is str, bytes or bytearray? I see your point, however I don't think the `is_iterable` name is useful either. Is there a name for this class of types? `bytes` and `bytearray` aren't strings but they are string like per the suggestion below I changed it to `string_like` To continue the discussion on `non_string_iterable`...\\r\\nI also don't like the name, and I think we should not create `non_*` tests, when jinja has bultin `not` support.\\r\\nTo keep consistency over all tests I would suggest something like:\\r\\n\\r\\n\\r\\n\\r\\nSo users can write\\r\\n\\r\\n\\r\\n\\r\\nWhat do you think? works for me, updated Do we actually type these? From other tests I saw that only things provided by HA are typed. I am OK with typing them just want to make sure we aren't breaking standard In my opinion, it is always better to provide more type hints if you can/know the types. With the type hints the IDE and all our checking tools (mypy, ruff, pylint, ...) can give you hints if you are using a variable wrong. This is not called from outside this module, it should be `_is_list`, not `is_list`. Same for the other functions.\\r\\nExisting template functions should be modified in a follow-up PR.\",\n",
       " 'It needs to be made clear this is supposed to be a youtube-dl query It still needs to be made clear this is supposed to be a youtube-dl query, maybe just change to:\\r\\n Should this default to the `CONF_DEFAULT_STREAM_QUERY` instead? Otherwise it\\'s weird that the `CONF_DEFAULT_STREAM_QUERY` influences the `play_media` service but not the new service. I don\\'t think `extract_media` is a good name for the service. The gist of the service is that it returns a dictionary with a URL with the wanted format, can we try to make that clear in the name too? Maybe \"get_media_url\" or \"get_stream_url\" or something like that?',\n",
       " 'Little longer but at least we avoid writing `advertising_interval += TRACKER_BUFFERING_WOBBLE_SECONDS` twice Yeah I went backwards and forwards on that line a few times ðŸ˜‚ This is also used in _prefer_previous_adv_from_different_source pytest.approx would probably be better here pytest.approx would probably be better here pytest.approx would probably be better here pytest.approx would probably be better here pytest.approx would probably be better here pytest.approx would probably be better here pytest.approx would probably be better here pytest.approx would probably be better here pytest.approx would probably be better here',\n",
       " \"Store this in `hass.data` instead. The container should also be updated when the device is removed, either directly or when the config entry is unloaded. Make this a `@callback` callback function instead. We don't need to await inside. I think we should rename this class to `MySensorNodeEntity` and inherit from `Entity`. Rename this class to `MySensorsChildEntity`. We can remove this property. This should move to the parent entity class.\",\n",
       " \"Can we maybe make separate sensors out of these attributes? We try to avoid putting too much in the attributes sure thing I'm guessing this is a sensor for temperatures. I think we should add the native unit of measurement and the device class Temperature it's actually not, it is a sensor related to this red section in the app:\\r\\n![image](\\r\\nwhith humidity comfort in horizontal and temperature comfort in vertical. Values are text only... Note that freshnees is the yellow part ![image](\\r\\n ooh right, what can the values be? We have a SensorDeviceClass for ENUMs, you can then add the possible values and them to the translation file, making it easier to make automations for. Example: #L76 i don't know the different values :'(\\r\\nI can try to run some stress tests on the sensor ðŸ˜›  I mean this would be the best option, this way when you create automations you can see the possible values:\\r\\n\\r\\n![image](\\r\\n I'm guessing this is a sensor for humidity. I think we should add the native unit of measurement and the device class humidity see above \\r\\nI mean we have the sensor definition static here, there is no case where someone accidentally added one of these Is Air Comfort a brand name? If so:\\r\\n\\r\\nelse:\\r\\n\\r\\n Oh right, this is a binary sensor, we should move this one to the binary_sensor.py file, we can do that in another PR done If the return value is a date, please use device_class TIMESTAMP If the return value is a date, please use device_class TIMESTAMP Also, I think this is the same as datetime.from_iso or something along those lines\",\n",
       " 'You don\\'t need both translation key and name. So remove name.\\n\\nIs power the amount of modes the integration has? The power identifies the target power of the device, it can be set from 1 to 9. Is power also used as name for the setting in the app? I am thinking it might get people confused with power as in kW. (As the name will be translated, I think it might get translated to the power in kW variant in some languages, so I\\'m trying to avoid that) I understand it might be difficult to have the full picture on how the device operates, would be good to include in the \"standards\" a markdown file with device information and capabilities, I believe this would be good for reviewers to have the big picture of the device.\\r\\n\\r\\nThat being said, I also spent some time thinking on what would be the best approach and namings for the device.\\r\\nThis device is a fireplace that have the following capabilities:\\r\\n* Operation mode: On of the following modes are valid: Temperature or Power/Potency\\r\\n* Target: When in temperature mode the target could be a temperature and when in potency mode it requires to be a integer between 1 and 9. In the API/CGI of the device this is set by 2 different parameters (in spanish consigna_potencia and consigna_temperatura).\\r\\n* on and off switch: the allow to set the device on and off, while the device is starting or shutting dow it will iterate over a state machine, it doesn\\'t go directly to on and off state. but this parameter in the API/CGI allow us to set on and off. The switch is set to off only when the state is off otherwise it\\'s on since the device is working. Ideally while shutting down and powering on the state shouldn\\'t be changeable either.\\r\\n\\r\\nAfter this what are your thoughts?\\r\\n\\r\\n How does it switch between temperature mode and power mode? Does it automatically switch when you update one of the two? Or will you add a select entity for that in the future?\\n\\nMaybe \"power level\" covers it.  It doesn\\'t switch automatically but it can be done in the API/CGI so in the future a select can be added. For now only power will be supported. \\r\\n\\r\\nPower level seems fine to me, also considered it, also though on power target and temperature target, but feels awkward. I\\'m leaving that for you (although I do want to mention target temperature sounds better ;) ) You already have this in the super class \\nIt\\'s generic ;)',\n",
       " 'I do not like this but I can\\'t think of another way.\\r\\n\\r\\nThe unit is not predefined and can be everything, but in practice we see only \\'m3\\' and \\'GJ\\' for external devices.\\r\\n\\r\\nAnother problem is that is is theoretically possible to have an invalid unit for the device class. (Gas can have \\'GJ\\' or \\'Cats\\' for example.)\\r\\n\\r\\n--\\r\\n\\r\\nWe also can return the most likely unit for the device type, but that can trigger some issues when the unit is unexpected (which is also possible with this implementation).\\r\\n\\r\\nE.g. If we return GJ for \\'Energy\\' and a device decided to use \\'kWh\\' as unit. You set the device class in the entity description, so this is clearly not OK.\\r\\n\\r\\nYou have two choices as I see it:\\r\\n1. Don\\'t add sensors where the units are not allowed, you can use the `DEVICE_CLASS_UNITS` map for that\\r\\n2. Don\\'t set the device class in the entity description, instead add a \"suggested_device_class\" or something, which you validate (if the unit is valid make the device_class property return that, and if it isn\\'t return None) Implemented a bit of both, seems to work nicely. Whay do you think?\\r\\n\\r\\nDescription now as a suggested device_class, and will only be implemented if unit is accepted by DEVICE_CLASS_UNITS.  TBH, this is a bit filthy. The ExternalDevice list in diagnostics return a list where the unique_id\\'s are used as keys for the dict, we should hide that.\\r\\n\\r\\nBut.. This hides all the values in this list, which can be used for real diagnostics. In the meantime it seems a list is redacted recursively, which fixed this issue.  The keys seem to be natural language, whereas the existing sensors don\\'t have those kind of keys. Why is this? Have things changed upstream since your original PR? I misuse the key in device name (\"Gas meter (G0017591236671715)\"). \\r\\n\\r\\nWe now maybe can use the `name` field, but that also feels wrong. Do you maybe have a suggestion? We now allow composing entity names of a translated base and a placeholder.\\r\\nIn this case, you should set the translated name to \"Gas meter ({serial_number})\", and then set the serial_number in the `_attr_translation_placeholders`\\r\\nOr this doesn\\'t help you because you use this as base for the device name, not the entity name?\\r\\nIf that\\'s the case, maybe add a `device_name` to `HomeWizardExternalSensorEntityDescription` so you can change it later without affecting the key? Good one, picket the `device_name` works nicely! Instead of this, can you add translations? Done ðŸ‘  Why are these removed? Does it mean this is a breaking change? - total_gas_m3 is now exposed as sensor in the added device. So no breaking change expected.\\r\\n- gas_unique_id is added in the name. This value never changes (a new device is added when the gas meter is replaced). We can mark this as a breaking change but it is a small one IMO. > gas_unique_id is added in the name\\r\\n\\r\\nThat I think is not a good idea. It is not really user friendly to squash IDs into names. Besides, once renamed, you loose track of it.\\r\\n\\r\\nI would encourage to revert that change.\\r\\n\\r\\n../Frenck Change has been reverted, by adding the unique ID as sensor in the external device. No unit test has been written (yet), but it seems to work. Will do this when the rest is approved Please go ahead with the tests to show migration works Sorry, test have been added a while ago (even I forgot that). Please see `test_gas_meter_migrated()` I have the feeling this can be easier.. not sure how This is an copy what is found in entity.py, but different. Not sure how and if we can improve that.\\r\\n\\r\\n#L20-L30 Instead of adding this sensor just to show the serial number, can you add it as serial number to the device?\\r\\n#L93 That is an option? cool!\\r\\n\\r\\nI will take a quick look at that, as I think that would suggest that the P1 meter\\'s serial number is that of the gas meter. It seems this is fine, as the P1 meter itself is referenced nicely! Would this be enough instead of the sensor with this information?\\r\\n We can remove the sensor and that will be enough IMO. But as it removes the sensor, which is migrated from the original configuration, we should mark it as breaking I think. Please add code which removes the now defunct `gas_unique_id` sensor, otherwise users will still see it, but unavailable Good point! Can you hint me what function to use for that or an integration that does this? Sure, here\\'s an example #L52-L58 Nice, added removal and test. I\\'m not sold on this approch. Is there really that many different possible native units of this device per suggested device class that we can\\'t create entity descriptions for each combination? Then we could handle special cases like m3 above already in the mapping.',\n",
       " '\\r\\nPlease also change this at the rest. Only Title case, unless its a brand name or something I would suggest to rename unknown to something like `Unknown alarm` since Unknown is also a state when the sensor itself is unknown \\n',\n",
       " \"I was planning on deprecating the true/false attributes since you can figure it out fully from the operation one.  \\n\\nI would say we probably shouldn't add new ones but it won't cause a lot of database churn since they are mutually exclusive and it's best to do away with them in a future PR when we can give 6 months for users to adapt I agree that the operation should be enough.  The true/false sounds more like debug info, but for this PR I just followed the other attributes. Minor: fetch the state once instead of calling `hass.states.get()` twice Please fetch the state once instead of calling `hass.states.get()` multiple times Please fetch the state once instead of calling `hass.states.get()` multiple times Please fetch the state once instead of calling `hass.states.get()` multiple times These are used the same way in all the old tests as well.  Should I change them there at the same time, or should I leave that to another PR? It would be great to clean up the older tests in followup PR I'll do that once this is merged\",\n",
       " 'So two new entities per device here as well? Yep!',\n",
       " 'In all of the other platforms we keep the Block (Gen1) related definitions before Rpc (Gen2) definitions, this keeps easier tracking Gen1/Gen2 and is also sorted alphabetically.\\r\\n\\r\\n Good point, thanks. Same as above, better to move before `RPC_EVENT` Same, before `ShellyRpcEvent` \\r\\nI noticed during testing that this should be `description` and not `type`',\n",
       " \"Can we do a validation here like in the config flow? Just to check if we can receive data? Isn't that covered by the fact we call `await coordinator.async_config_entry_first_refresh()`? I am still getting into the core internals, I have followed `ipma` and `enphase_envoy` integration as example for the structure.\\r\\n \\r\\nI can also make the same call as in input validation of config flow, but in this case what is the way to handle errors? Hmm, I just checked some code and not every integration does this, and I think I remember this as a good practice to do. One reason I can imagine is for example auth. If someones password has changed, we don't want to start up everything and retry the old password every poll. If we can do a simple request at start to check if the credentials are valid, we can continue, if they are not, we return False and we just tell HA that the integration isn't ready but won't be coming up without user inteference (but later we might replace this with the reauth flow) Default can be omitted, everyone's network is built differently, and I would imagine that someone working with HA at least know what a host is. The reason why I considered adding the default was to provide a hint for the https port, but I will add this to the documentation, it seems a better place. I know that this is from the hassfest scaffold, but I think you can just move this into the `async_step_user` there isn't a lot of added overhead. what are we trying here? Can't we move this inside of the user_input is not None block?  why would `self.unique_id` be set at this point? you can remove this check \\r\\nLess hassle, more short :) The whole trickery you're doing here: we have something for that!\\r\\n\\r\\n`self._async_abort_entries_match({CONF_HOST: user_input[CONF_HOST])`\\r\\n\\r\\nThis will do exactly what you want You're not using host anywhere, you can omit it I use the coordinator.host as way to pass device host information, in this particular case it's used by the entity to set the device identifier. Maybe we could find a better way but I felt this way this info would be shared using the coordinator only. Do you believe this is blocker? You can remove this comment as we know :) I personally, like the added info since might be helpfull for other that are learning just like me. Any way, I am removing it as you requested. This comment is right as well, except for the fact, you don't have reauth yet. So best way is to add the initial data check in `__init__.py` like I commented before, so if the auth is invalid, we don't start the integration, but if something happened during a HA session we just keep looping (It's not nice but I think it's the best we can do) You can make this shorthand via `_attr_device_info` in the constructor Remove the empty objects IPMA ?? You're already asserting this in the entity. If you want to make sure the coordinator actually got data, use that check in `__init__.py` and prevent it to actually setup the platforms \\r\\nIs already present in EcoforestEntity this is not a test... I have followed the examples from other components such as ipma and enphase envoy, didn't entirely understood what should be changed here. You're already doing this in the entity. You can make sure the types work to declare `entity_description: EcoforestSensorEntityDescription` outside of the constructor I am learning python while doing this, so my apologies my language knowledge is limited. I tried to work around this and wasn't able to.\\r\\n\\r\\n\\r\\nWhile using this I get a ruff error with:\\r\\n\\r\\n\\r\\nand  mypy error with:\\r\\n\\r\\n\\r\\n Outside of the constructor just like in \\r\\n#L87 Is there any significance in having Room there? If we can omit that, you can remove this translation key and use the default device class translation We will have several other temperature sensors, just wanted to make it more explicit but I think it's ok to use the default.\",\n",
       " \"Wouldn't this be clearer in the intent?\\r\\n Maybe list_notifications would be clearer? Especially if I remove the force parameter. See other comment. Renamed to list_notifications I'm confused by the whole coordinator being here?\\r\\nWhy are we using a coordinator and not just fetch the latest always? Flume API has a limit of 120 queries per hour per account. We are already fetching notifications via the coordinator every 5 minutes. In fact I should remove the force parameter. One can use `homeassistant.update_entity` or even `homeassistant.reload_config_entry`.\\r\\n\\r\\nThis is quite similar to the `calendar.list_events` service that returns previously synced data and Google Calendar syncs every 15 minutes. The advantage of keeping the force parameter is it's clearer the service returns cached data and makes it easier to force fetch fresh data. I think the latter is a documentation issue.\\r\\n\\r\\nLet's remove it. We can always add it back in the future if a use case and bigger need for it raises.  Removed This doesn't need to be a coroutine function as there's no await inside. Done in  Same here. Done in \",\n",
       " 'Const shouldn\\'t be needed here.\\n\\nYou should also think about adding test for the others Give a clearer error inside config entry not ready. It\\'s typical for people to put stuff like this inside a models.py look at lookin as an example Make sure you run pre-commit, I believe this wont pass linting when checks are approved to run  I Make sure  run pre-commit.      pre-commit-config.yaml Too broad of an exception You should catch the possible errors seperately and have human readable errors inside config entry not ready re-evaluate if some of these should be private return value No need to set attr name twice \\r\\n\\r\\nself._attr_name = device.dev_name if channel == 0 else f\"{device.dev_name}-{channel}\" Also is dev_name already a str? if so no need to do a f str can just set this once with _attr_should_poll since it never changes Comment should be different than just the title of the function - you do this a few times You should only create an entry if you can confirm you can communicate with the hub Same as before - you need comments that aren\\'t just the title of the function this check isn\\'t needed. When device.channels has a len of 0 in the for loop below, it will essentially continue anyways It\\'s not really a wrapper, it\\'s a subclass. Just call it RefossSwitchEntity Seems to me like this should be debug, not info Seems to me like this should be debug, not info import this from const instead I tried to understand, but why are we storing location data? Please only have code in the try that could actually raise an issue Do we have Refoss specific exceptions we can catch? There\\'s nothing special here, only the exceptions inside the socket. I define an exception to identify the exceptions inside the socket Can be moved outside of the constructor New integrations must use `_attr_has_entity_name = True`, more info at #has_entity_name-true-mandatory-for-new-integrations Do we need this? Isn\\'t this something that should be in the library? \\r\\nThis will utilize has entity name = True better',\n",
       " \"Don't store anything in `hass.data` until after we possibly raise `ConfigEntryNotReady`. The library client should use this auth instance. It looks unused now. We just instantiate it but then don't use it.\\r\\n\\r\\nWhen the library client wants to get an access token to use, ie before every request, it should use `async_get_access_token` defined in this class. The library doesn't seem to have been updated to allow this. I recommend reading our library guide on how to structure the library and client:\\r\\n\\r\\n I've reworked the library according to the documentation. I actually like this approach.\\r\\nEverything works fine now except of the websocket connection. It's not possible to establish it and I don't get an error. I've tried very long, but wasn't able to get it working. Could you have a look at the library, please?\\r\\n#L371\\r\\n I don't think you should make a loop when connecting the websocket. Just have a `connect` method that connects the websocket and stores a reference to it on the client.\\r\\n\\r\\n#L148-L160\\r\\n\\r\\nThen have another method `listen` that fetches incoming messages and iterates over them and handles them. It's this method that the library user should create a background task for.\\r\\n\\r\\n#L374\\r\\n\\r\\nThe benefit of separating the `connect` and `listen` methods is that we can make sure we can connect the websocket with a timeout before we create the task that should listen for websocket messages. If we can connect the websocket the chances are high that the websocket communication will work. If we fail to connect during the timeout, we want to raise `ConfigEntryNotReady` and try again later automatically.\\r\\n\\r\\nSide notes:\\r\\n1. It looks like there's a double call to update data callbacks:\\r\\n#L380-381\\r\\n#L342\\r\\n\\r\\n2. I'd remove the schedule immediately parameter. The library user can call the callback themselves if needed.\\r\\n#L74 If we create a `connect` method in the library for the websocket, there should also be a `disconnect` method for the websocket. There is now a `close` method Is the token and user id optional? If we know that the key is in the dict, we should use `dict[key]` and not `dict.get(key)`. No, it's not optional. I changed it. Is the user id friendly for the user to read? If so, we could use that as title to let them distinguish between config entries. It's not user friendly. But we can get some user information out of the JWT and make an individual for each config entry. See:\\r\\n I looked at the library. It currently doesn't consistently use the aiohttp client session that is provided when instantiating the abstract auth class. The library should use that provided client session for all requests made. It's ok to create a default aiohttp client session if no session is provided by the library user.\\r\\n\\r\\nI also suggest dropping or making optional the task that gets the status. The library user can do that. In Home Assistant we can use the update coordinator here to do that.\\r\\n\\r\\nWe can also use the coordinator and set updated data when the websocket callbacks with updated data. There's this coordinator method:\\r\\n\\r\\n#L400-L402\\r\\n\\r\\nThen we can remove the callback registration from the entities, and just do that in the coordinator instead. The coordinator will update all coordinator entities when the coordinator is updated.\\r\\n\\r\\nI also suggest being consistent in the library with exceptions and logging.\\r\\n\\r\\n- Debug logging is always ok.\\r\\n- Errors that happen in non background tasks are preferably raised as library specific exceptions and not logged. Let the library user decide how to handle the error and if they want to log it.\\r\\n- In background tasks raised exceptions are not as useful, unless we make sure that the library user can handle the exception. One way to do that is to let the library user create and handle the task, ie just make a coroutine method that listens for the websocket messages and let the library user create the task for that. This way the library user can easier react to exceptions and decide how to handle them, eg re-connecting with a backoff, like what is done when Home Assistant raises `ConfigEntryNotReady`. We also need to clean up running tasks on Home Assistant stop event. Search for `EVENT_HOMEASSISTANT_STOP` for examples. These dataclasses should not be in Home Assistant but in the library. Why do we set it to empty string? I'd not use empty string to mean something in the library. I suggest making a helper method on the `mower` class in the library that takes `ws_data` and updates the mower attributes. But then I would have to pass the polled data from the coordinator to the library. Wouldn't that be too complicated, without a real benefit? No, I suggest we pass the websocket update data, ie the `MowerData` instance  to a method on the existing stored `MowerData` instance. The benefit is that the library takes care of the details of how to apply the updated websocket data.\\r\\n\\r\\nAlternatively since the library already stores the `MowerData` instances on the client, the websocket could update them directly and just let the library user know which mower was updated.\\r\\n\\r\\nAlso, I suggest storing the `MowerData` instances in a dict instead of a list, if the `id` of the mower data instance is unique. That way we can easily look up a specific mower data instance if we have the id. Okay, got it. If this just stores the callback reference, we probably don't need to do it after every connect call, but just once for the coordinator. Or is the callback unregistered if the connection is lost? Please raise `HomeAssistantError` with the message as exception argument instead of logging the message.\\r\\n\\r\\nThe message will show in the frontend.\\r\\n\\r\\n#silver- The large data constants can be stored as JSON files in a `fixtures` directory under this integration tests. We have helpers to load fixture files.\\r\\n\\r\\n#L470-L494\\r\\n\\r\\n Please don't interact directly with the coordinator or any entities in tests. Those are integrations details. Set up the integration while patching the client library appropriately and assert core state.\\r\\n\\r\\n#writing-tests-for-integrations I've changed some of the tests in this file. Can you tell me, if this is going in the right direction? We shouldn't need to patch all these details. Why are we enabling the socket? Remove all these.\\r\\n Looks like loading the fixture, making the mowers list and setting up the integration should be three different pytest fixtures. Loading the fixture should be scoped to the test session so it's not done more than once.\",\n",
       " \"If you short circuit out here if there is no configuration, will it remove existing entries if you completely removed the config? It looks like it would leave those intact. The existing config  remains intact in case of failure here. That is similar to the implementations in the `Rest`,  and `HomeKit` components.\\r\\nI believe if all entities are removed, the root domain would still be present in the configuration, so removal of all entities should be fine.\\r\\n\\r\\nThough I doubt the necesity of the suppression here. Just because the same pattern is used in homekit does not mean it's correct.\\r\\n\\r\\nI agree it's expected that all services are removed if `rest_command` is removed from the configuration, and I think that should be the case also for rest. It should remove all the services but not the reload service itself.\\r\\n\\r\\nThe pattern exists in HomeKit and Rest so if you make a mistake, the reload service is not gone and you can still recover.  If its not actually removing the integration instance though, thats a bug Thanks @bdraco ðŸ‘ \\r\\n\\r\\nThe pattern in `rest` is  different, we don't exit early if `DOMAIN not in conf`, and there's a specific test testing what happens when the `rest` configuration is removed: `test_reload_and_remove_all` - everything is cleaned up.\\r\\n\\r\\nWhat's happening in this PR looks like a bug because the services won't be removed. Oh, it looks like this was intended. Is this standard practice already? Not sure if standard practice, but copied from / inspired by the `Rest`, and `HomeKit` components. \\r\\n\\r\\n This pattern is used in mqtt, but I'm not sure it's wanted. `async_integration_yaml_config` returns `None` if the configuration can't be parsed, for example if there's a yaml syntax error.\\r\\n\\r\\nI think it's better to return early if `async_integration_yaml_config` returns `None` and otherwise clean up. I mean something like this:\\r\\n\",\n",
       " 'Can anyone point me in the right direction to test the service calls? I\\'m getting `pytest_socket.SocketBlockedError: A test tried to use socket.socket.` errors and from looking at other components I don\\'t see what I\\'m missing...  Can be removed as validation is done by the schema \\r\\nWe should raise when a user inserted date is invalid \\r\\n\\r\\nThe library sets it default to True and we should keep it for constistency. We should remove the type \"all\" as two requests must be made, one for gas and one for energy.\\r\\nIf the user really wants both prices, the service should be called twice. We should add a hint for user, what happen if the date is omitted. I think it\\'s a good practice to make these fields constants `ATTR_*` I have my doubts about BTW, as it\\'s a very dutch term (although energyzero is also a dutch thing). Would you still mind to change it to `taxes`? or just VAT? However, I also use `incl_btw` as a parameter in the package, which is on my list to change this month. Oh right, that is the english term \\r\\n\\r\\nA user doesnt have to know what a datetime is. Can you make these parametrize return partial dicts? \\r\\n\\r\\nfor example\\r\\n In here you can do `data |= incl_btw` Reason behind this is that we want to avoid branches in tests so we don\\'t test a \"maybe\" Can we rename the attribute as well?',\n",
       " 'Can it be this list is empty? If that is the case may we should only add `ClimateEntityFeature.FAN_MODE` if the list is populated. I added a conditional in `supported_features`. Now `ClimateEntityFeature.FAN_MODE` will only apply if the list is not empty. Is the debug message correct here? Updated, thanks! \\r\\nWe should only set this attribute if we enable the feature Instead of a property, can we set `self._attr_supported_features` at `__init__()`? Yes - I moved it to `__init__`. Need to translate \"Circulate\" from the Resideo API to to FAN_DIFFUSE for HA mapped Need to translate from HA\\'s FAN_DIFFUSE to Resideo API\\'s \"Circulate\" There is a couple of predefined modes. If possible then use these. \\r\\n Using predefined fan modes will enable translations. mapped You could split out `KeyError` when a not existing fan_mode is requested and log a clear error message. added The default value is `None` and not needed to add. fixed changed',\n",
       " \"What do we do if OFF is NOT in the HVAC modes?\\r\\n\\r\\nThe existing `async_turn_off` does nothing in that case, but I think we should add a `ClimateEntityFeature.TURN_OFF` flag which is automatically set if either `HVACMode.OFF in self.hvac_modes` or either of `async_toggle` or `toggle` are overridden / implemented. @emontnemery should we perhaps make a preliminary PR to implement it for the existing `turn_off` before adding on this? I'm not opposed to extending the turn_off functionality, but I do think it deserves its own PR.\\r\\nThis PR is intentionally narrow, its focus is to just provide more consistency, where if the climate has both turn_on and turn_off, it follows that it should have toggle as well.\\r\\nMaking turn_off function better is in my view orthogonal to this, and can be done later if the decision to pursue it is made. > What do we do if OFF is NOT in the HVAC modes?\\r\\n\\r\\nWe raise and fail the service, as discussed. If an integration want to implement a better version of the toggle service, they are free to do so. Agreed it should have it's own architecture issue + PR ðŸ‘ \\r\\n\\r\\nArchitecture issue: \\r\\nPR:  We could also have a base implementation in the base class, maybe that makes it more clear it can be extended?\\r\\n\\r\\n I think that in general we should promote the async pattern more and consider the sync versions more of a legacy thing, so I would be rather against this change.\\r\\nAlso the current async_turn_on and async_turn_off use the same pattern, so if this was changed, those two probably should as well. > I think that in general we should promote the async pattern more and consider the sync versions more of a legacy thing, so I would be rather against this change.\\r\\n\\r\\nThat's not really the case. The sync version is needed to integrate with 3rd party libraries which do not themselves use `asyncio` An alternative is to do the same implementation as `ToggleEntity`:\\r\\n\\r\\n This seems like a valid assumption, we should document `turn_off`, `turn_on` and `toggle` here  and for turn_off mention the HVAC mode should be set to `HVACMode.Off` Do you agree with #discussion_r1353410885? If so, I could add something like that to the docs. Why do we need to allow overriding these, can't we make them `@final`? Integrations interact with devices that often have some form of native TOGGLE command, it then might make sense to use it to the integration author, instead of relying on checking state and then sending TURN_ON or TURN_OFF.\\r\\n\\r\\nAs for the achieved functionality, you are right that it probably should never be actually necessary to override it. But the exact same argument applies to `async_turn_off`. There is an obvious use case for overriding `async_turn_on`, namely if your device provides a way to turn on without explicitly setting mode of operation (usually setting the one it had before being turned off). But there is no obvious necessity to ever override `async_turn_off` - its operation should be the same as setting mode to `HVACMode.OFF`, which is exactly what our base implementation does already.\\r\\n\\r\\nThe only reason I see someone might need to override `async_turn_off` is when they are dealing with some very weird device, that does not technically support turning off, but kind of does. For instance a device that only supports two modes: `[HVACMode.COOL, HVACMode.FAN_ONLY]`. It might make sense then to interpret the second one as a sort of pseudo-off. And then you would need to override `async_turn_off` and `async_toggle` as well. In general overriding `async_toggle` seems to be actually necessary in exactly the same (extremely rare) situations where overriding `async_turn_off` is necessary. So if we were to make those functions final, we should do the exact same to TURN_OFF.\\r\\n\\r\\nAnd I feel like both are unnecessarily restrictive to integrations authors, while providing negligible benefits in general. Like I said the main reason to allow overriding is to more closely mirror in code what actual devices are typically supporting, and toggle seems like a common enough functionality.  So to sum up, I think our advice for a typical climate integration should be:\\r\\n\\r\\n- Override (async or sync) `turn_on` if your device supports native TURN_ON. Make sure that `hvac_mode` will (eventually) be correct as well.\\r\\n\\r\\n- Override (async or sync) `turn_off` if your device supports native TURN_OFF. Make sure to set `hvac_mode` to `HVACMode.Off`. In `set_hvac_mode` make sure setting it to `HVACMode.Off` does the exact same thing (probably you can just call `turn_off` from there).\\r\\n\\r\\n- Override (async or sync) `toggle` if your device supports native TOGGLE. In that case make sure that TURN_ON and TURN_OFF are supported as well. OK, this makes sense.\\r\\nCan you please open and link to a PR of  which explains this? Let's explain this:\\r\\n Instead of adding this, and the corresponding helper to detect if turn off is supported, I'd suggest we wait for  and then rebase this PR to use the new feature flags. Does that seem OK @arturpragacz ? What do you think about doing the reverse, that is merge this first and then use those helpers for the checking in  ? That would make no sense as we should use the feature flags so I would then have to remove these checks in the other PR. \\nAnyhow it's shortly finished so you don't need to wait long to finalize. ðŸ‘  @gjohansson-ST You would use exactly those checks to set the flags for the back compat. And then use the flags themselves for everything else.\",\n",
       " 'Good catch, changed !! to be honest I actually thought your change would yield a boolean as result. \\r\\nYou can do the same here missed that done, but in a slightly different manner, that at least to me adds less confusion. This is also on option, the only difference is that it will alway evaluate `entry.get(CONF_DEVICE_ADDRESS, 0)` even when it is not used. The `or` method will go on if there was a result. \\r\\nWill only evaluate `entry.get(CONF_DEVICE_ADDRESS, 0)` when so slave is set. Which is correct, since they are defined as being exclusive in __init__.py\\r\\n I am not saying the statement is in correct, but only that is more efficient using `or` Changed to your way, I have no strong feelings about \"or\" or the other. Thnx!',\n",
       " 'Could use the `or` operator here too. Of course, done, good that you are awake ðŸ˜„ ',\n",
       " 'What is the definition of \"is_not_full\" vs. \"is_not_empty\", they seems like duplicates, and surely will give cause to a lot of confusion.\\r\\n\\r\\nI am used to having \"is_between\" which means neither \"empty\" nor \"full\".',\n",
       " '@klaasnicolaas I know this has been originally removed from the integration: #discussion_r1059137921\\r\\n\\r\\n~~Maybe by adding a new sensor that has the price in a JSON encoded string?~~ There is a limit of 255 chars for a sensor value, so we can\\'t use that.\\r\\n\\r\\nSo the only way to add the prices is through the attributes. This seems pretty vital information if you want any form of graph with prices for the day.  Careful here. The string `\"false\"` is considered a truthy value and would pass `if incl_btw:` It is typed a string and a \"feature\" of ',\n",
       " 'Only store in hass.data once you are sure the integration is going to set up Please remove items that aren\\'t supported yet. They can be added in the future if/when they become supported Please use address instead of name\\r\\n\\r\\n#unique-id-requirements I assume this was copied from airthings-ble\\r\\n\\r\\n Actually, the name of the device contains the MAC address, so I think this meets the requirements for unique IDs, doesn\\'t it? I\\'ll ensure that if \"identifier\" is not defined, then address is used as a fallback. Don\\'t use the name because if the name changes the unique id will change and than all the entities will get recreated.\\r\\n\\r\\nYou don\\'t need to include the domain or platform because they are already considered for the unique id.\\r\\n\\r\\n`{mac}_{key}` is a good stable unique id Updated! Is `self._attr_unique_id` supposed to end up being the entity\\'s unique ID ? Or is it just one of the parameters used to determine the eventual unique_id ? The full unique id is handled by the entity registry #L423 You can access this directly there is no need to make a copy since its not being mutated We generally don\\'t want to reference other unrelated integrations in comments since they can change and than the comments would be wrong Use `@pytest.mark.parametrize` instead Do you have pointers on doing this? There are a lot of config flow tests that use this already\\r\\n`git grep \\'pytest.mark.parametrize\\' tests/components/*/test_config_flow.py`\\r\\n \\r\\n\\r\\nPlease remove all unused code `StateType` can likely be narrowed since there is currently only one sensor I was thinking this would be more flexible if I add support for other devices that support more sensor types? Otherwise I can definitely narrow down to `Float` for now... While its good to be thinking ahead, we want the code to reflect the current state of things. We can always change it or make it more flexible later if its not an architectural or foundational code block.  See below - there are also USB/Serial devices made by Medcom, hence the `_ble` integration \\r\\n\\r\\nUnless there is plans on adding non-BLE devices we should use `medcom` since the namespace is available.\\r\\n\\r\\nWe only postfix when there is a namespace conflict Medcom also makes non-BLE devices - USB or serial connected - which is why I used the suffix. So far it\\'s better to use two different integrations for BLE and non-BLE devices even of the same brand, correct? Should be fine to leave the `domain` as-is but I\\'d call the title `Medcom Bluetooth` since most users won\\'t know what BLE is  Is this better as far as using `@pytest.mark.parametrize` is concerned ? Yes, but you don\\'t need to `parametrize` `MEDCOM_SERVICE_INFO` since its always the same It doesn\\'t look like you need parametrize here since you only have on set of data #r1334759367',\n",
       " '',\n",
       " \"You can use Syrupy for a nice way of testing an tracking changes :) Checkout the youtube diagnostic test. You can use that code and then execute `pytest ./tests/components/twinkly/ --snapshot-update` and it will create snapshots I have tried to wrap my head around that, but I am just not getting it.  I guess I don't know all the inner workings of HA well enough...\\r\\nThere is a problem here:\\r\\n\\r\\n#L31-L34\\r\\n\\r\\nSince the ID is auto-generated every time, and `device_name` is set to `id` the snapshots will differ.\\r\\n\\r\\nNow, I don't know why the device_name and entity_id is supposed to be different for each test, but it will be a showstopper for this... \\r\\n I am able to fix this, but that requires some minor changes to some of the other tests as well.  Hope that does not block the PR.  Will be fixed. Thanks. Fixed How did I miss that.  Thanks again. We can redact this in one go:\\r\\n\\r\\n\",\n",
       " \"Remove removed: e7101c1066926b3da1a08c578a4567dea0c5c87e These could be constants changed to constant: 34198d314c5750a8c545234375076f33fe346e83 These look unused?  removed: 0234b0301391e9dc0f955df46698b47f9fe47f47 How often are these used? I'd suggest putting them where they are used if its only one file. Personally helpers and utils files are in general are bad pattern.  removed helpers.py and moved the functions to the correct files: 81ed50a29d91d1ecd71c489f258095868d2fd4ce Remove zeroconf and ssdp removed: 30ec2044247e56aff10994d90b8929b423284e29 Remove\\r\\n Seeing lots of strings thst should be consts Changed some of the strings to constants. I left some strings that I think make sense since it's a dict key. If they all need to be constants I could change it.. b552bbe1e811f3c05c66f2ee5b6b454484d83e08 sorrry, this changed in another commit again which also contains some other changes. c5edcf87c7a1a20bf4b95b3fca4bd16a5505cf72 Remove this file removed en.json: 243a89757b309dbf67ebbc1486d08d9ed833da82 Change back undid the changes to scripts/setup: 59e9c6c5e1dca46513101088e55753e00c73ced9 I believe this should be `UnitOfPower.KILO_WATT` instead. changed unit to kW changed unit to kW I believe this should be `SensorDeviceClass.POWER` instead. also changed to power instead of energy We should include the unit of our HA sensor in `schedule_input` and deal with it in the client. I opened  for this. I don't think we should add variables that will not be used for the API call to the client functions. I've made a pull request to the fm client to add the unit conversion as a static method: \\r\\n\\r\\nIn the integration the return values can be converted using this method.  Okay. But just to note that, at some point, the API *will* accept the unit field. I think it is even in the API documentation already (but it might be broken in API v3, whereas older API versions have been sunset). I don't think you need to exclude these from coverage, they will be covered just by importing them? What's this for? It doesn't seem to be used? The integration only allows a single config entry, we don't need to index by config entry id here. Also, this is stored, but doesn't seem to be used? This dict is created but never used, please remove it\",\n",
       " \"do we need to update before add if we're doing a `first_refresh` of the coordinator in `__init__.py`? Removed. I think you may want `enter` here.\\r\\n\\r\\n Why do we set a unique id if we only allow one config entry? And the inverse question, why only allow one config entry if we can set a unique id? Second question first: I first set this up with a unique id then saw the service call adds tasks without referencing a config entry or entity, and so that looked like a problem.\\n(The config entry however does reference a project name, so it could be possible perhaps to infer but that seemed sketchy).\\n\\nFirst question: However, I thought it might be possible to add more config entries in the future if the service changes or is deprecated so I left the unique id. I didn't think it hurts, is there a down side?\\n\\nAs we talk through, I also realize this could potentially be updated in the future to support re-auth updating the API key so maybe this isn't a valid in unique id.  I was thinking of it like an oauth client id but realize how it's not really like than. Given that, perhaps needs to be removed anyway. I'm not sure what, then, could be a unique id but theoretically I'd like this to be able to support multiple accounts since once the service is fixed there's no big reason it couldn't otherwise.\\n\\n Ok. Yeah, I don't think token is a good unique_id since we want to be able to re-authenticate without changing unique_id.\\r\\n\\r\\nI'd migrate the service to an entity service. The service call targets a specific project which equals an entity, right? Then we don't need to worry about unique_id for the config entry for the sake of the service. Will remove the unique id...\\n\\nYeah entity service sounds right. When I did the same thing for Google calendar, it needed to be a new service with a new name etc and s deprecation period before removal of the old service? That is, it can't be immediately moved.\\n\\nI'm thinking here that using a new Todo entity service may work...\\n\\nAm I thinking about that right or is there a shortcut? Yeah, it will need to be a new service so we can keep the old one around and create a repair issue when the old service is called, telling users to use the new service instead. The entity service will require an entity target so we can't reuse the old service name if we want old service calls to still work.\",\n",
       " \"We don't allow changes to this part of the code as it belongs in a 3rd party library. It's protocol details.\",\n",
       " \"This would remove any current elevation.\\r\\nShould be changed so parameter is only set if service call data includes elevation Don't think we need to update config data twice.\\r\\nCheck first and then call `async_update` once. I would move this assertion before line 308 and modify it slightly:\\r\\n\\r\\n\\r\\nNow, we can assert here that the elevation was not changed if we don't set it.\\r\\n Done, thanks. \\n Shouldn't we use a number selector in `box` mode with step `any`?\\r\\n\\r\\n#number-selector\\r\\n\\r\\nSame goes for the latitude and longitude, where we can also set min and max values. See \",\n",
       " \"This code should be updated to exclude disabled components and capabilities. Why is this conditional statement necessary? All of this logic, including the check for `disabledComponents` and `disabledCapabilities` should be moved inside `broker.get_assigned`. This method, and the supporting logic should be modified to operate on a component. That's actually how I started, but it turned out to be a large refactor and I moved to this method instead. But I'll give it another go. Is this conditional line needed? I think status data for main is only on the primary status object, not nested in the component status objects, therefore we need to branch every time we try to fetch the current status.\\r\\n\\r\\nAlternately, we could modify the base library further to refactor how the main component stores it's statuses, but that is a breaking change.\",\n",
       " 'Could be better at the top Config flow needs 100% test coverage Not used, should be removed Removed Why adding an handler ? Removed Creating your own DataUpdateCoodrinator will avoid adding fetch logic in your `__init__.py`',\n",
       " \"Done Are these the only options octoprint is supporting? Yup \\r\\n\\r\\nAs there are fewer config_entries for a device, this should be quicker. Done Imo the command is wrong. I assume it's from a copy paste  Done I don't see this as a showstopper for this PR. Unless there's some coding standard this violates for HA. This should be a `ServiceValidationError`, ideally with a tranlsation in strings.json explaining what went wrong.\\r\\n\\r\\nLike this:\\r\\n#L305-L311\",\n",
       " 'Please first create the coordinator, then execute the first refresh, only then you may add it to the hass object. Only having `async_unload_entry` as function should be enough to enable reloading the integration so you can remove this one \\r\\nauth... what? We want to avoid having people set names themselves in new integrations/config flows and are slowly removing it in current integrations as well. People can set the name by renaming the device and or config entry. \\r\\nDoesn\\'t really need to be private imo Instead of name you could use the coordinates as name We like our config entry data structures flat, so it should flat out the CONF_LOCATION so the latitude and longitude are on the same level as the rest Can these be made constants or moved to the library? (not sure whats best here) This could be already initialized above This would trigger a reauth flow, but you don\\'t have any. Can we check if we can actually get data in the `__init__.py`\\'s `async_setup_entry` and raise the ConfigEntryAuthFailed there? \\r\\nOnly if \"Apple Team\" is a brand, otherwise ignore This can be a shorthand attribute in the constructor `_attr_unique_id = ...` New integrations must use `has_entity_name = True`. My advice would be to add `_attr_has_entity_name = True`, add a device (service) (without a name) and then set `_attr_name = None`. Check IPMA for an example. This way the name of the config entry is used as name for the entity, so if someone changes the config entry name, they automatically get their weather renamed #has_entity_name-true-mandatory-for-new-integrations Idem Idem Consider adding tests as they reduce the amount of regressions It would be cleaner to put the data in the coordinator so you only have to pass around one object You could make a \\r\\n\\r\\n\\r\\n\\r\\nThan you can replace all the `self.coordinator.data` calls with `self.data`\\r\\n\\r\\nIts a tiny bit slower but makes all the properties a lot more readable You might also want something that like this to avoid writing out all the currentWeather gets\\r\\n\\r\\n',\n",
       " \"Why dont you make this a separate binary sensor? Is this the last ring? Shouldn't that be an event entity? Binary sensor?\",\n",
       " 'Unused Can you maybe elaborate why you chose to initialise the coordinator here? A coordinator is usually used for having one central place for updates for multiple platforms. In this case I don\\'t really see a point of using a data update coordinator here unless you give some context I can create a better opinion on how to use it  My brain is too childish for this\\n\\n\\n\\n \\n Please add typing New entities should use `has_entity_name = True`. Please check developer docs -> entity for more info. Remind me to post a link to it. Static, can be moved outside of the constructor Please use a better name Can this return None? This can be a short hand attribute `_attr_device_info` Please use the DeviceInfo object Where is the `\"logger\"`? This is a small function, you can integrate this into the stel itself Never raised Title is always static, why do we get it from info when we already know the answer Data schema is one field, can be moved here Not used Not used  Please use `CONF_API_KEY` from homeassistsnt.const Config flow should have 100% test coverage',\n",
       " \"\\r\\nNo need for this line \\r\\nand add the entity to strings\\r\\n\\r\\nI believe this is the correct way to do this.\\r\\n\\r\\ne.g \\r\\n I've removed the `translation_key`. Because the mower (as main entity) should just have the name of the device. And there is no translation required.\\r\\n`_attr_has_entity_name = True` is already in `entity.py` Please move this to `coordinator.py` I am not sure how at this point, but want to mention it, I think this is data that should be in the entry itself, I'll have a second look later. If you're missing a scope, wouldn't starting a reauth with the new token work better? General thing, I think having all this session setup code would be better in the `async_setup_entry` and then pass the session to the coordinator. TimeoutErrors from asyncio are already catched in the data update coordiantor Why would a general Exception cause a reauth? Wouldn't having no internet trigger this (as that raises a CannotConnect error or something along those lines) That should raise `UpdateFailed` instead. \\r\\nI mean that's the whole point of setdefault ;) What could raise? \\r\\nIn the YouTube integration I did not get any errors for this, so maybe your env isn't fully set up, or you forgot to remove this :) \\r\\nShouldn't need this If possible, let's move reauth to a follow up PR so we can focus on the rest and make it as small as possible. The reauth still might need some work when looking at logging in with the right account (for example, you create the config with account A, and reauth with acount B). But let's keep that out of scope for now, and instead of ConfigEntryAuthFailed, just raise ConfigEntryNotReady for the time being \\r\\nThis will raise an issue if the unique_id is already set. This way you can't login twice with the same account. You can merge this step with the step above as there is no real reason to split it out \\r\\nWe don't need this anymore as core will be the issue tracker to go :) \\r\\nWe love a well typed integration <3 Why do we actually use a number to differentiate on the mowers? Could we maybe use some mower id instead? This way it's an property and can be accessed with `self.mower_attributes`\",\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_comments_review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "963e52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, TextGeneration\n",
    "# KeyBERT\n",
    "keybert_model = KeyBERTInspired()\n",
    "\n",
    "\n",
    "# MMR\n",
    "mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "\n",
    "# System prompt describes information given to all conversations\n",
    "system_prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics.\n",
    "<</SYS>>\n",
    "\"\"\"\n",
    "main_prompt = \"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = \"\"\"\n",
    "I have a topic that contains the following documents:\n",
    "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
    "- Meat, but especially beef, is the word food in terms of emissions.\n",
    "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
    "\n",
    "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "\n",
    "[/INST] Environmental impacts of eating meat\n",
    "\"\"\"\n",
    "\n",
    "prompt = system_prompt+ example_prompt + main_prompt\n",
    "\n",
    "\n",
    "llama2 = TextGeneration(generator, prompt=prompt)\n",
    "representation_model = {\n",
    "    \"Llama2\": llama2,\n",
    "    \"MMR\": mmr_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab59d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64681d402f8740b4bb9be938eb993534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "df['processed_comments_review'] = df['processed_comments_review'].apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "embeddings_30k = embedding_model.encode(df['processed_comments_review'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be4ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "umap_model_30k = UMAP(n_neighbors=5, n_components=4, min_dist=0., metric='cosine', random_state=42)\n",
    "hdbscan_model_30k = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f58372b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 16:13:11,910 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-02-02 16:13:18,803 - BERTopic - Dimensionality - Completed âœ“\n",
      "2025-02-02 16:13:18,804 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-02-02 16:13:18,875 - BERTopic - Cluster - Completed âœ“\n",
      "2025-02-02 16:13:18,876 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      " 11%|â–ˆ         | 6/56 [02:08<21:13, 25.46s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      " 18%|â–ˆâ–Š        | 10/56 [05:17<24:18, 31.71s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 25\u001b[0m\n\u001b[0;32m      9\u001b[0m topic_model_30k \u001b[38;5;241m=\u001b[39m BERTopic(\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m   \u001b[38;5;66;03m# Sub-models\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m   verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m topics_30k, probs_30k \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model_30k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed_comments_review\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_30k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(topics_30k[:\u001b[38;5;241m10\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bertopic\\_bertopic.py:493\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[1;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_representative_docs(custom_documents)\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# Extract topics by calculating c-TF-IDF\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# Reduce topics\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics:\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bertopic\\_bertopic.py:3991\u001b[0m, in \u001b[0;36mBERTopic._extract_topics\u001b[1;34m(self, documents, embeddings, mappings, verbose)\u001b[0m\n\u001b[0;32m   3989\u001b[0m documents_per_topic \u001b[38;5;241m=\u001b[39m documents\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m], as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin})\n\u001b[0;32m   3990\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_tf_idf_, words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_tf_idf(documents_per_topic)\n\u001b[1;32m-> 3991\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_representations_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_words_per_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_topic_vectors(documents\u001b[38;5;241m=\u001b[39mdocuments, embeddings\u001b[38;5;241m=\u001b[39membeddings, mappings\u001b[38;5;241m=\u001b[39mmappings)\n\u001b[0;32m   3993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bertopic\\_bertopic.py:4327\u001b[0m, in \u001b[0;36mBERTopic._extract_words_per_topic\u001b[1;34m(self, words, documents, c_tf_idf, calculate_aspects)\u001b[0m\n\u001b[0;32m   4325\u001b[0m         aspects \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mextract_topics(\u001b[38;5;28mself\u001b[39m, documents, c_tf_idf, aspects)\n\u001b[0;32m   4326\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(aspect_model, BaseRepresentation):\n\u001b[1;32m-> 4327\u001b[0m     aspects \u001b[38;5;241m=\u001b[39m \u001b[43maspect_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_tf_idf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(aspect_model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for representation_model[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(aspect)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4331\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bertopic\\representation\\_textgeneration.py:156\u001b[0m, in \u001b[0;36mTextGeneration.extract_topics\u001b[1;34m(self, topic_model, documents, c_tf_idf, topics)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts_\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Extract result from generator and use that as label\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m topic_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m topic_description \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    158\u001b[0m     (description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m description \u001b[38;5;129;01min\u001b[39;00m topic_description\n\u001b[0;32m    159\u001b[0m ]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(topic_description) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:285\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1362\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1356\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         )\n\u001b[0;32m   1360\u001b[0m     )\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1369\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1368\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1369\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1370\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1269\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1268\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1269\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:383\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    381\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 383\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2252\u001b[0m     )\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2275\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:3243\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3240\u001b[0m         model_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_compiled_call(generation_config\u001b[38;5;241m.\u001b[39mcompile_config)\n\u001b[0;32m   3242\u001b[0m is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 3243\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_peer_finished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\n\u001b[0;32m   3245\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   3246\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[0;32m   3247\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   3249\u001b[0m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:2453\u001b[0m, in \u001b[0;36mGenerationMixin._has_unfinished_sequences\u001b[1;34m(self, this_peer_finished, synced_gpus, device, cur_len, max_length)\u001b[0m\n\u001b[0;32m   2451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m this_peer_finished_flag\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   2452\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import nltk\n",
    "from bertopic.vectorizers import ClassTfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "topic_model_30k = BERTopic(\n",
    "\n",
    "  # Sub-models\n",
    "  embedding_model=embedding_model,\n",
    "  umap_model=umap_model_30k,\n",
    "  hdbscan_model=hdbscan_model_30k,\n",
    "  vectorizer_model=vectorizer_model,\n",
    "  ctfidf_model=ctfidf_model,\n",
    "  representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "topics_30k, probs_30k = topic_model_30k.fit_transform(df['processed_comments_review'].tolist(), embeddings_30k)\n",
    "print(topics_30k[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdfad582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Llama2</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>-1_section_wanted_appreciation_express</td>\n",
       "      <td>[section, wanted, appreciation, express, seria...</td>\n",
       "      <td>[Serialization of configuration sections, , , ...</td>\n",
       "      <td>[section, wanted, appreciation, express, seria...</td>\n",
       "      <td>[\\n, , The other day I tried to serialize a vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3211</td>\n",
       "      <td>0_use_think_don_just</td>\n",
       "      <td>[use, think, don, just, need, device, entity, ...</td>\n",
       "      <td>[\\nEnvironmental impacts of eating, but with t...</td>\n",
       "      <td>[need, device, change, code, config, integrati...</td>\n",
       "      <td>[Let's define this as a `namedtuple` to make i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1_sneak_tessie_teslemetry_walrus</td>\n",
       "      <td>[sneak, tessie, teslemetry, walrus, forget, sp...</td>\n",
       "      <td>[Sneaky Walrus Reverts, , , , , , , , , ]</td>\n",
       "      <td>[sneak, tessie, teslemetry, walrus, speed, rev...</td>\n",
       "      <td>[, \\r\\nDon't forget the walrus!, What entity d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2_decision_configuration_integration_yaml</td>\n",
       "      <td>[decision, configuration, integration, yaml, a...</td>\n",
       "      <td>[Integration Refactoring Required, , , , , , ,...</td>\n",
       "      <td>[decision, yaml, adr, flow, config, pr, change...</td>\n",
       "      <td>[We no longer allow integrations to add or cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                       Name  \\\n",
       "0     -1     17     -1_section_wanted_appreciation_express   \n",
       "1      0   3211                       0_use_think_don_just   \n",
       "2      1     95           1_sneak_tessie_teslemetry_walrus   \n",
       "3      2     66  2_decision_configuration_integration_yaml   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [section, wanted, appreciation, express, seria...   \n",
       "1  [use, think, don, just, need, device, entity, ...   \n",
       "2  [sneak, tessie, teslemetry, walrus, forget, sp...   \n",
       "3  [decision, configuration, integration, yaml, a...   \n",
       "\n",
       "                                              Llama2  \\\n",
       "0  [Serialization of configuration sections, , , ...   \n",
       "1  [\\nEnvironmental impacts of eating, but with t...   \n",
       "2          [Sneaky Walrus Reverts, , , , , , , , , ]   \n",
       "3  [Integration Refactoring Required, , , , , , ,...   \n",
       "\n",
       "                                                 MMR  \\\n",
       "0  [section, wanted, appreciation, express, seria...   \n",
       "1  [need, device, change, code, config, integrati...   \n",
       "2  [sneak, tessie, teslemetry, walrus, speed, rev...   \n",
       "3  [decision, yaml, adr, flow, config, pr, change...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [\\n, , The other day I tried to serialize a vo...  \n",
       "1  [Let's define this as a `namedtuple` to make i...  \n",
       "2  [, \\r\\nDon't forget the walrus!, What entity d...  \n",
       "3  [We no longer allow integrations to add or cha...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "if False:\n",
    "    df = pd.DataFrame(topic_model_30k.get_topic_info())\n",
    "    df.to_csv('bertopic_output_30k.csv', index=False)\n",
    "    \n",
    "# Show topics\n",
    "topic_model_30k.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329a1263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR Number</th>\n",
       "      <th>processed_comments_review</th>\n",
       "      <th>processed_comments_issue</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129755</td>\n",
       "      <td>Tests are missing. Waiting on an intents bump ...</td>\n",
       "      <td>[Why is this added to the November release mil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129675</td>\n",
       "      <td>This are glob pattern not regexes, so the {6} ...</td>\n",
       "      <td>[Do we need a docs PR here?, &gt; Do we need a do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129299</td>\n",
       "      <td>Please reduce to one platform #home-assistant-...</td>\n",
       "      <td>[I made the single PR for the whole lg_thinq i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129232</td>\n",
       "      <td>I think a few of these are bugfixes that shoul...</td>\n",
       "      <td>[There are quite a few tests which does a reau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129088</td>\n",
       "      <td>This can now be moved to a constant at the top...</td>\n",
       "      <td>[@epenet What's the advantage of `suggested_va...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128984</td>\n",
       "      <td>Can we let this function return a list instead...</td>\n",
       "      <td>[I'll add more tests once I get some feedback ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128947</td>\n",
       "      <td></td>\n",
       "      <td>[drafting for one more lib bump since the CO2 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128942</td>\n",
       "      <td>We normally only want to import from the integ...</td>\n",
       "      <td>[Your force push overwrote my commit., &gt; Your ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128919</td>\n",
       "      <td>let's make the domain `music_assistant` Hah, I...</td>\n",
       "      <td>[Small note: the coverage for config_flow.py d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128909</td>\n",
       "      <td>Are both of these exceptions realistic? When s...</td>\n",
       "      <td>[&gt; Also, I am now wondering, does `nest` suppo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128870</td>\n",
       "      <td>Is this a real value? You probably use Twitch ...</td>\n",
       "      <td>[Added tier to tests.  Tests do not currently ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128856</td>\n",
       "      <td>Please use the migrate function for this `asyn...</td>\n",
       "      <td>[Nice work @bouwew ]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128794</td>\n",
       "      <td>Please use `SnapshotAssertion` in diagnostic t...</td>\n",
       "      <td>[You can exclude those keys in the snapshot]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128789</td>\n",
       "      <td>Hi there @vingerha ðŸ‘‹ \\r\\n\\r\\nWe do not allow i...</td>\n",
       "      <td>[@exxamalte quite a while ago I asked if reduc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128547</td>\n",
       "      <td>Why didn't we implement the water_heater platf...</td>\n",
       "      <td>[This PR needs to be rebased properly.]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128455</td>\n",
       "      <td>No other data that we send to the frontend is ...</td>\n",
       "      <td>[A camera test is failing., Frontend is approv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>128452</td>\n",
       "      <td>Does this only support 1 room? Yes, it is the ...</td>\n",
       "      <td>[Not sure why the tests are failing.\\r\\n\\r\\nI ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>128432</td>\n",
       "      <td>Maybe add an enum for these strings and use th...</td>\n",
       "      <td>[Ready to merge. Frontend is approved]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128430</td>\n",
       "      <td>Single-use variable\\r\\n</td>\n",
       "      <td>[Can be merged when frontend is happy., Looks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>128365</td>\n",
       "      <td>\".HA_RESTORE\" is only here while testing, this...</td>\n",
       "      <td>[Thanks @MartinHjelmare; I _think_ I covered a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PR Number                          processed_comments_review  \\\n",
       "0      129755  Tests are missing. Waiting on an intents bump ...   \n",
       "1      129675  This are glob pattern not regexes, so the {6} ...   \n",
       "2      129299  Please reduce to one platform #home-assistant-...   \n",
       "3      129232  I think a few of these are bugfixes that shoul...   \n",
       "4      129088  This can now be moved to a constant at the top...   \n",
       "5      128984  Can we let this function return a list instead...   \n",
       "6      128947                                                      \n",
       "7      128942  We normally only want to import from the integ...   \n",
       "8      128919  let's make the domain `music_assistant` Hah, I...   \n",
       "9      128909  Are both of these exceptions realistic? When s...   \n",
       "10     128870  Is this a real value? You probably use Twitch ...   \n",
       "11     128856  Please use the migrate function for this `asyn...   \n",
       "12     128794  Please use `SnapshotAssertion` in diagnostic t...   \n",
       "13     128789  Hi there @vingerha ðŸ‘‹ \\r\\n\\r\\nWe do not allow i...   \n",
       "14     128547  Why didn't we implement the water_heater platf...   \n",
       "15     128455  No other data that we send to the frontend is ...   \n",
       "16     128452  Does this only support 1 room? Yes, it is the ...   \n",
       "17     128432  Maybe add an enum for these strings and use th...   \n",
       "18     128430                            Single-use variable\\r\\n   \n",
       "19     128365  \".HA_RESTORE\" is only here while testing, this...   \n",
       "\n",
       "                             processed_comments_issue  topic  \n",
       "0   [Why is this added to the November release mil...      0  \n",
       "1   [Do we need a docs PR here?, > Do we need a do...      0  \n",
       "2   [I made the single PR for the whole lg_thinq i...      0  \n",
       "3   [There are quite a few tests which does a reau...      0  \n",
       "4   [@epenet What's the advantage of `suggested_va...      0  \n",
       "5   [I'll add more tests once I get some feedback ...      0  \n",
       "6   [drafting for one more lib bump since the CO2 ...      1  \n",
       "7   [Your force push overwrote my commit., > Your ...      0  \n",
       "8   [Small note: the coverage for config_flow.py d...      0  \n",
       "9   [> Also, I am now wondering, does `nest` suppo...      0  \n",
       "10  [Added tier to tests.  Tests do not currently ...      0  \n",
       "11                               [Nice work @bouwew ]      0  \n",
       "12       [You can exclude those keys in the snapshot]      0  \n",
       "13  [@exxamalte quite a while ago I asked if reduc...      0  \n",
       "14            [This PR needs to be rebased properly.]      0  \n",
       "15  [A camera test is failing., Frontend is approv...      0  \n",
       "16  [Not sure why the tests are failing.\\r\\n\\r\\nI ...      0  \n",
       "17             [Ready to merge. Frontend is approved]      0  \n",
       "18  [Can be merged when frontend is happy., Looks ...      0  \n",
       "19  [Thanks @MartinHjelmare; I _think_ I covered a...      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"topic\"] = topics_30k\n",
    "df.iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92673f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1dc853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae4deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
